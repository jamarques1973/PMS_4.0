# Auto-generated from PMS 3.6.0 by PMS 4.0.0
# Section 0: root

# Artifact: exec exec_0
import pandas as pd

# Artifact: exec exec_1
import numpy as np

# Artifact: exec exec_2
import matplotlib.pyplot as plt

# Artifact: exec exec_3
import pickle, os

# Artifact: exec exec_4
from io import StringIO

# Artifact: exec exec_5
import ipywidgets as widgets

# Artifact: exec exec_6
from IPython.display import display, clear_output

# Artifact: exec exec_7
import shap

# Artifact: exec exec_8
import lime

# Artifact: exec exec_9
import lime.lime_tabular

# Artifact: exec exec_10
from keras_tuner import BayesianOptimization

# Artifact: exec exec_11
from sklearn.model_selection import KFold

# Artifact: exec exec_12
import shutil

# Artifact: exec exec_13
import time

# Artifact: exec exec_14
import threading

# Artifact: exec exec_15
from tensorflow.keras.callbacks import EarlyStopping

# Artifact: exec exec_16
from sklearn.svm import SVR

# Artifact: exec exec_17
from sklearn.preprocessing import StandardScaler

# Artifact: exec exec_18
from sklearn.metrics import mean_squared_error, r2_score

# Artifact: exec exec_19
from sklearn.model_selection import cross_val_score, KFold

# Artifact: exec exec_20
from sklearn.model_selection import train_test_split, KFold

# Artifact: exec exec_21
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Artifact: exec exec_22
import keras_tuner as kt

# Artifact: exec exec_23
import pickle

# Artifact: exec exec_24
import os

# Artifact: exec exec_25
import tensorflow as tf

# Artifact: exec exec_26
from tensorflow.keras.models import Sequential, load_model

# Artifact: exec exec_27
from tensorflow.keras.layers import Dense

# Artifact: exec exec_28
from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam, Ftrl

# Artifact: exec exec_29
from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback

# Artifact: exec exec_30
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Artifact: exec exec_31
import random

# Artifact: exec exec_32
from xgboost import XGBRegressor

# Artifact: exec exec_33
from xgboost.callback import EarlyStopping as XgbEarlyStopping

# Artifact: exec exec_34
import pkgutil

# Artifact: exec exec_35
import seaborn as sns

# Artifact: exec exec_36
from sklearn.ensemble import RandomForestRegressor

# Artifact: exec exec_37
from sklearn.feature_selection import mutual_info_regression

# Artifact: exec exec_38
import threading, time, pickle, os

# Artifact: exec exec_39
from ipywidgets import Output

# Artifact: exec exec_40
import io

# Artifact: exec exec_41
from google.colab import output

# Artifact: exec exec_42
from IPython.display import display, HTML, clear_output

# Artifact: exec exec_43
import re

# Artifact: function sanitize_name
def sanitize_name(s):
    """
    Unifica la sanitización de cualquier string de columna:
    Reemplaza espacios, puntos, comas, punto y coma, dos puntos,
    barras (/ \\), paréntesis (), corchetes [], llaves {},
    signo %, +, -, *, &, ^, $, #, @, !, ?, =, <, >, |, `, ~
    por guión bajo y colapsa múltiples guiones bajos.
    """
    # Reemplaza todo carácter no alfanumérico o guión bajo por '_'
    t = re.sub(r"[^\w]", "_", str(s))
    # Colapsa múltiples guiones bajos consecutivos
    t = re.sub(r"_+", "_", t)
    return t.strip("_")

# Artifact: assign out_carga
out_carga = widgets.Output()

# Artifact: assign out_svr
out_svr = widgets.Output()

# Artifact: assign out_nn
out_nn = widgets.Output()

# Artifact: assign out_xgb
out_xgb = widgets.Output()

# Artifact: assign out_pred
out_pred = widgets.Output()

# Artifact: assign out_graf
out_graf = widgets.Output()

# Artifact: assign out_xai
out_xai = widgets.Output()

# Artifact: assign out_bienvenida
out_bienvenida = widgets.Output()

# Artifact: assign out_ayuda
out_ayuda = widgets.Output()

# Artifact: assign out_nn_opt
out_nn_opt = widgets.Output()

# Artifact: assign stop_flag
stop_flag = threading.Event()

# Artifact: assign stop_flag_nn
stop_flag_nn = threading.Event()

# Artifact: assign out_svr_opt
out_svr_opt = widgets.Output()

# Artifact: assign stop_flag_svr
stop_flag_svr = threading.Event()

# Artifact: assign out_xgb_opt
out_xgb_opt = widgets.Output()

# Artifact: assign stop_flag_xgb
stop_flag_xgb = threading.Event()

# Artifact: assign out_rf
out_rf = widgets.Output()

# Artifact: assign rf_timer_stop_event
rf_timer_stop_event = threading.Event()

# Artifact: exec exec_63
if 'out_rnn' not in globals():
    out_rnn = widgets.Output()

# Artifact: assign ayuda_visible
ayuda_visible = [False]

# Artifact: exec exec_65
output.enable_custom_widget_manager()

# Artifact: function mostrar_ayuda_completa
def mostrar_ayuda_completa() -> None:
    """
    Despliega la ayuda global, dividida en 4 bloques:

    Bloque 1 → Carga, Segmentación y Selección de Variables
    Bloque 2 → Entrenamiento y Visualización de Modelos
    Bloque 3 → Optimización Multicapa (SVR, NN, XGB, RF, RNN)
    Bloque 4 → Interpretabilidad xIA, Navegación y Menú Principal

    Cada bloque se explica en profundidad con texto, tablas e
    imágenes incrustadas (generadas al vuelo).  El usuario puede
    cambiar de bloque pulsando los botones de navegación.
    """

    # -----------------------------------------------
    #  util_img_blocks.py  ·  4 generadores de imagen
    # -----------------------------------------------
    import matplotlib.pyplot as plt
    from matplotlib.patches import FancyArrowPatch, Rectangle
    import numpy as np, io, base64, textwrap, itertools, random
    from IPython.display import display, HTML, clear_output

    # ──────────────────────────────────────────
    def _fig_to_b64(fig) -> str:
        "Convierte una figura matplotlib en cadena base64"
        buf = io.BytesIO()
        fig.savefig(buf, format="png", bbox_inches="tight", dpi=140)
        plt.close(fig); buf.seek(0)
        return base64.b64encode(buf.read()).decode()

    # ──────────────────────────────────────────
    # BLOQUE 1  ·  Tubo de carga → split → selección
    def _img_block1() -> str:
        fig, ax = plt.subplots(figsize=(6, 2))
        ax.axis("off")

        # 1) CSV/Excel
        ax.add_patch(Rectangle((0.05, .25), .18, .5, fc="#f0f8ff", ec="#4682b4", lw=1.5))
        ax.text(.14, .5, "Excel/CSV", ha="center", va="center", weight="bold")

        # 2) DataFrame
        ax.add_patch(Rectangle((.30, .25), .18, .5, fc="#e6ffe6", ec="#2e8b57", lw=1.5))
        ax.text(.39, .5, "DataFrame\n(pandas)", ha="center", va="center")

        # 3) Train/Test
        ax.add_patch(Rectangle((.55, .45), .18, .3, fc="#fff4e6", ec="#ff8c00", lw=1.5))
        ax.text(.64, .60, "Train", ha="center", va="center", size=8)
        ax.add_patch(Rectangle((.55, .25), .18, .15, fc="#ffe6e6", ec="#d80027", lw=1.5))
        ax.text(.64, .325, "Test", ha="center", va="center", size=8)

        # 4) Selección de variables (nodos pequeños)
        methods = ["Pearson", "Mutual\nInfo", "Boruta", "UMAP"]
        for i, m in enumerate(methods):
            x = .82; y = .6 - i*0.15
            ax.add_patch(Rectangle((x, y), .13, .1, fc="#fafafa", ec="#555", lw=1))
            ax.text(x+.065, y+.05, m, ha="center", va="center", size=7)

        # Flechas
        def arrow(xy1, xy2):
            ax.add_patch(FancyArrowPatch(xy1, xy2, arrowstyle="->", lw=1, color="#444"))
        arrow((.23, .5), (.30, .5))
        arrow((.48, .5), (.55, .5))
        arrow((.73, .5), (.82, .55))
        arrow((.73, .5), (.82, .4))
        arrow((.73, .5), (.82, .25))
        fig.suptitle("Pipeline Bloque 1", fontweight="bold")
        return _fig_to_b64(fig)

    # ──────────────────────────────────────────
    # BLOQUE 2  ·  Comparativa de desempeño de modelos
    def _img_block2() -> str:
        models = ["SVR", "NN", "XGB", "RF", "RNN"]
        scores = [0.82, 0.88, 0.91, 0.86, 0.84]  # ejemplo R²
        fig, ax = plt.subplots(figsize=(5, 3))
        bars = ax.bar(models, scores, color="#4c9be8")
        ax.set_ylim(0, 1.0)
        ax.set_ylabel("R² en Test")
        ax.set_title("Rendimiento modelos (ejemplo)")
        for b, s in zip(bars, scores):
            ax.text(b.get_x() + b.get_width()/2, s+0.02, f"{s:.2f}", ha="center", va="bottom", size=8)
        return _fig_to_b64(fig)

    # ──────────────────────────────────────────
    # BLOQUE 3  ·  Convergencia de búsqueda HPO
    def _img_block3() -> str:
        fig, ax = plt.subplots(figsize=(5.5, 3))
        n_iter = 30
        # curva “score” ficticia para 3 técnicas
        rng = np.random.RandomState(0)
        for label, c in zip(("GridSearch", "BayesSearch", "Optuna"), ("#999", "#2e8b57", "#d62728")):
            best_so_far = np.maximum.accumulate(rng.uniform(.5, .9, n_iter))
            ax.plot(range(1, n_iter+1), best_so_far, label=label, lw=1.8, color=c)
        ax.set_xlabel("Iteración")
        ax.set_ylabel("Score acumulado (R²)")
        ax.set_title("Evolución búsqueda de hiperparámetros")
        ax.legend(frameon=False, fontsize=8)
        return _fig_to_b64(fig)

    # ──────────────────────────────────────────
    # BLOQUE 4  ·  Mini-summary de interpretabilidad (SHAP simulado)
    def _img_block4() -> str:
        feats = ["X1", "X2", "X3", "X4", "X5"]
        shap_vals = np.array([0.4, -0.35, 0.25, -0.15, 0.05])
        colors = ['#d62728' if v<0 else '#2ca02c' for v in shap_vals]
        fig, ax = plt.subplots(figsize=(4.5, 3))
        ax.barh(feats, shap_vals, color=colors)
        ax.axvline(0, color="#444", lw=0.8)
        ax.set_xlabel("Valor SHAP (impacto en la predicción)")
        ax.set_title("Contribución de variables (ejemplo)")
        plt.tight_layout()
        return _fig_to_b64(fig)

    # ----------------------------------------------------------
    # 1️⃣  TEXTOS DE AYUDA  (puedes ampliarlos todo lo que quieras)
    #     — Cada bloque es un gran HTML con títulos, listas,
    #       tablas <table>, imágenes <img>…
    # ----------------------------------------------------------
    bloque1_html = HTML(f"""
    <h3 style='color:#2E8B57;'>🟢 Bloque 1 – Carga, segmentación y selección de variables</h3>
    <p><b>Objetivo:</b> transformar hojas Excel o .csv en matrices <code>X</code> (predictoras) y
    <code>Y</code> (objetivo).</p>

    <h4>📥 Carga de datos</h4>
    <ul>
      <li>Importación directa desde área de transferencia (<i>copy–paste</i> de Excel) o desde fichero.</li>
      <li>Validación de encabezados, tipos y <code>NaN</code>.</li>
      <li>Ejemplo rápido:<br>
      <code>X, Y = cargar_desde_clipboard(sep='\\t')</code></li>
    </ul>

    <h4>🧩 Segmentación Train/Test</h4>
    <ul>
      <li>División estratificada opcional (<i>stratify=Y</i> cuando <code>Y</code> es discreta).</li>
      <li>Seed reproducible (<code>random_state=42</code>).</li>
      <li>Visualización: tabla de tamaños y gráfico “barra apilada” para comparar distribución de
          objetivos.</li>
    </ul>

    <h4>🔍 Selección de variables <i>X</i></h4>
    <table>
    <thead><tr><th>Método</th><th>Descripción resumida</th><th>Métrica interna</th></tr></thead>
    <tbody>
    <tr><td>Pearson / Spearman</td><td>Descarta colinealidad lineal / monótona</td><td>|ρ| &gt; τ</td></tr>
    <tr><td>Mutual Info</td><td>Información mutua no-lineal</td><td>MI &gt; τ</td></tr>
    <tr><td>Boruta</td><td>Selección envolvente basada en RF</td><td>Importancia &gt; shadow</td></tr>
    <tr><td>UMAP</td><td>Reducción de dimensión no lineal (embedding)</td><td>Varianza retenida</td></tr>
    </tbody></table>

    <p><i>Resultado:</i> diccionario <code>RESUMEN_METODOS</code> con el subconjunto de columnas
    aprobado por cada técnica.</p>
    <<img src="data:image/png;base64,{_img_block1()}"  ></td></tr>>
    """)

    bloque2_html = HTML(f"""
    <h3 style='color:#1E90FF;'>🔵 Bloque 2 – Entrenamiento y visualización de modelos</h3>
    <p>Incluye:</p>
    <ul>
      <li><b>SVR</b> (kernels lineal / RBF)</li>
      <li><b>Red Neuronal densa</b> (Keras/TensorFlow)</li>
      <li><b>XGBoost</b> (regresión)</li>
      <li><b>Random Forest</b> (sklearn)</li>
      <li><b>RNN</b> / LSTM para series temporales</li>
    </ul>

    <h4>Flujo de trabajo general</h4>
    <ol>
      <li>Escalado (<code>StandardScaler</code>) de <code>X</code> y <code>Y</code>.</li>
      <li>Entrenamiento con <code>X_train</code>, evaluación con <code>X_test</code>.</li>
      <li>Métricas trazadas: R², MSE, RMSE, MAE, MedAE.</li>
      <li>Gráficos:
        <ul>
            <li>Y real vs Y predicho (scatter y línea)</li>
            <li>Residuos: histograma + Q–Q + <i>residual vs fitted</i></li>
        </ul>
      </li>
    </ol>

    <h4>Ejemplo mínimo – SVR RBF</h4>
    <pre>
    svr = SVR(kernel='rbf', C=10, epsilon=0.1, gamma='scale')
    svr.fit(X_train_scaled, y_train_scaled)
    pred = scaler_y.inverse_transform(svr.predict(X_test_scaled).reshape(-1,1))
    </pre>
    <img src="data:image/png;base64,{_img_block2()}"  ></td></tr>
    """)

    bloque3_html = HTML(f"""
    <h3 style='color:#FFA500;'>🟠 Bloque 3 – Optimización multicapa (HPO)</h3>
    <p>Se soportan cinco motores por tipo de modelo:</p>
    <ul>
      <li><b>GridSearchCV</b></li>
      <li><b>RandomizedSearchCV</b></li>
      <li><b>BayesSearchCV</b> (scikit-optimize)</li>
      <li><b>Optuna</b></li>
      <li><b>Hyperband / HalvingSearchCV</b></li>
    </ul>

    <table>
    <thead><tr><th>Modelo</th><th>Espacio de búsqueda ⊂ ℝⁿ</th><th>Trials por defecto</th></tr></thead>
    <tbody>
    <tr><td>SVR</td><td>C, ε, kernel</td><td>30</td></tr>
    <tr><td>Neural Net</td><td>#capas, neuronas, LR, dropout, ℓ₂</td><td>50</td></tr>
    <tr><td>XGBoost</td><td>depth, lr, n_estim, γ, subsample…</td><td>100</td></tr>
    <tr><td>Random Forest</td><td>n_estim, depth, mtry, bootstrap…</td><td>70</td></tr>
    <tr><td>RNN</td><td>units, batch, epochs, LR</td><td>50</td></tr>
    </tbody></table>

    <p>Cada ejecución devuelve:</p>
    <ul>
      <li>TOP-5 configuraciones (tabla ordenada)</li>
      <li>Mejor curva de predicción y residuos</li>
      <li>Heat-map de métricas normalizadas + Radar chart</li>
    </ul>
    <img src="data:image/png;base64,{_img_block3()}"  ></td></tr>
    """)

    bloque4_html = HTML(f"""
    <h3 style='color:#8A2BE2;'>🟣 Bloque 4 – Interpretabilidad xIA &amp; Navegación</h3>
    <p>El módulo integra <b>14</b> técnicas:</p>
    <ol>
      <li>SHAP (Tree / Kernel / Deep)</li>
      <li>LIME (tabular)</li>
      <li>KernelExplainer (SHAP caja negra)</li>
      <li>Integrated Gradients</li>
      <li>DeepLIFT / LRP</li>
      <li>Permutation Feature Importance</li>
      <li>Partial Dependence Plots (PDP)</li>
      <li>Accumulated Local Effects (ALE)</li>
      <li>ICE plots</li>
      <li>Counterfactual Explainer</li>
      <li>Anchors (árboles locales)</li>
      <li>Modelos sustitutos (árbol global + líneas locales)</li>
      <li>Explainable Boosting Machine (EBM)</li>
      <li>Optuna Hyper-parameter Importance</li>
    </ol>

    <p>Para cada técnica se generan:</p>
    <ul>
      <li>Gráfico principal (summary, barras, scatter…)</li>
      <li>Tabla local (primeras 10 muestras)</li>
      <li>Tabla de importancia global</li>
      <li>Bloque de interpretación con <i>tips</i> y lectura guiada</li>
    </ul>
    <img src="data:image/png;base64,{_img_block4()}"  ></td></tr>
    <p><i>Consejo:</i> combina SHAP + PDP + Permutation para tener una visión 360°: explicaciones locales,
    efecto medio y robustez de cada variable.</p>
    """)

    # ───────────────────────────────────────────────────────────
    # Botones + enlace a callback
    # ————————————————————————————————————————
    # ----------------------------------------------------------
    # 2️⃣  ÁREA DE SALIDA (visible a todas las funciones)
    # ----------------------------------------------------------
    _help_output = widgets.Output()

    # ----------------------------------------------------------
    # 3️⃣  RENDER FUNCTIONS (deben existir ANTES de .on_click)
    # ----------------------------------------------------------
    def _render_bloque_1(*_):
        _help_output.clear_output()
        with _help_output:
            display(bloque1_html)

    def _render_bloque_2(*_):
        _help_output.clear_output()
        with _help_output:
            display(bloque2_html)

    def _render_bloque_3(*_):
        _help_output.clear_output()
        with _help_output:
            display(bloque3_html)

    def _render_bloque_4(*_):
        _help_output.clear_output()
        with _help_output:
            display(bloque4_html)

    # ----------------------------------------------------------
    # 4️⃣  BOTONES  (creados DESPUÉS de las funciones)
    # ----------------------------------------------------------
    btn_b1 = widgets.Button(description="ℹ️ Bloque 1 – DATOS",           button_style='info')
    btn_b2 = widgets.Button(description="ℹ️ Bloque 2 – ENTRENAMIENTO",   button_style='info')
    btn_b3 = widgets.Button(description="ℹ️ Bloque 3 – OPTIMIZACIÓN",    button_style='info')
    btn_b4 = widgets.Button(description="ℹ️ Bloque 4 – INTERPRETABILIDAD", button_style='info')

    # Enlazar callbacks  (ya no produce NameError)
    btn_b1.on_click(_render_bloque_1)
    btn_b2.on_click(_render_bloque_2)
    btn_b3.on_click(_render_bloque_3)
    btn_b4.on_click(_render_bloque_4)

    # ----------------------------------------------------------
    # 5️⃣  INTERFAZ – se muestra la cabecera + botones + área
    # ----------------------------------------------------------
    display(
        widgets.VBox([
            widgets.HTML("<h2 style='color:#1E90FF;'>📘 AYUDA GLOBAL — Guía Completa de la Aplicación</h2>"),
            widgets.HTML("<p>Selecciona el bloque sobre el que necesitas información detallada.</p>"),
            widgets.HBox([btn_b1, btn_b2, btn_b3, btn_b4]),
            _help_output
        ])
    )

# Artifact: exec exec_67
import io, base64, numpy as np, matplotlib.pyplot as plt

# Artifact: function _fig_to_b64
def _fig_to_b64(fig):
    """Devuelve la figura matplotlib codificada en base-64 (PNG)."""
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight", dpi=130)
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode()

# Artifact: function _block2_img_training_prediction
def _block2_img_training_prediction():
    fig, ax = plt.subplots(figsize=(6.2, 1.0))
    ax.axis("off")
    boxes = [
        ("ENTRENAMIENTO", "#e6ffe6", "#2e8b57"),
        ("VALIDACIÓN",    "#fffbd5", "#ff8c00"),
        ("PREDICCIÓN",    "#d6e0ff", "#4169e1")
    ]
    xs = [.02, .36, .70]
    for x, (txt, fc, ec) in zip(xs, boxes):
        ax.annotate(
            txt, (x, .5), ha="left", va="center",
            bbox=dict(fc=fc, ec=ec, lw=1.4, boxstyle="round,pad=0.28"))
    for x in [.28, .62]:
        ax.annotate(
            "", xy=(x+.03, .5), xytext=(x-.03,.5),
            arrowprops=dict(arrowstyle="->", lw=1.5))
    ax.set_xlim(0, 1); ax.set_ylim(0, 1)
    return _fig_to_b64(fig)

# Artifact: function _img_flow_trainpred
def _img_flow_trainpred():
    fig, ax = plt.subplots(figsize=(4.5, .9)); ax.axis("off")
    ax.annotate("Bloque 1\nCarga, \nSegmentacion y \nSelección", (.05,.5), va="center",
                bbox=dict(fc="#f0f8ff", ec="#4682b4"))
    ax.annotate("Bloque 2\nEntrenamiento, \nPredicción y \nComparación IA", (.55,.5), va="center",
                bbox=dict(fc="#e6ffe6", ec="#2e8b57"))
    ax.annotate("", xy=(.43,.5), xytext=(.33,.5),
                arrowprops=dict(arrowstyle="->", lw=1.6))
    ax.set_xlim(0,1); ax.set_ylim(0,1)
    return _fig_to_b64(fig)

# Artifact: function _img_flow_opt
def _img_flow_opt():
    fig, ax = plt.subplots(figsize=(5.2, .9)); ax.axis("off")
    ax.annotate("Bloque 1\nCarga, \nSegmentacion y \nSelección", (.05,.5), va="center",
                bbox=dict(fc="#f0f8ff", ec="#4682b4"))
    ax.annotate("Bloque 3\nOptimización \nModelos \nde IA", (.55,.5), va="center",
                bbox=dict(fc="#fff4e6", ec="#ff8c00"))
    ax.annotate("", xy=(.43,.5), xytext=(.33,.5),
                arrowprops=dict(arrowstyle="->", lw=1.6))
    ax.set_xlim(0,1); ax.set_ylim(0,1)
    return _fig_to_b64(fig)

# Artifact: function _img_flow_xai
def _img_flow_xai():
    fig, ax = plt.subplots(figsize=(6.8, .9)); ax.axis("off")
    xs = [.03,.29,.55,.80]
    labels  = ["Bloque 1\nCarga, \nSegmentacion y \nSelección","Bloque 2\nEntrenamiento, \nPredicción y \nComparación IA","Bloque 3\nOptimización \nModelos \nde IA","Bloque 4\nExplicación \nModelos \nde IA"]
    fcs     = ["#f0f8ff","#e6ffe6","#fff4e6","#fde2ff"]
    frames  = ["#4682b4","#2e8b57","#ff8c00","#ba55d3"]
    for x,l,fc,ec in zip(xs, labels, fcs, frames):
        ax.annotate(l, (x,.5), va="center",
                    bbox=dict(fc=fc, ec=ec))
    for x in [.21,.47,.72]:
        ax.annotate("", xy=(x+.05,.5), xytext=(x-.05,.5),
                    arrowprops=dict(arrowstyle="->", lw=1.6))
    ax.set_xlim(0,1); ax.set_ylim(0,1)
    return _fig_to_b64(fig)

# Artifact: function mostrar_bienvenida
def mostrar_bienvenida():
    """Pantalla de bienvenida profesional con itinerarios y accesos rápidos."""
    clear_output(wait=True)

    html_intro = HTML(f"""
    <style>
      .pms h1   {{font-family:'Segoe UI',Roboto,sans-serif;font-size:1.95rem;margin:.2em 0}}
      .pms h2   {{font-size:1.15rem;color:#2E8B57;margin:.8em 0 .3em}}
      .pms h3   {{font-size:1.05rem;margin:1.0em 0 .5em}}
      .pms p, .pms li {{font-size:.95rem;line-height:1.55em}}
      .pms .flow img {{border:1px solid #d0d0d0;border-radius:6px}}
      .pms ul   {{margin-top:.2em;margin-bottom:1em}}
    </style>

    <div class='pms'>

      <h1>🚀 Pipeline Modeling Suite (PMS)</h1>
      <p><em>Entorno interactivo «pasta-y-ejecuta» para ciencia de datos end-to-end:
         desde la preparación de datos hasta la explicación xAI.</em></p>

      <!-- ▸▸ ITINERARIO 1: ENTRENAR + PREDICCIONES -->
      <h2>Itinerarios sugeridos de uso</h2>

      <h3>🧪 Entrenar <b>y predecir</b> &nbsp;(<i>Bloques 1 → 2</i>)</h3>
      <div class='flow'><img src="data:image/png;base64,{_img_flow_trainpred()}" /></div>
      <ul>
        <li><b>Funcionalidades Bloque 1 - Carga, segmentación y selección:</b></li>
        <li><b>📥 Cargar Datos:</b> pegar o cargar X&nbsp;/ Y desde Excel/CSV.</li>
        <li><b>🔀 Segmentar:</b> Train / Test (<code>stratify</code> opcional).</li>
        <li><b>🔍 Seleccionar Variables:</b> Pearson, Spearman, Mutual Info, Boruta, UMAP.</li>
      </ul>
        <li><b>Funcionalidades Bloque 2 - Entrenamiento, predicción y comparación de modelos de IA:</b></li>
        <li><b>🤖 Entrenar SVR:</b> SVR (Support Vector Regression) es un algoritmo de aprendizaje supervisado que busca predecir valores continuos ajustando una función que mantenga los errores dentro de un margen tolerable (épsilon) y maximizando la generalización del modelo.</li>
        <li><b>🧠 Entrenar NN:</b> Una red neuronal (NN) es un modelo de aprendizaje automático inspirado en el cerebro humano, compuesto por capas de nodos interconectados que procesan datos para reconocer patrones y hacer predicciones.</li>
        <li><b>🌲 Entrenar XGBoost:</b> Algoritmo de aprendizaje automático basado en árboles de decisión que utiliza técnicas de gradiente boosting para lograr alta precisión y eficiencia en tareas de clasificación y regresión. </li>
        <li><b>🌳 Entrenar Random Forest.</b> Algoritmo de aprendizaje automático basado en conjuntos que construye múltiples árboles de decisión y combina sus predicciones para mejorar la precisión y reducir el sobreajuste. </li>
        <li><b>🔁 Entrenar RNN:</b> La Red Neuronal Recurrente (RNN)) es un tipo de red neuronal diseñada para procesar secuencias de datos, donde cada salida depende no solo de la entrada actual sino también del estado anterior, lo que la hace ideal para tareas como series temporales, texto o audio</li>
        <li><b>📈 Predicción con modelos SVR, NN, XGBoostm RandomForest y RNN:</b> compara Y-real vs Y-predicho, residuos y curvas.</li>
        <li><b>📊 Comparador:</b> ranking métrico y visual entre modelos.</li>
      </ul>
      <div style="margin-bottom:1em;text-align:center">
        <img src="data:image/png;base64,{_block2_img_training_prediction()}" />
        <div style="font-size:.86rem;margin-top:.3em;color:#555">
          Flujo interno de Bloque 2: entrenamiento → validación → <b>predicción</b>
        </div>
      </div>

      <!-- ▸▸ ITINERARIO 2: OPTIMIZAR -->
      <h3>⚙️ Optimizar modelos &nbsp;(<i>Bloques 1 → 3</i>)</h3>
      <div class='flow'><img src="data:image/png;base64,{_img_flow_opt()}" /></div>
      <ul>
        <li><b>Funcionalidades Bloque 3 - Optimización de Modelos de Inteligencia Artificial:</b></li>
        <li><b>🔧 Optimizar SVR:</b> Grid, Random, Optuna, BayesSearch.</li>
        <li><b>⚙️ Optimizar NN:</b> RandomSearch, Bayesian, Hyperband, Optuna.</li>
        <li><b>🔩 Optimizar XGB:</b> RandomSearch, Bayesian, Hyperband, Optuna.</li>
        <li><b>🌳⚙️ Optimizar RF:</b> RandomSearch, Bayesian, Hyperband, Optuna.</li>
        <li><b>🔁 Optimizar RNN:</b> RandomSearch, Bayesian, Hyperband, Optuna.</li>
      </ul>

      <!-- ▸▸ ITINERARIO 3: EXPLICAR -->
      <h3>🧠 Explicar modelos &nbsp;(<i>Bloques 1 → 2 → 3 → 4</i>)</h3>
      <div class='flow'><img src="data:image/png;base64,{_img_flow_xai()}" /></div>
      <ul>
        <li><b>Funcionalidades Bloque 4 - Inteligencia Artificial Explicativa xIA:</b></li>
        <li><b>📝 SHAP, LIME, KernelExplainer.</b></li>
        <li><b>📈 PDP, ALE, ICE.</b></li>
        <li><b>🧭 Surrogate Models &amp; Anchors.</b></li>
        <li><b>💠 EBM, Contrafactuales.</b></li>
      </ul>
    """)

    # Muestra el HTML + botones
    display(html_intro)

# Artifact: exec exec_74
from IPython.display import display, clear_output, HTML

# Artifact: assign X_data,Y_data,FECHAS,y_variable_name
X_data, Y_data, FECHAS, y_variable_name = None, None, None, None

# Artifact: function mostrar_carga
def mostrar_carga(b=None):
    out_carga.clear_output()

    text_X = widgets.Textarea(
        placeholder='Pega aquí la matriz X desde Excel (sin índice).',
        layout=widgets.Layout(width='100%', height='150px')
    )
    text_Y = widgets.Textarea(
        placeholder='Pega aquí la matriz Y (una o más columnas).',
        layout=widgets.Layout(width='100%', height='100px')
    )
    text_F = widgets.Textarea(
        placeholder='Pega aquí la columna de fechas (una sola columna con encabezado).',
        layout=widgets.Layout(width='100%', height='100px')
    )

    boton_importar = widgets.Button(description="📥 Importar Datos", button_style='success')
    salida = widgets.Output()

    def importar_datos(_):
        salida.clear_output()
        global X_data, Y_data, FECHAS, y_variable_name

        try:
            # ------------------ Matriz X ------------------
            X = pd.read_csv(io.StringIO(text_X.value.strip()), sep='\t', header=0)
            X = X.apply(lambda col: col.str.replace(',', '.', regex=False) if col.dtype == 'object' else col)
            X = X.apply(pd.to_numeric, errors='raise')

            # ------------------ Matriz Y ------------------
            Y = pd.read_csv(io.StringIO(text_Y.value.strip()), sep='\t', header=0)
            Y = Y.apply(lambda col: col.str.replace(',', '.', regex=False) if col.dtype == 'object' else col)
            Y = Y.apply(pd.to_numeric, errors='raise')
            y_variable_name = ', '.join(Y.columns) if Y.shape[1] > 1 else Y.columns[0]

            # ------------------ Columna de Fechas ------------------
            raw_text = text_F.value.strip()
            F = pd.read_csv(io.StringIO(raw_text), sep='\t', header=0)
            if F.shape[1] != 1:
                raise ValueError("❌ La columna de fechas debe tener solo una columna.")

            fecha_raw = F.iloc[:, 0].astype(str).str.strip()
            FECHAS = pd.to_datetime(fecha_raw, errors='coerce', format="%Y-%m-%d %H:%M")

            if FECHAS.isna().sum() > 0:
                display(HTML("<b style='color:red;'>❌ Estas son las fechas no reconocidas:</b>"))
                display(pd.DataFrame({"Fecha original": fecha_raw[FECHAS.isna()]}))
                raise ValueError("❌ Algunas fechas no se pudieron interpretar. Revisa el formato o caracteres ocultos.")

            # ------------------ Validar dimensiones ------------------
            if not (len(X) == len(Y) == len(FECHAS)):
                raise ValueError(f"❌ Dimensiones incompatibles: X({len(X)}), Y({len(Y)}), Fechas({len(FECHAS)})")

            # ------------------ Guardar ------------------
            X_data = X.copy()
            Y_data = Y.copy()
            mostrar_estadisticas_datos()  # ← Añadir esta línea al final

            display(HTML("<b style='color:green;'>✅ Datos cargados correctamente.</b>"))
            mostrar_estadisticas_datos()

        except Exception as e:
            display(HTML(f"<span style='color:red;'>❌ Error al importar: {str(e)}</span>"))

    boton_importar.on_click(importar_datos)

    with out_carga:
        display(HTML("<h3>📥 Carga de Datos</h3>"))
        display(widgets.VBox([
            widgets.Label("🔷 Matriz X (variables predictoras):"), text_X,
            widgets.Label("🔶 Matriz Y (variable/s a predecir):"), text_Y,
            widgets.Label("🕒 Columna de Fechas (una sola columna):"), text_F,
            boton_importar, salida
        ]))

    # ✅ Mostrar el output
    display(out_carga)

# Artifact: function mostrar_estadisticas_datos
def mostrar_estadisticas_datos():
    with out_carga:
        try:
            display(HTML("<h3>📊 Estadísticas de los Datos Cargados</h3>"))

            # Estadísticas de X
            if X_data is not None:
                display(HTML("<h4>📈 Estadísticas de X (Variables Independientes):</h4>"))
                display(X_data.describe(include='all').T.style.set_caption("Resumen Estadístico de X").format(precision=3))

            # Estadísticas de Y
            if Y_data is not None:
                display(HTML("<h4>🎯 Estadísticas de Y (Variable Objetivo):</h4>"))
                display(Y_data.describe(include='all').T.style.set_caption("Resumen Estadístico de Y").format(precision=3))

            # Estadísticas de Fechas
            if FECHAS is not None and not FECHAS.isna().all():
                display(HTML("<h4>📅 Estadísticas de Fechas:</h4>"))
                display(pd.DataFrame({
                    'Primera fecha': [FECHAS.min()],
                    'Última fecha': [FECHAS.max()],
                    'Total registros': [len(FECHAS)],
                    'Frecuencia media (días)': [FECHAS.diff().dt.total_seconds().dropna().mean() / 86400]
                }).T.rename(columns={0: 'Valor'}))

        except Exception as e:
            display(HTML(f"<span style='color:red;'>❌ Error al mostrar estadísticas: {str(e)}</span>"))

# Artifact: exec exec_78
from IPython.display import display, HTML, Javascript, clear_output

# Artifact: exec exec_79
from sklearn.model_selection import train_test_split

# Artifact: assign out_split
out_split = widgets.Output()

# Artifact: function mostrar_split
def mostrar_split(event=None):
    clear_output(wait=True)           # 🔁 Borra todo lo visible antes de pintar de nuevo
#    out_split.clear_output()          # 🔁 Borra lo que había dentro del widget
    with out_split:
        #out_split.clear_output()
        # Validar que los datos estén cargados
        if 'X_data' not in globals() or 'Y_data' not in globals():
            print("❌ Debes cargar primero los datos (X_data, Y_data)")
            return
        X = X_data.copy()
        Y = Y_data.copy()

        # Título e instrucciones
        display(HTML("<h3 style='color:#2E8B57;'>🔀 Filtrado de Datos para Train/Test</h3>"))
        print("Configura el split de tu dataset (recomendado test_size=0.2, random_state=42)")

        # Controles de usuario
        test_size = widgets.FloatSlider(
            value=0.2, min=0.05, max=0.5, step=0.05,
            description='test_size:', tooltip='reserva el % de filas para test'
        )
        random_state = widgets.BoundedIntText(
            value=42, min=0, description='random_state:'
        )
        stratify_chk = widgets.Checkbox(
            value=False, description='Estratificar según Y'
        )
        bin_method = widgets.Dropdown(
            options=['qcut','cut'], value='qcut', description='Método bins:'
        )
        q_bins = widgets.BoundedIntText(
            value=5, min=2, max=20, description='q (bins):'
        )
        btn_split = widgets.Button(
            description='Aplicar Split', button_style='success'
        )

        display(widgets.VBox([test_size, random_state,
                              stratify_chk, bin_method, q_bins, btn_split]))

        def run_split(b):
            out_split.clear_output()      # <-- CAMBIO: borra cualquier contenido previo en out_split cuando se pulsa de nuevo
            global X_train, X_test, Y_train, Y_test, FECHAS_train, FECHAS_test
            # Preparar stratify
            stratify = None
            if stratify_chk.value:
                try:
                    # Asegurar que usamos una sola columna para la estratificación
                    if isinstance(Y, pd.DataFrame):
                        Y_strat = Y.iloc[:, 0]
                    else:
                        Y_strat = pd.Series(Y)

                    if bin_method.value == 'qcut':
                        bins = pd.qcut(Y_strat, q=q_bins.value, duplicates='drop')
                    else:
                        bins = pd.cut(Y_strat, bins=q_bins.value)
                    stratify = bins
                except Exception as e:
                    print(f"❌ Error al crear bins: {e}")
                    return

            # Realizar split
            try:
                X_train, X_test, Y_train, Y_test, FECHAS_train, FECHAS_test = train_test_split(
                    X, Y, FECHAS,
                    test_size=test_size.value,
                    random_state=random_state.value,
                    stratify=stratify if stratify_chk.value else None
                )
                # justo aquí, guardo los parámetros en globals
                global SPLIT_PARAMS                           # Nuevo desde aqui: Creado para poder generar el informe final
                SPLIT_PARAMS = {
                    "test_size": test_size.value,
                    "random_state": random_state.value,
                    "stratify": stratify_chk.value,
                    "bin_method": bin_method.value,
                    "q_bins": q_bins.value
                }                                             # Nuevo hasta aqui
            except Exception as e:
                print(f"❌ Error en train_test_split: {e}")
                return

            y_col = Y.columns[0]
            df_train = X_train.copy()
            df_train[y_col] = Y_train.values
            df_train['fecha'] = FECHAS_train.values
            df_train['set'] = 'train'

            df_test = X_test.copy()
            df_test[y_col] = Y_test.values
            df_test['fecha'] = FECHAS_test.values
            df_test['set'] = 'test'

            df_out = pd.concat([df_train, df_test], axis=0)

            # Mostrar resumen de partición
            print(f"🔹 Total registros: {len(X)}")
            print(f"🔹 Registros en Train: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)")
            print(f"🔹 Registros en Test: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)")

            # Mostrar DataFrame final
            print("📊 Resultado del split (train/test) para copiar y pegar:")
            display(df_out)

            # Botones de copia X e Y
            # Entrenamiento Y
            btn_copy_y_train = widgets.Button(
                description='📋 Copiar Y Train', icon='clipboard', button_style='info'
            )
            # Entrenamiento X
            btn_copy_x_train = widgets.Button(
                description='📋 Copiar X Train', icon='clipboard', button_style='info'
            )
            # Entrenamiento Fechas
            btn_copy_f_train = widgets.Button(
                description='📋 Copiar Fechas Train', icon='calendar', button_style='info'
            )
            # Test Y
            btn_copy_y_test = widgets.Button(
                description='📋 Copiar Y Test', icon='clipboard', button_style='info'
            )
            # Test X
            btn_copy_x_test = widgets.Button(
                description='📋 Copiar X Test', icon='clipboard', button_style='info'
            )
            # Test Fechas
            btn_copy_f_test = widgets.Button(
                description='📋 Copiar Fechas Test', icon='calendar', button_style='info'
            )
            msg_train_y = widgets.Output()
            msg_train_x = widgets.Output()
            msg_test_y = widgets.Output()
            msg_test_x = widgets.Output()
            msg_f_train = widgets.Output()
            msg_f_test = widgets.Output()

            def copy_y_train(_):
                try:
                    Y_train.to_frame() .to_clipboard(index=False)
                    with msg_train_y:
                        display(HTML("<span style='color:green;'>✅ Y Train copiada</span>"))
                except Exception:
                    csv = Y_train.to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_train_y:
                        display(HTML("<span style='color:green;'>✅ Y Train copiada via JS</span>"))
            def copy_x_train(_):
                try:
                    df_train.drop(columns=[Y.name,'set']).to_clipboard(index=False)
                    with msg_train_x:
                        display(HTML("<span style='color:green;'>✅ X Train copiada</span>"))
                except Exception:
                    csv = df_train.drop(columns=[Y.name,'set']).to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_train_x:
                        display(HTML("<span style='color:green;'>✅ X Train copiada via JS</span>"))
            def copy_f_train(_):
                try:
                    FECHAS.iloc[X_train.index].to_frame().to_clipboard(index=False)
                    with msg_f_train:
                        msg_f_train.clear_output()
                        display(HTML("<span style='color:green;'>✅ Fechas Train copiadas</span>"))
                except Exception:
                    csv = FECHAS.iloc[X_train.index].to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_f_train:
                        msg_f_train.clear_output()
                        display(HTML("<span style='color:green;'>✅ Fechas Train copiadas vía JS</span>"))

            def copy_y_test(_):
                try:
                    Y_test.to_frame().to_clipboard(index=False)
                    with msg_test_y:
                        display(HTML("<span style='color:green;'>✅ Y Test copiada</span>"))
                except Exception:
                    csv = Y_test.to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_test_y:
                        display(HTML("<span style='color:green;'>✅ Y Test copiada via JS</span>"))
            def copy_x_test(_):
                try:
                    df_test.drop(columns=[Y.name,'set']).to_clipboard(index=False)
                    with msg_test_x:
                        display(HTML("<span style='color:green;'>✅ X Test copiada</span>"))
                except Exception:
                    csv = df_test.drop(columns=[Y.name,'set']).to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_test_x:
                        display(HTML("<span style='color:green;'>✅ X Test copiada via JS</span>"))
            def copy_f_test(_):
                try:
                    FECHAS.iloc[X_test.index].to_frame().to_clipboard(index=False)
                    with msg_f_test:
                        msg_f_test.clear_output()
                        display(HTML("<span style='color:green;'>✅ Fechas Test copiadas</span>"))
                except Exception:
                    csv = FECHAS.iloc[X_test.index].to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_f_test:
                        msg_f_test.clear_output()
                        display(HTML("<span style='color:green;'>✅ Fechas Test copiadas vía JS</span>"))

            btn_copy_y_train.on_click(copy_y_train)
            btn_copy_x_train.on_click(copy_x_train)
            btn_copy_f_train.on_click(copy_f_train)
            btn_copy_y_test.on_click(copy_y_test)
            btn_copy_x_test.on_click(copy_x_test)
            btn_copy_f_test.on_click(copy_f_test)

            #display(widgets.HBox([btn_copy_y_train, btn_copy_x_train, btn_copy_y_test, btn_copy_x_test]))
            display(widgets.HBox([
                btn_copy_y_train, btn_copy_x_train, btn_copy_y_test, btn_copy_x_test,
                btn_copy_f_train, btn_copy_f_test
            ]))
            #display(widgets.HBox([msg_train_y, msg_train_x, msg_test_y, msg_test_x]))
            display(widgets.HBox([
                msg_train_y, msg_train_x, msg_test_y, msg_test_x, msg_f_train, msg_f_test
            ]))

        btn_split.on_click(run_split)

    display(out_split)

# Artifact: assign BORUTA_AVAILABLE
BORUTA_AVAILABLE = pkgutil.find_loader('boruta') is not None

# Artifact: assign UMAP_AVAILABLE
UMAP_AVAILABLE   = pkgutil.find_loader('umap')   is not None

# Artifact: exec exec_84
if BORUTA_AVAILABLE:
    from boruta import BorutaPy

# Artifact: exec exec_85
if UMAP_AVAILABLE:
    import umap

# Artifact: assign _timer_stop_event
_timer_stop_event = threading.Event()

# Artifact: function _update_timer
def _update_timer(event, widget):
    start = time.time()
    while not event.is_set():
        widget.value = f"⏱️ {time.time() - start:.1f}s"
        time.sleep(0.5)

# Artifact: assign dlg_out
dlg_out = widgets.Output()

# Artifact: assign res_out
res_out = widgets.Output()

# Artifact: assign ayuda_out
ayuda_out = widgets.Output()

# Artifact: assign VARIABLES_SELECCIONADAS
VARIABLES_SELECCIONADAS = {}

# Artifact: assign METODO_SELECCION
METODO_SELECCION = ""

# Artifact: assign VALORES_CORRELACION
VALORES_CORRELACION = pd.Series(dtype=float)

# Artifact: assign RESUMEN_METODOS
RESUMEN_METODOS = {}

# Artifact: function mostrar_seleccion_variables
def mostrar_seleccion_variables(event=None):
    global X_train, Y_train
    dlg_out.clear_output()
    res_out.clear_output()
    display(dlg_out, res_out)

    with dlg_out:
        clear_output()
        if 'X_train' not in globals() or 'Y_train' not in globals():
            print("❌ Debes segmentar antes los datos (X_train, Y_train).")
            return

        X = X_train.copy()
        Y = Y_train.copy()
        if isinstance(Y, pd.DataFrame):
            Y_corr = Y.iloc[:, 0]
        else:
            Y_corr = pd.Series(Y)

        print(f"🔍 Variables disponibles: {X.shape[1]}")
        print(f"🔍 Observaciones en entrenamiento: {X.shape[0]}")

        display(HTML("<h3 style='color:#2E8B57;'>🔎 Selección de Variables</h3>"))

        ayuda_pearson = widgets.HTML("""
        <ul>
            <li><b>Umbral X–Y:</b> Selecciona las variables cuya correlación absoluta con Y supera un valor determinado.</li>
            <li><b>Valores recomendados:</b> entre 0.3 y 0.6 para evitar colinealidad excesiva.</li>
            <li><i>Pearson mide relaciones lineales.</i></li>
        </ul>
        """)
        ayuda_spearman = widgets.HTML("""
        <ul>
            <li><b>Umbral X–Y:</b> Selecciona variables con alta correlación de rangos con Y.</li>
            <li><b>Recomendado:</b> igual a Pearson (0.3 – 0.6).</li>
            <li><i>Spearman es útil para relaciones no lineales monótonas.</i></li>
        </ul>
        """)
        ayuda_mi = widgets.HTML("""
        <ul>
            <li><b>Top k MI:</b> Número de variables con mayor información mutua respecto a Y.</li>
            <li><b>Valores recomendados:</b> entre 5 y 10 para datasets medianos.</li>
            <li><i>Captura relaciones no lineales.</i></li>
        </ul>
        """)
        ayuda_boruta = widgets.HTML("""
        <ul>
            <li><b>RF est:</b> Número de árboles del bosque aleatorio. (Recomendado: ≥ 100).</li>
            <li><b>Iter BOR:</b> Iteraciones del algoritmo Boruta. (Recomendado: 50–100).</li>
            <li><b>Alpha:</b> Nivel de significancia estadística. (Recomendado: 0.01 – 0.1).</li>
            <li><i>Selecciona solo variables relevantes con base en importancia del modelo.</i></li>
        </ul>
        """)
        ayuda_umap = widgets.HTML("""
        <ul>
            <li><b>Dims UMAP:</b> Dimensiones latentes en la proyección (típicamente 2–5).</li>
            <li><b>Top k UMAP:</b> Variables con mayor correlación a las dimensiones proyectadas.</li>
            <li><i>UMAP revela estructuras no lineales complejas en los datos.</i></li>
        </ul>
        """)

        metodo = widgets.Dropdown(
            options=["Pearson", "Spearman", "MutualInfo"]
                    + (["Boruta"] if BORUTA_AVAILABLE else [])
                    + (["UMAP"] if UMAP_AVAILABLE else []),
            description='Método:'
        )
        th_xy = widgets.FloatSlider(
            value=0.1, min=0.0, max=1.0, step=0.01, description='Umbral X–Y:', readout=False
        )
        th_xy_lbl = widgets.Label(value=f"{th_xy.value:.2f}")
        def actualizar_umbral(change):
            th_xy_lbl.value = f"{change['new']:.2f}"
        th_xy.observe(actualizar_umbral, names='value')
        fila_th_xy = widgets.HBox([th_xy, th_xy_lbl])

        mi_k     = widgets.BoundedIntText(value=5, min=1, max=X.shape[1], description='Top k MI:')
        bor_n    = widgets.BoundedIntText(value=100, min=1, max=1000, description='RF est:')
        bor_iter = widgets.BoundedIntText(value=50, min=1, max=500, description='Iter BOR:')
        bor_a    = widgets.BoundedFloatText(value=0.05, min=0.0, max=1.0, description='Alpha:')
        umap_d   = widgets.BoundedIntText(value=2, min=1, max=min(10, X.shape[1]), description='Dims UMAP:')
        umap_k   = widgets.BoundedIntText(value=5, min=1, max=X.shape[1], description='Top k UMAP:')
        btn_run  = widgets.Button(description='Ejecutar', button_style='success')
        btn_resumen = widgets.Button(description='📋 Ver Resumen', button_style='info')
        timer_lbl= widgets.Label('⏱️ 0.0s')

        ayudas = {
            'Pearson': ayuda_pearson,
            'Spearman': ayuda_spearman,
            'MutualInfo': ayuda_mi,
            'Boruta': ayuda_boruta,
            'UMAP': ayuda_umap
        }

        fila_th_xy.layout.display = 'none'
        mi_k.layout.display = 'none'
        bor_n.layout.display = 'none'
        bor_iter.layout.display = 'none'
        bor_a.layout.display = 'none'
        umap_d.layout.display = 'none'
        umap_k.layout.display = 'none'

        def toggle_params(_=None):
            m = metodo.value
            corr_visible = m in ['Pearson', 'Spearman']
            fila_th_xy.layout.display = 'flex' if corr_visible else 'none'
            mi_k.layout.display     = 'block' if m == 'MutualInfo' else 'none'
            bor_n.layout.display    = 'block' if m == 'Boruta' else 'none'
            bor_iter.layout.display = 'block' if m == 'Boruta' else 'none'
            bor_a.layout.display    = 'block' if m == 'Boruta' else 'none'
            umap_d.layout.display   = 'block' if m == 'UMAP' else 'none'
            umap_k.layout.display   = 'block' if m == 'UMAP' else 'none'
            with ayuda_out:
                clear_output()
                if m in ayudas:
                    display(ayudas[m])

        metodo.observe(toggle_params, names='value')
        toggle_params()

        display(widgets.VBox([
            metodo, fila_th_xy, mi_k, bor_n, bor_iter, bor_a, umap_d, umap_k, ayuda_out, btn_run, btn_resumen, timer_lbl
        ]))

    def run_selection(_):
        global VARIABLES_SELECCIONADAS, METODO_SELECCION, VALORES_CORRELACION, RESUMEN_METODOS
        res_out.clear_output()
        _timer_stop_event.clear()
        threading.Thread(target=_update_timer, args=(_timer_stop_event, timer_lbl), daemon=True).start()

        with res_out:
            X = X_train.copy()
            Y = Y_train.copy()
            Y_corr = Y.iloc[:, 0] if isinstance(Y, pd.DataFrame) else pd.Series(Y)
            method = metodo.value
            selected = []
            correlaciones = pd.Series(dtype=float)

            if method in ['Pearson', 'Spearman']:
                correlaciones = X.apply(lambda col: col.corr(Y_corr, method=method.lower()))
                correlaciones_abs = correlaciones.abs()
                display(HTML(f"<h4>📈 Correlaciones X–Y (abs) usando <u>{method}</u>:</h4>"))
                display(correlaciones_abs.to_frame(name=f'|correlación {method}|'))
                selected = correlaciones_abs[correlaciones_abs >= th_xy.value].index.tolist()
                not_selected = correlaciones_abs[~correlaciones_abs.index.isin(selected)].index.tolist()

                if selected:
                    display(HTML(f"<h4 style='color:green;'>✅ Variables Seleccionadas ({method}, umbral ≥ {th_xy.value}):</h4>"))
                    display(correlaciones[selected].to_frame(name=f'correlación {method}').sort_values(by=f'correlación {method}', ascending=False))
                else:
                    display(HTML(f"<h4 style='color:red;'>⚠️ No se seleccionaron variables con {method} ≥ {th_xy.value}</h4>"))

                if not_selected:
                    display(HTML(f"<h4>📌 Variables No Seleccionadas ({method}):</h4>"))
                    display(correlaciones[not_selected].to_frame(name=f'correlación {method}').sort_values(by=f'correlación {method}', ascending=False))

            elif method == 'MutualInfo':
                mi = mutual_info_regression(X, Y_corr)
                correlaciones = pd.Series(mi, index=X.columns).sort_values(ascending=False)
                display(HTML('<b>Top MutualInfo:</b>'))
                display(correlaciones.head(mi_k.value).to_frame('MI'))
                selected = correlaciones.head(mi_k.value).index.tolist()

            elif method == 'Boruta' and BORUTA_AVAILABLE:
                #rf = RandomForestRegressor(n_estimators=bor_n.value, random_state=42)
                #bor = BorutaPy(rf, alpha=bor_a.value, max_iter=bor_iter.value, random_state=42)
                # ─── AÑADIDO: usar todos los cores ───
                rf = RandomForestRegressor(
                    n_estimators=bor_n.value,
                    random_state=42,
                    n_jobs=-1              # Paraleliza el entrenamiento del RF
                )
                bor = BorutaPy(
                    estimator=rf,
                    alpha=bor_a.value,
                    max_iter=bor_iter.value,
                    random_state=42,
                    verbose=2          # <–– 1 para resumen, 2 o 3 para detalle completo
                )
                bor.fit(X.values, Y_corr.values)
                support_mask = bor.support_
                correlaciones = pd.Series(bor.ranking_, index=X.columns)
                dfb = pd.DataFrame({'Feature': X.columns, 'Rank': bor.ranking_, 'Support': support_mask})
                display(HTML('<b>Ranking Boruta Top10:</b>'))
                display(dfb.sort_values('Rank').head(10))
                selected = list(X.columns[support_mask])

            elif method == 'UMAP' and UMAP_AVAILABLE:
                reducer = umap.UMAP(n_components=umap_d.value, random_state=42)
                emb = reducer.fit_transform(X)
                dfemb = pd.DataFrame(emb)
                corr = X.apply(lambda c: np.mean([abs(np.corrcoef(c, dfemb[i])[0,1]) for i in range(dfemb.shape[1])]), axis=0)
                correlaciones = corr
                display(HTML('<b>Correlación media UMAP:</b>'))
                display(correlaciones.to_frame('mean_corr'))
                selected = correlaciones.sort_values(ascending=False).head(umap_k.value).index.tolist()

            if not selected:
                print("❌ No se seleccionaron variables. Ajusta el umbral o método.")
            else:
                VARIABLES_SELECCIONADAS = selected
                METODO_SELECCION = method
                VALORES_CORRELACION = correlaciones
                RESUMEN_METODOS[method] = selected

                # ——— AÑADIDO: sanitizar nombres para que no haya corchetes, % ni espacios raros ———
                #import re
                #clean = lambda c: re.sub(r'[\[\]<>%]', '_', str(c))
                #selected = [ clean(c) for c in selected ]
                # ——— FIN AÑADIDO ———
                #RESUMEN_METODOS[method] = selected

                dfout = X[selected].copy()
                dfout[Y_corr.name] = Y_corr.values
                display(HTML('<b>Variables Seleccionadas:</b>'))
                display(dfout)
                txt = widgets.Textarea(value=dfout.drop(columns=[Y_corr.name]).to_csv(index=False),
                                       layout=widgets.Layout(width='100%', height='150px'))
                display(HTML('<b>CSV X:</b>'))
                display(txt)

        _timer_stop_event.set()

    def mostrar_resumen(b):
        with res_out:
            clear_output()
            if not RESUMEN_METODOS:
                display(HTML("<b>⚠️ No hay métodos ejecutados aún.</b>"))
            else:
                for metodo, variables in RESUMEN_METODOS.items():
                    display(HTML(f"<h4>📌 {metodo}:</h4>"))
                    display(pd.DataFrame(variables, columns=["Variables Seleccionadas"]))

    btn_run.on_click(run_selection, remove=True)
    btn_run.on_click(run_selection)
    btn_resumen.on_click(mostrar_resumen)

# Artifact: exec exec_96
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Artifact: exec exec_97
if 'out_svr' not in globals():
    out_svr = widgets.Output()

# Artifact: function mostrar_svr
def mostrar_svr(b=None):
    if b is None:
        display(out_svr)

    with out_svr:
        clear_output()

        if 'X_train' not in globals() or 'X_test' not in globals():
            display(widgets.HTML("""<span style='color:red;'>❌ Primero debes segmentar los datos en train/test.</span>"""))
            return

        # Bloque para sincronizar variables individuales a partir del resumen RESUMEN_METODOS
        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        # Widgets para configuración
        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )
        C_val = widgets.FloatLogSlider(value=1.0, base=10, min=-2, max=2, step=0.1, description='C:')
        epsilon_val = widgets.FloatLogSlider(value=0.1, base=10, min=-3, max=0, step=0.1, description='Epsilon:')
        kernel_val = widgets.Dropdown(options=['rbf', 'linear', 'poly', 'sigmoid'], value='rbf', description='Kernel:')
        gamma_val = widgets.Dropdown(options=['scale', 'auto'], description='Gamma:')

        btn_train = widgets.Button(description="🚀 Entrenar SVR", button_style='success')
        output_area = widgets.Output()
        tiempo_lbl = widgets.Label()

        def entrenar_svr(_):
            output_area.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            with output_area:
                for i, metodo in enumerate(metodos):
                    var_key = f"selected_vars_{metodo.lower()}"
                    if var_key not in globals():
                        print(f"⚠️ No hay variables seleccionadas para el método: {metodo}")
                        continue
                    selected_vars = globals()[var_key]

                    Xtr, Xts = X_train[selected_vars], X_test[selected_vars]
                    ytr, yts = Y_train.values.ravel(), Y_test.values.ravel()

                    sx, sy = StandardScaler(), StandardScaler()
                    Xtr_scaled = sx.fit_transform(Xtr)
                    Xts_scaled = sx.transform(Xts)
                    ytr_scaled = sy.fit_transform(ytr.reshape(-1,1)).ravel()

                    model = SVR(C=C_val.value, epsilon=epsilon_val.value, kernel=kernel_val.value, gamma=gamma_val.value)
                    model.fit(Xtr_scaled, ytr_scaled)

                    y_pred_scaled = model.predict(Xts_scaled)
                    y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()

                    r2 = r2_score(yts, y_pred)
                    mse = mean_squared_error(yts, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(yts, y_pred)

                    resumen_modelos.append({
                        'Método': metodo,
                        'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                    })

                    # Guardar modelo
                    nombre_archivo = f"modelo_svr_{metodo.lower()}.pkl"
                    with open(nombre_archivo, 'wb') as f:
                        pickle.dump({'model': model, 'sx': sx, 'sy': sy, 'cols': selected_vars, 'yname': y_variable_name}, f)

                    ax.plot(y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])
                    print(f"✅ Modelo {metodo} entrenado. R²: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")

                if resumen_modelos:
                    ax.plot(yts, label='Y Real', color='black', linewidth=2)
                    ax.set_title('Comparación Y Real vs Predicciones SVR por Método')
                    ax.grid(); ax.legend()
                    plt.show()

                    # Tabla resumen
                    print("\n📊 Resumen comparativo de métricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('Método'))

            tiempo_lbl.value = f"⏱️ Duración total: {time.time()-inicio:.2f} segundos"

        btn_train.on_click(entrenar_svr)

        # Ayuda extendida
        ayuda = widgets.HTML("""
        <h4>ℹ️ Ayuda - Parámetros del modelo SVR</h4>
        <ul>
            <li><b>C:</b> Penalización al error. Valores altos = bajo sesgo, alto sobreajuste. Recomendado: 0.1 a 100</li>
            <li><b>Epsilon:</b> Margen de tolerancia para el error. Cuanto mayor, más simple el modelo. Recomendado: 0.001 a 0.1</li>
            <li><b>Kernel:</b> Función para proyectar los datos. rbf es el más común. Otras: linear, poly, sigmoid</li>
            <li><b>Gamma:</b> Influencia de un punto de entrenamiento. 'scale' es recomendado.</li>
        </ul>
        """)

        display(widgets.VBox([
            widgets.HBox([metodo_sel]),
            widgets.HBox([C_val, epsilon_val]),
            widgets.HBox([kernel_val, gamma_val]),
            btn_train, tiempo_lbl,
            ayuda, output_area
        ]))

# Artifact: exec exec_99
from tensorflow.keras.models import Sequential

# Artifact: exec exec_100
from tensorflow.keras.optimizers import Adam, SGD, RMSprop

# Artifact: exec exec_101
if 'out_nn' not in globals():
    out_nn = widgets.Output()

# Artifact: function mostrar_nn
def mostrar_nn(b=None):
    if b is None:
        display(out_nn)

    with out_nn:
        clear_output()

        if 'X_train' not in globals() or 'X_test' not in globals():
            display(widgets.HTML("<span style='color:red;'>❌ Primero debes segmentar los datos en train/test.</span>"))
            return

        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )

        capas = widgets.BoundedIntText(value=2, min=1, max=10, description='Capas ocultas:')
        neuronas = widgets.Text(value='64,32', description='Neuronas por capa:', placeholder='Ej: 64,32')
        activacion = widgets.Dropdown(options=['relu','tanh','sigmoid'], value='relu', description='Activación:')
        loss_fn = widgets.Dropdown(options=[('MSE','mse'),('MAE','mae'),('Huber','huber')], value='mse', description='Pérdida:')
        tasa = widgets.FloatText(value=0.001, description='Learning Rate:')
        epocas = widgets.BoundedIntText(value=100, min=1, description='Epocas:')
        batch = widgets.BoundedIntText(value=32, min=1, description='Batch size:')
        opt = widgets.Dropdown(options=['adam','sgd','rmsprop'], value='adam', description='Optimizador:')

        btn_train = widgets.Button(description='🚀 Entrenar NN', button_style='success')
        output_area = widgets.Output()
        tiempo_lbl = widgets.Label()

        def entrenar_nn(_):
            output_area.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            with output_area:
                for i, metodo in enumerate(metodos):
                    var_key = f"selected_vars_{metodo.lower()}"
                    if var_key not in globals():
                        print(f"⚠️ No hay variables seleccionadas para el método: {metodo}")
                        continue

                    selected_vars = globals()[var_key]
                    Xtr, Xts = X_train[selected_vars], X_test[selected_vars]
                    ytr, yts = Y_train.values.ravel(), Y_test.values.ravel()

                    sx, sy = StandardScaler(), StandardScaler()
                    Xtr_scaled = sx.fit_transform(Xtr)
                    Xts_scaled = sx.transform(Xts)
                    ytr_scaled = sy.fit_transform(ytr.reshape(-1,1)).ravel()

                    model = Sequential()
                    try:
                        layers = [int(n) for n in neuronas.value.split(',')]
                        if len(layers) != capas.value:
                            raise ValueError("❌ Especifica tantas capas como valores de neuronas.")
                        model.add(Dense(layers[0], activation=activacion.value, input_shape=(Xtr_scaled.shape[1],)))
                        for units in layers[1:]:
                            model.add(Dense(units, activation=activacion.value))
                        model.add(Dense(1))
                    except Exception as e:
                        print(f"❌ Error en la definición de la arquitectura: {e}")
                        return

                    opt_dict = {'adam': Adam, 'sgd': SGD, 'rmsprop': RMSprop}
                    optimizer = opt_dict[opt.value](learning_rate=tasa.value)

                    loss = {'mse':'mean_squared_error','mae':'mean_absolute_error','huber':tf.keras.losses.Huber()}[loss_fn.value]
                    model.compile(optimizer=optimizer, loss=loss, metrics=['mae'])

                    # === Aquí guardamos los hiperparámetros antes de entrenar ===
                    hp = {
                        'capas_ocultas': capas.value,
                        'neuronas_por_capa': neuronas.value,  # e.g. '64,32'
                        'activacion': activacion.value,
                        'loss_fn': loss_fn.value,
                        'learning_rate': tasa.value,
                        'epocas': epocas.value,
                        'batch_size': batch.value,
                        'optimizador': opt.value
                    }
                    import pickle
                    hp_fname = f"hyperparams_nn_{metodo.lower()}.pkl"
                    try:
                        with open(hp_fname, "wb") as f_hp:
                            pickle.dump(hp, f_hp)
                        print(f"✅ Hiperparámetros guardados en {hp_fname}")
                    except Exception as e:
                        print(f"❌ No se pudo guardar hiperparámetros en {hp_fname}: {e}")

                    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
                    history = model.fit(Xtr_scaled, ytr_scaled, validation_split=0.2, epochs=epocas.value, batch_size=batch.value, verbose=0, callbacks=[es])

                    y_pred_scaled = model.predict(Xts_scaled).ravel()
                    y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()

                    r2 = r2_score(yts, y_pred)
                    mse = mean_squared_error(yts, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(yts, y_pred)

                    resumen_modelos.append({'Método': metodo, 'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae})

                    nombre_archivo = f"modelo_nn_{metodo.lower()}.h5"
                    model.save(nombre_archivo)

                    with open(f"escaladores_nn_{metodo.lower()}.pkl", "wb") as f:
                        pickle.dump({
                            'scaler_X': sx,
                            'scaler_Y': sy,
                            'cols': selected_vars,
                            'yname': y_variable_name
                        }, f)

                    ax.plot(y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])
                    print(f"✅ Modelo {metodo} entrenado. R²: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")


                if resumen_modelos:
                    ax.plot(yts, label='Y Real', color='black', linewidth=2)
                    ax.set_title('Comparación Y Real vs Predicciones NN por Método')
                    ax.grid(); ax.legend()
                    plt.show()

                    print("\n📊 Resumen comparativo de métricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('Método'))

            tiempo_lbl.value = f"⏱️ Duración total: {time.time()-inicio:.2f} segundos"

        btn_train.on_click(entrenar_nn)

        ayuda = widgets.HTML("""
        <h4>ℹ️ Ayuda - Parámetros de la Red Neuronal</h4>
        <ul>
            <li><b>Capas ocultas:</b> Número de capas intermedias. Más capas pueden mejorar la expresividad.</li>
            <li><b>Neuronas por capa:</b> Lista separada por comas. Cada valor representa una capa. Ej: 64,32</li>
            <li><b>Activación:</b> Funciones como relu (recomendado), tanh, sigmoid. Afectan la no linealidad.</li>
            <li><b>Learning Rate:</b> Tamaño del paso. Valores típicos: 0.001, 0.01</li>
            <li><b>Epocas:</b> Número de iteraciones sobre el dataset. Demasiadas pueden sobreajustar.</li>
            <li><b>Batch size:</b> Tamaño de lote en cada actualización de gradiente.</li>
            <li><b>Optimizador:</b> Algoritmo de ajuste. Adam es general. SGD es más simple. RMSprop es bueno en secuencias.</li>
        </ul>
        """)

        display(widgets.VBox([
            widgets.HBox([metodo_sel]),
            widgets.HBox([capas, neuronas]),
            widgets.HBox([activacion, opt]),
            widgets.HBox([tasa, epocas, batch]),
            widgets.HBox([loss_fn]),
            btn_train, tiempo_lbl,
            ayuda, output_area
        ]))

# Artifact: exec exec_103
if 'out_xgb' not in globals():
    out_xgb = widgets.Output()

# Artifact: function mostrar_xgb
def mostrar_xgb(b=None):
    if b is None:
        display(out_xgb)

    with out_xgb:
        clear_output()

        if 'X_train' not in globals() or 'X_test' not in globals():
            display(widgets.HTML("""<span style='color:red;'>❌ Primero debes segmentar los datos en train/test.</span>"""))
            return

        # Bloque para sincronizar variables individuales a partir del resumen RESUMEN_METODOS
        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )
        n_estimators = widgets.IntSlider(value=100, min=10, max=1000, step=10, description='Árboles:')
        learning_rate = widgets.FloatLogSlider(value=0.1, base=10, min=-3, max=0, step=0.01, description='Learning Rate:')
        max_depth = widgets.IntSlider(value=3, min=1, max=20, step=1, description='Profundidad:')
        subsample = widgets.FloatSlider(value=1.0, min=0.1, max=1.0, step=0.1, description='Subsample:')

        btn_train = widgets.Button(description="🚀 Entrenar XGBoost", button_style='success')
        output_area = widgets.Output()
        tiempo_lbl = widgets.Label()

        def entrenar_xgb(_):
            output_area.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            with output_area:
                for i, metodo in enumerate(metodos):
                    var_key = f"selected_vars_{metodo.lower()}"
                    if var_key not in globals():
                        print(f"⚠️ No hay variables seleccionadas para el método: {metodo}")
                        continue
                    selected_vars = globals()[var_key]

                    Xtr, Xts = X_train[selected_vars], X_test[selected_vars]
                    ytr, yts = Y_train.values.ravel(), Y_test.values.ravel()

                    sx, sy = StandardScaler(), StandardScaler()
                    Xtr_scaled = sx.fit_transform(Xtr)
                    Xts_scaled = sx.transform(Xts)
                    ytr_scaled = sy.fit_transform(ytr.reshape(-1,1)).ravel()

                    model = XGBRegressor(
                        n_estimators=n_estimators.value,
                        learning_rate=learning_rate.value,
                        max_depth=max_depth.value,
                        subsample=subsample.value,
                        verbosity=0
                    )
                    model.fit(Xtr_scaled, ytr_scaled)

                    y_pred_scaled = model.predict(Xts_scaled)
                    y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()

                    r2 = r2_score(yts, y_pred)
                    mse = mean_squared_error(yts, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(yts, y_pred)

                    resumen_modelos.append({
                        'Método': metodo,
                        'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                    })

                    # Guardar modelo
                    nombre_archivo = f"modelo_xgb_{metodo.lower()}.pkl"
                    with open(nombre_archivo, 'wb') as f:
                        pickle.dump({'model': model, 'sx': sx, 'sy': sy, 'cols': selected_vars, 'yname': y_variable_name}, f)

                    ax.plot(y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])
                    print(f"✅ Modelo {metodo} entrenado. R²: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")

                if resumen_modelos:
                    ax.plot(yts, label='Y Real', color='black', linewidth=2)
                    ax.set_title('Comparación Y Real vs Predicciones XGBoost por Método')
                    ax.grid(); ax.legend()
                    plt.show()

                    print("\n📊 Resumen comparativo de métricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('Método'))

            tiempo_lbl.value = f"⏱️ Duración total: {time.time()-inicio:.2f} segundos"

        btn_train.on_click(entrenar_xgb)

        ayuda = widgets.HTML("""
        <h4>ℹ️ Ayuda - Parámetros del modelo XGBoost</h4>
        <ul>
            <li><b>n_estimators:</b> número de árboles. Mayor número = mayor precisión pero más tiempo.</li>
            <li><b>learning_rate:</b> tasa de aprendizaje. Pequeños valores mejoran precisión, pero requieren más árboles.</li>
            <li><b>max_depth:</b> profundidad de árboles. Mayor profundidad permite más complejidad, pero riesgo de sobreajuste.</li>
            <li><b>subsample:</b> fracción de muestras usadas por árbol. Menor valor ayuda a regularización.</li>
        </ul>
        """)

        display(widgets.VBox([
            widgets.HBox([metodo_sel]),
            widgets.HBox([n_estimators, learning_rate]),
            widgets.HBox([max_depth, subsample]),
            btn_train, tiempo_lbl,
            ayuda, output_area
        ]))

# Artifact: exec exec_105
if 'out_rf' not in globals():
    out_rf = widgets.Output()

# Artifact: function mostrar_rf
def mostrar_rf(b=None):
    if b is None:
        display(out_rf)

    with out_rf:
        clear_output()

        if 'X_train' not in globals() or 'X_test' not in globals():
            display(widgets.HTML("""<span style='color:red;'>❌ Primero debes segmentar los datos en train/test.</span>"""))
            return

        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )

        n_estimators = widgets.IntSlider(value=100, min=10, max=500, step=10, description='Árboles:')
        max_depth = widgets.IntSlider(value=5, min=1, max=50, step=1, description='Profundidad:')
        min_samples_split = widgets.IntSlider(value=2, min=2, max=20, step=1, description='Min Split:')
        min_samples_leaf = widgets.IntSlider(value=1, min=1, max=20, step=1, description='Min Leaf:')
        max_features = widgets.Dropdown(options=['auto', 'sqrt', 'log2'], value='sqrt', description='Max Features:')
        bootstrap = widgets.Checkbox(value=True, description='Bootstrap:')

        btn_train = widgets.Button(description="🚀 Entrenar RF", button_style='success')
        output_area = widgets.Output()
        tiempo_lbl = widgets.Label()

        def entrenar_rf(_):
            output_area.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            with output_area:
                for i, metodo in enumerate(metodos):
                    var_key = f"selected_vars_{metodo.lower()}"
                    if var_key not in globals():
                        print(f"⚠️ No hay variables seleccionadas para el método: {metodo}")
                        continue
                    selected_vars = globals()[var_key]

                    Xtr, Xts = X_train[selected_vars], X_test[selected_vars]
                    ytr, yts = Y_train.values.ravel(), Y_test.values.ravel()

                    sx, sy = StandardScaler(), StandardScaler()
                    Xtr_scaled = sx.fit_transform(Xtr)
                    Xts_scaled = sx.transform(Xts)
                    ytr_scaled = sy.fit_transform(ytr.reshape(-1,1)).ravel()

                    model = RandomForestRegressor(
                        n_estimators=n_estimators.value,
                        max_depth=max_depth.value,
                        min_samples_split=min_samples_split.value,
                        min_samples_leaf=min_samples_leaf.value,
                        max_features=max_features.value,
                        bootstrap=bootstrap.value,
                        random_state=42,
                        n_jobs=-1
                    )
                    model.fit(Xtr_scaled, ytr_scaled)
                    y_pred_scaled = model.predict(Xts_scaled)
                    y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()

                    r2 = r2_score(yts, y_pred)
                    mse = mean_squared_error(yts, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(yts, y_pred)

                    resumen_modelos.append({
                        'Método': metodo,
                        'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                    })

                    nombre_archivo = f"modelo_rf_{metodo.lower()}.pkl"
                    with open(nombre_archivo, 'wb') as f:
                        pickle.dump({'model': model, 'sx': sx, 'sy': sy, 'cols': selected_vars, 'yname': y_variable_name}, f)

                    ax.plot(y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])
                    print(f"✅ Modelo {metodo} entrenado. R²: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")

                if resumen_modelos:
                    ax.plot(yts, label='Y Real', color='black', linewidth=2)
                    ax.set_title('Comparación Y Real vs Predicciones Random Forest por Método')
                    ax.grid(); ax.legend()
                    plt.show()

                    print("\n📊 Resumen comparativo de métricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('Método'))

            tiempo_lbl.value = f"⏱️ Duración total: {time.time()-inicio:.2f} segundos"

        btn_train.on_click(entrenar_rf)

        ayuda = widgets.HTML("""
        <h4>ℹ️ Ayuda - Parámetros del modelo Random Forest</h4>
        <ul>
            <li><b>n_estimators:</b> número de árboles. Mayor número = mejor precisión, mayor tiempo.</li>
            <li><b>max_depth:</b> profundidad máxima. Limita la complejidad del modelo.</li>
            <li><b>min_samples_split:</b> tamaño mínimo para dividir nodo. Mayor = menos sobreajuste.</li>
            <li><b>min_samples_leaf:</b> mínimo de muestras en hoja. Controla profundidad mínima.</li>
            <li><b>max_features:</b> nº de variables evaluadas por división. 'sqrt' es típico para regresión.</li>
            <li><b>bootstrap:</b> si se usan muestras con reemplazo. True mejora diversidad.</li>
        </ul>
        """)

        display(widgets.VBox([
            widgets.HBox([metodo_sel]),
            widgets.HBox([n_estimators, max_depth]),
            widgets.HBox([min_samples_split, min_samples_leaf]),
            widgets.HBox([max_features, bootstrap]),
            btn_train, tiempo_lbl,
            ayuda, output_area
        ]))

# Artifact: exec exec_107
import time, pickle

# Artifact: exec exec_108
from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Bidirectional, TimeDistributed, RepeatVector

# Artifact: exec exec_109
from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad

# Artifact: exec exec_110
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Artifact: exec exec_111
if 'output_area_rnn' not in globals():
    output_area_rnn = widgets.Output()

# Artifact: function mostrar_rnn
def mostrar_rnn(b=None):
    if b is None:
        display(out_rnn)

    with out_rnn:
        clear_output()

        if not all(k in globals() for k in ['X_train', 'X_test', 'Y_train', 'Y_test', 'FECHAS_train', 'FECHAS_test']):
            display(widgets.HTML("""<span style='color:red;'>❌ Primero debes segmentar los datos en train/test incluyendo fechas.</span>"""))
            return

        # Actualizar variables seleccionadas si existen
        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )
        tipo_rnn = widgets.Dropdown(
            options=['Vanilla RNN', 'LSTM', 'GRU', 'BiLSTM', 'BiGRU', 'Deep RNN', 'Encoder-Decoder'],
            description='Tipo RNN:'
        )
        window_size = widgets.IntSlider(value=10, min=5, max=100, description='Ventana:')
        units = widgets.IntSlider(value=50, min=10, max=200, step=10, description='Unidades:')
        layers = widgets.IntSlider(value=1, min=1, max=5, description='Capas:')
        batch = widgets.IntSlider(value=32, min=8, max=128, step=8, description='Batch:')
        epochs = widgets.IntSlider(value=30, min=10, max=500, step=10, description='Épocas:')
        learning_rate = widgets.FloatLogSlider(value=0.001, base=10, min=-5, max=-1, step=0.1, description='LR:')
        optimizer = widgets.Dropdown(options=['adam', 'sgd', 'rmsprop', 'adagrad'], description='Optimizador:')
        loss_fn = widgets.Dropdown(options=['mse', 'mae', 'huber'], description='Pérdida:')
        activation = widgets.Dropdown(options=['tanh', 'relu', 'sigmoid'], description='Activación:')
        drop = widgets.FloatSlider(value=0.0, min=0.0, max=0.5, step=0.05, description='Dropout:')
        boton_entrenar = widgets.Button(description='🚀 Entrenar RNN', button_style='success')
        tiempo_lbl = widgets.Label()

        def entrenar_rnn(_):
            output_area_rnn.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            for i, metodo in enumerate(metodos):
                var_key = f"selected_vars_{metodo.lower()}"
                if var_key not in globals():
                    with output_area_rnn:
                        print(f"⚠️ No hay variables seleccionadas para el método: {metodo}")
                    continue
                selected_vars = globals()[var_key]

                df_train = X_train[selected_vars].copy()
                df_test = X_test[selected_vars].copy()
                y_train = Y_train.values.ravel()
                y_test = Y_test.values.ravel()

                sx, sy = StandardScaler(), StandardScaler()
                Xtr = sx.fit_transform(df_train)
                Xts = sx.transform(df_test)
                ytr = sy.fit_transform(y_train.reshape(-1,1)).ravel()

                def create_sequences(X, Y, window):
                    X_seq, Y_seq = [], []
                    for j in range(len(X) - window):
                        X_seq.append(X[j:j+window])
                        Y_seq.append(Y[j+window])
                    return np.array(X_seq), np.array(Y_seq)

                X_seq, Y_seq = create_sequences(Xtr, ytr, window_size.value)
                Xts_seq, Yts_seq = create_sequences(Xts, y_test, window_size.value)
                input_shape = (X_seq.shape[1], X_seq.shape[2])

                # ——————————————————————————————————————————————————————
                # Exportar las secuencias al namespace global para el motor IG
                globals()['X_seq'] = X_seq.copy()
                globals()['Y_seq'] = Y_seq.copy()
                # ——————————————————————————————————————————————————————

                model = Sequential()
                RNNLayer = {
                    'Vanilla RNN': SimpleRNN,
                    'LSTM': LSTM,
                    'GRU': GRU
                }.get(tipo_rnn.value.split()[0], LSTM)

                if 'Bi' in tipo_rnn.value:
                    for _ in range(layers.value - 1):
                        model.add(Bidirectional(RNNLayer(units.value, activation=activation.value, return_sequences=True), input_shape=input_shape))
                    model.add(Bidirectional(RNNLayer(units.value, activation=activation.value)))
                elif 'Deep' in tipo_rnn.value:
                    for _ in range(layers.value - 1):
                        model.add(RNNLayer(units.value, activation=activation.value, return_sequences=True))
                    model.add(RNNLayer(units.value, activation=activation.value))
                elif 'Encoder' in tipo_rnn.value:
                    model.add(LSTM(units.value, activation=activation.value, input_shape=input_shape))
                    model.add(RepeatVector(1))
                    model.add(LSTM(units.value, activation=activation.value, return_sequences=True))
                    model.add(TimeDistributed(Dense(1)))
                else:
                    for _ in range(layers.value - 1):
                        model.add(RNNLayer(units.value, activation=activation.value, return_sequences=True, input_shape=input_shape))
                    model.add(RNNLayer(units.value, activation=activation.value))

                if 'Encoder' not in tipo_rnn.value:
                    model.add(Dense(1))

                opt_dict = {
                    'adam': Adam(learning_rate=learning_rate.value),
                    'sgd': SGD(learning_rate=learning_rate.value),
                    'rmsprop': RMSprop(learning_rate=learning_rate.value),
                    'adagrad': Adagrad(learning_rate=learning_rate.value)
                }

                #model.compile(loss=loss_fn.value, optimizer=opt_dict[optimizer.value])
                from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, Huber

                loss_function = {
                    'mse': MeanSquaredError(),
                    'mae': MeanAbsoluteError(),
                    'huber': Huber()
                }[loss_fn.value]

                model.compile(loss=loss_function, optimizer=opt_dict[optimizer.value])

                model.fit(X_seq, Y_seq, epochs=epochs.value, batch_size=batch.value, verbose=0)
                Y_pred_scaled = model.predict(Xts_seq).ravel()
                Y_pred = sy.inverse_transform(Y_pred_scaled.reshape(-1,1)).ravel()
                Y_real = Yts_seq

                r2 = r2_score(Y_real, Y_pred)
                mse = mean_squared_error(Y_real, Y_pred)
                rmse = np.sqrt(mse)
                mae = mean_absolute_error(Y_real, Y_pred)

                resumen_modelos.append({
                    'Método': metodo,
                    'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                })

                # Dentro de la función entrenar_rnn, después de model.fit(...) y antes de model.save(...):
                hp = {
                    'tipo_rnn': tipo_rnn.value,
                    'window_size': window_size.value,
                    'units': units.value,
                    'layers': layers.value,
                    'batch_size': batch.value,
                    'epochs': epochs.value,
                    'learning_rate': learning_rate.value,
                    'optimizer': optimizer.value,
                    'loss_fn': loss_fn.value,
                    'activation': activation.value,
                    'dropout': drop.value
                }
                # Serializar en pickle:
                import pickle
                hp_fname = f"hyperparams_rnn_{metodo.lower()}.pkl"
                with open(hp_fname, "wb") as f_hp:
                    pickle.dump(hp, f_hp)
                print(f"✅ Hiperparámetros RNN guardados en {hp_fname}")

                nombre_archivo = f"modelo_rnn_{metodo.lower()}.h5"
                model.save(nombre_archivo)

                with open(f"escaladores_rnn_{metodo.lower()}.pkl", "wb") as f:
                    pickle.dump({
                        'scaler_X': sx,
                        'scaler_Y': sy,
                        'cols': selected_vars,
                        'yname': y_variable_name
                    }, f)

                ax.plot(Y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])

                with output_area_rnn:
                    print(f"✅ Modelo {metodo} entrenado. R²: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")

            if resumen_modelos:
                ax.plot(Y_real, label='Y Real', color='black', linewidth=2)
                ax.set_title('Comparación Y Real vs Predicciones RNN por Método')
                ax.grid(); ax.legend()

                with output_area_rnn:
                    plt.show()
                    print("\n📊 Resumen comparativo de métricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('Método'))

            tiempo_lbl.value = f"⏱️ Duración total: {time.time()-inicio:.2f} segundos"

        boton_entrenar.on_click(entrenar_rnn)

        ayuda = widgets.HTML("""
        <h4>ℹ️ Ayuda - Parámetros del modelo RNN</h4>
        <ul>
            <li><b>Tipo RNN:</b> Define la arquitectura de red. LSTM y GRU son recomendados para series con dependencia larga.</li>
            <li><b>Ventana:</b> Número de pasos de tiempo usados para predecir el siguiente valor.</li>
            <li><b>Capas / Unidades:</b> Más capas y unidades aumentan capacidad, pero también el riesgo de sobreajuste.</li>
            <li><b>Batch, Epochs:</b> Controlan tamaño del lote y número de iteraciones de entrenamiento.</li>
            <li><b>LR:</b> Tasa de aprendizaje. Valores muy altos o bajos pueden afectar la convergencia.</li>
            <li><b>Dropout:</b> Regulariza y previene sobreajuste. 0.1–0.3 común.</li>
        </ul>
        """)

        display(widgets.VBox([
            metodo_sel,
            widgets.HBox([tipo_rnn, window_size]),
            widgets.HBox([units, layers, batch]),
            widgets.HBox([epochs, learning_rate, optimizer]),
            widgets.HBox([activation, drop, loss_fn]),
            boton_entrenar, tiempo_lbl,
            ayuda, output_area_rnn
        ]))

# Artifact: exec exec_113
from tensorflow.keras.models import load_model

# Artifact: assign out_model_comparator
out_model_comparator = widgets.Output()

# Artifact: assign btn_lanzar_comparador
btn_lanzar_comparador = widgets.Button(description='📊 Comparar Modelos Entrenados', button_style='success')

# Artifact: function mostrar_comparador_modelos
def mostrar_comparador_modelos(b=None):
    with out_model_comparator:
        clear_output()
        display(btn_lanzar_comparador)

# Artifact: function ejecutar_comparador
def ejecutar_comparador(b=None):
    with out_model_comparator:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>📊 Comparador de Modelos Entrenados</h3>
        <p>Este comparador analiza los modelos entrenados con distintos algoritmos y métodos de selección de variables.</p>
        """))

        ruta_modelos = '.'
        modelos_validos = []

        print("🔍 Buscando modelos guardados...")
        for archivo in os.listdir(ruta_modelos):
            if archivo.startswith("modelo_") and (archivo.endswith(".pkl") or archivo.endswith(".h5")):
                nombre_modelo = archivo.replace("modelo_", "").replace(".pkl", "").replace(".h5", "")
                try:
                    if archivo.endswith(".pkl"):
                        with open(os.path.join(ruta_modelos, archivo), 'rb') as f:
                            modelo_guardado = pickle.load(f)
                        modelo = modelo_guardado.get('model')
                        scaler_X = modelo_guardado.get('scaler_X', modelo_guardado.get('sx'))
                        scaler_Y = modelo_guardado.get('scaler_Y', modelo_guardado.get('sy'))
                        cols = modelo_guardado.get('cols')
                        yname = modelo_guardado.get('yname')
                        if scaler_X is None or scaler_Y is None:
                            raise KeyError("Faltan escaladores")
                    else:
                        modelo = load_model(os.path.join(ruta_modelos, archivo))
                        escalador_path = f"escaladores_{nombre_modelo}.pkl"
                        with open(escalador_path, 'rb') as f:
                            escaladores = pickle.load(f)
                        scaler_X = escaladores['scaler_X']
                        scaler_Y = escaladores['scaler_Y']
                        cols = escaladores['cols']
                        yname = escaladores['yname']

                    modelos_validos.append({
                        'nombre': nombre_modelo,
                        'modelo': modelo,
                        'scaler_X': scaler_X,
                        'scaler_Y': scaler_Y,
                        'cols': cols,
                        'yname': yname
                    })
                except Exception as e:
                    print(f"❌ Error al procesar {archivo}: {e}")

        if not modelos_validos:
            display(HTML("<b style='color:red;'>⚠️ No se encontraron modelos entrenados válidos.</b>"))
            return

        resultados = []
        detalles_modelos = []

        for entry in modelos_validos:
            nombre = entry['nombre']
            model = entry['modelo']
            sx = entry['scaler_X']
            sy = entry['scaler_Y']
            cols = entry['cols']
            yname = entry['yname']

            Xtest = X_test[cols].copy()
            ytest = Y_test.values.ravel()

            # Detectar si es un modelo RNN por la forma esperada
            try:
                input_shape = model.input_shape
                is_rnn = len(input_shape) == 3
            except:
                is_rnn = False

            if is_rnn:
                window = input_shape[1]
                X_full = X_test[cols].copy()
                y_full = Y_test.values.ravel()
                X_scaled = sx.transform(X_full)
                y_scaled = sy.transform(y_full.reshape(-1, 1)).ravel()

                X_seq, y_seq = [], []
                for i in range(len(X_scaled) - window):
                    X_seq.append(X_scaled[i:i+window])
                    y_seq.append(y_full[i+window])
                X_seq = np.array(X_seq)
                y_seq = np.array(y_seq)

                pred_scaled = model.predict(X_seq).ravel()
                pred = sy.inverse_transform(pred_scaled.reshape(-1, 1)).ravel()
                ytest = y_seq  # ajustar Y real a misma longitud
            else:
                Xtest_scaled = sx.transform(Xtest)
                pred_scaled = model.predict(Xtest_scaled)
                if isinstance(pred_scaled, tuple): pred_scaled = pred_scaled[0]
                pred = sy.inverse_transform(pred_scaled.reshape(-1, 1)).ravel()
                ytest = ytest  # no cambia

            r2 = r2_score(ytest, pred)
            mse = mean_squared_error(ytest, pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(ytest, pred)

            resultados.append({
                'Modelo': nombre,
                'R2': r2,
                'MSE': mse,
                'RMSE': rmse,
                'MAE': mae,
                'Pred': pred
            })

            detalles_modelos.append({
                'Modelo': nombre,
                'Variables X': ', '.join(cols),
                'Variable Y': yname,
                'Nº Variables': len(cols),
                'Tipo Modelo': nombre.split('_')[0].upper(),
                'Método Selección': nombre.split('_')[-1].capitalize()
            })

        df_resultados = pd.DataFrame(resultados)
        df_detalles = pd.DataFrame(detalles_modelos)

        display(HTML("<h4>📋 Comparativa de Resultados</h4>"))
        display(df_resultados[['Modelo', 'R2', 'RMSE', 'MAE', 'MSE']]
                .sort_values(by='R2', ascending=False)
                .style.set_caption("Ranking de Modelos por R²")
                .set_properties(**{'border': '1px solid gray', 'padding': '6px'})
                .set_table_styles([
                    {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('font-weight', 'bold')]},
                ]))

        df_sorted = df_resultados.sort_values(by='R2', ascending=False)
        fig, ax = plt.subplots(figsize=(10, 6))
        colors = ['gold', 'silver', 'peru'] + ['lightblue']*(len(df_sorted)-3)
        ax.barh(df_sorted['Modelo'], df_sorted['R2'], color=colors[:len(df_sorted)])
        ax.set_title("🏆 Ranking de Modelos por R²")
        ax.invert_yaxis()
        for i, v in enumerate(df_sorted['R2']):
            ax.text(v + 0.01, i, f"{v:.3f}", va='center')
        plt.grid(axis='x')
        plt.tight_layout()
        plt.show()

        display(HTML("<h4>🔧 Parámetros de Entrenamiento de los Modelos</h4>"))
        display(df_detalles.style.set_caption("Resumen de Configuración de Modelos")
                .set_properties(**{'border': '1px solid gray', 'padding': '6px'})
                .set_table_styles([
                    {'selector': 'th', 'props': [('background-color', '#e0f7fa'), ('font-weight', 'bold')]},
                ]))

        # Mostrar tabla con parámetros técnicos (si existen)
        tabla_parametros = []

        for entry in modelos_validos:
            nombre = entry['nombre']
            modelo = entry['modelo']

            fila = {'Modelo': nombre}
            try:
                if hasattr(modelo, 'get_params'):
                    fila.update(modelo.get_params())
                elif isinstance(modelo, tf.keras.Model):
                    config = modelo.get_config()
                    fila['Capas'] = len(config['layers'])
                    fila['Optimizador'] = config.get('optimizer_config', {}).get('class_name', 'Desconocido')
                    fila['Pérdida'] = config.get('loss', 'Desconocida')
                else:
                    fila['Info'] = '⚠️ Tipo de modelo no reconocido'
            except Exception as e:
                fila['Error'] = str(e)

            tabla_parametros.append(fila)

        df_parametros = pd.DataFrame(tabla_parametros)
        display(HTML("<h4>🧾 Parámetros de Configuración (Detalles Técnicos)</h4>"))
        if not df_parametros.empty:
            display(df_parametros.style.set_caption("Parámetros usados en cada modelo")
                    .set_properties(**{'border': '1px solid #ccc', 'padding': '4px'})
                    .set_table_styles([{'selector': 'th', 'props': [('background-color', '#f8f8f8'), ('font-weight', 'bold')]}]))
        else:
            display(HTML("<i>No se pudieron recuperar parámetros para los modelos cargados.</i>"))

        display(HTML("<h4>📈 Gráficos Comparativos Y Real vs. Predicción</h4>"))
        for res in resultados:
            nombre = res['Modelo']
            pred = res['Pred']
            fig, ax = plt.subplots(figsize=(10,4))
            ax.plot(Y_test.values, label='Y Real', color='black')
            ax.plot(pred, label=f'{nombre}', linestyle='--')
            ax.set_title(f'{nombre}: Real vs Predicho')
            ax.legend()
            ax.grid(True)
            plt.show()

        # Tabla de parámetros completos si están disponibles
        display(HTML("<h4>🧾 Parámetros de Configuración (Detalles Técnicos)</h4>"))

        tabla_parametros = []

        for entry in modelos_validos:
            modelo = entry['modelo']
            nombre = entry['nombre']
            tipo   = nombre.split('_')[0].upper()

            if hasattr(modelo, 'get_params'):
                try:
                    params = modelo.get_params()
                    tabla_parametros.append({
                        'Modelo': nombre,
                        **params
                    })
                except:
                    tabla_parametros.append({'Modelo': nombre, 'Info': '⚠️ No se pudieron extraer los parámetros'})
            elif isinstance(modelo, tf.keras.Model):
                config = modelo.get_config()
                tabla_parametros.append({
                    'Modelo': nombre,
                    'Capas': len(config['layers']),
                    'Optim.': config.get('optimizer_config', {}).get('class_name', 'N/A'),
                    'Loss': config.get('loss', 'N/A') if isinstance(config.get('loss'), str) else str(config.get('loss')),
                    'Tipo': tipo
                })
            else:
                tabla_parametros.append({'Modelo': nombre, 'Info': '⚠️ Modelo no compatible'})

        df_params = pd.DataFrame(tabla_parametros)
        display(df_params.style.set_caption("🛠️ Parámetros de Ajuste de Cada Modelo")
                .set_properties(**{'border': '1px solid #999', 'padding': '5px'})
                .set_table_styles([{'selector': 'th', 'props': [('background-color', '#f9f9f9'), ('font-weight', 'bold')]}]))

# Artifact: exec exec_118
btn_lanzar_comparador.on_click(ejecutar_comparador)

# Artifact: exec exec_119
display(out_model_comparator)

# Artifact: assign out_pred_svr
out_pred_svr = widgets.Output()

# Artifact: function mostrar_prediccion_svr
def mostrar_prediccion_svr(b=None):
    with out_pred_svr:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>🔮 Predicción con Modelo SVR</h3>
        <p>Este módulo permite realizar predicciones con modelos SVR entrenados previamente
        utilizando variables seleccionadas automáticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selección de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='Nº Casos:')

        modo_datos = widgets.ToggleButtons(
            options=['Automático', 'Manual'],
            description='Modo de entrada:'
        )

        btn_generar = widgets.Button(description='➡️ Generar Variables X')
        btn_predecir = widgets.Button(description='📈 Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='📋 Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        datos_generados = {}
        resultados = {}

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                nombre_modelo = f"modelo_svr_{metodo.lower()}.pkl"
                if not os.path.exists(nombre_modelo):
                    continue
                with open(nombre_modelo, 'rb') as f:
                    modelo_dict = pickle.load(f)
                cols = modelo_dict['cols']

                df_x = pd.DataFrame()
                for col in cols:
                    if col not in X_data.columns or X_data[col].isnull().all():
                        continue
                    serie = X_data[col]
                    minimo, maximo = serie.min(), serie.max()
                    tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                    if modo_datos.value == 'Automático':
                        vals = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' \
                            else np.linspace(maximo, minimo, num_casos.value)
                        df_x[col] = vals
                    else:
                        df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                datos_generados[metodo] = df_x

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>🧾 Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))

                    if isinstance(df, pd.DataFrame) and modo_datos.value == 'Automático':
                        display(df)
                    elif modo_datos.value == 'Manual':
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i+1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                if metodo not in datos_generados:
                    continue
                df = datos_generados[metodo]
                nombre_modelo = f"modelo_svr_{metodo.lower()}.pkl"
                if not os.path.exists(nombre_modelo):
                    continue
                with open(nombre_modelo, 'rb') as f:
                    modelo_dict = pickle.load(f)

                sx, sy, model = modelo_dict['sx'], modelo_dict['sy'], modelo_dict['model']

                if modo_datos.value == 'Manual':
                    df_manual = pd.DataFrame()
                    for col in df.columns:
                        df_manual[col] = [w.value for w in df[col]]
                    df_to_use = df_manual
                else:
                    df_to_use = df

                x_scaled = sx.transform(df_to_use.values)
                y_pred = sy.inverse_transform(model.predict(x_scaled).reshape(-1, 1)).ravel()
                df_pred = df_to_use.copy()
                df_pred['Y_pred'] = y_pred
                resultados[metodo] = df_pred

            tabla_pred.clear_output()
            contenedor_tablas = []
            for metodo in metodos:
                if metodo in resultados:
                    df = resultados[metodo]
                    contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>🧮 {metodo}</h4>"))
                    contenedor_tablas.append(widgets.Output())
                    with contenedor_tablas[-1]:
                        display(df)

            with tabla_pred:
                clear_output()
                display(HTML("<h3>📋 Resultados de la Predicción</h3>"))
                display(widgets.VBox(contenedor_tablas))

            with grafico_pred:
                plt.figure(figsize=(10, 4))
                for metodo in metodos:
                    if metodo in resultados:
                        y_vals = resultados[metodo]['Y_pred'].values
                        if y_vals.size > 0:
                            plt.plot(y_vals, label=str(metodo), linestyle='--')

                plt.title("📊 Predicciones Y por Método")
                plt.xlabel("Caso")
                plt.ylabel("Y_predicho")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        def copiar_al_portapapeles(_):
            from IPython.display import Javascript
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("✅ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_122
display(out_pred_svr)

# Artifact: assign out_pred_nn
out_pred_nn = widgets.Output()

# Artifact: function mostrar_prediccion_nn
def mostrar_prediccion_nn(b=None):
    with out_pred_nn:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>🔮 Predicción con Red Neuronal</h3>
        <p>Este módulo permite realizar predicciones con redes neuronales previamente entrenadas
        utilizando variables seleccionadas automáticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selección de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='Nº Casos:')

        modo_datos = widgets.ToggleButtons(
            options=['Automático', 'Manual'],
            description='Modo de entrada:'
        )

        btn_generar = widgets.Button(description='➡️ Generar Variables X')
        btn_predecir = widgets.Button(description='📈 Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='📋 Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        datos_generados = {}
        resultados = {}

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                modelo_path = f"modelo_nn_{metodo.lower()}.h5"
                scaler_path = f"escaladores_nn_{metodo.lower()}.pkl"
                if not os.path.exists(modelo_path) or not os.path.exists(scaler_path):
                    continue
                with open(scaler_path, 'rb') as f:
                    datos = pickle.load(f)
                cols = datos['cols']

                df_x = pd.DataFrame()
                for col in cols:
                    if col not in X_data.columns or X_data[col].isnull().all():
                        continue
                    serie = X_data[col]
                    minimo, maximo = serie.min(), serie.max()
                    tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                    if modo_datos.value == 'Automático':
                        vals = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' \
                            else np.linspace(maximo, minimo, num_casos.value)
                        df_x[col] = vals
                    else:
                        df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                datos_generados[metodo] = df_x

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>🧾 Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))
                    if isinstance(df, pd.DataFrame) and modo_datos.value == 'Automático':
                        display(df)
                    elif modo_datos.value == 'Manual':
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i+1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                if metodo not in datos_generados:
                    continue
                df = datos_generados[metodo]
                modelo_path = f"modelo_nn_{metodo.lower()}.h5"
                scaler_path = f"escaladores_nn_{metodo.lower()}.pkl"
                if not os.path.exists(modelo_path) or not os.path.exists(scaler_path):
                    continue

                model = load_model(modelo_path)
                with open(scaler_path, 'rb') as f:
                    datos = pickle.load(f)
                sx, sy = datos['scaler_X'], datos['scaler_Y']

                if modo_datos.value == 'Manual':
                    df_manual = pd.DataFrame()
                    for col in df.columns:
                        df_manual[col] = [w.value for w in df[col]]
                    df_to_use = df_manual
                else:
                    df_to_use = df

                x_scaled = sx.transform(df_to_use.values)
                y_pred = sy.inverse_transform(model.predict(x_scaled)).ravel()
                df_pred = df_to_use.copy()
                df_pred['Y_pred'] = y_pred
                resultados[metodo] = df_pred

            tabla_pred.clear_output()
            contenedor_tablas = []
            for metodo in metodos:
                if metodo in resultados:
                    df = resultados[metodo]
                    contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>🧮 {metodo}</h4>"))
                    contenedor_tablas.append(widgets.Output())
                    with contenedor_tablas[-1]:
                        display(df)

            with tabla_pred:
                clear_output()
                display(HTML("<h3>📋 Resultados de la Predicción</h3>"))
                display(widgets.VBox(contenedor_tablas))

            with grafico_pred:
                plt.figure(figsize=(10, 4))
                for metodo in metodos:
                    if metodo in resultados:
                        plt.plot(resultados[metodo]['Y_pred'].values, label=metodo, linestyle='--')
                plt.title("📊 Predicciones Y por Método (NN)")
                plt.xlabel("Caso")
                plt.ylabel("Y_predicho")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        def copiar_al_portapapeles(_):
            from IPython.display import Javascript
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("✅ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_125
display(out_pred_nn)

# Artifact: assign out_pred_xgb
out_pred_xgb = widgets.Output()

# Artifact: function mostrar_prediccion_xgboost
def mostrar_prediccion_xgboost(b=None):
    with out_pred_xgb:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>🔮 Predicción con XGBoost</h3>
        <p>Este módulo permite realizar predicciones con modelos XGBoost previamente entrenados
        utilizando variables seleccionadas automáticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selección de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='Nº Casos:')

        modo_datos = widgets.ToggleButtons(
            options=['Automático', 'Manual'],
            description='Modo de entrada:'
        )

        btn_generar = widgets.Button(description='➡️ Generar Variables X')
        btn_predecir = widgets.Button(description='📈 Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='📋 Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        datos_generados = {}
        resultados = {}

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                path_model = f"modelo_xgb_{metodo.lower()}.pkl"
                if not os.path.exists(path_model):
                    continue
                with open(path_model, 'rb') as f:
                    datos = pickle.load(f)
                cols = datos['cols']

                df_x = pd.DataFrame()
                for col in cols:
                    if col not in X_data.columns or X_data[col].isnull().all():
                        continue
                    serie = X_data[col]
                    minimo, maximo = serie.min(), serie.max()
                    tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                    if modo_datos.value == 'Automático':
                        vals = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' \
                            else np.linspace(maximo, minimo, num_casos.value)
                        df_x[col] = vals
                    else:
                        df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                datos_generados[metodo] = df_x

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>🧾 Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))
                    if isinstance(df, pd.DataFrame) and modo_datos.value == 'Automático':
                        display(df)
                    elif modo_datos.value == 'Manual':
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i+1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                if metodo not in datos_generados:
                    continue
                df = datos_generados[metodo]
                path_model = f"modelo_xgb_{metodo.lower()}.pkl"
                if not os.path.exists(path_model):
                    continue

                with open(path_model, 'rb') as f:
                    datos = pickle.load(f)
                model = datos['model']
                sx, sy = datos['sx'], datos['sy']

                if modo_datos.value == 'Manual':
                    df_manual = pd.DataFrame()
                    for col in df.columns:
                        df_manual[col] = [w.value for w in df[col]]
                    df_to_use = df_manual
                else:
                    df_to_use = df

                x_scaled = sx.transform(df_to_use.values)
                y_pred = sy.inverse_transform(model.predict(x_scaled).reshape(-1, 1)).ravel()
                df_pred = df_to_use.copy()
                df_pred['Y_pred'] = y_pred
                resultados[metodo] = df_pred

            contenedor_tablas = []
            for metodo in metodos:
                if metodo in resultados:
                    df = resultados[metodo]
                    contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>🧮 {metodo}</h4>"))
                    contenedor_tablas.append(widgets.Output())
                    with contenedor_tablas[-1]:
                        display(df)

            with tabla_pred:
                clear_output()
                display(HTML("<h3>📋 Resultados de la Predicción (XGBoost)</h3>"))
                display(widgets.VBox(contenedor_tablas))

            with grafico_pred:
                plt.figure(figsize=(10, 4))
                for metodo in metodos:
                    if metodo in resultados:
                        plt.plot(resultados[metodo]['Y_pred'].values, label=metodo, linestyle='--')
                plt.title("📊 Predicciones Y por Método (XGBoost)")
                plt.xlabel("Caso")
                plt.ylabel("Y_predicho")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        def copiar_al_portapapeles(_):
            from IPython.display import Javascript
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("✅ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_128
display(out_pred_xgb)

# Artifact: exec exec_129
import pickle, os, traceback, time

# Artifact: exec exec_130
from IPython.display import display, HTML, clear_output, Javascript

# Artifact: assign out_pred_rf
out_pred_rf = widgets.Output()

# Artifact: function mostrar_prediccion_rf
def mostrar_prediccion_rf(b=None):
    with out_pred_rf:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>🔮 Predicción con Random Forest</h3>
        <p>Este módulo permite realizar predicciones con modelos Random Forest previamente entrenados
        utilizando variables seleccionadas automáticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selección de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='Nº Casos:')

        modo_datos = widgets.ToggleButtons(
            options=['Automático', 'Manual'],
            description='Modo de entrada:'
        )

        btn_generar = widgets.Button(description='➡️ Generar Variables X')
        btn_predecir = widgets.Button(description='📈 Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='📋 Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        progreso = widgets.Label()

        datos_generados = {}
        resultados = {}

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                path_model = f"modelo_rf_{metodo.lower()}.pkl"
                if not os.path.exists(path_model):
                    continue
                try:
                    with open(path_model, 'rb') as f:
                        datos = pickle.load(f)
                    cols = datos.get('cols', [])
                    if not cols:
                        continue

                    df_x = pd.DataFrame()
                    for col in cols:
                        if col not in X_data.columns or X_data[col].isnull().all():
                            continue
                        serie = X_data[col]
                        minimo, maximo = serie.min(), serie.max()
                        tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                        if modo_datos.value == 'Automático':
                            vals = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' \
                                else np.linspace(maximo, minimo, num_casos.value)
                            df_x[col] = vals
                        else:
                            df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                    datos_generados[metodo] = df_x
                except Exception as e:
                    print(f"❌ Error al generar variables para {metodo}: {e}")

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>🧾 Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))
                    if isinstance(df, pd.DataFrame) and modo_datos.value == 'Automático':
                        display(df)
                    elif modo_datos.value == 'Manual':
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i+1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            progreso.value = "⏳ Realizando predicciones..."
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            t_ini = time.time()
            errores = []  # ← para mostrar errores al final

            for metodo in metodos:
                if metodo not in datos_generados:
                    continue
                df = datos_generados[metodo]
                path_model = f"modelo_rf_{metodo.lower()}.pkl"
                if not os.path.exists(path_model):
                    continue

                try:
                    with open(path_model, 'rb') as f:
                        datos = pickle.load(f)
                    model = datos['model']
                    #sx, sy = datos['scaler_X'], datos['scaler_Y']
                    sx = datos.get('scaler_X', None)
                    sy = datos.get('scaler_Y', None)


                    if modo_datos.value == 'Manual':
                        df_manual = pd.DataFrame()
                        for col in df.columns:
                            df_manual[col] = [w.value for w in df[col]]
                        df_to_use = df_manual
                    else:
                        df_to_use = df

                    if set(df_to_use.columns) != set(datos['cols']):
                        errores.append(f"⚠️ Columnas incompatibles para {metodo}. Se omite.")
                        continue
                    df_to_use = df_to_use[datos['cols']]

                    if df_to_use.empty:
                        errores.append(f"⚠️ DataFrame vacío para {metodo}. Se omite.")
                        continue

                    print(f"[DEBUG] Prediciendo para método: {metodo}, df.shape = {df_to_use.shape}")

                    # === Predicción con o sin escalado ===
                    if sx is not None:
                        x_scaled = sx.transform(df_to_use.values)
                    else:
                        x_scaled = df_to_use.values

                    y_pred_scaled = model.predict(x_scaled).reshape(-1, 1)

                    if sy is not None:
                        y_pred = sy.inverse_transform(y_pred_scaled).ravel()
                    else:
                        y_pred = y_pred_scaled.ravel()

                    df_pred = df_to_use.copy()
                    df_pred['Y_pred'] = y_pred
                    resultados[metodo] = df_pred

                except Exception as e:
                    errores.append(f"❌ Error al predecir para {metodo}:\n{traceback.format_exc()}")

            progreso.value = f"✅ Predicciones completadas en {time.time() - t_ini:.1f}s"

            contenedor_tablas = []
            for metodo in metodos:
                if metodo in resultados:
                    df = resultados[metodo]
                    contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>🧮 {metodo}</h4>"))
                    contenedor_tablas.append(widgets.Output())
                    with contenedor_tablas[-1]:
                        display(df)

            with tabla_pred:
                clear_output()
                display(HTML("<h3>📋 Resultados de la Predicción (Random Forest)</h3>"))
                if contenedor_tablas:
                    display(widgets.VBox(contenedor_tablas))
                if errores:
                    display(HTML("<h4 style='color:red;'>❌ Errores detectados:</h4>"))
                    for err in errores:
                        display(HTML(f"<pre style='color:darkred;'>{err}</pre>"))

            with grafico_pred:
                clear_output()
                plt.figure(figsize=(10, 4))
                hay_datos = False
                for metodo in metodos:
                    if metodo in resultados:
                        plt.plot(resultados[metodo]['Y_pred'].values, label=metodo, linestyle='--')
                        hay_datos = True
                if hay_datos:
                    plt.title("📊 Predicciones Y por Método (Random Forest)")
                    plt.xlabel("Caso")
                    plt.ylabel("Y_predicho")
                    plt.legend()
                    plt.grid(True)
                    plt.tight_layout()
                    plt.show()

        def copiar_al_portapapeles(_):
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("✅ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            progreso,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_133
display(out_pred_rf)

# Artifact: exec exec_134
import pickle, os, traceback

# Artifact: assign out_pred_rnn
out_pred_rnn = widgets.Output()

# Artifact: assign resultados
resultados = {}

# Artifact: assign datos_generados
datos_generados = {}

# Artifact: function mostrar_prediccion_rnn
def mostrar_prediccion_rnn(b=None):
    with out_pred_rnn:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>🔮 Predicción con RNN</h3>
        <p>Este módulo permite realizar predicciones con modelos RNN previamente entrenados
        utilizando variables seleccionadas automáticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selección de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='Nº Casos:')
        modo_datos = widgets.ToggleButtons(options=['Automático', 'Manual'], description='Modo de entrada:')

        btn_generar = widgets.Button(description='➡️ Generar Variables X')
        btn_predecir = widgets.Button(description='📈 Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='📋 Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        progreso = widgets.Label()

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            progreso.value = ""
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                modelo_path = f"modelo_rnn_{metodo.lower()}.h5"
                scaler_path = f"escaladores_rnn_{metodo.lower()}.pkl"
                if not os.path.exists(modelo_path) or not os.path.exists(scaler_path):
                    continue
                with open(scaler_path, 'rb') as f:
                    datos = pickle.load(f)
                cols = datos.get('cols', [])
                if not cols:
                    continue

                df_x = pd.DataFrame()
                for col in cols:
                    if col not in X_data.columns or X_data[col].isnull().all():
                        continue
                    serie = X_data[col]
                    minimo, maximo = serie.min(), serie.max()
                    tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                    if modo_datos.value == 'Automático':
                        valores = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' else np.linspace(maximo, minimo, num_casos.value)
                        df_x[col] = valores
                    else:
                        df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                datos_generados[metodo] = df_x

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>🧾 Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))
                    df = datos_generados[metodo]
                    if modo_datos.value == 'Automático':
                        display(df)
                    else:
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i + 1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            progreso.value = "⏳ Realizando predicciones..."
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            errores = []

            for metodo in metodos:
                try:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]

                    modelo_path = f"modelo_rnn_{metodo.lower()}.h5"
                    scaler_path = f"escaladores_rnn_{metodo.lower()}.pkl"
                    if not os.path.exists(modelo_path) or not os.path.exists(scaler_path):
                        errores.append(f"❌ Archivos no encontrados para {metodo}")
                        continue

                    with open(scaler_path, 'rb') as f:
                        datos = pickle.load(f)
                    sx, sy = datos.get('scaler_X'), datos.get('scaler_Y')
                    model = load_model(modelo_path)

                    if modo_datos.value == 'Manual':
                        df_manual = pd.DataFrame()
                        for col in df.columns:
                            df_manual[col] = [w.value for w in df[col]]
                        df_to_use = df_manual
                    else:
                        df_to_use = df

                    if set(df_to_use.columns) != set(datos['cols']):
                        errores.append(f"⚠️ Columnas incompatibles para {metodo}. Se omite.")
                        continue
                    df_to_use = df_to_use[datos['cols']]

                    x_scaled = sx.transform(df_to_use.values)
                    x_scaled_rnn = x_scaled.reshape((x_scaled.shape[0], 1, x_scaled.shape[1]))
                    y_pred_scaled = model.predict(x_scaled_rnn).reshape(-1, 1)
                    y_pred = sy.inverse_transform(y_pred_scaled).ravel()

                    df_pred = df_to_use.copy()
                    df_pred['Y_pred'] = y_pred
                    resultados[metodo] = df_pred

                except Exception as e:
                    errores.append(f"❌ Error al predecir para {metodo}:\n{traceback.format_exc()}")

            progreso.value = "✅ Predicciones completadas"

            with tabla_pred:
                clear_output()
                contenedor_tablas = []
                for metodo in metodos:
                    if metodo in resultados:
                        df = resultados[metodo]
                        contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>🧮 {metodo}</h4>"))
                        contenedor_tablas.append(widgets.Output())
                        with contenedor_tablas[-1]:
                            display(df)
                if contenedor_tablas:
                    display(HTML("<h3>📋 Resultados de la Predicción (RNN)</h3>"))
                    display(widgets.VBox(contenedor_tablas))
                if errores:
                    display(HTML("<h4 style='color:red;'>❌ Errores detectados:</h4>"))
                    for err in errores:
                        display(HTML(f"<pre style='color:darkred;'>{err}</pre>"))

            with grafico_pred:
                clear_output()
                plt.figure(figsize=(10, 4))
                for metodo in metodos:
                    if metodo in resultados:
                        plt.plot(resultados[metodo]['Y_pred'].values, label=metodo, linestyle='--')
                plt.title("📊 Predicciones Y por Método (RNN)")
                plt.xlabel("Caso")
                plt.ylabel("Y_predicho")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        def copiar_al_portapapeles(_):
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("✅ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            progreso,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_139
display(out_pred_rnn)

# Artifact: exec exec_140
import glob

# Artifact: exec exec_141
from keras.models import load_model

# Artifact: assign out_graf_86
out_graf_86 = widgets.Output()

# Artifact: function listar_modelos
def listar_modelos():
    modelos = {}
    for path in glob.glob("modelo_*.pkl"):
        nombre = os.path.splitext(os.path.basename(path))[0].replace("modelo_", "").upper()
        modelos[nombre] = path

    for h5_path in glob.glob("modelo_*.h5"):
        nombre = os.path.splitext(os.path.basename(h5_path))[0].replace("modelo_", "").upper()
        pkl_path = f"escaladores_{nombre.lower()}.pkl"
        if os.path.exists(pkl_path):
            modelos[nombre] = (h5_path, pkl_path)
        else:
            modelos[nombre] = h5_path
    return modelos

# Artifact: function mostrar_grafico_y_vs_x
def mostrar_grafico_y_vs_x():
    with out_graf_86:
        clear_output()

        if 'X_data' not in globals() or 'Y_data' not in globals():
            print("❌ Faltan datos cargados (X_data o Y_data).")
            return

        modelos_disponibles = listar_modelos()

        selector_variable = widgets.Dropdown(
            options=X_data.columns.tolist(),
            description='Variable X:',
            layout=widgets.Layout(width='50%')
        )

        selector_dataset = widgets.ToggleButtons(
            options=['Train', 'Test'],
            description='Dataset:',
            style={'description_width': 'initial'}
        )

        selector_modelos = widgets.SelectMultiple(
            options=list(modelos_disponibles.keys()),
            description='Modelos:',
            layout=widgets.Layout(width='50%', height='150px')
        )

        boton_ver = widgets.Button(description='📊 Comparar Y', button_style='success')
        resumen_out = widgets.Output()
        tabla_out = widgets.Output()
        debug_out = widgets.Output()
        grafico_out = widgets.Output()

        def graficar(_):
            resumen_out.clear_output()
            tabla_out.clear_output()
            grafico_out.clear_output()
            debug_out.clear_output()

            var_x = selector_variable.value
            if var_x is None:
                print("⚠️ No se ha seleccionado variable X")
                return

            dataset = selector_dataset.value
            if dataset == 'Train':
                X_base = X_train.copy()
                Y_base = Y_train.copy()
            else:
                X_base = X_test.copy()
                Y_base = Y_test.copy()

            x_vals = X_base[var_x].values
            y_vals = Y_base.values.ravel()
            df = pd.DataFrame({"X": x_vals, "Y_real": y_vals})
            metricas = {}

            modelos_seleccionados = selector_modelos.value
            if isinstance(modelos_seleccionados, str):
                modelos_seleccionados = [modelos_seleccionados]
            elif isinstance(modelos_seleccionados, tuple):
                modelos_seleccionados = list(modelos_seleccionados)

            for modelo_key in modelos_seleccionados:
                modelo_path = modelos_disponibles.get(modelo_key)
                if not modelo_path:
                    with debug_out:
                        print(f"⚠️ Modelo {modelo_key} no encontrado.")
                    continue

                try:
                    if isinstance(modelo_path, tuple):
                        h5_file, pkl_file = modelo_path
                        model = load_model(h5_file)
                        with open(pkl_file, 'rb') as f:
                            datos = pickle.load(f)
                    else:
                        with open(modelo_path, 'rb') as f:
                            datos = pickle.load(f)
                        model = datos.get('model')

                    if model is None:
                        raise ValueError("❌ No se encontró el modelo entrenado en el archivo.")

                    sx = datos.get('scaler_X', datos.get('sx'))
                    sy = datos.get('scaler_Y', datos.get('sy'))

                    if sx is None or sy is None:
                        raise ValueError("❌ No se encontraron los escaladores (sx/sy o scaler_X/scaler_Y) en el modelo.")

                    cols = datos.get('cols', None)
                    if cols is None:
                        cols = list(set(X_base.columns) & set(sx.feature_names_in_))
                        if not cols:
                            raise ValueError("❌ No se pudo inferir columnas para aplicar scaler_X")

                    X_scaled = sx.transform(X_base[cols])

                    # Si el modelo requiere entrada 3D (ej. RNN)
                    if hasattr(model, 'input_shape') and len(model.input_shape) == 3:
                        X_scaled = np.expand_dims(X_scaled, axis=1)  # Convertir a (batch_size, 1, features)

                    y_pred_scaled = model.predict(X_scaled).reshape(-1, 1)
                    y_pred = sy.inverse_transform(y_pred_scaled).ravel()

                    df[f"Y_{modelo_key}"] = y_pred
                    metricas[modelo_key] = {
                        'R2': r2_score(y_vals, y_pred),
                        'MSE': mean_squared_error(y_vals, y_pred),
                        'MAE': mean_absolute_error(y_vals, y_pred)
                    }
                except Exception as e:
                    with debug_out:
                        print(f"⚠️ Error al procesar {modelo_key}: {e}")
                        print(f"📁 Contenido del modelo cargado: {list(datos.keys()) if 'datos' in locals() else '❌ No cargado'}")

            with resumen_out:
                display(HTML("<h4>📌 Métricas comparativas:</h4>"))
                filas = [[m, f"{v['R2']:.3f}", f"{v['MSE']:.3f}", f"{v['MAE']:.3f}"] for m, v in metricas.items()]
                display(pd.DataFrame(filas, columns=['Modelo', 'R²', 'MSE', 'MAE']))

            with tabla_out:
                display(HTML("<h4>📊 Tabla X, Y real y predicho (Top 20 casos):</h4>"))
                display(df.head(20))
                try:
                    import pyperclip
                    pyperclip.copy(df.to_csv(sep=';', index=False))
                    print("📋 Copiado al portapapeles")
                except:
                    print("⚠️ pyperclip no disponible")

            with grafico_out:
                plt.figure(figsize=(10,6))
                plt.scatter(df['X'], df['Y_real'], label='Y Real', color='black', s=50, alpha=0.6)
                for col in df.columns:
                    if col.startswith("Y_"):
                        modelo = col[2:]
                        if modelo in metricas:
                            plt.scatter(df['X'], df[col], label=f"{modelo} (R²={metricas[modelo]['R2']:.2f})", alpha=0.6)
                plt.xlabel(var_x)
                plt.ylabel('Y')
                plt.title(f"Comparación Y real vs predicción - {var_x} ({dataset})")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        boton_ver.on_click(graficar)

        display(widgets.VBox([
            selector_variable,
            selector_dataset,
            selector_modelos,
            boton_ver,
            resumen_out,
            tabla_out,
            grafico_out,
            debug_out
        ]))

# Artifact: exec exec_145
display(out_graf_86)

# Artifact: exec exec_146
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Artifact: exec exec_147
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, median_absolute_error

# Artifact: exec exec_148
from IPython.display import display, clear_output, HTML, Javascript

# Artifact: exec exec_149
import optuna

# Artifact: exec exec_150
from skopt import BayesSearchCV

# Artifact: exec exec_151
from skopt.space import Real, Categorical

# Artifact: exec exec_152
import scipy.stats as stats

# Artifact: exec exec_153
from scipy.stats import shapiro

# Artifact: assign out_opt_svr
out_opt_svr = widgets.Output()

# Artifact: function mostrar_optimizacion_svr
def mostrar_optimizacion_svr():
    with out_opt_svr:
        clear_output()

        # 1) Verifico que ya se haya segmentado X_train/X_test
        if 'X_train' not in globals() or 'X_test' not in globals():
            print("❌ Ejecute primero la segmentación para definir X_train y X_test.")
            return

        # 2) Ahora sí puedo sanear columnas
        # Usar sanitize_name para limpiar columnas en el payload
        def clean_cols(col_list):
            return [sanitize_name(c) for c in col_list]
        # Ejemplo de sanitización de X_train antes de fit
        X_train.columns = [sanitize_name(col) for col in X_train.columns]
        X_test.columns = [sanitize_name(col) for col in X_test.columns]

        display(HTML("<h3 style='color:#2E8B57;'>🔧 Optimización de Hiperparámetros - Modelo SVR</h3>"))
        display(HTML("""
            <h3 style='color:#2E8B57;'>🔧 Optimización de Hiperparámetros - Modelo SVR</h3>
            <p>Este módulo permite encontrar la mejor configuración de hiperparámetros del modelo SVR
            usando distintos motores de optimización. Cada motor aplica estrategias diferentes de búsqueda del óptimo:</p>
            <ul>
                <li><b>GridSearchCV</b>: búsqueda exhaustiva sobre combinaciones definidas. Garantiza el hallazgo del mejor resultado entre todas las combinaciones, pero puede ser computacionalmente costoso.</li>
                <li><b>RandomizedSearchCV</b>: muestreo aleatorio sobre el espacio de búsqueda. Acelera el proceso seleccionando combinaciones al azar.</li>
                <li><b>Optuna</b>: optimización bayesiana con estrategia de aprendizaje secuencial. Aprende de cada iteración para mejorar la siguiente.</li>
                <li><b>BayesSearchCV</b>: búsqueda bayesiana usando scikit-optimize. Muy eficaz para espacios amplios con hiperparámetros complejos.</li>
                <li><b>HalvingGridSearchCV</b>: búsqueda jerárquica que evalúa inicialmente muchas configuraciones con pocos recursos y reserva los recursos mayores solo a las mejores.</li>
            </ul>

            <h4 style="color:#1E90FF;">📘 ¿Qué es la Validación Cruzada?</h4>
            <p>La validación cruzada (CV) evalúa la capacidad de generalización de un modelo dividiendo los datos en varias particiones ("folds").
            En cada iteración, uno de los folds se usa como conjunto de validación mientras los restantes se usan para entrenamiento.
            El modelo se entrena y valida múltiples veces y luego se promedia la métrica para obtener una evaluación más robusta.</p>
            <p>Esto reduce el riesgo de sobreajuste y asegura que el modelo funciona correctamente en datos que no ha visto.</p>

            <h4 style="color:#1E90FF;">📊 ¿Qué son los residuos?</h4>
            <p>Los residuos son la diferencia entre los valores reales (observados) y los predichos por el modelo.
            Se calculan como:</p>
            <pre>residuo = valor_real - valor_predicho</pre>
            <p>Interpretación:</p>
            <ul>
                <li>🔹 Residuos cercanos a cero indican buen ajuste.</li>
                <li>🔹 Una distribución normal de los residuos es deseable: implica que los errores son aleatorios.</li>
                <li>🔹 La presencia de sesgos, asimetrías o colas en los residuos puede indicar fallos estructurales del modelo.</li>
            </ul>
            <p>Además de los histogramas, se utiliza el test de Shapiro-Wilk para evaluar si los residuos siguen una distribución normal:</p>
            <pre>p-value > 0.05 ➜ los residuos se consideran normales.</pre>

            <h4 style="color:#1E90FF;">📉 Comparativa Visual entre Modelos</h4>
            <p>Una vez obtenidos los 5 mejores modelos, se genera una comparativa visual con las métricas R², MSE, MAE, RMSE y MedAE
            para facilitar la selección del modelo más robusto en función de las prioridades del usuario.</p>
            <p>También se generan histogramas de residuos para evaluar el comportamiento del error y gráficos Q-Q para validar la normalidad de dichos residuos.</p>
            <p>Se incluirán gráficos de barras para comparar métricas entre modelos y residuos superpuestos para identificar el más preciso.</p>
            <hr>
            <p style="color:gray;">Puedes lanzar la optimización seleccionando el método de selección de variables (Pearson, MutualInfo, etc.) y los motores deseados.</p>
            """))

        metodos = list(RESUMEN_METODOS.keys()) if isinstance(RESUMEN_METODOS, dict) else []
        if not metodos:
            display(HTML("<span style='color:red;'>⚠️ No se encontraron variables seleccionadas por ningún método en RESUMEN_METODOS.</span>"))
            return

        metodo_selector = widgets.Dropdown(
            options=metodos + ['Todos'],
            description='Variables X:',
            layout=widgets.Layout(width='50%')
        )

        funcion_selector = widgets.Dropdown(
            options=['R2', 'MSE', 'MAE', 'RMSE', 'MedAE'],
            value='R2',
            description='Función objetivo:',
            layout=widgets.Layout(width='50%')
        )

        motor_selector = widgets.SelectMultiple(
            options=['GridSearchCV', 'RandomizedSearchCV', 'Optuna', 'BayesSearchCV', 'Todos'],
            value=['GridSearchCV'],
            description='Motores de Optimización:',
            layout=widgets.Layout(width='70%', height='100px')
        )

        btn_ejecutar = widgets.Button(description='🚀 Ejecutar Optimización', button_style='success')
        progreso = widgets.HTML()
        traza = widgets.Output()
        salida_resultados = widgets.Output()

        def ejecutar_optimizacion(_):
            with salida_resultados:
                clear_output()
            with traza:
                clear_output()
                print("🟢 Iniciando optimización...")

            inicio = time.time()
            metodos_a_probar = metodos if metodo_selector.value == 'Todos' else [metodo_selector.value]
            motores = ['GridSearchCV', 'RandomizedSearchCV', 'Optuna', 'BayesSearchCV'] if 'Todos' in motor_selector.value else list(motor_selector.value)

            mejores_modelos = []

            for metodo in metodos_a_probar:
                with traza:
                    print(f"\n🔍 Optimizando para variables seleccionadas por: {metodo}")
                #vars_x = RESUMEN_METODOS.get(metodo, [])
                #if not vars_x:
                #    with traza:
                #        print(f"⚠️ No hay variables seleccionadas por {metodo}. Se omite.")
                #    continue
                # ——— AÑADIDO: limpiar lista de variables antes de indexar ———
                raw_vars = RESUMEN_METODOS.get(metodo, [])
                if not raw_vars:
                    with traza:
                        print(f"⚠️ No hay variables para {metodo}, omito.")
                    continue
                vars_x = clean_cols(raw_vars)
                # ——— FIN AÑADIDO ———
                try:
                    X_train_sel = X_train[vars_x].copy()
                    X_test_sel = X_test[vars_x].copy()
                    y_train_sel = Y_train.values.ravel()
                    y_test_sel = Y_test.values.ravel()

                    sx = StandardScaler()
                    sy = StandardScaler()
                    X_train_scaled = sx.fit_transform(X_train_sel)
                    X_test_scaled = sx.transform(X_test_sel)
                    y_train_scaled = sy.fit_transform(y_train_sel.reshape(-1, 1)).ravel()

                    def calcular_score(y_real, y_pred):
                        if funcion_selector.value == 'R2': return r2_score(y_real, y_pred)
                        elif funcion_selector.value == 'MSE': return mean_squared_error(y_real, y_pred)
                        elif funcion_selector.value == 'MAE': return mean_absolute_error(y_real, y_pred)
                        elif funcion_selector.value == 'RMSE': return np.sqrt(mean_squared_error(y_real, y_pred))
                        elif funcion_selector.value == 'MedAE': return median_absolute_error(y_real, y_pred)

                    def objetivo_optuna(trial):
                        C = trial.suggest_float('C', 1e-2, 1e3, log=True)
                        epsilon = trial.suggest_float('epsilon', 1e-4, 0.5, log=True)
                        kernel = trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly'])
                        degree = trial.suggest_int('degree', 2, 4) if kernel == 'poly' else 3

                        #C = trial.suggest_float('C', 0.1, 100, log=True)
                        #epsilon = trial.suggest_float('epsilon', 0.01, 1.0, log=True)
                        #kernel = trial.suggest_categorical('kernel', ['rbf', 'linear'])

                        #svr = SVR(C=C, epsilon=epsilon, kernel=kernel)

                        svr = SVR(C=C, epsilon=epsilon, kernel=kernel, degree=degree)
                        svr.fit(X_train_scaled, y_train_scaled)
                        y_pred = sy.inverse_transform(svr.predict(X_test_scaled).reshape(-1, 1)).ravel()
                        score = calcular_score(y_test_sel, y_pred)
                        return score if funcion_selector.value == 'R2' else -score

                    for motor in motores:
                        with traza:
                            print(f"⚙️ Motor: {motor} → Variables: {len(vars_x)} → Datos: {X_train_scaled.shape}")

                        best_model = None

                        if motor == 'GridSearchCV':
                            grid = GridSearchCV(
                                SVR(),
#                                param_grid={
#                                    'C': [0.1, 1, 10, 100],
#                                    'epsilon': [0.01, 0.1, 0.5, 1],
#                                    'kernel': ['rbf', 'linear']
#                                },
                                param_grid= {
                                    'C': [0.01, 0.1, 1, 10, 100, 1000],
                                    'epsilon': [0.001, 0.01, 0.1, 0.5],
                                    'kernel': ['rbf', 'linear', 'poly'],
                                    'degree': [2, 3]  # solo si kernel = poly
                                },
                                scoring='r2', cv=3, n_jobs=-1
                            )
                            grid.fit(X_train_scaled, y_train_scaled)
                            best_model = grid.best_estimator_

                        elif motor == 'RandomizedSearchCV':
                            rand = RandomizedSearchCV(
                                SVR(),
#                                param_distributions={
#                                    'C': np.logspace(-1, 2, 20),
#                                    'epsilon': np.logspace(-2, 0, 20),
#                                    'kernel': ['rbf', 'linear']
#                                },
                                param_distributions={
                                    'C': stats.reciprocal(1e-2, 1e3),
                                    'epsilon': stats.reciprocal(1e-4, 0.5),
                                    'kernel': ['rbf', 'linear', 'poly'],
                                    'degree': stats.randint(2, 4)
                                },
                                scoring='r2', n_iter=30, cv=3, n_jobs=-1, random_state=42
                            )
                            rand.fit(X_train_scaled, y_train_scaled)
                            best_model = rand.best_estimator_

                        elif motor == 'Optuna':
                            study = optuna.create_study(direction='maximize' if funcion_selector.value == 'R2' else 'minimize')
                            study.optimize(objetivo_optuna, n_trials=30)
                            best_model = SVR(**study.best_params)
                            best_model.fit(X_train_scaled, y_train_scaled)

                        elif motor == 'BayesSearchCV':
                            bayes = BayesSearchCV(
                                SVR(),
#                                search_spaces={
#                                    'C': Real(0.1, 100, prior='log-uniform'),
#                                    'epsilon': Real(0.01, 1.0, prior='log-uniform'),
#                                    'kernel': Categorical(['rbf', 'linear'])
#                                },
                                search_spaces={
                                    'C': Real(1e-2, 1e3, prior='log-uniform'),
                                    'epsilon': Real(1e-4, 0.5, prior='log-uniform'),
                                    'kernel': Categorical(['rbf', 'linear', 'poly']),
                                    'degree': (2, 4)
                                },
                                scoring='r2', cv=3, n_iter=30, n_jobs=-1, random_state=42
                            )
                            bayes.fit(X_train_scaled, y_train_scaled)
                            best_model = bayes.best_estimator_

                        y_pred = sy.inverse_transform(best_model.predict(X_test_scaled).reshape(-1, 1)).ravel()
                        score = calcular_score(y_test_sel, y_pred)
                        mejores_modelos.append((f"{metodo} - {motor}", best_model, score, y_test_sel, y_pred))

                        with traza:
                            print(f"✅ {metodo} [{motor}] → {funcion_selector.value}: {score:.4f}")

                        # ──────────────────────────────────────────────────
                        # ⬇️  Bloque de Grabación de resultados - persistencia
                        # ──────────────────────────────────────────────────
                        try:
                            from pathlib import Path
                            import pickle

                            save_dir = Path("modelos_opt")
                            save_dir.mkdir(exist_ok=True)

                            modelo_fname = (
                                save_dir / f"modelo_svr_{metodo.lower()}_opt_{motor.lower()}.pkl"
                            )
                            study_fname = (
                                save_dir / f"optuna_svr_{metodo.lower()}_opt_{motor.lower()}.pkl"
                            )

                            # Obtener nombre Y de forma robusta
                            if isinstance(Y_train, pd.Series):
                                y_name = Y_train.name or "target"
                            else:  # DataFrame (una sola columna)
                                y_name = Y_train.columns[0] if Y_train.shape[1] == 1 else "target"

                            payload = {
                                "model":  best_model,
                                "sx":     sx,
                                "sy":     sy,
                                "cols":   vars_x,
                                "yname":  y_name,
                                "score":  score,
                                "metric": funcion_selector.value,
                            }

                            with open(modelo_fname, "wb") as f:
                                pickle.dump(payload, f)

                            study_fname = "optuna_study.pkl"   # nombre que espera la celda 10
                            if motor.lower() == "optuna" and "study" in locals():
                                with open(study_fname, "wb") as f:
                                    pickle.dump(study, f)
                                with traza: print(f"📁 Estudio Optuna guardado en: {study_fname}")

                            with traza: print(f"💾 Modelo guardado en: {modelo_fname}")

                            # Registrar en un diccionario global opcional
                            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
                            OPT_MODELS[("svr", metodo.lower(), motor.lower())] = payload
                            if motor.lower() == "optuna" and "study" in locals():
                                OPT_MODELS[("svr", metodo.lower(), "optuna_study")] = study

                        except Exception as e:
                            with traza: print(f"⚠️ No se pudo guardar el modelo o estudio: {e}")
                        # ──────────────────────────────────────────────
                        # ⬆️  FIN DEL BLOQUE DE PERSISTENCIA
                        # ──────────────────────────────────────────────
                except Exception as e:
                    with traza:
                        print(f"❌ Error al optimizar {metodo}: {e}")

            with salida_resultados:
                if mejores_modelos:
                    mejores_modelos.sort(key=lambda x: x[2], reverse=(funcion_selector.value == 'R2'))
                    top5 = mejores_modelos[:5]

                    df_top5 = pd.DataFrame([{
                        'Método-Motor': m[0],
                        funcion_selector.value: round(m[2], 4),
                        'C': m[1].C,
                        'Epsilon': m[1].epsilon,
                        'Kernel': m[1].kernel
                    } for m in top5])

                    display(HTML("<h4 style='color:#2E8B57;'>📊 Top 5 Modelos Optimizado...</h4>"))
                    display(df_top5.style.set_caption("Top 5 configuraciones SVR")
                            .set_properties(**{'border': '1px solid gray', 'text-align': 'center'})
                            .set_table_styles([{'selector': 'th', 'props': [('background-color', '#2E8B57'), ('color', 'white')]}]))

                    mejor = top5[0]
                    metodo_motor, model, score, y_real, y_pred = mejor

                    display(HTML(f"""
                    <h4 style='color:green;'>🎯 Mejor configuración encontrada:</h4>
                    <b>Método:</b> {metodo_motor}<br>
                    <b>{funcion_selector.value}:</b> {score:.4f}
                    <hr>
                    <h4>📋 Detalle de Hiperparámetros:</h4>
                    """))

                    df_hp = pd.DataFrame({
                        'Parámetro': ['C', 'epsilon', 'kernel'],
                        'Valor Óptimo': [model.C, model.epsilon, model.kernel],
                        'Descripción': [
                            'Penalización del margen. Equilibra error y generalización',
                            'Zona de tolerancia sin penalización en el error',
                            'Función que transforma el espacio (lineal o no lineal)'
                        ],
                        'Rango Típico': ['0.1 – 100', '0.01 – 1.0', 'rbf / linear']
                    })

                    display(df_hp.style.set_table_styles([
                        {'selector': 'th', 'props': [('background-color', '#2E8B57'), ('color', 'white')]},
                        {'selector': 'td', 'props': [('text-align', 'center')]}
                    ]).set_properties(**{'border': '1px solid gray', 'padding': '6px'}))

                    plt.figure(figsize=(8, 5))
                    plt.plot(y_real, label='Real', marker='o')
                    plt.plot(y_pred, label='Predicción', marker='x')
                    plt.title(f'Y Real vs Y Predicho (Mejor SVR - {metodo_motor})')
                    plt.legend()
                    plt.grid()
                    plt.tight_layout()
                    plt.show()

                    # ===============================================================
                    # Análisis de Residuos del Mejor Modelo
                    # ===============================================================
                    residuos = y_real - y_pred

                    display(HTML("<h4 style='color:#2E8B57;'>📉 Análisis de Residuos del Mejor Modelo</h4>"))
                    display(HTML("""
                    <p>Los <b>residuos</b> representan la diferencia entre los valores reales (observados) y los predichos por el modelo.
                    Evaluar su comportamiento ayuda a determinar si el modelo ha capturado correctamente la estructura de los datos.</p>
                    <ul>
                    <li><b>Residuos = Valor Real – Valor Predicho</b></li>
                    <li>Distribución simétrica centrada en cero es señal de buen ajuste</li>
                    <li>Asimetría, colas largas o concentraciones pueden indicar sobreajuste, variables omitidas u otros problemas.</li>
                    </ul>
                    """))

                    # Estadísticas básicas
                    res_stats = pd.DataFrame({
                        'Métrica': ['Media', 'Desviación estándar', 'Mínimo', 'Máximo'],
                        'Valor': [np.mean(residuos), np.std(residuos), np.min(residuos), np.max(residuos)]
                    })
                    display(res_stats.style.set_caption("📌 Estadísticas de los Residuos")
                            .set_properties(**{'border': '1px solid gray', 'text-align': 'center'})
                            .set_table_styles([{'selector': 'th', 'props': [('background-color', '#2E8B57'), ('color', 'white')]}]))

                    # Histograma de residuos
                    plt.figure(figsize=(8,4))
                    plt.hist(residuos, bins=25, color='skyblue', edgecolor='black')
                    plt.title('📊 Histograma de Residuos')
                    plt.xlabel('Residuo')
                    plt.ylabel('Frecuencia')
                    plt.grid(True)
                    plt.tight_layout()
                    plt.show()

                    # Gráfico Q-Q
                    plt.figure(figsize=(6, 6))
                    stats.probplot(residuos, dist="norm", plot=plt)
                    plt.title('📈 Gráfico Q-Q de los Residuos')
                    plt.grid(True)
                    plt.tight_layout()
                    plt.show()

                    # Test de normalidad de Shapiro-Wilk
                    residuos_validos = residuos[~np.isnan(residuos) & ~np.isinf(residuos)]

                    display(HTML("<h4>📐 Test de Normalidad (Shapiro-Wilk)</h4>"))

                    print(f"Número de residuos válidos: {len(residuos_validos)}")
                    print("Primeros residuos válidos:", residuos_validos[:10])

                    if residuos_validos.size >= 3:
                        try:
                            stat, p = shapiro(residuos_validos)
                            interpretacion = '✅ Residuos normales (p > 0.05)' if p > 0.05 else '⚠️ Residuos no normales (p ≤ 0.05)'
                            display(HTML(f"""
                                <ul>
                                    <li><b>Estadístico:</b> {stat:.4f}</li>
                                    <li><b>p-valor:</b> {p:.4f}</li>
                                    <li>{interpretacion}</li>
                                </ul>
                            """))
                        except Exception as e:
                            display(HTML(f"<span style='color:red;'>❌ Error al ejecutar el test de Shapiro: {e}</span>"))
                    else:
                        display(HTML("<span style='color:red;'>❌ No hay suficientes datos válidos para realizar el test de normalidad.</span>"))

                    # ==========================================================
                    # 🔍 ANALISIS COMPARATIVO AVANZADO
                    # ==========================================================
                    # ============================================
                    # 📊 CREACIÓN DE DATAFRAME DE MÉTRICAS PARA COMPARATIVA
                    # ============================================
                    metricas_df = pd.DataFrame([
                        {
                            'Modelo': nombre,
                            'R2': r2_score(y_real, y_pred),
                            'MSE': mean_squared_error(y_real, y_pred),
                            'MAE': mean_absolute_error(y_real, y_pred),
                            'RMSE': np.sqrt(mean_squared_error(y_real, y_pred)),
                            'MedAE': median_absolute_error(y_real, y_pred)
                        }
                        for nombre, modelo, _, y_real, y_pred in top5
                    ])

                    # ============================================
                    # 🔥 MAPA DE CALOR DE MÉTRICAS
                    # ============================================
                    metricas_norm = (metricas_df.drop('Modelo', axis=1) - metricas_df.drop('Modelo', axis=1).min()) / (
                        metricas_df.drop('Modelo', axis=1).max() - metricas_df.drop('Modelo', axis=1).min())
                    plt.figure(figsize=(10, 5))
                    sns.heatmap(metricas_norm.T, annot=True, cmap='YlGnBu', xticklabels=metricas_df['Modelo'], fmt=".2f")
                    plt.title("🌡️ Mapa de Calor de Métricas Normalizadas")
                    plt.tight_layout()
                    plt.show()

                    # ============================================
                    # 🎯 RADAR CHART DE MÉTRICAS
                    # ============================================
                    #import matplotlib.pyplot as plt
                    from math import pi

                    # Preparar datos
                    categorias = list(metricas_df.columns[1:])
                    N = len(categorias)
                    angles = [n / float(N) * 2 * pi for n in range(N)]
                    angles += angles[:1]

                    plt.figure(figsize=(8, 6))
                    for i in range(len(metricas_df)):
                        valores = metricas_df.iloc[i, 1:].values.flatten().tolist()
                        valores += valores[:1]
                        plt.polar(angles, valores, label=metricas_df.iloc[i, 0], marker='o')

                    plt.xticks(angles[:-1], categorias, color='grey', size=8)
                    plt.title("🎯 Radar Chart - Comparativa Multimétrica")
                    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
                    plt.tight_layout()
                    plt.show()

                    # ===============================================================
                    # ACopiar resultados al portapapeles
                    # ===============================================================
                    btn_copiar = widgets.Button(description='📋 Copiar Hiperparámetros', button_style='info')
                    def copiar(_):
                        texto = str(model.get_params())
                        js = f"navigator.clipboard.writeText(`{texto}`)"
                        display(Javascript(js))
                        print("📋 Copiados al portapapeles.")
                    btn_copiar.on_click(copiar)
                    display(btn_copiar)

                else:
                    print("⚠️ No se encontró ninguna configuración óptima válida.")

            progreso.value = f"⏱️ Tiempo total de optimización: {time.time() - inicio:.2f} segundos"

        btn_ejecutar.on_click(ejecutar_optimizacion)

        display(widgets.VBox([
            metodo_selector,
            funcion_selector,
            motor_selector,
            btn_ejecutar,
            progreso,
            traza,
            salida_resultados
        ]))

# Artifact: exec exec_156
display(out_opt_svr)

# Artifact: exec exec_157
from ipywidgets import VBox, HBox, Dropdown, IntSlider, IntText, IntProgress, FloatSlider, SelectMultiple, Button, Output, HTML, Accordion

# Artifact: exec exec_158
from tensorflow import keras

# Artifact: exec exec_159
from tensorflow.keras import layers, regularizers

# Artifact: exec exec_160
from tensorflow.keras import mixed_precision

# Artifact: exec exec_161
mixed_precision.set_global_policy('mixed_float16')

# Artifact: exec exec_162
from tensorflow.keras.callbacks import EarlyStopping, Callback

# Artifact: class TimeStopping
class TimeStopping(Callback):
    """Detiene el entrenamiento si supera un tiempo máximo (en segundos)."""
    def __init__(self, max_seconds=600):
        super().__init__()
        self.max_seconds = max_seconds

    def on_train_begin(self, logs=None):
        self.start_time = time.time()

    def on_epoch_end(self, epoch, logs=None):
        if time.time() - self.start_time > self.max_seconds:
            self.model.stop_training = True

# Artifact: exec exec_164
import signal

# Artifact: class TimeoutException
class TimeoutException(Exception):
    pass

# Artifact: function _timeout_handler
def _timeout_handler(signum, frame):
    raise TimeoutException()

# Artifact: exec exec_167
signal.signal(signal.SIGALRM, _timeout_handler)

# Artifact: class R2
class R2(tf.keras.metrics.Metric):
    def __init__(self, name='r2', **kwargs):
        super().__init__(name=name, **kwargs)
        self.sse = self.add_weight(name='sse', initializer='zeros')
        self.sst = self.add_weight(name='sst', initializer='zeros')
    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.cast(y_pred, tf.float32)
        resid = tf.reduce_sum(tf.square(y_true - y_pred))
        mean_true = tf.reduce_mean(y_true)
        sst_value = tf.reduce_sum(tf.square(y_true - mean_true))
        self.sse.assign_add(resid)
        self.sst.assign_add(sst_value)
    def result(self):
        return 1.0 - (self.sse / (self.sst + tf.keras.backend.epsilon()))
    def reset_states(self):
        self.sse.assign(0.0)
        self.sst.assign(0.0)

# Artifact: exec exec_169
from keras_tuner import RandomSearch, BayesianOptimization, Hyperband, Objective

# Artifact: assign ayuda_parametros
ayuda_parametros = HTML("""
<h4>📘 Explicación de Parámetros</h4>
<ul>
  <li><b>Métodos X:</b> Métodos de selección de variables predictoras. Usan correlaciones estadísticas o algoritmos de reducción de dimensión. <br>
      <i>Pearson</i> y <i>Spearman</i>: correlaciones lineales y monótonas.<br>
      <i>MutualInfo</i>: mide dependencia informacional. <br>
      <i>Boruta</i>: selección envolvente basada en árboles. <br>
      <i>UMAP</i>: reducción no lineal de dimensiones. <br>
      <b>Todos</b> ejecuta cada uno secuencialmente.</li>
  <li><b>Motores:</b> Algoritmos de optimización de hiperparámetros. <br>
      <i>RandomSearch</i>: búsqueda aleatoria. <br>
      <i>BayesianOptimization</i>: estima regiones óptimas. <br>
      <i>Hyperband</i>: eficiente para grandes espacios de búsqueda. <br>
      <i>Optuna</i>: flexible y potente. <br>
      <b>Todos</b> ejecuta todos los motores.</li>
  <li><b>Función objetivo:</b> Métrica a maximizar o minimizar: <br>
      <i>R2</i>: se desea maximizar. <i>MAE</i> y <i>MSE</i>: se minimizan.</li>
  <li><b>Trials:</b> Número de combinaciones a evaluar en la búsqueda.</li>
  <li><b>Épocas:</b> Iteraciones completas sobre el dataset de entrenamiento (100 a 2000 recomendado).</li>
  <li><b>Capas:</b> Cantidad de capas ocultas en la red (1 a 20 habitual, máximo 100 para pruebas avanzadas).</li>
  <li><b>Neuronas/capa:</b> Número de neuronas por capa (32 a 512 recomendado).</li>
  <li><b>Dropout:</b> Fracción de neuronas descartadas en entrenamiento (0.1 a 0.4 recomendado).</li>
  <li><b>L2 Reg:</b> Regularización L2 para evitar sobreajuste (0.001 a 0.01 habitual).</li>
</ul>
""")

# Artifact: assign select_metodos
select_metodos = SelectMultiple(
    options=['Pearson', 'Spearman', 'Mutualinfo', 'Boruta', 'UMAP', 'Todos'],
    description='Métodos Selección Variables X:',
    layout={'width': '50%'}
)

# Artifact: assign select_motores
select_motores = SelectMultiple(
    options=['RandomSearch', 'BayesianOptimization', 'Hyperband', 'Optuna', 'Todos'],
    description='Motores:',
    layout={'width': '50%'}
)

# Artifact: assign func_objetivo
func_objetivo = Dropdown(
    options=['R2', 'MAE', 'MSE'],
    value='R2',
    description='Función objetivo:',
    layout={'width': '40%'}
)

# Artifact: assign n_trials_slider
n_trials_slider = IntSlider(value=10, min=1, max=50, step=1, description='Trials:')

# Artifact: assign rango_epocas
rango_epocas = IntSlider(value=500, min=1, max=200, step=10, description='Épocas:')

# Artifact: assign rango_capas
rango_capas = IntSlider(value=3, min=1, max=6, step=1, description='Capas:')

# Artifact: assign rango_neuronas
rango_neuronas = IntSlider(value=64, min=256, max=512, step=8, description='Neuronas/capa:')

# Artifact: assign dropout_rate
dropout_rate = FloatSlider(value=0.2, min=0.0, max=0.7, step=0.05, description='Dropout:')

# Artifact: assign l2_reg
l2_reg = FloatSlider(value=0.001, min=0.0, max=0.01, step=0.0005, description='L2 Reg:')

# Artifact: assign btn_ejecutar
btn_ejecutar = Button(description='🚀 Ejecutar Optimización NN', button_style='success')

# Artifact: assign progreso_bar
progreso_bar = IntProgress(min=0, max=1, description='Progreso:', style={'bar_color': 'green'})

# Artifact: assign out_nn
out_nn = Output()

# Artifact: function ejecutar_optimizacion
def ejecutar_optimizacion(_):
    with out_nn:
        clear_output()

        # 2) Ahora sí puedo sanear columnas
        # Usar sanitize_name para limpiar columnas en el payload
        def clean_cols(col_list):
            return [sanitize_name(c) for c in col_list]
        # Ejemplo de sanitización de X_train antes de fit
        X_train.columns = [sanitize_name(col) for col in X_train.columns]
        X_test.columns = [sanitize_name(col) for col in X_test.columns]

        print("⏳ Iniciando optimización...")
        start_time = time.time()
        max_total_time = 6000   # 100 minutos en total para TODO el tuning
        resultados_modelos = []

        for metodo in select_metodos.value:
            print(f"🔍 Método: {metodo}")
            # Simulación de filtrado de variables según el método seleccionado
            X_train_sel, X_test_sel = X_train.copy(), X_test.copy()
            y_train_sel, y_test_sel = Y_train.copy(), Y_test.copy()

            # ──────────────────────────────────────────────────────────
            # Si el usuario marca “Todos”, reemplazamos esa opción
            motores = list(select_motores.value)
            if "Todos" in motores:
                motores = ["RandomSearch", "BayesianOptimization", "Hyperband", "Optuna"]
            # ──────────────────────────────────────────────────────────
            from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError
            #from tensorflow_addons.metrics import RSquare  # si lo tienes instalado

            #for motor in select_motores.value:
            for motor in motores:
                print(f"⚙️ Motor: {motor}")

                # ——— AÑADIDO: tope global de tiempo ———
                # 1. Chequeo de tiempo PARA ESTE motor
                elapsed = time.time() - start_time
                if elapsed > max_total_time:
                    print(f"⏹️ Tiempo agotado antes de {motor} en {metodo}; sigo con el siguiente método.")
                    break   # solo sale del bucle 'motor'
                # ——— FIN AÑADIDO ———

                metric_name = func_objetivo.value.lower()
                direction = 'max' if metric_name == 'r2' else 'min'
                # Ahora monitorizamos la métrica de validación correcta:
                tuner_metric = f"val_{metric_name}"                 # 'val_r2', 'val_mae' o 'val_mse'

                #tuner_metric = 'val_loss' if metric_name == 'r2' else metric_name
                #tuner_metric = 'val_r2'   if metric_name=='r2' else f'val_{metric_name}'

                def build_model(hp):
                    model = keras.Sequential()
                    model.add(layers.Input(shape=(X_train_sel.shape[1],)))
                    for i in range(hp.Int('layers', 1, rango_capas.max)):
                        model.add(layers.Dense(hp.Int(f'units_{i}', 8, rango_neuronas.max), activation='relu'))
                        model.add(layers.Dropout(hp.Float(f'dropout_{i}', 0.0, dropout_rate.max)))
                    model.add(layers.Dense(1))
                    #model.compile(optimizer='adam', loss='mse')
                    model.compile(
                        optimizer='adam',
                        loss='mse',
                        metrics=[R2(name='r2'),
                                tf.keras.metrics.MeanSquaredError(name='mse'),
                                tf.keras.metrics.MeanAbsoluteError(name='mae')]
                    )
                    return model

                #callbacks = [EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]
                # ——— AÑADIDO: EarlyStopping con min_delta + TimeStopping ———
                callbacks = [
                    EarlyStopping(
                        monitor=tuner_metric,      # mejorar según la métrica que toque
                        mode = 'max' if metric_name == 'r2' else 'min',
                        min_delta=1e-1,            # mejora mínima del 10%
                        patience=3,               # si no mejora tras 3 épocas, cortar
                        restore_best_weights=True
                    ),
                    TimeStopping(max_seconds=120)  # tope de 120 s (~2 min) por modelo
                ]
                # ——— FIN AÑADIDO ———

                # Eliminar directorios previos si existen
                if motor == 'RandomSearch':
                    tuner_dir = f'randomsearch_dir/random_{metodo}'
                    if os.path.exists(tuner_dir):
                        shutil.rmtree(tuner_dir)
                    tuner = RandomSearch(
                        build_model,
                        objective=Objective(tuner_metric, direction=direction),
                        max_trials=n_trials_slider.value,
                        executions_per_trial=1,
                        directory='randomsearch_dir',
                        project_name=f'random_{metodo}'
                    )
                    #tuner.search(X_train_sel, y_train_sel, epochs=rango_epocas.value, validation_split=0.2, verbose=1, callbacks=callbacks)
                    # ——— AÑADIDO: timeout para este tuner ———
                    remaining = max_total_time - (time.time() - start_time)
                    # no menos de 1 segundo
                    timeout_secs = int(max(1, remaining))
                    signal.alarm(timeout_secs)
                    try:
                        tuner.search(
                          X_train_sel, y_train_sel,
                          epochs=rango_epocas.value,
                          validation_split=0.2,
                          verbose=1,
                          callbacks=callbacks
                        )
                    except TimeoutException:
                        print(f"⏹️ RandomSearch ({metodo}) interrumpido tras {timeout_secs}s")
                    finally:
                        signal.alarm(0)
                  # ——— FIN AÑADIDO ———
                    best_hps = tuner.get_best_hyperparameters(1)[0]

                elif motor == 'BayesianOptimization':
                    tuner_dir = f'bo_dir/bo_{metodo}'
                    if os.path.exists(tuner_dir):
                        shutil.rmtree(tuner_dir)
                    tuner = BayesianOptimization(
                        build_model,
                        objective=Objective(tuner_metric, direction=direction),
                        max_trials=n_trials_slider.value,
                        directory='bo_dir',
                        project_name=f'bo_{metodo}'
                    )
                    #tuner.search(X_train_sel, y_train_sel, epochs=rango_epocas.value, validation_split=0.2, verbose=1, callbacks=callbacks)
                    # ——— AÑADIDO: timeout para este tuner ———
                    remaining = max_total_time - (time.time() - start_time)
                    # no menos de 1 segundo
                    timeout_secs = int(max(1, remaining))
                    signal.alarm(timeout_secs)
                    try:
                        tuner.search(
                           X_train_sel, y_train_sel,
                           epochs=rango_epocas.value,
                           validation_split=0.2,
                           verbose=1,
                           callbacks=callbacks
                        )
                    except TimeoutException:
                        print(f"⏹️ RandomSearch ({metodo}) interrumpido tras {timeout_secs}s")
                    finally:
                        signal.alarm(0)
                    # ——— FIN AÑADIDO ———
                    best_hps = tuner.get_best_hyperparameters(1)[0]

                elif motor == 'Hyperband':
                    tuner_dir = f'hyperband_dir/hyper_{metodo}'
                    if os.path.exists(tuner_dir):
                        shutil.rmtree(tuner_dir)
                    tuner = Hyperband(
                        build_model,
                        objective=Objective(tuner_metric, direction=direction),
                        #max_epochs=rango_epocas.max,
                        max_epochs=rango_epocas.value,
                        factor=4,                         # ← de 2 a 4 ⇒ menos brackets
                        directory='hyperband_dir',
                        project_name=f'hyper_{metodo}'
                    )
                    # ─── AÑADIDO AQUÍ: callbacks específicos para Hyperband ───
                    callbacks = [
                        EarlyStopping(
                            monitor=tuner_metric,
                            mode = 'max' if metric_name == 'r2' else 'min',  # <— aquí le decimos a Keras qué queremos
                            min_delta=1e-2,
                            patience=2,
                            restore_best_weights=True
                        ),
                        TimeStopping(max_seconds=120)
                    ]
                    # ─── FIN AÑADIDO ───

                    #tuner.search(X_train_sel, y_train_sel, validation_split=0.2, verbose=1, callbacks=callbacks)
                    #tuner.search(X_train_sel, y_train_sel, epochs=rango_epocas.value, validation_split=0.2, verbose=1, callbacks=callbacks)

                    # ——— AÑADIDO: timeout para este tuner ———
                    remaining = max_total_time - (time.time() - start_time)
                    # no menos de 1 segundo
                    timeout_secs = int(max(1, remaining))
                    signal.alarm(timeout_secs)
                    try:
                        tuner.search(
                           X_train_sel, y_train_sel,
                           epochs=rango_epocas.value,
                           validation_split=0.2,
                           verbose=1,
                           callbacks=callbacks
                        )
                    except TimeoutException:
                        print(f"⏹️ RandomSearch ({metodo}) interrumpido tras {timeout_secs}s")
                    finally:
                        signal.alarm(0)
                    # ——— FIN AÑADIDO ———
                    best_hps = tuner.get_best_hyperparameters(1)[0]

                elif motor == 'Optuna':
                    def objective(trial):
                        model = keras.Sequential()
                        model.add(layers.Input(shape=(X_train_sel.shape[1],)))
                        for i in range(trial.suggest_int('n_layers', 1, rango_capas.max)):
                            model.add(layers.Dense(trial.suggest_int(f'n_units_l{i}', 8, rango_neuronas.max), activation='relu'))
                            model.add(layers.Dropout(trial.suggest_float(f'dropout_l{i}', 0.0, dropout_rate.max)))
                        model.add(layers.Dense(1))
                        model.compile(optimizer='adam', loss='mse')
                        #model.fit(X_train_sel, y_train_sel, epochs=rango_epocas.value, batch_size=32, verbose=0, validation_split=0.2)
                        model.fit(X_train_sel, y_train_sel, epochs=rango_epocas.value, batch_size=32, verbose=1, validation_split=0.2, callbacks=callbacks)
                        preds = model.predict(X_test_sel).ravel()
                        return -r2_score(y_test_sel, preds) if func_objetivo.value == 'R2' else mean_absolute_error(y_test_sel, preds)

                    direction = 'maximize' if func_objetivo.value == 'R2' else 'minimize'

                    #study = optuna.create_study(direction=direction)
                    # ——— AÑADIDO: Pruner para cortar trials poco prometedores ———
                    from optuna.pruners import MedianPruner
                    remaining = max_total_time - (time.time() - start_time)
                    if remaining <= 0:
                        print("⏹️ Ya no queda tiempo para Optuna.")
                        continue

                    study = optuna.create_study(direction=direction,
                                              pruner=MedianPruner(n_startup_trials=3, n_warmup_steps=10))
                    # timeout detiene el optimize tras X segundos, sin esperar a n_trials
                    study.optimize(objective,
                                  n_trials=n_trials_slider.value,
                                  timeout=remaining)
                    # ——— FIN AÑADIDO ———
                    #study.optimize(objective, n_trials=n_trials_slider.value)

                    best_params = study.best_params

                progreso_bar.value += 1
                print(f"✅ Completado: Método {metodo}, Motor {motor}")
                print(f"✅ Optimización completada en {time.time() - start_time:.2f} segundos.")

                # Placeholder para evaluación final
                model = keras.Sequential()
                model.add(layers.Input(shape=(X_train_sel.shape[1],)))
                for _ in range(rango_capas.value):
                    model.add(layers.Dense(rango_neuronas.value, activation='relu'))
                    model.add(layers.Dropout(dropout_rate.value))
                model.add(layers.Dense(1))
                model.compile(optimizer='adam', loss='mse')
                model.fit(X_train_sel, y_train_sel, epochs=rango_epocas.value, batch_size=32, verbose=0, callbacks=callbacks)

                y_pred = model.predict(X_test_sel).ravel()
                r2 = r2_score(y_test_sel, y_pred)
                mae = mean_absolute_error(y_test_sel, y_pred)
                mse = mean_squared_error(y_test_sel, y_pred)

                # *********************************************************
                # Visualización del modelo optimizado
                # *********************************************************
                fig, ax = plt.subplots(figsize=(6, 4))
                ax.scatter(range(len(y_pred)), y_test_sel.values.ravel(), label='Y Real')
                ax.plot(range(len(y_pred)), y_pred, color='orange', label='Y Predicho')
                ax.set_title(f"XY-Y Real vs. Predicho: {metodo}-{motor}")
                ax.set_xlabel("Casos")
                ax.set_ylabel("Y")
                ax.legend()
                ax.grid(True)
                plt.tight_layout()
                plt.show()

                # ──────────────────────────────────────────────────────────────
                # 🔒  BLOQUE DE PERSISTENCIA  (NO ALTERA LA LÓGICA EXISTENTE)
                #     · Guarda el mejor modelo de cada motor en /modelos_opt
                #     · Guarda escaladores y columnas en un .pkl auxiliar
                #     · Guarda el study de Optuna, si existe
                # ──────────────────────────────────────────────────────────────
                try:
                    from pathlib import Path
                    import pickle

                    # 1️⃣  Métrica que queremos persistir como «score»
                    if func_objetivo.value == "R2":
                        score_val = r2
                    elif func_objetivo.value == "MAE":
                        score_val = mae
                    else:                                 # "MSE"
                        score_val = mse

                    # ---------- rutas ----------
                    save_dir = Path("modelos_opt")
                    save_dir.mkdir(exist_ok=True)

                    # nombre robusto variable-objetivo
                    if isinstance(Y_train, pd.Series):
                        y_name = Y_train.name or "target"
                    else:                                # DataFrame
                        y_name = Y_train.columns[0] if Y_train.shape[1] == 1 else "target"

                    base_fname  = f"nn_{metodo.lower()}_opt_{motor.lower()}"
                    model_fname = save_dir / f"modelo_{base_fname}.h5"          # modelo
                    meta_fname  = save_dir / f"meta_{base_fname}.pkl"           # metadatos
                    study_fname = save_dir / f"optuna_{base_fname}.pkl"         # estudio Optuna

                    # ---------- modelo ----------
                    model_to_save = model                # alias universal
                    model_to_save.save(model_fname, include_optimizer=True)

                    best_hps_dict = {}
                    if motor in ("RandomSearch","BayesianOptimization","Hyperband"):
                        # para Keras Tuner:
                        best_hps = tuner.get_best_hyperparameters(1)[0]
                        best_hps_dict = {
                          "layers":  best_hps.get("layers"),
                          "neurons": best_hps.get("units_0"),
                          "dropout": best_hps.get("dropout_0"),
                          "epochs":  rango_epocas.value
                        }
                    elif motor == "Optuna":
                        # Optuna:
                        best_hps_dict = study.best_params.copy()
                        best_hps_dict["epochs"] = rango_epocas.value

                    # Comprobación de scalers
                    if 'sx' not in locals():
                        sx = None
                    if 'sy' not in locals():
                        sy = None

                    # Extrae los hiperparámetros relevantes asegurando ambos nombres
                    # (esto funciona tanto para Optuna como KerasTuner)
                    layers_ = best_hps_dict.get("layers") or best_hps_dict.get("n_layers")
                    neurons_ = best_hps_dict.get("neurons") or best_hps_dict.get("n_units_l0")
                    dropout_ = best_hps_dict.get("dropout") or best_hps_dict.get("dropout_l0")
                    epochs_ = best_hps_dict.get("epochs")

                    meta_payload = {
                        "sx":    locals().get("sx", None),
                        "sy":    locals().get("sy", None),
                        "cols":  X_train_sel.columns.tolist(),
                        "yname": y_name,
                        "score": float(score_val),
                        "metric": func_objetivo.value,
                        "motor": motor,
                        "metodo": metodo,
                        # Nombres duplicados para compatibilidad máxima
                        "layers": layers_,
                        "n_layers": layers_,
                        "neurons": neurons_,
                        "n_units_l0": neurons_,
                        "dropout": dropout_,
                        "dropout_l0": dropout_,
                        "epochs": epochs_,
                        **{k: v for k, v in best_hps_dict.items() if k not in ["layers", "n_layers", "neurons", "n_units_l0", "dropout", "dropout_l0", "epochs"]}
                    }

                    with open(meta_fname, "wb") as f_meta:
                        pickle.dump(meta_payload, f_meta)

                    # ---------- Optuna ----------
                    msg_opt = ""
                    if motor == "Optuna" and "study" in locals():
                        with open(study_fname, "wb") as f_st:
                            pickle.dump(study, f_st)
                        msg_opt = f" · Estudio guardado → {study_fname}"

                    # ---------- feedback ----------
                    try:                                        # usa traza si existe
                        with traza:
                            print(f"💾 Modelo guardado → {model_fname}")
                            print(f"🗂️  Metadatos     → {meta_fname}{msg_opt}")
                    except NameError:
                        print(f"💾 Modelo guardado → {model_fname}")
                        print(f"🗂️  Metadatos     → {meta_fname}{msg_opt}")

                    # ---------- registro global opcional ----------
                    OPT_MODELS = globals().setdefault("OPT_MODELS", {})
                    OPT_MODELS[("nn", metodo.lower(), motor.lower())] = {
                        # 1️⃣ rutas de fichero obligatorias
                        "model_path":  str(model_fname),
                        "meta_path":   str(meta_fname),
                        # guardamos el propio objeto (o su path si prefieres)
                        "model":       model_to_save,
                        # escaladores
                        "sx":          sx,
                        "sy":          sy,
                        # columnas utilizadas
                        "cols":        X_train_sel.columns.tolist(),
                        # métrica y score
                        "metric":      func_objetivo.value,
                        "score":       float(score_val),
                        # metadatos de optimización
                        "motor":       motor,
                        "metodo":      metodo,
                        # hiperparámetros, duplicados para compat
                        "layers":      layers_,
                        "n_layers":    layers_,
                        "neurons":     neurons_,
                        "n_units_l0":  neurons_,
                        "dropout":     dropout_,
                        "dropout_l0":  dropout_,
                        "epochs":      epochs_,
                        # cualquier otro parámetro de best_hps_dict
                        **{k: v for k, v in best_hps_dict.items()
                            if k not in {"layers","neurons","dropout","epochs"}}
                    }

                    if motor == "Optuna" and "study" in locals():
                        OPT_MODELS[("nn", metodo.lower(), "optuna_study")] = study

                except Exception as e:
                    # si algo falla, avisa pero NO interrumpe la optimización
                    try:
                        with traza:
                            print(f"⚠️  No se pudo guardar el modelo o estudio: {e}")
                    except NameError:
                        print(f"⚠️  No se pudo guardar el modelo o estudio: {e}")
                # ──────────────────────────────────────────────────────────────
                # 🔚  FIN BLOQUE DE PERSISTENCIA
                # ──────────────────────────────────────────────────────────────

                resultados_modelos.append({
                    'Motor': motor, 'Método': metodo,
                    'R2': r2, 'MAE': mae, 'MSE': mse,
                    'Épocas': rango_epocas.value,
                    'Capas': rango_capas.value,
                    'Neuronas': rango_neuronas.value,
                    'Dropout': dropout_rate.value,
                    'L2': l2_reg.value
                })

            # tras bucle motores, chequeo global de tiempo  # MODIFICADO
            if time.time() - start_time > max_total_time:
                print("⏹️ Tiempo total agotado; salgo de métodos.")
                break  # rompe bucle métodos

        global df_results
        df_results = pd.DataFrame(resultados_modelos)
        df_top5 = df_results.sort_values(by=func_objetivo.value, ascending=(func_objetivo.value != 'R2')).head(5)
        best = df_top5.iloc[0]

        display(HTML("<h4>🏆 Top 5 Modelos Optim.</h4>"))
        display(df_top5.style.set_caption("Modelos Óptimos").format(precision=4))

        y_pred = model.predict(X_test_sel).ravel()
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.scatter(y_test_sel, y_pred, alpha=0.6)
        ax.plot([y_test_sel.min(), y_test_sel.max()], [y_test_sel.min(), y_test_sel.max()], 'r--')
        ax.set_title("Y Real vs. Y Predicho")
        ax.set_xlabel("Y Real")
        ax.set_ylabel("Y Predicho")
        plt.grid(True)
        plt.show()

        #residuos = y_test_sel - y_pred
        residuos = y_test_sel.values.ravel() - y_pred
        plt.figure(figsize=(6, 4))
        plt.scatter(y_pred, residuos, alpha=0.6)
        plt.axhline(0, color='red', linestyle='--')
        plt.title("Residuos vs. Predicción")
        plt.xlabel("Y Predicho")
        plt.ylabel("Residuos")
        plt.grid(True)
        plt.show()

        stat, p_value = shapiro(residuos)
        display(HTML(f"<b>📊 Test de Shapiro:</b> p = {p_value:.5f} → {'Normal' if p_value > 0.05 else 'No normal'}"))

        from math import pi
        categorias = ['R2', 'MAE', 'MSE']
        valores = [best['R2'], best['MAE'], best['MSE']]
        valores += valores[:1]
        angles = [n / float(len(categorias)) * 2 * pi for n in range(len(categorias))]
        angles += angles[:1]
        plt.figure(figsize=(6, 6))
        ax = plt.subplot(111, polar=True)
        plt.xticks(angles[:-1], categorias)
        ax.plot(angles, valores, linewidth=2)
        ax.fill(angles, valores, alpha=0.3)
        plt.title("Radar de Métricas")
        plt.show()

        global NN_RESULTADOS_TOP5, NN_MEJOR_MODELO, NN_RESIDUOS, NN_METODO_MEJOR, NN_MOTOR_MEJOR
        NN_RESULTADOS_TOP5 = df_top5
        NN_MEJOR_MODELO = best
        NN_RESIDUOS = residuos
        NN_METODO_MEJOR = best['Método']
        NN_MOTOR_MEJOR = best['Motor']

# ***********************************************************************
# Visualización de los mejores modelos optimizados
# ***********************************************************************
        for idx, row in df_top5.iterrows():
            metodo, motor = row['Método'], row['Motor']
            model = keras.Sequential()
            model.add(layers.Input(shape=(X_train_sel.shape[1],)))
            for _ in range(int(row['Capas'])):
                model.add(layers.Dense(int(row['Neuronas']), activation='relu'))
                model.add(layers.Dropout(row['Dropout']))
            model.add(layers.Dense(1))
            model.compile(optimizer='adam', loss='mse')
            model.fit(X_train_sel, y_train_sel, epochs=rango_epocas.value, batch_size=32, verbose=0, callbacks=callbacks)

            y_pred = model.predict(X_test_sel).ravel()
            fig, ax = plt.subplots(figsize=(6, 4))
            ax.scatter(range(len(y_pred)), y_test_sel.values.ravel(), label='Y Real')
            ax.plot(range(len(y_pred)), y_pred, color='orange', label='Y Predicho')
            ax.set_title(f"XY-Y Real vs. Predicho: {metodo}-{motor}")
            ax.set_xlabel("Casos")
            ax.set_ylabel("Y")
            ax.legend()
            ax.grid(True)
            plt.tight_layout()
            plt.show()

        print(f"✅ Optimización completada en {time.time() - start_time:.2f} segundos.")

# Artifact: assign control_panel
control_panel = VBox([
    HTML("<h3>🔧 Configuración Optimización NN</h3>"),
    ayuda_parametros,
    HBox([select_metodos, select_motores]),
    func_objetivo,
    n_trials_slider,
    HBox([rango_epocas, rango_capas]),
    HBox([rango_neuronas, dropout_rate, l2_reg]),
    btn_ejecutar,
    progreso_bar,
    out_nn
])

# Artifact: function mostrar_optimizacion_nn
def mostrar_optimizacion_nn():
    display(control_panel)

# Artifact: exec exec_186
try:
    btn_ejecutar._click_handlers.callbacks.clear()
except:
    pass

# Artifact: exec exec_187
btn_ejecutar.on_click(ejecutar_optimizacion)

# Artifact: function mostrar_optimizacion_xgb
def mostrar_optimizacion_xgb():
    from IPython.display import display, HTML, clear_output
    import pandas as pd
    import ipywidgets as widgets
    import traceback
    import matplotlib.pyplot as plt
    import seaborn as sns
    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
    from sklearn.model_selection import RandomizedSearchCV
    from xgboost import XGBRegressor
    import numpy as np
    from skopt import BayesSearchCV  # Motor de optimización bayesiano
    # Importar Hyperband
    from sklearn.experimental import enable_halving_search_cv  # noqa
    from sklearn.model_selection import HalvingRandomSearchCV
    # Importar Optuna
    from optuna.integration import OptunaSearchCV
    import optuna
    optuna.logging.set_verbosity(optuna.logging.INFO)
    from optuna.distributions import IntDistribution, FloatDistribution

    # Mostrar progreso en RandomSearch mediante logging
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    global out_opt_xgb, traza_xgb
    out_opt_xgb   = widgets.Output()      # panel principal
    traza_xgb     = widgets.Output()      # trazas de cada motor

    # ========= AÑADIDOS: Funciones de saneamiento =========

    # 2) Ahora sí puedo sanear columnas
    # Usar sanitize_name para limpiar columnas en el payload
    def clean_cols(col_list):
        return [sanitize_name(c) for c in col_list]
    # Ejemplo de sanitización de X_train antes de fit
    X_train.columns = [sanitize_name(col) for col in X_train.columns]
    X_test.columns = [sanitize_name(col) for col in X_test.columns]

    # ——— SANITIZAR LISTAS DE RESUMEN_METODOS ———
    for metodo, vars_ in RESUMEN_METODOS.items():
        if isinstance(vars_, list):
            RESUMEN_METODOS[metodo] = [sanitize_name(v) for v in vars_]
        elif isinstance(vars_, pd.DataFrame) and not vars_.empty:
            # asumimos que la columna de variable se llama "Variable" o la primera
            col = 'Variable' if 'Variable' in vars_.columns else vars_.columns[0]
            # saneamos esa columna in‑place
            RESUMEN_METODOS[metodo][col] = vars_[col].astype(str).map(sanitize_name)
    # ——— FIN SANITIZACIÓN RESUMEN_METODOS ———

    #import re

    #def clean_columns(df):
    #    """
    #    Transforma todos los nombres de columna a str y sustituye
    #    corchetes, %, <, > y espacios por guiones bajos.
    #    """
    #    df = df.copy()
    #    df.columns = (
    #        df.columns
    #          .astype(str)
    #          .str.replace(r'[\[\]<>%]', '_', regex=True)
    #          .str.replace(r'\s+', '_', regex=True)
    #          .str.strip('_')
    #    )
    #    return df

    #def clean_cols(var_list):
    #    """
    #    Limpia una lista de nombres de columna con las mismas reglas.
    #    """
    #    return [
    #        re.sub(r'[\[\]<>%]', '_', str(v))
    #          .replace(' ', '_')
    #          .strip('_')
    #        for v in var_list
    #    ]

    # ======================================================

    # 📌 Parámetros configurables del motor de optimización
    slider_n_iter = widgets.IntSlider(value=50, min=10, max=300, step=10,
                                      description='n_iter:', layout=widgets.Layout(width='45%'))
    ayuda_n_iter = widgets.HTML("<small><b>n_iter:</b> número de combinaciones aleatorias a probar (mayor = más preciso, pero más lento). No aplica a  Hyperbrand.</small>")

    slider_cv = widgets.IntSlider(value=3, min=2, max=10, step=1,
                                  description='cv:', layout=widgets.Layout(width='45%'))
    ayuda_cv = widgets.HTML("<small><b>cv:</b> número de particiones para validación cruzada (mínimo 2)</small>")

    selector_funcion_objetivo = widgets.Dropdown(
        options=['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'],
        value='r2',
        description='Función:',
        layout=widgets.Layout(width='45%')
    )
    ayuda_funcion = widgets.HTML("<small><b>Función:</b> métrica a optimizar. R2 para ajuste, MSE o MAE para error</small>")

    def seleccionar_variables_filtradas(metodo):
        global X_train, Y_train, X_test, RESUMEN_METODOS

        # --- AÑADIDO: sanear columnas globales antes de todo ---
        #X_train = clean_columns(X_train)
        #X_test  = clean_columns(X_test)
        # --- FIN AÑADIDO -----------------------------------------

        print(f"\n🔧 [seleccionar_variables_filtradas] Iniciando con método: '{metodo}'")
        try:
            assert 'X_train' in globals(), "❌ 'X_train' no está definido"
            assert 'Y_train' in globals(), "❌ 'Y_train' no está definido"
            assert 'RESUMEN_METODOS' in globals(), "❌ 'RESUMEN_METODOS' no está definido"

            vars_sel = []
            if metodo.strip().lower() == "todos":
                all_vars = []
                for k, df in RESUMEN_METODOS.items():
                    if isinstance(df, list):
                        all_vars.extend(df)
                    elif isinstance(df, pd.DataFrame) and not df.empty:
                        col = 'Variable' if 'Variable' in df.columns else df.columns[0]
                        all_vars.extend(df[col].dropna().tolist())
                vars_sel = list(set(all_vars))
            elif metodo in RESUMEN_METODOS:
                df_vars = RESUMEN_METODOS[metodo]
                if isinstance(df_vars, list):
                    vars_sel = df_vars
                elif isinstance(df_vars, pd.DataFrame):
                    if not df_vars.empty:
                        col = 'Variable' if 'Variable' in df_vars.columns else df_vars.columns[0]
                        vars_sel = df_vars[col].dropna().tolist()
                    else:
                        return
                else:
                    return
            else:
                return
            if not vars_sel:
                return

            columnas_faltantes = [col for col in vars_sel if col not in X_train.columns]
            if columnas_faltantes:
                print(f"❌ Columnas no existentes en X_train: {columnas_faltantes}")
                return


        #    # ——— AÑADIDO: obtener y limpiar lista raw_vars ———
        #    raw_vars = []
        #    if metodo.strip().lower() == "todos":
        #        all_vars = []
        #        for df in RESUMEN_METODOS.values():
        #            if isinstance(df, list):
        #                all_vars += df
        #            elif isinstance(df, pd.DataFrame) and not df.empty:
        #                col = 'Variable' if 'Variable' in df.columns else df.columns[0]
        #                all_vars += df[col].dropna().tolist()
        #        raw_vars = list(set(all_vars))
        #    elif metodo in RESUMEN_METODOS:
        #        df_vars = RESUMEN_METODOS[metodo]
        #        if isinstance(df_vars, list):
        #            raw_vars = df_vars
        #        elif isinstance(df_vars, pd.DataFrame) and not df_vars.empty:
        #            col = 'Variable' if 'Variable' in df_vars.columns else df_vars.columns[0]
        #            raw_vars = df_vars[col].dropna().tolist()
        #    else:
        #        return

        #    if not raw_vars:
        #        with traza_xgb:
        #            print(f"⚠️ No hay variables para '{metodo}'.")
        #        return

            # limpiar lista de nombres
        #    vars_sel = clean_cols(raw_vars)

        #    # comprobar que existen tras limpiar
        #    faltantes = [c for c in vars_sel if c not in X_train.columns]
        #    if faltantes:
        #        with traza_xgb:
        #            print(f"❌ Columnas no existentes en X_train: {faltantes}")
        #        return
        #    # ——— FIN AÑADIDO ———

            X_sel = X_train[vars_sel].copy()
            Y_sel = Y_train.copy()
            globals()['X_train_filtrado'] = X_sel
            globals()['Y_train_filtrado'] = Y_sel
            globals()['metodo_usado_xgb'] = metodo

        except Exception as e:
            print("❌ Excepción atrapada desde consola principal:")
            print(traceback.format_exc())

    def ejecutar_metricas_finales(modelo, nombre_motor="Desconocido"):
        try:
            X_test_filtrado = X_test[X_train_filtrado.columns]
            preds = best_model.predict(X_test_filtrado)

            r2 = r2_score(Y_test, preds)
            mse = mean_squared_error(Y_test, preds)
            mae = mean_absolute_error(Y_test, preds)

            df_metricas = pd.DataFrame({
                'Métrica': ['R2', 'MSE', 'MAE'],
                'Valor': [r2, mse, mae]
            })
            display(df_metricas.style.set_caption("📈 Rendimiento del Modelo Óptimo").format(precision=4))

            # Cálculo de residuos y análisis
            residuos = Y_test.values.ravel() - preds.ravel()
            df_residuos = pd.DataFrame({
                'Índice': range(len(residuos)),
                'Y_real': Y_test.values.ravel(),
                'Y_predicho': preds.ravel(),
                'Residuo': residuos
            })
            display(df_residuos.head().style.set_caption("🧮 Ejemplo de Cálculo de Residuos"))

            # Histograma de residuos
            plt.figure(figsize=(6, 4))
            sns.histplot(residuos, bins=30, kde=True, color='skyblue')
            plt.axvline(0, color='red', linestyle='--')
            plt.title("Histograma de Residuos")
            plt.xlabel("Residuo (Y_real - Y_predicho)")
            plt.ylabel("Frecuencia")
            plt.show()

            # 📌 Prueba de normalidad de Shapiro-Wilk
            stat, p_value = shapiro(residuos)
            display(HTML(f"<h4>🧪 Prueba de Normalidad (Shapiro-Wilk)</h4><ul><li>Estadístico: {stat:.4f}</li><li>p-valor: {p_value:.4f}</li><li>{'✅ Los residuos siguen una distribución normal (p > 0.05)' if p_value > 0.05 else '⚠️ Los residuos no siguen una distribución normal (p ≤ 0.05)'}</li></ul>"))

            # Explicación de los resultados
            display(HTML("""
                <h4>🧾 Explicación de Resultados:</h4>
                <ul>
                    <li><b>R2:</b> mide el grado de ajuste del modelo. Valores cercanos a 1 indican buen ajuste.</li>
                    <li><b>MSE:</b> error cuadrático medio. Penaliza más los errores grandes.</li>
                    <li><b>MAE:</b> error absoluto medio. Más robusto ante valores atípicos.</li>
                    <li><b>Residuos:</b> diferencia entre el valor real y el predicho. Deben estar centrados en 0.</li>
                    <li><b>Histograma:</b> ayuda a evaluar si los residuos siguen una distribución normal.</li>
                    <li><b>Shapiro-Wilk:</b> prueba estadística que indica si los residuos son normales. Se acepta normalidad si p > 0.05.</li>
                </ul>
            """))

            # Gráficas modelo optimo
            plt.figure(figsize=(10, 4))
            plt.subplot(1, 2, 1)
            plt.plot(Y_test.values, label='Real')
            plt.plot(preds, label='Predicho')
            plt.legend()
            plt.title("X-Y Real vs X-Y Predicho")

            plt.subplot(1, 2, 2)
            plt.scatter(Y_test, preds, alpha=0.6)
            min_val = min(Y_test.values.min(), preds.min())
            max_val = max(Y_test.values.max(), preds.max())
            plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Ideal')
            plt.xlabel("Y real")
            plt.ylabel("Y predicho")
            plt.title("Y Real vs Y Predicho")
            plt.legend()

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print("❌ Error en métricas finales:", traceback.format_exc())
    # ────────────────────────────────────────────────────────────────
    # 🔒 FUNCIÓN DE PERSISTENCIA  (XGBoost)
    # ────────────────────────────────────────────────────────────────
    import pickle, pathlib, datetime
    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

    def guardar_xgb(best_model, best_params, nombre_motor,
                    metodo_usado_xgb, selector_funcion_objetivo,
                    X_train_filtrado, X_test, Y_train, Y_test,
                    study=None, traza_out=None):
        score_val = None
        try:
            # 1) carpeta
            pathlib.Path("modelos_opt").mkdir(exist_ok=True)

            # 3) nombre robusto de variable-objetivo
            y_name = getattr(Y_train, "name", None) or \
                    (Y_train.columns[0] if hasattr(Y_train, "columns") else "Y")

            # 4) rutas
            ts      = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            tag     = f"xgb_{metodo_usado_xgb.lower()}_{nombre_motor.lower()}_opt_{ts}"
            model_f = f"modelos_opt/{tag}.pkl"
            meta_f  = f"modelos_opt/{tag}_meta.pkl"
            study_f = f"modelos_opt/{tag}_study.pkl"

            # 5) modelo
            with open(model_f, "wb") as f:
                pickle.dump(best_model, f)

            # 6) metadatos
            meta = dict(
                score       = float(score_val),
                func_obj    = selector_funcion_objetivo.value,
                motor       = nombre_motor,
                metodo_x    = metodo_usado_xgb,
                cols        = list(X_train_filtrado.columns),
                yname       = y_name,
                best_params = best_params,
                fecha       = ts,
            )
            with open(meta_f, "wb") as f:
                pickle.dump(meta, f)

            # 7) estudio Optuna (si procede)
            if nombre_motor.lower() == "optuna" and study is not None:
                with open(study_f, "wb") as f:
                    pickle.dump(study, f)

        except Exception as e:
            # Si score_val aún no se ha calculado, no emitir warning
            if score_val is None:
                return
            if traza_out is not None:
                with traza_out:
                    print(f"⚠️  No se pudo guardar modelo/estudio: {e}")
            else:
                print(f"⚠️  No se pudo guardar modelo/estudio: {e}")

    # ===================================================
    # Motor de Optimización RandomSearch CV
    # ===================================================
    def optimizar_randomsearch():
        try:
            assert 'X_train_filtrado' in globals()
            assert 'Y_train_filtrado' in globals()

            print("📌 Iniciando optimización con RandomSearch...")
            funcion_objetivo = selector_funcion_objetivo.value
            n_iter_val = slider_n_iter.value
            cv_val = slider_cv.value
            print(f"🎯 Función de optimización seleccionada: {funcion_objetivo} (n_iter={n_iter_val}, cv={cv_val})")

            param_dist = {
                'n_estimators': list(range(50, 300)),
                'max_depth': list(range(3, 15)),
                'learning_rate': np.linspace(0.01, 0.3, 30),
                'subsample': np.linspace(0.5, 1.0, 20),
                'colsample_bytree': np.linspace(0.5, 1.0, 20),
                'gamma': np.linspace(0, 5, 20)
            }

            print(f"🔧 Hiperparámetros a optimizar: {list(param_dist.keys())}")
            print(f"🔁 Número de iteraciones: {n_iter_val}, Validación cruzada (cv): {cv_val}")

            model = XGBRegressor(random_state=42, verbosity=0)
            search = RandomizedSearchCV(model, param_distributions=param_dist,
                                        n_iter=n_iter_val, scoring=funcion_objetivo, cv=cv_val, random_state=42,
                                        n_jobs=-1, verbose=3)

            # ——— AÑADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TRAIN ———
            # 1) Forzar que todos los nombres sean str
            #X_train_filtrado.columns = X_train_filtrado.columns.astype(str)
            ## 2) Reemplazar corchetes y '<', '>' por '_'
            #X_train_filtrado.columns = (
            #    X_train_filtrado
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ——— FIN AÑADIDO ———
            # # ——— AÑADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TEST ———
            #X_test.columns = X_test.columns.astype(str)
            #X_test.columns = (
            #    X_test
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ——— FIN AÑADIDOS ———

            search.fit(X_train_filtrado, Y_train_filtrado)

            global best_model, best_params
            best_model = search.best_estimator_
            best_params = search.best_params_
            tabla_resultados = pd.DataFrame(best_params.items(), columns=['Hiperparámetro', 'Valor óptimo'])
            display(tabla_resultados.style.set_caption("📋 Tabla de Hiperparámetros Óptimos").format(precision=4))

            ejecutar_metricas_finales(best_model, nombre_motor="RandomSearch")

            # ─── Tras best_model, best_params en optimizar_randomsearch() ───
            # Calcular el score real con los datos de test
            preds = best_model.predict(X_test[X_train_filtrado.columns])
            if selector_funcion_objetivo.value == "r2":
                score_val = r2_score(Y_test, preds)
            elif selector_funcion_objetivo.value == "neg_mean_absolute_error":
                score_val = mean_absolute_error(Y_test, preds)
            else:
                score_val = mean_squared_error(Y_test, preds)

            # Guardar en OPT_MODELS
            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "randomsearch")] = {
                "model":       best_model,
                "score":       float(score_val),
                "metric":      selector_funcion_objetivo.value,
                "param_dist":  param_dist,           # <- espacio RandomSearch
                "best_params": best_params,
                "cols":        list(X_train_filtrado.columns)
            }
            # ──────────────────────────────────────────────────────────────────

            # --- llamada de persistencia ----
            guardar_xgb(best_model, best_params, "RandomSearch",
                        metodo_usado_xgb, selector_funcion_objetivo,
                        X_train_filtrado, X_test, Y_train, Y_test,
                        study=None, traza_out=traza_xgb)
            print("✅ Optimización con RandomSearch completada.")
            # ─── 3) Imprime la confirmación aquí dentro ───
            if traza_xgb is not None:
                with traza_xgb:
                    print(f"💾 Modelo guardado     → modelos_opt/xgb_{metodo_usado_xgb.lower()}_randomsearch_opt_*.pkl")
                    print(f"💾 Metadatos guardados → modelos_opt/xgb_{metodo_usado_xgb.lower()}_randomsearch_opt_*_meta.pkl")

        except Exception as e:
            print("❌ Error en optimización RandomSearch:", traceback.format_exc())

    # ===================================================
    # Motor de Optimización Bayesian
    # ===================================================
    def optimizar_bayesian():
        try:
            assert 'X_train_filtrado' in globals()
            assert 'Y_train_filtrado' in globals()

            print("📌 Iniciando optimización con Bayesian Optimization...")
            funcion_objetivo = selector_funcion_objetivo.value
            n_iter_val = slider_n_iter.value
            cv_val = slider_cv.value

            param_spaces = {
                'n_estimators': (50, 300),
                'max_depth': (3, 15),
                'learning_rate': (0.01, 0.3, 'log-uniform'),
                'subsample': (0.5, 1.0),
                'colsample_bytree': (0.5, 1.0),
                'gamma': (0.0, 5.0)
            }

            print(f"🔧 Hiperparámetros a optimizar: {list(param_spaces.keys())}")
            print(f"🔁 Número de iteraciones: {n_iter_val}, Validación cruzada (cv): {cv_val}")

            model = XGBRegressor(random_state=42, verbosity=0)

            opt = BayesSearchCV(model, search_spaces=param_spaces,
                n_iter=n_iter_val, scoring=funcion_objetivo, cv=cv_val,
                n_jobs=-1, verbose=3, random_state=42)
            opt.fit(X_train_filtrado, Y_train_filtrado)

            global best_model, best_params
            if opt.best_estimator_ is not None:
                best_model = opt.best_estimator_
                best_params = opt.best_params_

            tabla_resultados = pd.DataFrame(best_params.items(), columns=['Hiperparámetro', 'Valor óptimo'])
            display(tabla_resultados.style.set_caption("📋 Tabla de Hiperparámetros Óptimos (Bayesian)").format(precision=4))

            ejecutar_metricas_finales(best_model, nombre_motor="Bayesian")

            # ─── Tras best_model, best_params en optimizar_bayesian() ───
            preds = best_model.predict(X_test[X_train_filtrado.columns])
            if selector_funcion_objetivo.value == "r2":
                score_val = r2_score(Y_test, preds)
            elif selector_funcion_objetivo.value == "neg_mean_absolute_error":
                score_val = mean_absolute_error(Y_test, preds)
            else:
                score_val = mean_squared_error(Y_test, preds)

            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "bayesian")] = {
                "model":       best_model,
                "score":       float(score_val),
                "metric":      selector_funcion_objetivo.value,
                "param_spaces": param_spaces,      # <- espacio BayesSearchCV
                "best_params": best_params,
                "cols":        list(X_train_filtrado.columns)
            }

            # --- llamada de persistencia ----
            guardar_xgb(best_model, best_params, "Bayesian",
                        metodo_usado_xgb, selector_funcion_objetivo,
                        X_train_filtrado, X_test, Y_train, Y_test,
                        study=None, traza_out=traza_xgb)
            print("✅ Optimización con Bayesian Optimization completada.")
            with traza_xgb:
                print(f"💾 Modelo guardado     → modelos_opt/xgb_{metodo_usado_xgb.lower()}_bayesian_opt_*.pkl")
                print(f"💾 Metadatos guardados → modelos_opt/xgb_{metodo_usado_xgb.lower()}_bayesian_opt_*_meta.pkl")

        except Exception as e:
            print("❌ Error en optimización Bayesian:", traceback.format_exc())

    # ===================================================
    # Motor de Optimización HyperBrand
    # ===================================================
    def optimizar_hyperband():
        try:
            assert 'X_train_filtrado' in globals()
            assert 'Y_train_filtrado' in globals()

            print("📌 Iniciando optimización con Hyperband...")
            funcion_objetivo = selector_funcion_objetivo.value
            cv_val = slider_cv.value

            # 🔧 Corregido: se elimina 'n_estimators' de los hiperparámetros buscados
            param_dist = {
                'max_depth': list(range(3, 15)),
                'learning_rate': np.linspace(0.01, 0.3, 30),
                'subsample': np.linspace(0.5, 1.0, 20),
                'colsample_bytree': np.linspace(0.5, 1.0, 20),
                'gamma': np.linspace(0, 5, 20)
            }

            model = XGBRegressor(random_state=42, verbosity=0)
            search = HalvingRandomSearchCV(model, param_dist,
                                          scoring=funcion_objetivo, cv=cv_val,
                                          factor=3, resource='n_estimators',
                                          max_resources=300, random_state=42,
                                          verbose=2, n_jobs=-1)

            # ——— AÑADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TRAIN ———
            # 1) Forzar que todos los nombres sean str
            #X_train_filtrado.columns = X_train_filtrado.columns.astype(str)
            # 2) Reemplazar corchetes y '<', '>' por '_'
            #X_train_filtrado.columns = (
            #    X_train_filtrado
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ——— FIN AÑADIDO ———
            # # ——— AÑADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TEST ———
            #X_test.columns = X_test.columns.astype(str)
            #X_test.columns = (
            #    X_test
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ——— FIN AÑADIDOS ———

            search.fit(X_train_filtrado, Y_train_filtrado)

            global best_model, best_params
            best_model = search.best_estimator_
            best_params = search.best_params_

            tabla_resultados = pd.DataFrame(best_params.items(), columns=['Hiperparámetro', 'Valor óptimo'])
            display(tabla_resultados.style.set_caption("📋 Tabla de Hiperparámetros Óptimos (Hyperband)").format(precision=4))

            ejecutar_metricas_finales(best_model, nombre_motor="Hyperband")

            # ─── Tras best_model, best_params en optimizar_hyperband() ───
            preds = best_model.predict(X_test[X_train_filtrado.columns])
            if selector_funcion_objetivo.value == "r2":
                score_val = r2_score(Y_test, preds)
            elif selector_funcion_objetivo.value == "neg_mean_absolute_error":
                score_val = mean_absolute_error(Y_test, preds)
            else:
                score_val = mean_squared_error(Y_test, preds)

            # Hyperband usaba param_dist también
            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "hyperband")] = {
                "model":       best_model,
                "score":       float(score_val),
                "metric":      selector_funcion_objetivo.value,
                "param_dist":  param_dist,           # <- espacio Hyperband
                "best_params": best_params,
                "cols":        list(X_train_filtrado.columns)
            }

            # --- llamada de persistencia ----
            guardar_xgb(best_model, best_params, "Hyperband",
                        metodo_usado_xgb, selector_funcion_objetivo,
                        X_train_filtrado, X_test, Y_train, Y_test,
                        study=None, traza_out=traza_xgb)
            print("✅ Optimización con Hyperband completada.")
            with traza_xgb:
               print(f"💾 Modelo guardado     → modelos_opt/xgb_{metodo_usado_xgb.lower()}_hyperband_opt_*.pkl")
               print(f"💾 Metadatos guardados → modelos_opt/xgb_{metodo_usado_xgb.lower()}_hyperband_opt_*_meta.pkl")

        except Exception as e:
            print("❌ Error en optimización Hyperband:", traceback.format_exc())

    # ===================================================
    # Motor de Optimización Optuna
    # ===================================================
    def optimizar_optuna():
        try:
            print("\n📌 Iniciando optimización con Optuna...")
            assert 'X_train_filtrado' in globals()
            assert 'Y_train_filtrado' in globals()

            # ——— AÑADIDO: Definir escaladores para Optuna ———
            from sklearn.preprocessing import StandardScaler
            # Ajustamos escalador de X sobre el train filtrado
            X_scaler = StandardScaler().fit(X_train_filtrado)
            # Ajustamos escalador de Y (reshape para vector columna)
            y_scaler = StandardScaler().fit(
                Y_train_filtrado.values.reshape(-1, 1)
            )
            # ——— FIN AÑADIDO ———

            param_dist = {
                'n_estimators': IntDistribution(50, 300),
                'max_depth': IntDistribution(3, 15),
                'learning_rate': FloatDistribution(0.01, 0.3),
                'subsample': FloatDistribution(0.5, 1.0),
                'colsample_bytree': FloatDistribution(0.5, 1.0),
                'gamma': FloatDistribution(0, 5)
            }

            model = XGBRegressor(random_state=42, verbosity=0)
            search = OptunaSearchCV(
                estimator=model,
                param_distributions=param_dist,
                scoring=selector_funcion_objetivo.value,
                n_trials=slider_n_iter.value,
                cv=slider_cv.value,
                random_state=42,
                n_jobs=-1
            )

            # ——— AÑADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TRAIN ———
            # 1) Forzar que todos los nombres sean str
            #X_train_filtrado.columns = X_train_filtrado.columns.astype(str)
            # 2) Reemplazar corchetes y '<', '>' por '_'
            #X_train_filtrado.columns = (
            #    X_train_filtrado
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ——— FIN AÑADIDO ———
            # # ——— AÑADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TEST ———
            #X_test.columns = X_test.columns.astype(str)
            #X_test.columns = (
            #    X_test
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ——— FIN AÑADIDOS ———

            search.fit(X_train_filtrado, Y_train_filtrado)
            global best_model
            best_model = search.best_estimator_

            print("\n✅ Hiperparámetros óptimos encontrados con Optuna:")
            global best_params
            best_params = search.best_params_
            display(pd.DataFrame([best_params]).T.rename(columns={0: 'Valor óptimo'}).style.set_caption("📋 Hiperparámetros Óptimos (Optuna)").format(precision=4))

            ejecutar_metricas_finales(best_model, nombre_motor="Optuna")

            # ─── Tras best_model, best_params en optimizar_optuna() ───
            preds = best_model.predict(X_test[X_train_filtrado.columns])
            if selector_funcion_objetivo.value == "r2":
                score_val = r2_score(Y_test, preds)
            elif selector_funcion_objetivo.value == "neg_mean_absolute_error":
                score_val = mean_absolute_error(Y_test, preds)
            else:
                score_val = mean_squared_error(Y_test, preds)

            # Capturamos el espacio usado por Optuna (param_dist) y el estudio
            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "optuna")] = {
                "model":       best_model,
                'sx':          X_scaler,        # tu StandardScaler de X
                'sy':          y_scaler,        # si existe
                "score":       float(score_val),
                "metric":      selector_funcion_objetivo.value,
                "param_dist":  param_dist,           # <- espacio de Optuna
                "best_params": best_params,
                "cols":        list(X_train_filtrado.columns)
            }
            # Si quieres guardar el study:
            if 'study' in locals():
                OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "optuna_study")] = study

            # --- llamada de persistencia ----
            guardar_xgb(best_model, best_params, "Optuna",
                        metodo_usado_xgb, selector_funcion_objetivo,
                        X_train_filtrado, X_test, Y_train, Y_test,
                        study=search.study_, traza_out=traza_xgb)
            print("✅ Optimización con Hyperband completada.")
            with traza_xgb:
                print(f"💾 Modelo guardado     → modelos_opt/xgb_{metodo_usado_xgb.lower()}_optuna_opt_*.pkl")
                print(f"💾 Metadatos guardados → modelos_opt/xgb_{metodo_usado_xgb.lower()}_optuna_opt_*_meta.pkl")

        except Exception as e:
            print("❌ Error en optimización Optuna:", traceback.format_exc())

    opciones_metodos = sorted(list(RESUMEN_METODOS.keys()) + ['Todos'])
    selector_metodo = widgets.Dropdown(
        options=opciones_metodos,
        description='Método:',
        layout=widgets.Layout(width='50%')
    )

    boton_confirmar = widgets.Button(description="📥 Cargar variables seleccionadas", button_style='primary')
    boton_confirmar.on_click(lambda b: seleccionar_variables_filtradas(selector_metodo.value))

    selector_motor = widgets.SelectMultiple(
        options=['RandomSearch', 'Bayesian', 'Hyperband', 'Optuna', 'Todos'],
        value=['RandomSearch'],
        description='Motores:',
        layout=widgets.Layout(width='50%', height='120px')
    )

    boton_opt = widgets.Button(description="🚀 Iniciar Optimización XGBoost", button_style='success')
    #boton_opt.on_click(lambda b: optimizar_randomsearch() if 'RandomSearch' in selector_motor.value or 'Todos' in selector_motor.value else None)

    def lanzar_optimizaciones(_):
        if 'RandomSearch' in selector_motor.value or 'Todos' in selector_motor.value:
            optimizar_randomsearch()
        if 'Bayesian' in selector_motor.value or 'Todos' in selector_motor.value:
            optimizar_bayesian()
        if 'Hyperband' in selector_motor.value or 'Todos' in selector_motor.value:
            optimizar_hyperband()
        if 'Optuna' in selector_motor.value or 'Todos' in selector_motor.value:
            optimizar_optuna()

    boton_opt.on_click(lanzar_optimizaciones)

    out_opt_xgb.clear_output()
    with out_opt_xgb:
        display(HTML("<h3>🔧 Selección de Variables para Optimización XGBoost</h3>"))
        display(widgets.HBox([selector_metodo, boton_confirmar]))
        display(HTML("<h3>⚙️ Parámetros de Optimización</h3>"))
        display(widgets.VBox([
            widgets.HBox([slider_n_iter, slider_cv]),
            widgets.HBox([ayuda_n_iter, ayuda_cv]),
            widgets.HBox([selector_funcion_objetivo]),
            ayuda_funcion
        ]))
        display(HTML("<h3>⚙️ Motores de Optimización</h3>"))
        display(widgets.VBox([selector_motor, boton_opt]))

        display(traza_xgb)             # 🔹 se muestra el panel de trazas

    display(out_opt_xgb)

# Artifact: exec exec_189
from sklearn.model_selection import RandomizedSearchCV

# Artifact: exec exec_190
from sklearn.experimental import enable_halving_search_cv

# Artifact: exec exec_191
from sklearn.model_selection import HalvingRandomSearchCV

# Artifact: exec exec_192
from optuna import Trial

# Artifact: exec exec_193
from optuna.integration import OptunaSearchCV

# Artifact: exec exec_194
from skopt.space import Integer, Categorical

# Artifact: exec exec_195
from scipy.stats import norm

# Artifact: exec exec_196
from scipy.stats import gaussian_kde

# Artifact: exec exec_197
import pathlib, datetime, pickle

# Artifact: exec exec_198
from sklearn.pipeline import Pipeline

# Artifact: exec exec_199
from sklearn.preprocessing import FunctionTransformer

# Artifact: function guardar_rf
def guardar_rf(best_model,
               optimizations_results,
               scaler_X, scaler_Y,
               cols,
               X_test, Y_test,
               func_objetivo,
               study=None,
               traza_out=None):
    try:
        # 1) Asegurar carpeta de destino
        pathlib.Path("modelos_opt").mkdir(exist_ok=True)

        # 2) Preparar datos de prueba filtrados y escalados
        X_test_sel = X_test[cols]
        X_scaled   = scaler_X.transform(X_test_sel)
        preds      = best_model.predict(X_scaled)
        preds_inv  = scaler_Y.inverse_transform(preds.reshape(-1,1)).ravel()

        # 3) Calcular métrica según func_objetivo
        if func_objetivo == "r2":
            score_val = r2_score(Y_test, preds_inv)
        elif func_objetivo == "neg_mean_absolute_error":
            score_val = mean_absolute_error(Y_test, preds_inv)
        else:
            score_val = mean_squared_error(Y_test, preds_inv)

        # 4) Definir rutas de archivo
        ts      = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        tag     = f"rf_{func_objetivo}_opt_{ts}"
        model_f = f"modelos_opt/{tag}.pkl"
        meta_f  = f"modelos_opt/{tag}_meta.pkl"
        study_f = f"modelos_opt/{tag}_study.pkl"

        # 5) Guardar modelo+escaladores+cols
        with open(model_f, "wb") as f:
            pickle.dump({
                "model": best_model,
                "sx":    scaler_X,
                "sy":    scaler_Y,
                "cols":  cols
            }, f)

        # 6) Guardar metadatos
        meta = {
            "score":  float(score_val),
            "metric": func_objetivo,
            "cols":   cols
        }
        with open(meta_f, "wb") as f:
            pickle.dump(meta, f)

        # 7) Guardar estudio Optuna si existe
        if study is not None:
            with open(study_f, "wb") as f:
                pickle.dump(study, f)

        # 8) Mensaje de confirmación
        if traza_out is not None:
            with traza_out:
                print(f"💾 Modelo guardado → {model_f}")
                print(f"💾 Metadatos guardados → {meta_f}")
                if study is not None:
                    print(f"💾 Study guardado → {study_f}")

    except Exception as e:
        msg = f"⚠️ No se pudo guardar modelo/estudio: {e}"
        if traza_out is not None:
            with traza_out:
                print(msg)
        else:
            print(msg)

# Artifact: exec exec_201
import logging

# Artifact: exec exec_202
logging.basicConfig(level=logging.INFO)

# Artifact: assign logger
logger = logging.getLogger(__name__)

# Artifact: assign out_rf_opt
out_rf_opt = widgets.Output()

# Artifact: assign optimizations_results
optimizations_results = []

# Artifact: function mostrar_optimizacion_rf
def mostrar_optimizacion_rf():
    with out_rf_opt:
        clear_output()

        # Aseguramos que las variables X e Y estén definidas globalmente
        global X_train, Y_train, X_test, Y_test
        if 'X_train' not in globals() or 'Y_train' not in globals() or 'X_test' not in globals() or 'Y_test' not in globals():
            print("❌ Asegúrate de que las variables X_train, Y_train, X_test y Y_test estén correctamente definidas.")
            return

        # ─── AÑADIDO: saneamiento global de nombres ───
        #import re
        #def clean_name(s):
        #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))  # corchetes, %, /, . y espacios → _
        #    t = re.sub(r'_+', '_', t)                     # colapsar guiones bajos repetidos
        #    return t.strip('_')

        # 1) Limpio las columnas de X_train y X_test
        #X_train.columns = [clean_name(c) for c in X_train.columns]
        #X_test.columns  = [clean_name(c) for c in X_test.columns]

        # 2) Limpio todas las listas de RESUMEN_METODOS
        #for m, lst in RESUMEN_METODOS.items():
        #    if isinstance(lst, list):
        #        RESUMEN_METODOS[m] = [clean_name(c) for c in lst]
        # ─── FIN AÑADIDO ───

        # 2) Ahora sí puedo sanear columnas
        # Usar sanitize_name para limpiar columnas en el payload
        def clean_cols(col_list):
            return [sanitize_name(c) for c in col_list]
        # Ejemplo de sanitización de X_train antes de fit
        X_train.columns = [sanitize_name(col) for col in X_train.columns]
        X_test.columns = [sanitize_name(col) for col in X_test.columns]

        # Mostrar menú para seleccionar el motor de optimización, el método y la función de optimización
        selector_motor = widgets.Dropdown(
            options=['RandomSearch', 'BayesianOptimization', 'Hyperband', 'Optuna', 'Todos'],
            description='Motor:',
            value='RandomSearch',
            layout=widgets.Layout(width='50%')
        )

        selector_metodo = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'Mutualinfo', 'Boruta', 'UAMP', 'Todos'],
            description='Método:',
            value='Todos',
            layout=widgets.Layout(width='50%')
        )

        func_objetivo = widgets.Dropdown(
            options=['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'],
            value='r2',
            description='Función:',
            layout=widgets.Layout(width='50%')
        )

        # Sliders para la configuración de la optimización
        n_iter = widgets.IntSlider(value=50, min=10, max=300, step=10, description='n_iter:')
        cv = widgets.IntSlider(value=5, min=2, max=10, step=1, description='cv:')

        # Botón de ejecutar optimización
        btn_ejecutar = widgets.Button(description="🚀 Ejecutar Optimización", button_style='success')
        barra_progreso = widgets.IntProgress(min=0, max=1, description='Progreso:')
        salida_resultados = widgets.Output()

        def ejecutar_optimización(_):
            global OPT_MODELS
            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            salida_resultados.clear_output()
            barra_progreso.bar_style = 'info'
            barra_progreso.value = 0
            tiempo_transcurrido = widgets.HTML('⏱️ Tiempo: 0.0s')
            mensaje_estado = widgets.HTML(value="⏳ <b>Optimización en curso...</b>")
            inicio = time.time()

            with salida_resultados:
                print("⏳ Ejecutando optimización...")

                # Escaladores para entrenamiento/test
                scaler_X = StandardScaler().fit(X_train)
                scaler_Y = StandardScaler().fit(Y_train.values.reshape(-1,1))
                X_train_scaled = scaler_X.transform(X_train)
                X_test_scaled  = scaler_X.transform(X_test)
                Y_train_scaled = scaler_Y.transform(Y_train.values.reshape(-1,1)).ravel()
                Y_test_scaled  = scaler_Y.transform(Y_test.values.reshape(-1,1)).ravel()

                # Inicializar motores de optimización
                search_random = None
                search_bayes = None
                search_hyperband = None
                best_rf_random = None
                best_rf_bayes = None
                best_rf_hyperband = None
                best_rf_optuna = None
                best_motor = None
                best_metodo = None
                best_rf = None
                best_score = -np.inf
                optimizations_results = []
                best_score_random = best_score_bayes = best_score_hyperband = best_score_optuna = None

                # Configurar lista de motores y métodos
                motors = (['RandomSearch','BayesianOptimization','Hyperband','Optuna']
                          if selector_motor.value=='Todos'
                          else [selector_motor.value])
                study = None          # placeholder que existirá en todos los motores
                for motor in motors:
                    # Para cada método de selección
                    methods = list(RESUMEN_METODOS.keys()) if selector_metodo.value=='Todos' else [selector_metodo.value]
                    for metodo in methods:
                        print(f"🔧 Motor: {motor} | Método: {metodo}")
                        #cols = RESUMEN_METODOS.get(metodo, X_train.columns.tolist())  # columnas de este método

                        # ——— REEMPLAZO: obtengo directamente las columnas saneadas ———
                        cols = RESUMEN_METODOS.get(metodo, [])
                        if not cols:
                            print(f"⚠️ No hay variables para '{metodo}', omito.")
                            continue
                        # ——— FIN REEMPLAZO ———

                        X_train_sel = X_train[cols]
                        X_test_sel  = X_test[cols]
                        scaler_X = StandardScaler().fit(X_train_sel)
                        X_train_scaled = scaler_X.transform(X_train_sel)
                        X_test_scaled  = scaler_X.transform(X_test_sel)

                        # Aquí nos aseguramos de que Y_train también se escala
                        sy = StandardScaler()
                        Y_train_scaled = sy.fit_transform(Y_train.values.reshape(-1, 1)).ravel()
                        Y_test_scaled = sy.transform(Y_test.values.reshape(-1, 1)).ravel()

                        # =================================================
                        # Motor Random Search
                        # =================================================
                        if motor == 'RandomSearch':
                            param_dist = {
                                'n_estimators': np.arange(50, 501, 50),
                                'max_depth': np.arange(3, 15, 1),
                                'min_samples_split': np.arange(2, 21, 1),
                                'min_samples_leaf': np.arange(1, 21, 1),
                                'max_features': ['sqrt', 'log2', None],
                                'bootstrap': [True, False]
                            }
                            search_random = RandomizedSearchCV(
                                RandomForestRegressor(random_state=42),
                                param_distributions=param_dist,
                                n_iter=n_iter.value,
                                cv=cv.value, n_jobs=-1, scoring=func_objetivo.value, random_state=42,
                                return_train_score=True, verbose=3
                            )
                            search_random.fit(X_train_scaled, Y_train_scaled)
                            best_rf_random = search_random.best_estimator_
                            best_score_random = search_random.best_score_
                            if best_score_random > best_score:
                                best_score = best_score_random
                                best_rf = best_rf_random
                                best_metodo = metodo
                                best_motor  = motor
                            # Almacenar los resultados del motor RandomSearch
                            # ─── Tras best_estimator_ y best_score de cada motor ───
                            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
                            # RandomSearch
                            OPT_MODELS[("rf", metodo.lower(), "randomsearch")] = {
                                "model":       best_rf_random,
                                "sx":          scaler_X,
                                "sy":          sy,
                                "score":       float(best_score_random),
                                "metric":      func_objetivo.value,
                                "param_dist":  param_dist,
                                "best_params": search_random.best_params_,
                                "cols":        cols
                            }
                            optimizations_results.append({
                                'motor' : motor,
                                'metodo': metodo,
                                'puntuación': best_score_random,
                                'R2': r2_score(Y_test_scaled, search_random.predict(X_test_scaled)),
                                'MSE': mean_squared_error(Y_test_scaled, search_random.predict(X_test_scaled)),
                                'MAE': mean_absolute_error(Y_test_scaled, search_random.predict(X_test_scaled)),
                                'params': search_random.best_params_
                            })

                            pass
                        # =================================================
                        # Motor Bayesian
                        # =================================================
                        elif motor == 'BayesianOptimization':
                            param_space = {
                                'n_estimators': Integer(50, 500),
                                'max_depth': Integer(3, 15),
                                'min_samples_split': Integer(2, 20),
                                'min_samples_leaf': Integer(1, 20),
                                'max_features': Categorical(['sqrt', 'log2', None]),
                                'bootstrap': Categorical([True, False])
                            }
                            search_bayes = BayesSearchCV(
                                RandomForestRegressor(random_state=42),
                                param_space,
                                n_iter=n_iter.value,
                                cv=cv.value, n_jobs=-1, scoring=func_objetivo.value, random_state=42,
                                return_train_score=True, verbose=3
                            )
                            search_bayes.fit(X_train_scaled, Y_train_scaled)
                            best_rf_bayes = search_bayes.best_estimator_
                            best_score_bayes = search_bayes.best_score_
                            if best_score_bayes > best_score:
                                best_score = best_score_bayes
                                best_rf = best_rf_bayes
                                best_metodo = metodo
                                best_motor  = motor
                            # Almacenar los resultados del motor Bayesian
                            OPT_MODELS[("rf", metodo.lower(), "bayesianoptimization")] = {
                                "model":       best_rf_bayes,
                                "sx":          scaler_X,
                                "sy":          sy,
                                "score":       float(best_score_bayes),
                                "metric":      func_objetivo.value,
                                "param_dist":  param_space,
                                "best_params": search_bayes.best_params_,
                                "cols":        cols
                            }
                            optimizations_results.append({
                                'motor' : motor,
                                'metodo': metodo,
                                'puntuación': best_score_bayes,
                                'R2': r2_score(Y_test_scaled, search_bayes.predict(X_test_scaled)),
                                'MSE': mean_squared_error(Y_test_scaled, search_bayes.predict(X_test_scaled)),
                                'MAE': mean_absolute_error(Y_test_scaled, search_bayes.predict(X_test_scaled)),
                                'params': search_bayes.best_params_
                            })

                            pass
                        # =================================================
                        # Motor Hyperband
                        # =================================================
                        elif motor == 'Hyperband':
                            param_dist = {
                                'n_estimators': np.arange(50, 501, 50),
                                'max_depth': np.arange(3, 15, 1),
                                'min_samples_split': np.arange(2, 21, 1),
                                'min_samples_leaf': np.arange(1, 21, 1),
                                'max_features': ['sqrt', 'log2', None],
                                'bootstrap': [True, False]
                            }
                            search_hyperband = HalvingRandomSearchCV(
                                RandomForestRegressor(random_state=42),
                                param_distributions=param_dist,
                                factor=3,  # Aumenta recursos a medida que mejora el modelo
                                max_resources=300,  # Máximo número de recursos para la optimización
                                min_resources=50,  # Número mínimo de recursos
                                cv=cv.value, n_jobs=-1, scoring=func_objetivo.value, random_state=42,
                                return_train_score=True, verbose=3
                            )
                            search_hyperband.fit(X_train_scaled, Y_train_scaled)
                            best_rf_hyperband = search_hyperband.best_estimator_
                            best_score_hyperband = search_hyperband.best_score_
                            if best_score_hyperband > best_score:
                                best_score = best_score_hyperband
                                best_rf = best_rf_hyperband
                                best_metodo = metodo
                                best_motor  = motor
                            # Almacenar los resultados del motor Hyperband
                            OPT_MODELS[("rf", metodo.lower(), "hyperband")] = {
                                "model":       best_rf_hyperband,
                                "sx":          scaler_X,
                                "sy":          sy,
                                "score":       float(best_score_hyperband),
                                "metric":      func_objetivo.value,
                                "param_dist":  param_dist,
                                "best_params": search_hyperband.best_params_,
                                "cols":        cols
                            }
                            optimizations_results.append({
                                'motor' : motor,
                                'metodo': metodo,
                                'puntuación': best_score_hyperband,
                                'R2': r2_score(Y_test_scaled, search_hyperband.predict(X_test_scaled)),
                                'MSE': mean_squared_error(Y_test_scaled, search_hyperband.predict(X_test_scaled)),
                                'MAE': mean_absolute_error(Y_test_scaled, search_hyperband.predict(X_test_scaled)),
                                'params': search_hyperband.best_params_
                            })

                            pass
                        # =================================================
                        # Motor Optuna
                        # =================================================
                        elif motor == 'Optuna':
                            def objective(trial: Trial):
                                param = {
                                    'n_estimators': trial.suggest_int('n_estimators', 50, 500, step=50),
                                    'max_depth': trial.suggest_int('max_depth', 3, 15),
                                    'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                                    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),
                                    'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),
                                    'bootstrap': trial.suggest_categorical('bootstrap', [True, False])
                                }
                                model = RandomForestRegressor(**param, random_state=42)
                                model.fit(X_train_scaled, Y_train_scaled)
                                preds = model.predict(X_test_scaled)
                                return mean_squared_error(Y_test_scaled, preds)

                            #study = optuna.create_study(direction='maximize')  # Maximizar la puntuación
                            direction = 'minimize' if func_objetivo.value != 'r2' else 'maximize'
                            study = optuna.create_study(direction=direction)
                            study.optimize(objective, n_trials=n_iter.value)

                            best_rf_optuna = RandomForestRegressor(**study.best_params, random_state=42)
                            best_rf_optuna.fit(X_train_scaled, Y_train_scaled)
                            best_score_optuna = study.best_value
                            if best_score_optuna > best_score:
                                best_score = best_score_optuna
                                best_rf = best_rf_optuna
                                best_metodo = metodo
                                best_motor  = motor

                            # Almacenar los resultados del motor Optuna
                            # … después de entrenar best_rf_optuna y antes de optimizations_results.append
                            pred_opt = best_rf_optuna.predict(X_test_scaled)   # ← calcula una sola vez

                            OPT_MODELS[("rf", metodo.lower(), "optuna")] = {
                                "model":       best_rf_optuna,
                                "sx":          scaler_X,
                                "sy":          sy,
                                "score":       float(best_score_optuna),
                                "metric":      func_objetivo.value,
                                "param_dist":  study.best_params,
                                "best_params": study.best_params,
                                "cols":        cols
                            }
                            optimizations_results.append({
                                'motor' : motor,
                                'metodo': metodo,
                                'puntuación': best_score_optuna,
                                'R2'    : r2_score(Y_test_scaled, pred_opt),
                                'MSE'   : mean_squared_error(Y_test_scaled, pred_opt),
                                'MAE'   : mean_absolute_error(Y_test_scaled, pred_opt),
                                'params': study.best_params
                            })

                            study = study

                            pass

                # Elegir el mejor modelo según el motor seleccionado
                best_rf = best_rf_random if best_rf_random else best_rf_bayes if best_rf_bayes else best_rf_hyperband if best_rf_hyperband else best_rf_optuna

                # Recopilamos sólo los scores que sí tenemos
                scores = [
                    best_score_random,
                    best_score_bayes,
                    best_score_hyperband,
                    best_score_optuna
                ]
                # Filtramos los None
                scores = [s for s in scores if s is not None]
                # Si hay al menos uno, tomamos el máximo; si no, dejamos None o 0
                best_score = max(scores) if scores else None

                # Registrar en memoria el mejor RF en OPT_MODELS
                OPT_MODELS = globals().setdefault("OPT_MODELS", {})
                OPT_MODELS[("rf", best_metodo.lower(), best_motor.lower())] = {
                    "model":       best_rf,
                    "sx":          scaler_X,
                    "sy":          sy,
                    "score":       float(best_score),
                    "metric":      func_objetivo.value,
                    "param_dist":  optimizations_results[-1]["params"],
                    "best_params": optimizations_results[-1]["params"],
                    "cols":        RESUMEN_METODOS.get(best_metodo, X_train.columns.tolist())
                }

                #import re
                # tras bucles, desescalamos y graficamos con el mejor de todos
                # Ajuste de columnas según selección de variables
                cols_rf = RESUMEN_METODOS.get(best_metodo, X_train.columns.tolist())
                # ——— AÑADIDO: sanitizar nombres de cols_rf ———
                # …después de determinar cols_rf original…
                #raw_cols_rf = RESUMEN_METODOS.get(best_metodo, X_train.columns.tolist())

                # 1) Sanitizamos:
                #cols_rf = [ re.sub(r'[\[\]<>]', '_', str(c)) for c in raw_cols_rf ]

                # 2) Filtramos para quedarnos solo con los que existen:
                #cols_rf = [ c for c in cols_rf if c in X_train.columns ]
                # ——— FIN AÑADIDO ———

                scaler_X_final = StandardScaler().fit(X_train[cols_rf])
                scaler_Y_final = StandardScaler().fit(Y_train.values.reshape(-1,1))
                X_test_sel = X_test[cols_rf]
                X_test_scaled_final = scaler_X_final.transform(X_test_sel)

                # Predicción sobre columnas seleccionadas
                preds_scaled = best_rf.predict(X_test_scaled_final)
                preds_final = scaler_Y_final.inverse_transform(preds_scaled.reshape(-1,1)).ravel()

                # >>> LLAMADA A PERSISTENCIA ───────────────────────────
                guardar_rf(
                    best_model=best_rf,
                    optimizations_results=optimizations_results,
                    scaler_X=scaler_X_final,
                    scaler_Y=scaler_Y_final,
                    cols=cols,
                    X_test=X_test,
                    Y_test=Y_test,
                    func_objetivo=func_objetivo.value,
                    study=study if study is not None else None,
                    traza_out=salida_resultados
                )
                # ──────────────────────────────────────────────────────
                # Mostrar el mejor modelo y los hiperparámetros
                print("✅ Optimización completada.")
                print(f"🔹 Mejor Modelo: {best_rf}")
                print(f"🔹 Mejor Puntuación: {best_score:.4f}")

                plt.figure(figsize=(10,4))
                plt.subplot(1,2,1)
                plt.scatter(Y_test, preds_final, alpha=0.6)
                plt.plot([Y_test.min(),Y_test.max()],[Y_test.min(),Y_test.max()],'r--', label='Ideal')
                plt.title(f"Real vs Predicho ({best_motor} - {best_metodo})")
                plt.xlabel("Y Real"); plt.ylabel("Y Predicho"); plt.legend(); plt.grid()

                # Histograma residuos y curvas de distribución
                residuos = Y_test.values.ravel() - preds_final
                plt.figure(figsize=(6,4))
                # Histograma
                n,bins,patches=plt.hist(residuos,bins=20,density=True,alpha=0.6,edgecolor='black',label='Distribución Residuos')
                # Curva normal
                mu,sd=norm.fit(residuos)
                x=np.linspace(bins.min(),bins.max(),100)
                plt.plot(x,norm.pdf(x,mu,sd),linewidth=2, label='Curva normal')
                # Curva KDE de la distribución real
                kde = gaussian_kde(residuos)
                x = np.linspace(bins.min(),bins.max(),100)
                plt.plot(x, kde(x), lw=2, label='Densidad KDE')  # añadido KDE
                plt.title('Histograma de residuos con curva normal y curva de densidad'); plt.tight_layout()
                plt.legend()
                plt.grid(True)
                plt.show()

                # Test normalidad Shapiro
                stat, p = shapiro(residuos)
                display(HTML(f"<h4>🧪 Prueba de Normalidad Shapiro-Wilk:</h4><ul><li>Estadístico: {stat:.4f}</li><li>p-valor: {p:.4f}</li><li>{'✅ Residuos normales' if p>0.05 else '⚠️ Residuos no normales'}</li></ul>"))

                # Eje de casos
                n_casos = len(Y_test)
                casos = range(n_casos)

                # Extraer valores
                y_real = Y_test.values if hasattr(Y_test, "values") else Y_test
                y_pred = preds_final  # ajusta el nombre si usas otro

                plt.figure(figsize=(10, 4))
                plt.scatter(casos, y_real, marker='o', label='Y real')
                plt.scatter(casos, y_pred, marker='x', label='Y predicho')
                plt.xlabel('Caso')
                plt.ylabel('Y')
                plt.title('Comparación de puntos: Y real vs. Y predicho')
                plt.legend()
                plt.grid(True)

                plt.tight_layout()
                plt.show()

                # Mostrar los hiperparámetros óptimos
                print("\n⚙️ Mejores hiperparámetros encontrados:")
                optimal_params_df = pd.DataFrame.from_dict(best_rf.get_params(), orient='index', columns=['Valor óptimo'])
                display(optimal_params_df.style.set_caption("📋 Parámetros Óptimos").format(precision=4))

                # Calcular y mostrar métricas
                r2 = r2_score(Y_test, preds_final)
                mse = mean_squared_error(Y_test, preds_final)
                rmse = np.sqrt(mse)
                mae = mean_absolute_error(Y_test, preds_final)

                print(f" Valores de ajuste para los datos de prueba")
                print(f"🔹 R²: {r2:.4f}")
                print(f"🔹 MSE: {mse:.4f}")
                print(f"🔹 RMSE: {rmse:.4f}")
                print(f"🔹 MAE: {mae:.4f}")

                # Tabla completa de optimizaciones
                df_all=pd.DataFrame(optimizations_results).rename(columns={'motor':'Motor','metodo':'Método'})
                display(df_all.style.set_caption("📊 Todos los resultados de optimización").format({'R2':'{:.4f}','MSE':'{:.4f}','MAE':'{:.4f}'}))

                # Ranking top 5
                df_rank = pd.DataFrame(sorted(optimizations_results, key=lambda x: x['puntuación'], reverse=True)[:5])
                display(df_rank.style.set_caption("🏅 Top 5 Optimización").format({"R2": "{:.4f}", "MSE":"{:.4f}", "MAE":"{:.4f}"}))

                barra_progreso.bar_style = 'success'
                barra_progreso.value = 1
                tiempo_transcurrido.value = f'⏱️ Tiempo total: {time.time() - inicio:.1f}s'
                mensaje_estado = widgets.HTML(value="✅ Optimización completada")

        # Conectar la acción del botón con la ejecución de la optimización
        btn_ejecutar.on_click(ejecutar_optimización)

        # Mostrar widgets
        display(HTML("<h3>🔧 Optimización</h3>"))
        display(widgets.VBox([
            selector_motor,
            selector_metodo,
            func_objetivo,
            n_iter,
            cv,
            btn_ejecutar,
            barra_progreso,
            salida_resultados
        ]))

# Artifact: exec exec_207
display(out_rf_opt)

# Artifact: exec exec_208
import threading, time

# Artifact: exec exec_209
from sklearn.base import BaseEstimator, RegressorMixin

# Artifact: exec exec_210
from sklearn.model_selection import RandomizedSearchCV, HalvingRandomSearchCV

# Artifact: exec exec_211
from tensorflow.keras.layers import SimpleRNN, Dense, Dropout

# Artifact: exec exec_212
from tensorflow.keras.optimizers import Adam

# Artifact: exec exec_213
from skopt.space import Real, Integer, Categorical

# Artifact: assign out_opt_rnn
out_opt_rnn = widgets.Output()

# Artifact: class RNNRegressor
class RNNRegressor(BaseEstimator, RegressorMixin):                             # NEW
    def __init__(self, units=32, dropout_rate=0.2, learning_rate=1e-3,
        epochs=50, batch_size=32, verbose=0, sy=None):
        self.units = units
        self.dropout_rate = dropout_rate
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.batch_size = batch_size
        self.verbose = verbose
        self.model_ = None
        self.sy = sy

    #def fit(self, X, y):
    def fit(self, X, y, **kwargs):
        # Si alguien pasa sy por fit, lo recogemos
        sy = kwargs.pop("sy", None)
        if sy is not None:
            self.sy = sy

        # Absorber posibles argumentos de recurso (epochs) de Hyperband
        kwargs.pop('epochs', None)
        # Aseguramos tipos nativos
        self.units = int(self.units)            # NOW ensures Python int
        self.dropout_rate = float(self.dropout_rate)
        self.learning_rate = float(self.learning_rate)
        self.epochs = int(self.epochs)
        self.batch_size = int(self.batch_size)

        # Damos formato 3D para la capa recurrente: (n_samples, timesteps=1, n_features)
        X3 = X.reshape((X.shape[0], 1, X.shape[1]))                             # NEW

        # Construimos el RNN
        self.model_ = Sequential()
        self.model_.add(SimpleRNN(self.units, activation='tanh', input_shape=(1, X.shape[1])))
        self.model_.add(Dropout(self.dropout_rate))
        self.model_.add(Dense(1))
        self.model_.compile(optimizer=Adam(learning_rate=self.learning_rate), loss='mse')

        # Entrenamiento
        self.model_.fit(X3, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)
        return self

    def predict(self, X):
        # Si vienen DataFrames o similares, extrae el ndarray:
        X_arr = X.values if hasattr(X, "values") else X
        # Ahora reshape en el ndarray:
        X3 = X_arr.reshape((X_arr.shape[0], 1, X_arr.shape[1]))
        y_scaled = self.model_.predict(X3, verbose=self.verbose).ravel()
        if self.sy is not None:
            return self.sy.inverse_transform(y_scaled.reshape(-1,1)).ravel()
        return y_scaled

# Artifact: exec exec_216
import pathlib, pickle, datetime

# Artifact: function guardar_rnn
def guardar_rnn(best_estimator, score, metodo, motor,
                selector_scoring, X_cols, Y_ref,
                sx, sy,                         # --- ADDED scaler args ---
                study=None, traza_out=None):

    """
    best_estimator  -> instancia RNNRegressor entrenada
    score           -> métrica devuelta por el CV
    metodo          -> método de selección (Pearson, …)
    motor           -> motor de optimización (RandomSearch, …)
    selector_scoring-> widget con la métrica elegida
    X_cols          -> lista de columnas usadas en X
    Y_ref           -> Y_train (Series o DataFrame) para extraer nombre
    study           -> objeto optuna.study.Study   (solo motor Optuna)
    traza_out       -> panel Output donde imprimir mensajes (opcional)
    """
    try:
        # 1) carpeta destino
        pathlib.Path("modelos_opt").mkdir(exist_ok=True)

        # 2) nombre robusto
        ts  = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        tag = f"rnn_{metodo.lower()}_{motor.lower()}_opt_{ts}"

        # 3) guardar sub-modelo Keras (*.keras)
        keras_f = f"modelos_opt/{tag}.keras"
        best_estimator.model_.save(keras_f, include_optimizer=True)

        # 4) metadatos
        y_name = getattr(Y_ref, "name", None) \
                 or (Y_ref.columns[0] if hasattr(Y_ref, "columns") else "Y")

        meta = dict(
            params       = best_estimator.get_params(),
            score        = float(score),
            func_obj     = selector_scoring.value,
            motor        = motor,
            metodo_x     = metodo,
            cols         = X_cols,
            yname        = y_name,
            fecha        = ts,
            sx           = sx,                 # --- ADDED ---
            sy           = sy                  # --- ADDED ---
        )
        with open(f"modelos_opt/{tag}_meta.pkl", "wb") as f:
            pickle.dump(meta, f)

        # 5) study Optuna (si procede)
        if motor.lower() == "optuna" and study is not None:
            with open(f"modelos_opt/{tag}_study.pkl", "wb") as f:
                pickle.dump(study, f)

        # 6) log
        if traza_out is not None:
            with traza_out:
                print(f"💾 Modelo guardado     → {keras_f}")
                print(f"💾 Metadatos guardados → {tag}_meta.pkl")
                if motor.lower() == "optuna" and study is not None:
                    print(f"💾 Study Optuna       → {tag}_study.pkl")

    except Exception as e:
        txt = f"⚠️ No se pudo guardar modelo/estudio: {e}"
        if traza_out is not None:
            with traza_out: print(txt)
        else:
            print(txt)

# Artifact: function mostrar_optimizacion_rnn
def mostrar_optimizacion_rnn():
    """
    Carga las variables X, Y y FECHAS de los conjuntos Train/Test
    según el método de selección escogido.
    Permite preview, selección de motores, y ejecuta RandomSearchCV
    sobre el wrapper RNNRegressor.
    """
    global X_train_sel, Y_train_sel, FECHAS_train_sel
    global X_test_sel, Y_test_sel, FECHAS_test_sel
    global X_train, Y_train, FECHAS_train, X_test, Y_test, FECHAS_test
    global RESUMEN_METODOS

    global OPT_MODELS
    if 'OPT_MODELS' not in globals() or not isinstance(OPT_MODELS, dict):
        OPT_MODELS = {}
    # ── ESCALERS GLOBALES PARA PASAR A guardar_rnn ──
    global sx, sy
    sx, sy = None, None

    with out_opt_rnn:
        clear_output(wait=True)
        # Verificar que los conjuntos existan
        required = ['X_train','Y_train','FECHAS_train','X_test','Y_test','FECHAS_test']
        missing = [v for v in required if v not in globals()]
        if missing:
            print(f"❌ Faltan datos: {', '.join(missing)}. Ejecuta la segmentación antes.")
            return

        # 2) Ahora sí puedo sanear columnas
        # Usar sanitize_name para limpiar columnas en el payload
        def clean_cols(col_list):
            return [sanitize_name(c) for c in col_list]
        # Ejemplo de sanitización de X_train antes de fit
        X_train.columns = [sanitize_name(col) for col in X_train.columns]
        X_test.columns = [sanitize_name(col) for col in X_test.columns]

        # Dropdown de métodos de selección
        metodos = ['Pearson','Spearman','MutualInfo','Boruta','UMAP']
        selector_metodo = widgets.Dropdown(
            options=['Todos'] + metodos,
            description='Método X:',
            layout=widgets.Layout(width='300px')
        )
        # Botón de carga de variables y preview
        btn_cargar = widgets.Button(description='📥 Cargar Variables', button_style='primary')
        salida_carga = widgets.Output()

        # Selector de motores (incluye Todos)
        motores = ['RandomSearch','Bayesian','Hyperband','Optuna']
        selector_motor = widgets.SelectMultiple(
            options=['Todos'] + motores,
            description='Motores:',
            layout=widgets.Layout(width='300px', height='100px')
        )
        # Scoring, CV y Nº iteraciones
        selector_scoring = widgets.Dropdown(
            options=['r2','neg_mean_squared_error','neg_mean_absolute_error'],
            value='r2',
            description='Scoring:',
            layout=widgets.Layout(width='300px')
        )
        cv = widgets.IntSlider(value=5, min=2, max=10, step=1, description='cv:')
        n_iter = widgets.IntSlider(value=10, min=5, max=100, step=1, description='Nº iter:')
        progreso_reloj = widgets.HTML('⏱️ 00:00:00')
        # Botón de ejecución
        btn_ejecutar = widgets.Button(description='🚀 Ejecutar Optimización', button_style='success')
        salida_logs = widgets.Output()

        # === cargar_variables: filtra y muestra preview ===
        def cargar_variables(_):
            global X_train_sel, Y_train_sel, FECHAS_train_sel
            global X_test_sel, Y_test_sel, FECHAS_test_sel
            salida_carga.clear_output(wait=True)

            metodo = selector_metodo.value
            with salida_carga:
                # Determinar columnas X
                if metodo == 'Todos':
                    cols = sorted({c for m in metodos for c in RESUMEN_METODOS.get(m, [])})
                else:
                    cols = RESUMEN_METODOS.get(metodo, [])
                if not cols:
                    print(f"❌ No hay variables para '{metodo}'.")
                    return

                X_train_sel = X_train[cols].copy()
                Y_train_sel = Y_train.copy()
                FECHAS_train_sel = FECHAS_train.copy()
                X_test_sel  = X_test[cols].copy()
                Y_test_sel  = Y_test.copy()
                FECHAS_test_sel  = FECHAS_test.copy()

                # Preview robusto: concat por posición (reset_index) para evitar NaN
                df_train = pd.concat([
                    X_train_sel.head(5).reset_index(drop=True),
                    Y_train_sel.head(5).reset_index(drop=True),
                    FECHAS_train_sel.head(5).reset_index(drop=True).rename('Fecha')
                ], axis=1)
                df_train['Tipo'] = 'Train'

                df_test = pd.concat([
                    X_test_sel.head(5).reset_index(drop=True),
                    Y_test_sel.head(5).reset_index(drop=True),
                    FECHAS_test_sel.head(5).reset_index(drop=True).rename('Fecha')
                ], axis=1)
                df_test['Tipo'] = 'Test'

                # --- ADDED: crear y guardar scalers ---
                global sx, sy
                sx = StandardScaler().fit(X_train_sel.values)
                sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                with salida_carga:
                    print(f"✅ Cargadas {len(cols)} variables y escalers preparados para '{metodo}'")

                df_preview = pd.concat([df_train, df_test], ignore_index=True)
                display(HTML("<h4>📋 Preview Train/Test (5 filas cada uno)</h4>"))
                display(df_preview)

        # === ejecutar_optimizacion: RandomSearchCV con RNNRegressor ===
        def ejecutar_optimizacion(_):
            # Iniciar reloj
            stop_event = threading.Event()
            start_time = time.time()
            def run_clock():
                while not stop_event.is_set():
                    elapsed = int(time.time() - start_time)
                    h, rem = divmod(elapsed, 3600)
                    m, s   = divmod(rem, 60)
                    progreso_reloj.value = f"⏱️ {h:02d}:{m:02d}:{s:02d}"
                    time.sleep(1)
            t = threading.Thread(target=run_clock, daemon=True)
            t.start()

            salida_logs.clear_output(wait=True)
            #start_time = time.time()  # inicio temporizador

            with salida_logs:
                resultados = []
                # determinar métodos
                sel_met = selector_metodo.value
                methods = metodos.copy() if sel_met=='Todos' else [sel_met]
                # determinar motores
                sel_mot = list(selector_motor.value)
                mot_sel = motores if 'Todos' in sel_mot else sel_mot

                for metodo in methods:

                    # (Aquí va la parte para obtener `cols` desde RESUMEN_METODOS)
                    if metodo == 'Todos':
                        cols = []
                        for m_aux in metodos:
                            cols += RESUMEN_METODOS.get(m_aux, [])
                        cols = sorted(set(cols))
                    else:
                        cols = RESUMEN_METODOS.get(metodo, [])

                    for motor in mot_sel:
                        # ✅ AQUI VA el bloque que te he entregado
                        print(f"➡️ {motor} en '{metodo}'…")

                        # Validar columnas existentes
                        effective_cols = [c for c in cols if c in X_test.columns]
                        print(f"[DEBUG] RNN método '{metodo}' - columnas esperadas: {len(cols)}, válidas: {len(effective_cols)} → {effective_cols}")

                        if len(effective_cols) < 2:
                            print(f"⚠️ Se omite '{metodo}' con motor '{motor}' porque solo seleccionó {len(effective_cols)} columnas válidas: {effective_cols}")
                            continue

                        # Preparar subconjuntos
                        X_train_sel = X_train[effective_cols].copy()
                        Y_train_sel = Y_train.copy()
                        FECHAS_train_sel = FECHAS_train.copy()

                        X_test_sel  = X_test[effective_cols].copy()
                        Y_test_sel  = Y_test.copy()
                        FECHAS_test_sel  = FECHAS_test.copy()

                        X_test_vals = X_test_sel.values
                        y_test_vals = Y_test.values.ravel()

                        kr = RNNRegressor()
                        # ============================================
                        # Motor de optimización RandomSearch
                        # ============================================
                        if motor == 'RandomSearch':
                            # ——— AÑADIDO: re-ajustar escaladores para el filtrado actual ———
                            sx = StandardScaler().fit(X_train_sel.values)
                            sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                            # preparar datos (ahora con el scaler correcto)
                            Xv = sx.transform(X_train_sel.values)
                            yv = sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            # Distribuciones de scipy.stats
                            from scipy.stats import randint, uniform, loguniform
                            # Usar nuestro wrapper
                            kr = RNNRegressor(
                                units=64, dropout_rate=0.2,
                                learning_rate=1e-3, epochs=50,
                                batch_size=32, verbose=3
                            )  # NEW
                            rs_params = {
                                'units': randint(10, 61),
                                'dropout_rate': uniform(0.0, 0.5),
                                'learning_rate': loguniform(1e-4, 1e-2),
                                'epochs': randint(50, 401),
                                'batch_size': randint(16, 257)
                            }
                            rs = RandomizedSearchCV(
                                estimator=kr,
                                param_distributions=rs_params,
                                n_iter=n_iter.value,
                                scoring=selector_scoring.value,
                                cv=cv.value,
                                random_state=42,
                                n_jobs=-1,
                                verbose = 3
                            )
                            print("🔍 Ejecutando RandomizedSearchCV…")
                            rs.fit(Xv, yv)
                            best = rs.best_estimator_
                            score = rs.best_score_
                            params = rs.best_params_

                        # ============================================
                        # Motor de optimización Bayesian
                        # ============================================
                        elif motor=='Bayesian':
                            # preparar datos
                            #Xv = X_train_sel.values
                            #yv = Y_train_sel.values.ravel()
                            sx = StandardScaler().fit(X_train_sel.values)
                            sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                            Xv = sx.transform(X_train_sel.values)
                            yv = sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            # Usar nuestro wrapper
                            kr = RNNRegressor()
                            #param_space = {
                            bay_params = {
                                'units': Integer(10,60),
                                'dropout_rate': Real(0.0,0.5),
                                'learning_rate': Real(1e-4,1e-2,'log-uniform'),
                                'epochs': Integer(50,400),
                                'batch_size': Integer(16,256)
                            }
                            bs = BayesSearchCV(
                                kr,
                                #param_space,
                                bay_params,
                                n_iter=n_iter.value,
                                scoring=selector_scoring.value,
                                cv=cv.value,
                                random_state=42,
                                n_jobs=-1,
                                verbose=3
                            )
                            print("🔍 Ejecutando Bayesian…")
                            bs.fit(Xv,yv)
                            best, score, params = bs.best_estimator_, bs.best_score_, bs.best_params_

                        # ============================================
                        # Motor de optimización Hyperband
                        # ============================================
                        elif motor=='Hyperband':
                            # preparar datos
                            #Xv = X_train_sel.values
                            #yv = Y_train_sel.values.ravel()
                            sx = StandardScaler().fit(X_train_sel.values)
                            sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                            Xv = sx.transform(X_train_sel.values)
                            yv = sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            # Usar nuestro wrapper
                            kr = RNNRegressor()
                            # Distribuciones scipy.stats para Hyperband
                            from scipy.stats import randint, uniform, loguniform
                            hb_params = {
                                'units': randint(10, 61),              # enteros 10–60
                                'dropout_rate': uniform(0.0, 0.5),      # continuo 0–0.5
                                'learning_rate': loguniform(1e-4, 1e-2),# log-uniform 1e-4–1e-2
                                'batch_size': randint(16, 257)         # enteros 16–256
                            }
                            hb = HalvingRandomSearchCV(
                                estimator=kr,
                                param_distributions=hb_params,
                                factor=3,
                                resource='epochs',
                                #max_resources=400,
                                max_resources=50,
                                scoring=selector_scoring.value,
                                cv=cv.value,
                                #cv=2,
                                random_state=42,
                                #n_jobs=-1,
                                n_jobs=1,
                                verbose=3,
                                error_score='raise'
                            )
                            print("🔍 Ejecutando Hyperband…")
                            hb.fit(Xv,yv)
                            best, score, params = hb.best_estimator_, hb.best_score_, hb.best_params_

                        # ============================================
                        # Motor de optimización Optuna
                        # ============================================
                        elif motor=='Optuna':
                            # Preparamos los datos
                            #Xv = X_train_sel.values
                            #yv = Y_train_sel.values.ravel()
                            sx = StandardScaler().fit(X_train_sel.values)
                            sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                            Xv = sx.transform(X_train_sel.values)
                            yv = sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            kr = RNNRegressor()  # wrapper limpio
                            import optuna
                            def objective(trial):
                                # Sugerencia de hiperparámetros
                                units = trial.suggest_int('units', 10, 20)
                                dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)
                                learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)
                                epochs = trial.suggest_int('epochs', 50, 100)
                                batch_size = trial.suggest_int('batch_size', 16, 256)
                                # Instanciamos y entrenamos el modelo
                                model = RNNRegressor(
                                    units=units,
                                    dropout_rate=dropout_rate,
                                    learning_rate=learning_rate,
                                    epochs=epochs,
                                    batch_size=batch_size,
                                    verbose=3
                                )
                                model.fit(Xv, yv)
                                preds = model.predict(Xv)
                                # Devolvemos la métrica a optimizar
                                if selector_scoring.value == 'r2':
                                    return r2_score(yv, preds)
                                elif selector_scoring.value == 'neg_mean_squared_error':
                                    return -mean_squared_error(yv, preds)
                                else:  # neg_mean_absolute_error
                                    return -mean_absolute_error(yv, preds)
                            # Creamos y ejecutamos el estudio
                            study = optuna.create_study(
                                direction='maximize'
                                if selector_scoring.value == 'r2'
                                else 'minimize'
                            )
                            study.optimize(objective, n_trials=n_iter.value)
                            # Recuperamos los mejores parámetros y entrenamos el modelo final
                            best_params = study.best_params
                            best = RNNRegressor(**best_params)
                            best.fit(Xv, yv)
                            # Interpretamos el score devuelto
                            if selector_scoring.value == 'r2':
                                score = study.best_value
                            else:
                                score = -study.best_value
                            params = best_params

                        else:
                            best=None
                            score = None
                            params = {}

                        # 🗄️ GUARDAR MODELO / METADATOS  ←―――――――――――――――――
                        guardar_rnn(best, score, metodo, motor,
                                    selector_scoring, cols, Y_train,
                                    sx, sy,                    # <-- ahora son obligatorios
                                    study if motor=='Optuna' else None,
                                    traza_out=salida_logs)
                        # ————————————————————————————————————————————————————

                        # ── AÑADIR REGISTRO EN OPT_MODELS AQUÍ ─────────────────────────────
                        # construimos el tag y las rutas (deberían coincidir con las usadas en guardar_rnn)
                        ts       = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                        tag      = f"rnn_{metodo.lower()}_{motor.lower()}_opt_{ts}"
                        model_f  = f"modelos_opt/{tag}.keras"
                        meta_f   = f"modelos_opt/{tag}_meta.pkl"

                        OPT_MODELS[('rnn', metodo, motor)] = {
                            'model_path': model_f,
                            'meta_path' : meta_f,
                            'score'     : float(score),
                            'metric'    : selector_scoring.value,   # ← aquí la métrica
                            'params'    : params,
                            'model'     : best,
                            'cols'      : cols,
                            'sx'        : sx,
                            'sy'        : sy
                        }
                        # Si es Optuna, guarda también la ruta al study
                        if motor.lower() == 'optuna' and study is not None:
                            OPT_MODELS[('rnn', metodo, motor)]['study_path'] = f"modelos_opt/{tag}_study.pkl"

                        # ────────────────────────────────────────────────────────────────

                        resultados.append({
                            'metodo':metodo,
                            'motor':motor,
                            'score':score,
                            'params':params,
                            'best':best
                        })
                # Detener reloj
                stop_event.set()
                t.join()
                # mostrar mejor
                valid = [r for r in resultados if r['score'] is not None]
                if valid:
                    best_r = max(valid, key=lambda x: x['score'])
                    print("\n🏆 Mejor optimización:")
                    print(f"  Método: {best_r['metodo']}")
                    print(f"  Motor: {best_r['motor']}")
                    print(f"  Score: {best_r['score']:.4f}")
                    print(f"  Params: {best_r['params']}")

                    # === Gráficas del mejor modelo ===
                    modelo_best = best_r['best']
                    metodo_best = best_r['metodo']
                    cols_best   = [sanitize_name(c) for c in RESUMEN_METODOS.get(metodo_best, [])]

                    # Filtramos columnas válidas que estén presentes
                    effective_cols = [c for c in cols_best if c in X_test.columns]
                    if len(effective_cols) < 2:
                        print(f"⚠️ El método '{metodo_best}' no tiene columnas válidas para el Test. Se omite predicción.")
                    else:
                        X_test_vals = X_test[effective_cols].copy().values
                        y_test_vals = Y_test.values.ravel()
                        fechas      = FECHAS_test.values

                        # 1) calcula la predicción escalada
                        y_pred_scaled = modelo_best.predict(X_test_vals)
                        # 2) inversa de sy para volver a la escala original
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()
                        residuos = y_test_vals - y_pred

                        # Gráfico de puntos Y real. vs. Y predicho por fecha
                        plt.figure(figsize=(8,3))
                        plt.scatter(fechas, y_test_vals, label='Y real')
                        plt.scatter(fechas, y_pred, label='Y predicha')
                        plt.xlabel('Fecha')
                        plt.ylabel('Y')
                        plt.title('Y real vs predicha por Fecha')
                        plt.legend()
                        plt.tight_layout()
                        plt.show()

                        # Gráfico scatter Y real vs Y predicha
                        plt.figure(figsize=(5,5))
                        plt.scatter(y_test_vals, y_pred, alpha=0.6)
                        plt.plot([y_test_vals.min(), y_test_vals.max()], [y_test_vals.min(), y_test_vals.max()], 'r--', label='Ideal')
                        plt.xlabel('Y real'); plt.ylabel('Y predicha'); plt.title('Y real vs Y predicha')
                        plt.tight_layout(); plt.legend(); plt.show()

                        # Histograma residuos con Normal y KDE
                        plt.figure(figsize=(6,4))
                        from scipy.stats import norm, gaussian_kde, shapiro
                        n,bins,_ = plt.hist(residuos, bins=20, density=True, alpha=0.6, label='Residuos')
                        mu, sd = norm.fit(residuos)
                        x = np.linspace(bins.min(), bins.max(), 100)
                        plt.plot(x, norm.pdf(x, mu, sd), 'r--', label='Normal')
                        kde = gaussian_kde(residuos)
                        plt.plot(x, kde(x), 'g-', label='KDE')
                        plt.xlabel('Residuo'); plt.ylabel('Densidad'); plt.title('Histograma de residuos')
                        plt.legend(); plt.tight_layout(); plt.show()

                        # Test de normalidad Shapiro-Wilk
                        stat, p_value = shapiro(residuos)
                        print(f"🧪 Shapiro-Wilk: estadístico={stat:.4f}, p-valor={p_value:.4f} -> {'Normal' if p_value > 0.05 else 'No normal'}")

                else:
                    print("⚠️ No hay resultados con score definido.")
                # Tabla completa de optimizaciones
                df_all=pd.DataFrame(resultados)
                display(HTML("<h4>📊 Todos los resultados de optimización</h4>"))
                display(df_all)

        # enlazar callbacks
        btn_cargar.on_click(cargar_variables)
        btn_ejecutar.on_click(ejecutar_optimizacion)

        # mostrar interfaz
        display(HTML("<h3>🔧 Optimización RNN - Carga y Motores</h3>"))
        display(widgets.VBox([
            selector_metodo,
            btn_cargar,
            salida_carga,
            selector_motor,
            selector_scoring,
            cv,
            n_iter,
            progreso_reloj,
            btn_ejecutar,
            salida_logs
        ]))

# Artifact: exec exec_219
display(out_opt_rnn)

# Artifact: exec exec_220
import glob, io, base64, pickle, random, pprint

# Artifact: exec exec_221
from pathlib import Path

# Artifact: exec exec_222
import os, re

# Artifact: exec exec_223
from tensorflow.keras.losses import MeanSquaredError

# Artifact: exec exec_224
from shap import TreeExplainer, KernelExplainer, GradientExplainer, DeepExplainer

# Artifact: exec exec_225
from lime.lime_tabular import LimeTabularExplainer

# Artifact: exec exec_226
from sklearn.inspection import permutation_importance

# Artifact: exec exec_227
from sklearn.neighbors import NearestNeighbors

# Artifact: exec exec_228
from sklearn.tree import DecisionTreeRegressor

# Artifact: exec exec_229
from sklearn.linear_model import LinearRegression

# Artifact: exec exec_230
try:
    from interpret.glassbox import ExplainableBoostingRegressor
except ImportError:
    ExplainableBoostingRegressor = None

# Artifact: exec exec_231
if 'xai_results' not in globals():                        # Nuevo para celda 12
    xai_results = {}

# Artifact: assign MODEL_KEYS
MODEL_KEYS = {
    'SVR': 'svr',
    'NN': 'nn',
    'XGBoost': 'xgb',
    'Random Forest': 'rf',
    'RNN': 'rnn'
}

# Artifact: assign ALL_MOTORES
ALL_MOTORES = [
    "SHAP",
    "LIME",
    "KernelExplainer",
    "Integrated Gradients",
    "DeepLIFT / LRP",
    "Permutation Feature Importance",
    "Partial Dependence Plots (PDP)",
    "Accumulated Local Effects (ALE)",
    "Individual Conditional Expectation (ICE) Plots",
    "Counterfactual Explanations",
    "Anchors",
    "Surrogate Models (Global/Local)",
    "Explainable Boosting Machine (EBM)",
    "Optuna Hyperparameter Importance"
]

# Artifact: exec exec_234
display(HTML("""
<style>
/* Ancho y tipografía de los widgets */
.widget-dropdown, .widget-select-multiple, .widget-button {
  width: 400px !important;       /* cajas más anchas */
  font-size: 14px !important;    /* texto de 14px */
}
.widget-dropdown > label, .widget-select-multiple > label {
  font-size: 14px !important;    /* etiquetas también grandes */
}
</style>
"""))

# Artifact: assign TRAINED_MODELS
TRAINED_MODELS = [f"{m}" for m in MODEL_KEYS]

# Artifact: assign OPTIMIZED_MODELS
OPTIMIZED_MODELS = [f"{m}" for m in MODEL_KEYS]

# Artifact: assign SELECT_METHODS
SELECT_METHODS = ['Pearson', 'Spearman', 'Mutualinfo', 'Boruta', 'UMAP']

# Artifact: assign XAI_METHODS
XAI_METHODS = [
    'SHAP', 'LIME', 'KernelExplainer', 'Integrated Gradients',
    'DeepLIFT / LRP', 'Permutation Feature Importance',
    'Partial Dependence Plots (PDP)', 'Accumulated Local Effects (ALE)',
    'Individual Conditional Expectation (ICE) Plots',
    'Counterfactual Explanations', 'Anchors',
    'Surrogate Models (Global/Local)', 'Explainable Boosting Machine (EBM)',
    'Optuna Hyperparameter Importance', 'Todos'
]

# Artifact: assign XAI_HELP
XAI_HELP = {
    'SHAP': (
        '<h4>SHAP</h4>'
        '<p><b>SHAP</b> (SHapley Additive exPlanations) utiliza teoría de juegos para descomponer '
        'la predicción de un modelo en aportes aditivos de cada característica.</p>'
        '<p><b>Valores SHAP:</b> representan la contribución de cada variable a la predicción final.</p>'
        '<ul>'
        '<li><b>Empuje hacia arriba (positivo):</b> indica que la variable incrementa la predicción respecto al valor base.</li>'
        '<li><b>Empuje hacia abajo (negativo):</b> indica que la variable decrementa la predicción respecto al valor base.</li>'
        '</ul>'
        '<p>El <i>valor base</i> es la predicción promedio del modelo sin conocer ninguna característica.</p>'
        '<p>Para un punto de datos, la suma de los valores SHAP más el valor base equivale a la predicción del modelo.</p>'
    ),
    'LIME': (
        '<h4>LIME</h4>'
        '<p><b>LIME</b> (Local Interpretable Model-agnostic Explanations) explica la predicción '
        'de cualquier modelo construyendo, en la vecindad de la instancia, un modelo lineal simple.</p>'
        '<ul>'
          '<li>Se perturban aleatoriamente las características de la muestra.</li>'
          '<li>Se calcula la predicción del modelo “negro”.</li>'
          '<li>Se ajusta una función lineal ponderada por proximidad al punto original.</li>'
          '<li>Los coeficientes resultantes indican dirección y magnitud de influencia local.</li>'
        '</ul>'
        '<p><b>Interpretación:</b> coeficiente positivo ⇒ la característica empuja la predicción hacia arriba; '
        'coeficiente negativo ⇒ la empuja hacia abajo.</p>'
    ),
    'KernelExplainer': (
        '<h4>KernelExplainer</h4>'
        '<p><b>KernelExplainer</b> es una extensión de SHAP para modelos de caja negra, '
        'usando un núcleo de similitud para aproximar valores SHAP sin requerir acceso a gradientes.</p>'
        '<ul>'
        '<li><b>Fondo (background):</b> subconjunto de datos para estimar valor base.</li>'
        '<li><b>Valor base:</b> predicción promedio del fondo.</li>'
        '<li><b>Valores Kernel SHAP:</b> contribuciones de cada característica calculadas mediante ponderaciones del núcleo.</li>'
        '<li><b>Empuje hacia arriba (positivo):</b> la característica aumenta la predicción con respecto al valor base.</li>'
        '<li><b>Empuje hacia abajo (negativo):</b> la característica disminuye la predicción.</li>'
        '</ul>'
        '<p>El método pesa cada combinación de características según su similitud al punto de interés, '
        'ofreciendo explicaciones globales y locales.</p>'
        '<p><i>Interpretación de tablas:</i> cada fila es una muestra, columnas son características; '
        'valores muestran su empuje.</p>'
        '<p><i>Interpretación del gráfico summary:</i> distribución de valores Kernel SHAP, '
        'el color indica magnitud de la característica.</p>'
    ),
    'Integrated Gradients': (
        '<h4>Integrated Gradients</h4>'
        '<p><b>Integrated Gradients</b> es un método de atribución para modelos diferenciables, '
        'que integra gradientes desde una referencia (p.ej. vector cero) hasta la instancia objetivo.</p>'
        '<ul>'
        '<li><b>Ruta de integración:</b> línea recta desde referencia hasta punto de interés en el espacio de características.</li>'
        '<li><b>Atributos IG:</b> promedio de gradientes a lo largo de la ruta, ponderando contribuciones.</li>'
        '<li><b>Interpretación:</b> valores positivos ➔ aumento de predicción; valores negativos ➔ disminución.</li>'
        '</ul>'
        '<p><i>Interpretación de tablas:</i> cada fila es una muestra, columnas son características; '
        'valores muestran la contribución integrada.</p>'
        '<p><i>Interpretación de gráfico:</i> distribución de valores IG, destacando variables con mayores efectos acumulados.</p>'
    ),
    'DeepLIFT / LRP': (
        '<h4>DeepLIFT / LRP</h4>'
        '<p><b>DeepLIFT</b> y <b>Layer-wise Relevance Propagation (LRP)</b> son métodos de atribución que '
        'propagan la relevancia de la salida de la red hacia atrás a cada neurona de entrada.</p>'
        '<ul>'
        '<li><b>Relevancia positiva:</b> indica que la característica contribuyó a aumentar la salida.</li>'
        '<li><b>Relevancia negativa:</b> indica que la característica contribuyó a disminuir la salida.</li>'
        '</ul>'
        '<p>La suma de las relevancias de entrada equivale a la activación de salida menos la referencia.</p>'
        '<p><b>Interpretación de tabla:</b> cada fila es una muestra, columnas son características y valores de relevancia.</p>'
        '<p><b>Interpretación de gráfico:</b> barras muestran relevancia media global.</p>'
    ),
    'Permutation Feature Importance': (
        '<h4>Permutation Feature Importance</h4>'
        '<p>Mide la importancia de cada característica evaluando la caída en rendimiento '
        'al permutar sus valores.</p>'
        '<ul>'
        '<li>Para cada variable, se permutan sus valores en el dataset de prueba.</li>'
        '<li>Se mide la diferencia en la métrica (p.ej. R²).</li>'
        '<li>Una caída mayor indica mayor importancia de esa variable.</li>'
        '</ul>'
        '<p>Interpretación de la tabla:</p>'
        '<ul>'
        '<li><b>Mean Importance:</b> promedio de las caídas de rendimiento tras permutar.</li>'
        '<li><b>Std Importance:</b> variabilidad en esos descensos.</li>'
        '</ul>'
        '<p>Interpretación del gráfico:</p>'
        '<ul>'
        '<li>Puntos representan importancia media; barras de error, desviación estándar.</li>'
        '</ul>'
    ),
    'Partial Dependence Plots (PDP)': (
        '<h4>Partial Dependence Plots (PDP)</h4>'
        '<p><b>Partial Dependence Plots</b> (PDP) permiten visualizar el efecto medio que tiene una variable (o par de variables) '
        'sobre la predicción de un modelo, manteniendo fijas todas las demás. Es un método global y agnóstico al modelo, muy útil para '
        'entender la dirección (positiva o negativa) y la magnitud del impacto de cada característica.</p>'

        '<h5>¿Cómo se calcula?</h5>'
        '<ul>'
        '<li>Se selecciona una variable y se construye una rejilla de valores representativos en su rango.</li>'
        '<li>Para cada valor de la rejilla, se reemplaza dicha variable en todas las observaciones del conjunto de datos con ese valor.</li>'
        '<li>Se predice el valor objetivo para este nuevo dataset y se calcula la media de las predicciones.</li>'
        '<li>Estos valores promedio constituyen la <b>curva PDP</b> de la variable.</li>'
        '</ul>'

        '<h5>Interpretación:</h5>'
        '<ul>'
        '<li>El <b>eje X</b> representa los valores posibles de la variable analizada.</li>'
        '<li>El <b>eje Y</b> representa la predicción promedio del modelo cuando la variable toma esos valores.</li>'
        '<li>Una <b>pendiente positiva</b> indica que un aumento de la variable incrementa la predicción media.</li>'
        '<li>Una <b>pendiente negativa</b> indica que un aumento de la variable reduce la predicción media.</li>'
        '</ul>'

        '<h5>Importancia global con PDP:</h5>'
        '<p>En este motor se calcula como el <b>rango</b> (máximo menos mínimo) de la curva PDP. '
        'Esto representa cuánto puede cambiar la predicción promedio si se modifica la variable a lo largo de todo su dominio. '
        'Cuanto mayor el rango, mayor es la importancia de esa variable en el comportamiento del modelo.</p>'

        '<h5>Importancia local:</h5>'
        '<p>También se calcula una tabla con los efectos PDP para las primeras muestras del conjunto de datos. '
        'Para cada muestra y variable, se evalúa cuánto cambia la predicción promedio cuando se fija la variable al valor observado '
        'y se mantiene el resto con su distribución real. Esto permite interpretar el efecto individual de cada característica '
        'en una muestra específica, de forma análoga a SHAP o LIME.</p>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>No tiene en cuenta interacciones entre variables (a menos que se usen PDP bivariados).</li>'
        '<li>Puede ser engañoso si hay fuerte correlación entre variables (reemplazar una variable puede generar combinaciones no plausibles).</li>'
        '</ul>'

        '<p><i>En resumen:</i> PDP ayuda a responder: <b>¿Cómo varía la predicción promedio del modelo cuando cambio una variable concreta?</b></p>'
    ),
    'Accumulated Local Effects (ALE)': (
        '<h4>Accumulated Local Effects (ALE)</h4>'
        '<p><b>ALE</b> (Efectos Locales Acumulados) es un método de interpretabilidad global que muestra '
        'cómo cambia la predicción promedio del modelo cuando una característica varía dentro de su dominio, '
        'teniendo en cuenta las correlaciones entre variables.</p>'

        '<h5>¿Cómo se calcula?</h5>'
        '<ul>'
        '<li>Se divide el rango de una variable en <i>bins</i> (intervalos), usualmente basados en cuantiles para que contengan un número similar de observaciones.</li>'
        '<li>En cada bin, se mide el efecto local de cambiar el valor de la variable desde el límite inferior al superior, manteniendo fijas las demás variables.</li>'
        '<li>Estos efectos se acumulan a lo largo de los bins, produciendo una <b>curva ALE</b> que muestra cómo influye la variable sobre la predicción.</li>'
        '</ul>'

        '<h5>Ventajas frente a PDP:</h5>'
        '<ul>'
        '<li><b>Robusto ante correlaciones:</b> A diferencia de PDP, ALE no genera combinaciones irreales de variables, ya que respeta la distribución original de los datos.</li>'
        '<li><b>Computacionalmente eficiente:</b> Sólo evalúa muestras dentro de cada bin, evitando duplicaciones masivas.</li>'
        '</ul>'

        '<h5>Interpretación:</h5>'
        '<ul>'
        '<li>El eje <b>X</b> representa el valor de la variable (centrado por defecto).</li>'
        '<li>El eje <b>Y</b> representa el efecto acumulado sobre la predicción del modelo.</li>'
        '<li>Una pendiente positiva indica que aumentar esa variable tiende a aumentar la predicción.</li>'
        '<li>Una pendiente negativa indica lo contrario.</li>'
        '</ul>'

        '<h5>Importancia global:</h5>'
        '<p>En este motor, la <b>importancia global</b> de una variable se calcula como el <b>rango</b> '
        'de su curva ALE (es decir, la diferencia entre el valor máximo y mínimo del efecto acumulado). '
        'Un mayor rango implica mayor impacto medio de esa característica sobre la salida del modelo.</p>'

        '<h5>Importancia local:</h5>'
        '<p>Se muestran los valores ALE correspondientes a las primeras muestras del conjunto de datos. '
        'Estos valores permiten entender el efecto individual de cada variable sobre la predicción de cada observación.</p>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>Asume que los efectos son aditivos y no modela explícitamente interacciones (aunque puede ampliarse con ALE 2D).</li>'
        '<li>Puede suavizar excesivamente relaciones no lineales muy complejas si se usan pocos bins.</li>'
        '</ul>'

        '<p><i>Resumen:</i> ALE es una técnica moderna, confiable y robusta para evaluar la importancia de cada variable '
        'respetando la estructura estadística real del dataset.</p>'
    ),
    'Individual Conditional Expectation (ICE) Plots': (
        '<h4>Individual Conditional Expectation (ICE) Plots</h4>'
        '<p><b>ICE</b> es una técnica de interpretabilidad local que representa cómo varía la predicción de un modelo '
        'para una observación concreta cuando se modifica una de sus características, manteniendo fijas las demás. '
        'Es una generalización del método PDP (Partial Dependence Plots), pero a nivel individual.</p>'

        '<h5>¿Cómo se calcula?</h5>'
        '<ul>'
        '<li>Para una observación concreta, se generan múltiples versiones de ella cambiando solo una variable (por ejemplo, X1) a lo largo de un rango de valores.</li>'
        '<li>Se evalúa el modelo sobre estas versiones y se obtienen las predicciones correspondientes.</li>'
        '<li>La curva resultante muestra cómo cambia la salida del modelo solo por esa variable en esa observación concreta.</li>'
        '<li>Repitiendo esto para varias muestras, se obtiene un conjunto de curvas ICE que capturan efectos individuales.</li>'
        '</ul>'

        '<h5>Interpretación:</h5>'
        '<ul>'
        '<li>Las curvas muestran cómo cambia la predicción de cada muestra cuando se varía una característica.</li>'
        '<li>Permiten detectar <b>interacciones no lineales</b>, <b>heterogeneidad de efectos</b> o <b>inestabilidad</b> en el modelo.</li>'
        '<li>Cuando todas las curvas son paralelas, la relación es globalmente estable (similar al PDP).</li>'
        '<li>Cuando las curvas difieren fuertemente entre sí, la variable tiene un efecto que depende del resto del contexto (otras variables).</li>'
        '</ul>'

        '<h5>Importancia global:</h5>'
        '<p>En este motor, la importancia global de una variable se calcula como la <b>media del rango</b> de las curvas ICE sobre un subconjunto de muestras. '
        'Este valor representa cuánto cambia, en promedio, la predicción individual cuando se varía esa característica. '
        'Un mayor rango indica mayor influencia.</p>'

        '<h5>Importancia local:</h5>'
        '<p>Se muestra también una tabla con los <b>rangos individuales ICE</b> para las primeras observaciones del conjunto. '
        'Esto permite ver cómo de sensible es cada muestra a cambios en una variable concreta.</p>'

        '<h5>Ventajas:</h5>'
        '<ul>'
        '<li>Captura <b>efectos individuales</b>, no promedios, lo que permite diagnósticos precisos por observación.</li>'
        '<li>Permite detectar comportamientos atípicos, interacciones complejas y sesgos locales.</li>'
        '</ul>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>Puede ser ruidoso si se muestran demasiadas curvas simultáneamente.</li>'
        '<li>Como PDP, puede generar combinaciones irreales si las variables están fuertemente correlacionadas.</li>'
        '</ul>'

        '<p><i>Resumen:</i> ICE muestra <b>cómo cambia la predicción para cada observación</b> al modificar una variable específica, '
        'ofreciendo una perspectiva individual que complementa la visión global de otros métodos.</p>'
    ),
    'Counterfactual Explanations' : (
        '<h4>Counterfactual Explanations</h4>'
        '<p>Las <b>explicaciones contrafactuales</b> muestran cómo debe modificarse una observación para que el modelo devuelva una predicción significativamente distinta, con el menor cambio posible en sus variables.</p>'

        '<h5>¿Cómo funciona?</h5>'
        '<ul>'
        '<li>Se parte de una predicción original y se busca un valor deseado que suponga un cambio relevante (por ejemplo, un +10%).</li>'
        '<li>Se recorren los datos reales del conjunto de entrenamiento en busca de observaciones cuya predicción cumpla ese cambio.</li>'
        '<li>De entre estas, se selecciona la más cercana (menor distancia) respecto a la observación original.</li>'
        '</ul>'

        '<h5>Interpretación:</h5>'
        '<ul>'
        '<li>La <b>tabla local</b> muestra los contrafactuales más cercanos para las primeras observaciones.</li>'
        '<li>La <b>importancia global</b> indica el cambio medio absoluto necesario en cada variable para alcanzar el objetivo deseado.</li>'
        '<li>El <b>gráfico</b> ayuda a identificar qué variables son más influyentes a la hora de cambiar el resultado del modelo.</li>'
        '</ul>'

        '<h5>Ventajas:</h5>'
        '<ul>'
        '<li>Interpretabilidad muy intuitiva: responde a la pregunta "¿qué tendría que cambiar para obtener otro resultado?"</li>'
        '<li>Utiliza ejemplos reales del dataset, evitando combinaciones irreales.</li>'
        '</ul>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>Puede no encontrar contrafactuales viables si el cambio deseado es muy ambicioso o los datos están muy restringidos.</li>'
        '<li>Los resultados dependen de la densidad del dataset y de su cobertura del espacio de entrada.</li>'
        '</ul>'

        '<p><i>Resumen:</i> Las explicaciones contrafactuales ofrecen una herramienta poderosa y humana para entender qué modificaciones mínimas podrían generar resultados más deseables en un modelo de regresión.</p>'
    ),
    'Anchors' : (
        '<h4>Anchors</h4>'
        '<p><b>Anchors</b> es un método de explicabilidad local que identifica reglas sencillas tipo "SI/ENTONCES" que justifican una predicción concreta. Estas reglas actúan como <b>anclas</b>, es decir, condiciones que al cumplirse aseguran con alta probabilidad que la predicción del modelo se mantenga inalterada.</p>'

        '<h5>¿Cómo se generan?</h5>'
        '<ul>'
        '<li>Para cada muestra, se selecciona un conjunto de observaciones vecinas (por ejemplo, mediante muestreo aleatorio).</li>'
        '<li>Se binariza la variable de salida en función del valor de la muestra objetivo.</li>'
        '<li>Se entrena un árbol de decisión con profundidad limitada para detectar las reglas que mejor separan los datos según esa binarización.</li>'
        '<li>Se extrae la regla correspondiente a la muestra objetivo (el camino en el árbol).</li>'
        '</ul>'

        '<h5>Interpretación de resultados:</h5>'
        '<ul>'
        '<li>La <b>tabla de reglas ancla</b> muestra, para cada muestra explicada, la regla encontrada, su <i>cobertura</i> (porcentaje de vecinos que la cumplen) y su <i>precisión</i> (porcentaje de vecinos cubiertos cuya predicción coincide con la de la muestra).</li>'
        '<li>La <b>tabla de importancia global</b> refleja la frecuencia con la que cada variable aparece en las reglas generadas para las distintas muestras.</li>'
        '<li>El <b>gráfico de dispersión</b> permite visualizar qué variables son más recurrentes en las reglas ancla, ayudando a detectar aquellas más influyentes en decisiones locales.</li>'
        '</ul>'

        '<h5>Ventajas:</h5>'
        '<ul>'
        '<li>Alta interpretabilidad, ya que genera explicaciones similares a reglas humanas simples.</li>'
        '<li>Evalúa tanto precisión como cobertura, ofreciendo una visión balanceada de la fiabilidad de la explicación.</li>'
        '</ul>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>No siempre se pueden encontrar reglas con buena cobertura y precisión.</li>'
        '<li>Las explicaciones pueden ser sensibles a la selección de vecinos y a la profundidad del árbol.</li>'
        '</ul>'

        '<p><i>Resumen:</i> Anchors permite entender las predicciones de un modelo mediante reglas simples que fijan su comportamiento local. Es especialmente útil cuando se busca justificar decisiones modelo en términos comprensibles y accionables.</p>'
    ),
    'Surrogate Models (Global/Local)' : (
        '<h4>Surrogate Models (Global/Local)</h4>'
        '<p>Los modelos sustitutos permiten interpretar el comportamiento de un modelo complejo mediante un segundo modelo interpretable que lo imita. En este motor se utilizan dos enfoques complementarios:</p>'
        '<h5>🔹 Surrogate Global</h5>'
        '<p>Se construye un árbol de decisión de profundidad limitada que se entrena sobre el dataset completo, utilizando como variable dependiente la salida del modelo original. El árbol actúa como un "modelo proxy" que resume las reglas generales de decisión del modelo complejo. La tabla resultante muestra la importancia relativa de cada variable en el árbol (contribución a la reducción del error).</p>'
        '<h5>🔸 Surrogate Local</h5>'
        '<p>Para cada una de las primeras muestras se construye un modelo lineal ajustado en su vecindario más cercano. Esto permite identificar qué variables tienen mayor influencia en cada caso individual. Se calcula el valor medio absoluto de los coeficientes para todas las variables y se presenta como una medida de importancia local.</p>'
        '<h5>📊 Comparación gráfica</h5>'
        '<p>El gráfico compara visualmente la importancia de cada variable en el modelo global frente a su influencia local promedio. Las variables con alta importancia en ambos enfoques son especialmente robustas. En cambio, si una variable tiene alta influencia local pero no global (o viceversa), puede indicar comportamientos específicos o inconsistencias locales.</p>'
        '<h5>✅ Utilidad</h5>'
        '<p>Este enfoque resulta útil cuando se desea contrastar patrones globales con explicaciones locales, evaluar consistencia en la importancia de las variables o detectar sesgos o excepciones locales en el modelo.</p>'
        '<h4>Surrogate Models (Global/Local)</h4>'
        '<p>Un <b>modelo sustituto</b> imita el comportamiento del modelo complejo con un algoritmo interpretable.</p>'
        '<h5>Global</h5><p>Árbol de decisión entrenado sobre todo el dataset.</p>'
        '<h5>Local</h5><p>Regresiones lineales ajustadas en vecindarios de cada muestra.</p>'
        '<p>Las tablas y el gráfico resumen la importancia de variables a ambas escalas.</p>'
    ),
    'Explainable Boosting Machine (EBM)' : (
        '<h4>Explainable Boosting Machine (EBM)</h4>'
        '<p>EBM (Explainable Boosting Machine) es un modelo de aprendizaje automático de tipo aditivo generalizado (GA²M) que combina interpretabilidad total con capacidad predictiva competitiva.</p>'
        '<p>EBM se basa en boosting de árboles muy pequeños (stumps) que se agregan para aprender funciones univariantes (una por variable) o bivariantes (combinaciones seleccionadas automáticamente). Estas funciones se combinan de forma aditiva para producir la predicción.</p>'
        '<h5>🧩 Funcionamiento:</h5>'
        '<ul>'
        '<li>Para cada variable, se ajusta una función parcial que explica su contribución a la predicción.</li>'
        '<li>Estas funciones se aprenden de forma secuencial y se corrigen entre sí (boosting).</li>'
        '<li>Al final, la predicción total es la suma de todas las contribuciones univariantes + un sesgo.</li>'
        '</ul>'
        '<h5>📊 Salidas del motor:</h5>'
        '<ul>'
        '<li><b>Importancia Global</b>: ganancia relativa de cada función parcial, ordenada de mayor a menor.</li>'
        '<li><b>Tabla Local</b>: muestra para las primeras muestras cuánto contribuye cada variable (positiva o negativamente) al valor final predicho.</li>'
        '<li><b>Gráfico de media absoluta</b>: la media de las contribuciones absolutas refleja la influencia promedio de cada variable.</li>'
        '</ul>'
        '<h5>✅ Interpretabilidad:</h5>'
        '<p>EBM permite visualizar cada función de forma directa: cómo cambia la predicción según los valores de una variable. Además, se pueden explorar interacciones seleccionadas por el modelo.</p>'
        '<h5>🧠 Utilidad:</h5>'
        '<p>EBM es especialmente útil cuando se requiere una explicación precisa, reproducible y completamente interpretable del modelo, sin necesidad de técnicas post-hoc.</p>'
    ),
    'Optuna Hyperparameter Importance' : (
        '<h4>Optuna Hyperparameter Importance</h4>'
        '<p>Este motor de interpretabilidad analiza el impacto de cada hiperparámetro en la métrica objetivo utilizada durante la optimización automática con Optuna.</p>'
        '<h5>⚙️ ¿Cómo funciona?</h5>'
        '<p>El motor se basa en el módulo <code>optuna.importance</code>, que estima la importancia de cada hiperparámetro utilizando técnicas basadas en permutaciones o regresión de sustitución. Evalúa cómo varía la métrica objetivo (por ejemplo, el error) cuando se altera un hiperparámetro en particular, manteniendo los demás fijos.</p>'
        '<ul>'
        '<li>Se utiliza un <code>study</code> previamente entrenado (en memoria o desde un archivo).</li>'
        '<li>Se extraen los <code>trials</code> y se aplica el método <code>get_param_importances()</code> para obtener las contribuciones relativas.</li>'
        '</ul>'
        '<h5>📊 Salidas interpretables</h5>'
        '<ul>'
        '<li><b>Tabla de Importancia Global</b>: muestra el porcentaje de influencia de cada hiperparámetro en la variabilidad del resultado. Cuanto mayor sea la contribución, más crítico es ese parámetro para mejorar el rendimiento del modelo.</li>'
        '<li><b>Top 10 Trials</b>: recoge los 10 mejores ensayos (trials) con sus hiperparámetros y resultados, lo que permite identificar configuraciones óptimas.</li>'
        '<li><b>Gráfico de barras</b>: visualiza la importancia relativa de los hiperparámetros, facilitando su comparación directa.</li>'
        '</ul>'
        '<h5>✅ Utilidad práctica</h5>'
        '<p>Esta herramienta es especialmente útil para:</p>'
        '<ul>'
        '<li>Identificar qué hiperparámetros son verdaderamente influyentes y cuáles se pueden fijar o descartar.</li>'
        '<li>Reducir el espacio de búsqueda para futuras optimizaciones.</li>'
        '<li>Justificar decisiones sobre tuning del modelo de forma objetiva y visual.</li>'
        '</ul>'
    ),
    'Todos': '<b>Todos</b>: Mostrar todas las explicaciones anteriores.'
}

# Artifact: assign N_SHAP_SAMPLES
N_SHAP_SAMPLES      = 50

# Artifact: assign N_SHAP_BACKGROUND
N_SHAP_BACKGROUND   = 50

# Artifact: assign N_LIME_SAMPLES
N_LIME_SAMPLES      = 50

# Artifact: assign N_KERNEL_SAMPLES
N_KERNEL_SAMPLES    = 50

# Artifact: assign N_KERNEL_BACKGROUND
N_KERNEL_BACKGROUND = 50

# Artifact: assign N_DEEP_SAMPLES
N_DEEP_SAMPLES      = 50

# Artifact: assign N_PERM_SAMPLES
N_PERM_SAMPLES      = 50

# Artifact: assign N_PDP_SAMPLES
N_PDP_SAMPLES       = 50

# Artifact: assign N_ALE_SAMPLES
N_ALE_SAMPLES       = 50

# Artifact: assign N_ICE_SAMPLES
N_ICE_SAMPLES       = 50

# Artifact: assign N_CF_SAMPLES
N_CF_SAMPLES        = 50

# Artifact: assign N_ANCHOR_SAMPLES
N_ANCHOR_SAMPLES    = 50

# Artifact: assign N_SURR_SAMPLES
N_SURR_SAMPLES      = 100

# Artifact: assign N_EBM_SAMPLES
N_EBM_SAMPLES       = 200

# Artifact: assign GRID_RES
GRID_RES            = 20

# Artifact: assign FIRST_SAMPLES
FIRST_SAMPLES       = 10

# Artifact: assign ALE_BINS
ALE_BINS            = 20

# Artifact: assign ICE_SAMPLES
ICE_SAMPLES         = 50

# Artifact: assign CF_SAMPLES
CF_SAMPLES          = 20

# Artifact: assign CF_TARGET_DELTA
CF_TARGET_DELTA     = 0.1

# Artifact: assign ANC_NEIGHBORS
ANC_NEIGHBORS       = 200

# Artifact: assign SURR_TREE_DEPTH
SURR_TREE_DEPTH     = 3

# Artifact: assign SURR_LOCAL_K
SURR_LOCAL_K        = 50

# Artifact: assign SURR_COLOR_GLOBAL
SURR_COLOR_GLOBAL   = "#1f77b4"

# Artifact: assign SURR_COLOR_LOCAL
SURR_COLOR_LOCAL    = "#d62728"

# Artifact: assign EBM_MAX_ITERS
EBM_MAX_ITERS       = 500

# Artifact: assign OPTUNA_STUDY_FILE
OPTUNA_STUDY_FILE = "optuna_study.pkl"

# Artifact: function _load_optuna_study
def _load_optuna_study(path: str):
    if optuna is None:
        return None
    try:
        with open(path, "rb") as f:
            return pickle.load(f)
    except FileNotFoundError:
        return None

# Artifact: function _fig_to_base64
def _fig_to_base64(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight"); plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode()

# Artifact: function _generate_simple_bar
def _generate_simple_bar(title, feats, vals, ylabel):
    fig, ax = plt.subplots(figsize=(4,3))
    ax.bar(feats, vals, color=["green" if v>0 else "red" for v in vals]); ax.axhline(0,c="k")
    ax.set_title(title); ax.set_ylabel(ylabel); plt.tight_layout();
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: assign _generate_shap_diagram
_generate_shap_diagram = lambda : _generate_simple_bar("Ejemplo Valores SHAP", ["X1","X2","X3","X4"], [0.4,-0.3,0.2,-0.1], "SHAP value")

# Artifact: assign _generate_lime_diagram
_generate_lime_diagram = lambda : _generate_simple_bar("Ejemplo Pesos LIME", ["X1","X2","X3","X4"], [0.7,-0.5,0.25,-0.15], "Peso LIME")

# Artifact: assign _generate_ig_diagram
_generate_ig_diagram   = lambda : _generate_simple_bar("Ejemplo Integrated Gradients", ["X1","X2","X3","X4"], [0.3,-0.1,0.4,-0.2], "IG value")

# Artifact: assign _generate_dl_diagram
_generate_dl_diagram   = lambda : _generate_simple_bar("Ejemplo DeepLIFT / LRP", ["X1","X2","X3","X4"], [0.2,-0.05,0.1,-0.15], "Relevancia")

# Artifact: function _generate_perm_diagram
def _generate_perm_diagram():
    feats = ["X1", "X2", "X3", "X4"]; means = [0.18, 0.07, 0.12, 0.25]; stds = [0.02, 0.01, 0.015, 0.03]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.errorbar(range(len(feats)), means, yerr=stds, fmt='o', capsize=5)
    ax.set_xticks(range(len(feats))); ax.set_xticklabels(feats)
    ax.set_title("Ejemplo Permutation Importance"); ax.set_ylabel("Importancia media"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_pdp_diagram
def _generate_pdp_diagram():
    feats = ["X1", "X2", "X3", "X4"]; rng = [0.8, 0.3, 0.5, 1.0]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.scatter(range(4), rng); ax.set_xticks(range(4)); ax.set_xticklabels(feats)
    ax.set_ylabel("Rango PDP"); ax.set_title("Ejemplo Importancia PDP"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_ale_diagram
def _generate_ale_diagram():
    feats = ["X1", "X2", "X3", "X4"]; rng = [1.1, 0.2, 0.6, 0.9]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.scatter(range(4), rng); ax.set_xticks(range(4)); ax.set_xticklabels(feats)
    ax.set_ylabel("Rango ALE"); ax.set_title("Ejemplo Importancia ALE"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_ice_diagram
def _generate_ice_diagram():
    feats=["X1","X2","X3","X4"]; rng=[0.6,0.15,0.35,0.75]
    fig,ax=plt.subplots(figsize=(4,3)); ax.scatter(range(4),rng); ax.set_xticks(range(4)); ax.set_xticklabels(feats)
    ax.set_ylabel("Rango ICE"); ax.set_title("Ejemplo Importancia ICE"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_cf_diagram
def _generate_cf_diagram():
    feats=["X1","X2","X3","X4"]; costs=[0.2,0.05,0.12,0.3]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.bar(feats, costs, color="steelblue"); ax.set_title("Ejemplo Coste Counterfactual"); ax.set_ylabel("|Δfeature| medio"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_anchor_diagram
def _generate_anchor_diagram():
    feats=["X1","X2","X3","X4"]; cover=[0.45,0.15,0.05,0.35]
    fig,ax=plt.subplots(figsize=(4,3)); ax.bar(feats,cover,color="skyblue"); ax.set_title("Cobertura Anchors ej."); ax.set_ylabel("Cobertura"); plt.tight_layout();
    return f"<img src='data:image/png;base64,{_fig_to_b64(fig)}' width='300px'>"

# Artifact: function _generate_surr_diagram
def _generate_surr_diagram():
    feats = ["X1", "X2", "X3", "X4"]; coef = [0.5, 0.1, 0.3, 0.2]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.bar(feats, coef, color='goldenrod'); ax.set_title('Coeficientes Surrogate ej.'); ax.set_ylabel('|Coef|'); plt.tight_layout()
    b64 = _fig_to_b64(fig)
    return f"<img src='data:image/png;base64,{b64}' width='300px'>"

# Artifact: function _generate_ebm_diagram
def _generate_ebm_diagram():
    feats=["X1","X2","X3","X4"]; gains=[0.25,0.1,0.15,0.35]
    fig,ax=plt.subplots(figsize=(4,3)); ax.bar(feats,gains,color='seagreen');
    ax.set_title('Importancia EBM ej.'); ax.set_ylabel('Ganancia relativa'); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_b64(fig)}' width='300px'>"

# Artifact: function _generate_optuna_diagram
def _generate_optuna_diagram():
    params=["lr","depth","n_estim","subsample"]; imp=[0.4,0.2,0.25,0.15]
    fig,ax=plt.subplots(figsize=(4,3)); ax.bar(params,imp,color='mediumpurple'); ax.set_title('Importancia Optuna ej.'); ax.set_ylabel('Contribución'); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_b64(fig)}' width='300px'>"

# Artifact: assign explainer
explainer = None

# Artifact: function _motor_shap
def _motor_shap(key, model_obj, X, predict_fn):
    """SHAP completo: valores, tabla y gráfico."""
    if key in ['xgb','rf']:
        explainer = TreeExplainer(model_obj)
        print("Verbose: Usando TreeExplainer")
    elif key=='svr':
        background = shap.sample(X, min(N_SHAP_BACKGROUND, len(X)))
        print(f"Verbose: Background SVR sample shape: {background.shape}")
        explainer = KernelExplainer(predict_fn, background)
        print("Verbose: Usando KernelExplainer para SVR")
    else:
        background = shap.sample(X, min(N_SHAP_BACKGROUND, len(X)))
        print(f"Verbose: Background kernel sample shape: {background.shape}")
        explainer = KernelExplainer(predict_fn, background)
        print("Verbose: Usando KernelExplainer")

    muestra = shap.sample(X, min(N_SHAP_SAMPLES, len(X)))
    print(f"Verbose: Muestra SHAP shape: {muestra.shape}")
    shap_vals = explainer.shap_values(muestra)
    print(f"Verbose: shap_vals shape: {np.array(shap_vals).shape}")

    # gráfica SHAP
    print("Verbose: Generando summary_plot...")
    shap.summary_plot(shap_vals, muestra, plot_type="dot", show=False)
    fig = plt.gcf()      # Nuevo para la celda 12
    plt.show()
    # === Explicación de la gráfica SHAP ===
    display(HTML("""
    <h4>Interpretación del gráfico SHAP</h4>
    <p>En el gráfico summary_plot:<ul>
    <li>Cada punto representa el efecto de una característica en una muestra.</li>
    <li>El eje X muestra el valor SHAP (positivo empuja la predicción hacia arriba, negativo hacia abajo).</li>
    <li>Los colores indican el valor de la característica (rojo = alto, azul = bajo).</li>
    </ul></p>
    """))

    # tabla de valores SHAP
    print("Verbose: Creando DataFrame de valores SHAP...")
    shap_df = pd.DataFrame(shap_vals, columns=X.columns)
    display(HTML("<h4>Valores SHAP (primeras 10 muestras)</h4>"))
    display(shap_df.head(10))

    # === Explicación de la tabla de valores SHAP ===
    display(HTML("""
    <h4>Interpretación de la tabla de valores SHAP</h4>
    <ul>
    <li>Cada fila corresponde a una muestra (observación).</li>
    <li>Cada columna muestra el valor SHAP de esa característica.</li>
    <li>Valores positivos empujan la predicción hacia arriba; negativos, hacia abajo.</li>
    </ul>
    """))

    # importancias globales
    mean_abs = np.abs(shap_vals).mean(axis=0)
    imp_df = pd.DataFrame({'feature':X.columns, 'mean_abs_shap':mean_abs})
    imp_df = imp_df.sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)
    #imp_df = imp_df.sort_values('mean_abs_shap', ascending=False)
    print("Verbose: Importancia global calculada")
    display(HTML("<h4>Importancia global (valor absoluto medio)</h4>"))
    display(imp_df)
    # === Explicación de la importancia global ===
    display(HTML("""
    <h4>Interpretación de la importancia global</h4>
    <p>La importancia global ordena características por su valor absoluto medio de SHAP.</p>
    <p>Valores más altos indican mayor contribución promedio al modelo.</p>
    <p>Ejemplo: Una característica con <i>mean_abs_shap</i>=0.5 contribuye en promedio 0.5 unidades a la predicción.</p>
    """))
    # Estadísticas adicionales  ---- Nuevo para la celda 12
    stats = {
        'shap_mean_abs_overall': float(mean_abs.mean()),
        'shap_std_abs_overall': float(np.abs(shap_vals).std()),
        'shap_imp_percentiles': imp_df['mean_abs_shap'].quantile([0.25,0.5,0.75]).to_dict()
    }
    # Resultado  ---- Nuevo para la celda 12
    resultado = {
        'imp_df': imp_df.rename(columns={'mean_abs_shap':'value'}),
        'df_local': shap_df,
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: exec exec_285
pass

# Artifact: function _motor_lime
def _motor_lime(X, predict_fn):
    """LIME completo."""
    print("Verbose: Generando explicación con LIME para", N_LIME_SAMPLES, "muestras...")
    explainer = LimeTabularExplainer(
        training_data=X.values,
        feature_names=X.columns.tolist(),
        mode='regression'
    )
    # Muestreamos sólo las primeras N_LIME_SAMPLES instancias
    X_sample = X.iloc[:N_LIME_SAMPLES]

    # calcular explicaciones para todas las muestras
    local_weights = np.zeros((X_sample.shape[0], X_sample.shape[1]))
    for i in range(X_sample.shape[0]):
        exp = explainer.explain_instance(X_sample.values[i], predict_fn)
        # usar índice_feat de exp.as_map()[0]
        for feat_idx, weight in exp.as_map()[0]:
            local_weights[i, feat_idx] = weight

    # tabla primeras 10 muestras
    lime_df = pd.DataFrame(local_weights, columns=X.columns)
    display(HTML("<h4>Valores LIME (primeras 10 muestras)</h4>"))
    display(lime_df.head(10))
    # Explicación tabla LIME
    display(HTML(
        '<p>En la tabla de LIME local, cada fila es una muestra y cada columna el peso asignado por LIME. '
        'Valores positivos indican que la característica aumenta la predicción localmente, negativos la disminuyen.</p>'
    ))

    # importancia global media
    mean_w = np.abs(local_weights).mean(axis=0)
    #imp_df = pd.DataFrame({'feature':X.columns,'mean_abs_weight':mean_w}).sort_values('mean_abs_weight',ascending=False)
    imp_df = pd.DataFrame({'feature': X.columns, 'mean_abs_weight': mean_w})
    imp_df = imp_df.sort_values('mean_abs_weight', ascending=False).reset_index(drop=True)
    display(HTML("<h4>Importancia global LIME</h4>"))
    display(imp_df)
    # Explicación importancia global LIME
    display(HTML(
        '<p>La importancia global de LIME se calcula como el valor absoluto medio de los pesos '
        'a través de todas las muestras. Característica con mayor valor afecta más la predicción de manera local.</p>'
    ))

    # gráfico LIME Value vs Feature Value
    plt.figure(figsize=(8,6))
    for idx, feat in enumerate(X.columns):
        plt.scatter(X_sample[feat], local_weights[:,idx], label=feat, alpha=0.6)
    plt.axhline(0,color='black',linewidth=0.8)
    plt.xlabel('Valor de la característica')
    plt.ylabel('Peso LIME')
    plt.title('LIME: Peso vs Valor de la característica')
    plt.legend(bbox_to_anchor=(1.05,1),loc='upper left')
    plt.tight_layout()
    fig = plt.gcf()           # Nuevo para la celda 12
    plt.show()
    display(HTML(
        '<p>En el gráfico LIME Value vs Feature Value, cada punto representa una muestra. '
        'La posición vertical es el peso LIME, horizontal el valor original de la característica. '
        'Permite ver cómo cambia la influencia de la variable según su valor.</p>'
    ))

    # Estadísticas adicionales  --- Nuevo para la celda 12
    stats = {
        'lime_imp_percentiles': imp_df['mean_abs_weight'].quantile([0.25,0.5,0.75]).to_dict()
    }

    resultado = {
        'imp_df': imp_df.rename(columns={'mean_abs_weight':'value'}),  # ['feature','value']
        'df_local': lime_df,  # DataFrame de pesos locales
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: function _motor_kernel
def _motor_kernel(X, predict_fn):
    """KernelExplainer (SHAP)."""
    print("Verbose: Calculando valores Kernel SHAP para", N_KERNEL_SAMPLES, " muestras...")

    # 1) Tomamos la muestra y el background de X
    muestra     = shap.sample(X, min(N_KERNEL_SAMPLES, len(X)))
    background  = shap.sample(X, min(N_KERNEL_BACKGROUND, len(X)))

    # 2) Creamos el explainer y calculamos SHAP‐values solo para 'muestra'
    ke_expl = KernelExplainer(predict_fn, background)
    print(f"[DEBUG] Calculando SHAP values para {len(muestra)} instancias…")
    ke_vals = ke_expl.shap_values(muestra.values)  # matriz (M, p)

    # 3) Importancia local y global
    ke_df = pd.DataFrame(ke_vals, columns=X.columns)
    mean_ke = np.abs(ke_vals).mean(axis=0)
    imp_df = pd.DataFrame({'feature': X.columns, 'mean_abs_kernel': mean_ke})
    imp_df = imp_df.sort_values('mean_abs_kernel', ascending=False).reset_index(drop=True)

    # 4) Summary plot — **usar 'muestra'**, no 'X' completo
    shap.summary_plot(ke_vals, muestra, show=False)   # <<< aquí estaba el error
    fig = plt.gcf()   # recupera la figura actual

    # 5) Estadísticas adicionales
    stats = {
        'kernel_shap_imp_percentiles': imp_df['mean_abs_kernel'].quantile([0.25,0.5,0.75]).to_dict()
    }

    display(HTML("<h4>Valores Kernel SHAP (primeras 10 muestras)</h4>"))
    display(ke_df.head(10))
    display(HTML(
        '<p>En la tabla anterior, cada fila corresponde a una muestra y cada columna al valor Kernel SHAP de esa característica. '
        'Valores positivos indican empuje hacia arriba, negativos empuje hacia abajo.</p>'
    ))
    display(HTML("<h4>Importancia global Kernel SHAP</h4>"))
    display(imp_df)
    display(HTML(
        '<p>La tabla de importancia global muestra el valor absoluto medio del Kernel SHAP para cada característica. '
        'Característica con valor más alto tiene mayor impacto medio en las predicciones.</p>'
    ))
    plt.show()
    display(HTML(
        '<p>El gráfico summary para Kernel SHAP funciona igual que SHAP: muestra distribución de valores, mostrando heterogeneidad e influencia de cada variable.</p>'
    ))

    # 6) Construir resultado
    resultado = {
        'imp_df': imp_df.rename(columns={'mean_abs_kernel':'value'}),
        'df_local': ke_df,
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: function _motor_ig
def _motor_ig(key, model_obj, X, cols, sx, predict_fn):
    """
    Integrated Gradients:
     - Para SVR/NN/XGBoost/RF: usamos SHAP GradientExplainer.
     - Para RNN: implementamos IG manual sobre la secuencia.
    """
    import numpy as np, pandas as pd, matplotlib.pyplot as plt
    from IPython.display import display, HTML
    import tensorflow as tf

    # parámetros IG
    STEPS   = 50     # pasos de interpolación
    TOP_N   = 5      # features globales a mostrar
    N_LOCAL = 3      # muestras locales a mostrar

    if key != 'rnn':
        # —————— Camino original con SHAP GradientExplainer ——————
        from shap import GradientExplainer

        background = sx.transform(
            X.sample(min(200, len(X)), random_state=0)
        )
        ig_expl = GradientExplainer(model_obj, background)
        vals = ig_expl.shap_values(sx.transform(X))

        # si devuelve shape (n, p, 1): comprímelo a 2D
        if isinstance(vals, np.ndarray) and vals.ndim == 3 and vals.shape[2] == 1:
            vals = np.squeeze(vals, -1)

        ig_vals = vals  # (n, p)
        # DataFrame de valores locales
        ig_df = pd.DataFrame(ig_vals, columns=cols)
        # importancia global
        mean_abs = np.abs(ig_vals).mean(axis=0)
        imp_df = (
            pd.DataFrame({'feature': cols, 'value': mean_abs})
              .sort_values('value', ascending=False)
              .reset_index(drop=True)
        )
        # gráfico global
        fig, ax = plt.subplots(figsize=(6,4))
        ax.barh(imp_df['feature'].head(TOP_N)[::-1],
                imp_df['value'].head(TOP_N)[::-1])
        ax.set_title('IG: Top Global')
        plt.tight_layout()

        display(HTML("<h4>IG: Importancia global (top features)</h4>"))
        display(imp_df.head(TOP_N))
        display(fig)
        display(HTML("<h4>IG: Valores locales (primeras muestras)</h4>"))
        display(ig_df.head(N_LOCAL))

        return {'imp_df': imp_df, 'df_local': ig_df, 'fig_summary': fig}

    else:
        # —————— IG manual para RNN ——————
        # necesitamos X_seq en globals(): array NumPy 3D (n_samples, timesteps, features)
        X_seq = globals().get('X_seq')
        if X_seq is None:
            raise RuntimeError("Para RNN necesitas tener `X_seq` en globals().")

        # submuestra
        n_sub = min(20, X_seq.shape[0])
        idxs  = np.random.RandomState(0).choice(X_seq.shape[0], n_sub, replace=False)
        seqs_np     = X_seq[idxs]                              # NumPy array (n_sub, t, f)
        baseline_np = np.zeros_like(seqs_np[0:1])              # (1, t, f)

        # convertimos a tensores solo para el tape
        seqs_t     = tf.convert_to_tensor(seqs_np,     dtype=tf.float32)
        baseline_t = tf.convert_to_tensor(baseline_np, dtype=tf.float32)

        # acumulador en NumPy
        all_grads = np.zeros_like(seqs_np, dtype=float)       # (n_sub, t, f)

        # bucle de interpolación
        for alpha in np.linspace(0, 1, STEPS):
            interp = baseline_t + alpha * (seqs_t - baseline_t)
            with tf.GradientTape() as tape:
                tape.watch(interp)
                preds = model_obj(interp)                      # (n_sub, 1)
            grads_t = tape.gradient(preds, interp)             # tf.Tensor (n_sub, t, f)
            grads_np = grads_t.numpy()                         # convertimos a NumPy
            all_grads += grads_np

        avg_grads = all_grads / STEPS                         # (n_sub, t, f)
        ig_attribs = (seqs_np - baseline_np) * avg_grads      # (n_sub, t, f)

        # importancia global: promedio absoluto sobre muestras y timesteps
        global_imp = np.mean(np.abs(ig_attribs), axis=(0,1))  # (f,)
        imp_df = (
            pd.DataFrame({'feature': cols, 'value': global_imp})
              .sort_values('value', ascending=False)
              .reset_index(drop=True)
        )

        timesteps = seqs_np.shape[1]

        # — aquí vamos a dividir los locales por variable —
        display(HTML("<h4>IG RNN: Valores locales por variable</h4>"))
        for feat_idx, feat_name in enumerate(cols):
            # extraemos la matriz (N_LOCAL, timesteps) para esta variable
            local_mat = ig_attribs[:N_LOCAL, :, feat_idx]
            local_df   = pd.DataFrame(
                local_mat,
                index=[f"muestra {i+1}" for i in range(local_mat.shape[0])],
                columns=[f"timestep {t}" for t in range(timesteps)]
            )
            display(HTML(f"<h5>Variable: {feat_name}</h5>"))
            display(local_df)

        # gráfico global RNN
        fig, ax = plt.subplots(figsize=(6,4))
        ax.barh(imp_df['feature'].head(TOP_N)[::-1],
                imp_df['value'].head(TOP_N)[::-1])
        ax.set_title('IG RNN: Top Global')
        plt.tight_layout()

        display(HTML("<h4>IG RNN: Importancia global</h4>"))
        display(imp_df.head(TOP_N))
        display(fig)

        return {'imp_df': imp_df, 'df_local': local_df, 'fig_summary': fig}

# Artifact: function _motor_dl
def _motor_dl(model_obj, key, X, cols, sx, sy):
    """DeepLIFT / LRP."""
    print("🔍 Calculando DeepLIFT/LRP para todas las muestras...")
    from shap import GradientExplainer
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import display, HTML

    # 1) Crear la submuestra y escalarla ─────────────────────────
    X_sample = X.sample(min(N_DEEP_SAMPLES, len(X)), random_state=0)
    X_scaled = sx.transform(X_sample)

    # ── 2) Si es RNN, reshape 2D→3D según la forma de entrada del modelo ──
    if key == 'rnn':
        # model_obj.input_shape suele ser (None, timesteps, features)
        _, timesteps, feat_dim = model_obj.input_shape
        try:
            X_scaled = X_scaled.reshape(-1, timesteps, feat_dim)
            print(f"[DEBUG] DeepLIFT RNN: reshaped a {X_scaled.shape}")
        except Exception as e:
            raise ValueError(
                f"No pude reshapear para RNN: esperaba (_, {timesteps}, {feat_dim}), "
                f"pero sx.transform devolvió {sx.transform(X_sample).shape}. "
                f"Error: {e}"
            )

    # ── 3) Crear explainer y calcular valores ───────────────────────
    explainer_dl = GradientExplainer(model_obj, X_scaled)
    dl_vals = explainer_dl.shap_values(X_scaled)   # ya 3D → funciona OK

    # 1.1) Squeeze si viene con dimensión extra
    if isinstance(dl_vals, np.ndarray):
        # eliminar ejes de longitud 1
        dl_vals = np.squeeze(dl_vals)
        print(f"[DEBUG] tras squeeze: {dl_vals.shape}")
        # si sigue siendo 3D, asumimos (n_samples, time_steps, n_features)
        if dl_vals.ndim == 3:
            # colapsamos time_steps tomando la media
            dl_vals = dl_vals.mean(axis=1)
            print(f"[DEBUG] tras mean over time axis: {dl_vals.shape}")

    # ── 5) DataFrame de relevancias locales ─────────────────────────
    dl_df = pd.DataFrame(dl_vals, columns=cols)
    display(HTML('<h4>DeepLIFT / LRP: Primeras 10 muestras</h4>'))
    display(dl_df.head(10))
    display(HTML("""
    <h4>📝 Cómo leer la tabla de las primeras 10 muestras</h4>
    <ul>
      <li>Cada fila corresponde a una de las primeras 10 observaciones de tu conjunto de datos.</li>
      <li>Cada columna muestra la relevancia asignada por DeepLIFT/LRP a esa característica en esa muestra.</li>
      <li>Un valor positivo indica que la característica empujó la predicción <b>hacia arriba</b> respecto al valor de referencia.</li>
      <li>Un valor negativo indica que la característica empujó la predicción <b>hacia abajo</b>.</li>
      <li>Por ejemplo, si para la muestra #3 el valor en la columna X2 es 0.15, quiere decir que X2 aumentó la salida del modelo en 0.15 unidades.</li>
    </ul>
    """))

    # ── 6) Importancia global (media absoluta) ───────────────────────
    mean_abs = np.abs(dl_vals).mean(axis=0)
    #imp_df = pd.DataFrame({'feature':cols,'mean_abs_dl':mean_abs}).sort_values('mean_abs_dl',ascending=False)
    imp_df = pd.DataFrame({'feature': cols, 'mean_abs_dl': mean_abs})
    imp_df = imp_df.sort_values('mean_abs_dl', ascending=False).reset_index(drop=True)
    display(HTML('<h4>DeepLIFT / LRP: Importancia global</h4>'))
    display(imp_df)
    display(HTML("""
    <h4>📝 Cómo leer la tabla de importancia global</h4>
    <ul>
      <li>La “importancia global” es la media del valor absoluto de las relevancias en <b>todas</b> las muestras.</li>
      <li>Se ordena de mayor a menor: las variables que aparecen arriba son las que, en promedio, más afectan la predicción.</li>
      <li>Por ejemplo, si la media absoluta de X4 es 0.35, significa que X4 desvió la predicción en ±0.35 de media.</li>
    </ul>
    """))

    # ── 7) Gráfico de importancia global ────────────────────────────
    plt.figure(figsize=(8,4))
    plt.scatter(range(len(imp_df)), imp_df['mean_abs_dl'], s=80)
    plt.xticks(range(len(imp_df)), imp_df['feature'], rotation=45)
    plt.title('Importancia DeepLIFT / LRP')
    display(HTML("""
    <h4>📝 Cómo interpretar el gráfico de relevancias</h4>
    <ul>
      <li>Cada barra representa la relevancia media absoluta de una característica (la misma que en la tabla).</li>
      <li>La altura de la barra indica cuán importante es esa variable en el conjunto completo.</li>
      <li>Las barras verdes (si tuvieras colores) son relevancias positivas medias y las rojas negativas medias.</li>
      <li>Una barra alta significa que, variando esa característica, la predicción del modelo cambia sustancialmente.</li>
      <li>Este gráfico te ayuda a ver de un vistazo qué variables “mueven” más la predicción.</li>
    </ul>
    """))
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # ── 8) Estadísticas adicionales ─────────────────────────────────
    stats = {'dlrp_imp_percentiles': imp_df['mean_abs_dl'].quantile([0.25, 0.5, 0.75]).to_dict()}

    # ── 9) Devolver en el formato esperado ───────────────────────────
    resultado = {
        'imp_df': imp_df.rename(columns={'mean_abs_dl':'value'}),
        'df_local': dl_df,
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: function _motor_perm
def _motor_perm(model_obj, X, cols, sx, sy):
    """Permutation Feature Importance."""
    from sklearn.inspection import permutation_importance
    import numpy as np, pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("🔍 Calculando Permutation Importance para un subconjunto de muestras...")

    # 1) Seleccionamos X_test/Y_test o fallback a X/Y
    X_target = globals().get('X_test', X)
    y_target = globals().get('Y_test', None)
    if y_target is None:
        raise ValueError("Y_test no definido para Permutation Importance")

    # ──────────────────────────────────────────────────────────
    # 1.1) HARD–CODE: número de muestras para la permutación
    #N_PERM_SAMPLES = 50
    # 1.2) Muestreamos esas instancias
    idxs = X_target.sample(
        n=min(N_PERM_SAMPLES, len(X_target)),
        random_state=0
    ).index
    X_target = X_target.loc[idxs, cols]
    y_target = y_target.loc[idxs]
    print(f"[DEBUG] Usando {len(X_target)} muestras para Permutation Importance")
    # ──────────────────────────────────────────────────────────

    # 2) Escalamos nuestro subset
    X_scaled = sx.transform(X_target)

    # 3) Calculamos la importancia por permutación
    if hasattr(model_obj, 'predict'):
        perm = permutation_importance(
            model_obj,
            X_scaled,
            y_target.values.ravel(),
            n_repeats=10,
            random_state=42,
            n_jobs=-1
        )
    else:
        raise TypeError("Modelo no soporta permutation_importance")

    # 4) Creamos el DataFrame ordenado
    imp_df = pd.DataFrame({
        'feature':         cols,
        'mean_importance': perm.importances_mean,
        'std_importance':  perm.importances_std
    }).sort_values('mean_importance', ascending=False).reset_index(drop=True)

    # 5) Mostramos la tabla global
    display(HTML('<h4>Permutation Importance (subconjunto)</h4>'))
    display(imp_df)

    # 6) Gráfico con barras de error
    plt.figure(figsize=(8,4))
    plt.errorbar(
        range(len(imp_df)),
        imp_df['mean_importance'],
        yerr=imp_df['std_importance'],
        fmt='o', capsize=5
    )
    plt.xticks(range(len(imp_df)), imp_df['feature'], rotation=45)
    plt.title('Permutation Feature Importance')
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # 7) Estadísticas adicionales
    stats = {
        'perm_imp_percentiles': imp_df['mean_importance']
                                  .quantile([0.25,0.5,0.75])
                                  .to_dict()
    }

    # 8) Devolvemos el resultado en el formato esperado
    return {
        'imp_df':      imp_df.rename(columns={'mean_importance':'value'}),
        'df_local':    imp_df.head(N_PERM_SAMPLES),  # top-N features
        'fig_summary': fig,
        'stats':       stats
    }

# Artifact: function _motor_pdp
def _motor_pdp(X: pd.DataFrame, cols: list[str], predict_fn):
    import numpy as np, pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("[DEBUG] Iniciando motor PDP")

    # ──────────────────────────────────────────────────────────
    # HARD–CODE: número de muestras para la parte local de PDP
    #N_PDP_SAMPLES = 50
    print(f"[DEBUG] Usando {N_PDP_SAMPLES} muestras aleatorias para PDP local")
    # ──────────────────────────────────────────────────────────

    # ---------- PDP global -----------------------------------
    pdp_ranges = []
    pdp_curves = {}
    for feat in cols:
        print(f"[DEBUG] Calculando PDP global para feature '{feat}'")
        grid = np.linspace(X[feat].min(), X[feat].max(), GRID_RES)
        pd_vals = []
        for g in grid:
            X_temp = X.copy()
            X_temp[feat] = g
            preds = predict_fn(X_temp)
            pd_vals.append(preds.mean())
        pd_vals = np.array(pd_vals)
        pdp_curves[feat] = pd_vals
        pdp_ranges.append(pd_vals.max() - pd_vals.min())

    imp_df = (
        pd.DataFrame({"feature": cols, "pdp_range": pdp_ranges})
          .sort_values("pdp_range", ascending=False)
          .reset_index(drop=True)
    )
    print("[DEBUG] DataFrame de importancia global PDP creado")

    display(HTML("<h4>PDP: Importancia global (rango de la curva)</h4>"))
    display(imp_df)
    display(HTML(
        "<p>La <b>importancia global</b> de cada característica se mide "
        "como el rango (máx − mín) de su curva PDP.</p>"
    ))

    # ---------- PDP local (subconjunto aleatorio) -------------
    X_sample = X.sample(n=min(N_PDP_SAMPLES, len(X)), random_state=0)
    n_samples = len(X_sample)
    print(f"[DEBUG] Calculando PDP local para {n_samples} muestras")

    base_pred_mean = predict_fn(X).mean()
    pdp_local = np.zeros((n_samples, len(cols)))
    for i, (_, row) in enumerate(X_sample.iterrows()):
        for j, feat in enumerate(cols):
            X_temp = X.copy()
            X_temp[feat] = row[feat]
            pdp_local[i, j] = predict_fn(X_temp).mean() - base_pred_mean

    pdp_df = pd.DataFrame(pdp_local, columns=cols)
    print("[DEBUG] DataFrame de PDP local creado")

    display(HTML(f"<h4>PDP: Valores para {n_samples} muestras seleccionadas</h4>"))
    display(pdp_df)
    display(HTML(
        "<p>Cada celda muestra cuánto varía la predicción promedio cuando "
        "fijamos la característica al valor de la muestra.</p>"
    ))

    # ---------- Gráfico global --------------------------------
    print("[DEBUG] Generando gráfico de importancia global PDP")
    plt.figure(figsize=(8, 4))
    plt.scatter(range(len(imp_df)), imp_df["pdp_range"], s=80)
    plt.xticks(range(len(imp_df)), imp_df["feature"], rotation=45)
    plt.ylabel("Rango PDP")
    plt.title("Importancia Partial Dependence (rango)")
    plt.axhline(0, color="black", linewidth=0.8)
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # ---------- Estadísticas adicionales ----------------------
    stats = {
        "pdp_range_percentiles": imp_df["pdp_range"]
                                   .quantile([0.25, 0.5, 0.75])
                                   .to_dict()
    }
    print(f"[DEBUG] Estadísticas adicionales calculadas: {stats}")

    # ---------- Resultado -------------------------------------
    return {
        "imp_df":      imp_df.rename(columns={"pdp_range": "value"}),
        "df_local":    pdp_df,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_ale
def _motor_ale(X: pd.DataFrame, cols: list[str], predict_fn, n_bins: int = ALE_BINS):
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("[DEBUG] Iniciando motor ALE")

    # ──────────────────────────────────────────────────────────
    # HARD–CODE: número de muestras para la parte local de ALE
    print(f"[DEBUG] Usando {N_ALE_SAMPLES} muestras aleatorias para ALE local")
    # ──────────────────────────────────────────────────────────

    # ---------- ALE global ------------------------------------
    ale_ranges = []
    ale_curves = {}
    for feat in cols:
        print(f"[DEBUG] Calculando ALE global para '{feat}'")
        # bordes de los bins
        edges = np.quantile(X[feat], np.linspace(0, 1, n_bins + 1))
        edges[0] -= 1e-9
        edges[-1] += 1e-9

        curve = np.zeros(n_bins)
        cum = 0.0
        for b in range(n_bins):
            lo, hi = edges[b], edges[b+1]
            mask = (X[feat] > lo) & (X[feat] <= hi)
            if mask.any():
                X_lo = X.loc[mask].copy(); X_hi = X.loc[mask].copy()
                X_lo[feat] = lo; X_hi[feat] = hi
                delta = predict_fn(X_hi) - predict_fn(X_lo)
                cum += delta.mean()
            curve[b] = cum
        ale_curves[feat] = curve
        ale_ranges.append(curve.max() - curve.min())

    imp_df = (
        pd.DataFrame({"feature": cols, "ale_range": ale_ranges})
          .sort_values("ale_range", ascending=False)
          .reset_index(drop=True)
    )
    print("[DEBUG] DataFrame de importancia global ALE creado")

    display(HTML("<h4>ALE: Importancia global (rango)</h4>"))
    display(imp_df)
    display(HTML(
        "<p>El <b>rango ALE</b> mide cuánto varía la curva acumulada "
        "al recorrer toda la distribución de la variable.</p>"
    ))

    # ---------- ALE local (subconjunto aleatorio) -------------
    X_sample = X.sample(n=min(N_ALE_SAMPLES, len(X)), random_state=0)
    n_samples = len(X_sample)
    print(f"[DEBUG] Calculando ALE local para {n_samples} muestras seleccionadas")

    ale_local = np.zeros((n_samples, len(cols)))
    for i, (_, row) in enumerate(X_sample.iterrows()):
        for j, feat in enumerate(cols):
            # identificar bin de la muestra
            bin_idx = np.digitize(row[feat], edges[1:-1], right=True)
            ale_local[i, j] = ale_curves[feat][bin_idx]

    ale_df = pd.DataFrame(ale_local, columns=cols)
    print("[DEBUG] DataFrame de ALE local creado")

    display(HTML(f"<h4>ALE: Valores para {n_samples} muestras seleccionadas</h4>"))
    display(ale_df)
    display(HTML(
        "<p>Cada celda muestra el valor ALE acumulado en el bin en que cae la muestra.</p>"
    ))

    # ---------- Gráfico global --------------------------------
    print("[DEBUG] Generando gráfico de importancia global ALE")
    plt.figure(figsize=(8, 4))
    plt.scatter(range(len(imp_df)), imp_df["ale_range"], s=80)
    plt.xticks(range(len(imp_df)), imp_df["feature"], rotation=45)
    plt.ylabel("Rango ALE")
    plt.title("Importancia Accumulated Local Effects")
    plt.axhline(0, color="black", linewidth=0.8)
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # ---------- Estadísticas adicionales ----------------------
    stats = {
        "ale_range_percentiles": imp_df["ale_range"]
                                   .quantile([0.25, 0.5, 0.75])
                                   .to_dict()
    }
    print(f"[DEBUG] Estadísticas adicionales calculadas: {stats}")

    # ---------- Resultado -------------------------------------
    return {
        "imp_df":      imp_df.rename(columns={"ale_range": "value"}),
        "df_local":    ale_df,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_ice
def _motor_ice(
    X: pd.DataFrame,
    cols: list[str],
    predict_fn,
    *,
    grid_res: int = GRID_RES
):
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("[DEBUG] Iniciando motor ICE")

    # ─────────────────────────────────────────────────────────────────
    # HARD–CODE: número de muestras para ICE (tanto global como local)
    #N_ICE_SAMPLES = 50
    print(f"[DEBUG] Usando N_ICE_SAMPLES={N_ICE_SAMPLES} para ICE global y local")
    # ─────────────────────────────────────────────────────────────────

    # ─── 1) Tomar subconjunto aleatorio para ICE global y local ─────
    X_sub = X.sample(n=min(N_ICE_SAMPLES, len(X)), random_state=0)
    n_total = len(X_sub)
    n_local = min(FIRST_SAMPLES, n_total)
    print(f"[DEBUG] Submuestra ICE creada con {n_total} instancias (local={n_local})")

    # contenedores
    ice_local = np.zeros((n_local, len(cols)))
    ice_ranges = []

    # ─────────────────────────────────────────────────────────────────
    # 2) Calcular rangos ICE por característica sobre X_sub
    # ─────────────────────────────────────────────────────────────────
    for j, feat in enumerate(cols):
        print(f"[DEBUG] Calculando curvas ICE para '{feat}'")
        grid = np.linspace(X[feat].min(), X[feat].max(), grid_res)
        ranges_feat = []

        for i, (_, row) in enumerate(X_sub.iterrows()):
            # construir DataFrame repitiendo la fila
            X_grid = pd.DataFrame(
                np.repeat(row.values.reshape(1, -1), grid_res, axis=0),
                columns=cols
            )
            X_grid[feat] = grid
            preds = predict_fn(X_grid)
            r = preds.max() - preds.min()
            ranges_feat.append(r)

            if i < n_local:
                ice_local[i, j] = r

        mean_range = float(np.mean(ranges_feat))
        ice_ranges.append(mean_range)
        print(f"[DEBUG] Rango medio ICE para '{feat}': {mean_range:.4f}")

    # ─────────────────────────────────────────────────────────────────
    # 3) Importancia global (media de rangos)
    # ─────────────────────────────────────────────────────────────────
    imp_df = (
        pd.DataFrame({
            "feature": cols,
            "ice_range_mean": ice_ranges
        })
        .sort_values("ice_range_mean", ascending=False)
        .reset_index(drop=True)
    )
    print("[DEBUG] DataFrame de importancia global ICE creado")

    display(HTML("<h4>ICE: Importancia global (media de rangos)</h4>"))
    display(imp_df)
    display(HTML(
        "<p>Cada punto muestra la media del rango ICE de la característica. "
        "Un valor mayor indica mayor sensibilidad de la predicción a esa variable.</p>"
    ))

    # ─────────────────────────────────────────────────────────────────
    # 4) Tabla local (primeras n_local muestras de X_sub)
    # ─────────────────────────────────────────────────────────────────
    ice_df = pd.DataFrame(ice_local, columns=cols)
    print("[DEBUG] DataFrame de ICE local creado")
    display(HTML(f"<h4>ICE: Rangos para las primeras {n_local} muestras</h4>"))
    display(ice_df)

    # ─────────────────────────────────────────────────────────────────
    # 5) Gráfico global
    # ─────────────────────────────────────────────────────────────────
    print("[DEBUG] Generando gráfico de importancia ICE")
    plt.figure(figsize=(8, 4))
    plt.scatter(range(len(imp_df)), imp_df["ice_range_mean"], s=80)
    plt.xticks(range(len(imp_df)), imp_df["feature"], rotation=45)
    plt.ylabel("Rango medio ICE")
    plt.title("Importancia Individual Conditional Expectation")
    plt.axhline(0, color="black", lw=0.8)
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    display(HTML(
        "<p>La dispersión de estos puntos indica qué variables tienen "
        "mayor efecto condicional individual sobre la predicción.</p>"
    ))

    # ─────────────────────────────────────────────────────────────────
    # 6) Estadísticas adicionales
    # ─────────────────────────────────────────────────────────────────
    stats = {
        "ice_range_percentiles": imp_df["ice_range_mean"]
                                    .quantile([0.25, 0.5, 0.75])
                                    .to_dict()
    }
    print(f"[DEBUG] Estadísticas ICE calculadas: {stats}")

    # ─────────────────────────────────────────────────────────────────
    # 7) Resultado
    # ─────────────────────────────────────────────────────────────────
    return {
        "imp_df":      imp_df.rename(columns={"ice_range_mean": "value"}),
        "df_local":    ice_df,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_counterfactual
def _motor_counterfactual(
    X: pd.DataFrame,
    predict_fn,
    *,
    rel_delta: float = CF_TARGET_DELTA,    # +10% por defecto
    show_first: int = FIRST_SAMPLES
):
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("[DEBUG] Iniciando motor Counterfactual")

    # ─────────────────────────────────────────────────────────────────
    # HARD–CODE: número de muestras para buscar contrafactuales
    #N_CF_SAMPLES = 50
    print(f"[DEBUG] Usando N_CF_SAMPLES={N_CF_SAMPLES} para submuestreo")
    # ─────────────────────────────────────────────────────────────────

    # 1) Submuestra aleatoria de X para buscar contrafactuales
    X_sub = X.sample(n=min(N_CF_SAMPLES, len(X)), random_state=0)
    print(f"[DEBUG] Submuestra creada con {len(X_sub)} instancias")

    # 2) Predicciones de la submuestra
    preds_sub = predict_fn(X_sub)
    print("[DEBUG] Predicciones calculadas para submuestra")

    cf_rows = []
    deltas = []

    # 3) Para cada muestra en X_sub, buscar el vecino más cercano que supere el delta
    for i, idx in enumerate(X_sub.index):
        x0 = X_sub.loc[idx].values.reshape(1, -1)
        y0 = preds_sub[i]
        target = y0 * (1 + rel_delta)
        print(f"[DEBUG] Muestra idx={idx}, y0={y0:.4f}, target>={target:.4f}")

        # candidatos de X (pueden ser toda X o X_sub, aquí usamos X para más posibilidades)
        all_preds = predict_fn(X)
        mask = all_preds >= target
        X_cand = X.loc[mask]
        print(f"[DEBUG] Encontrados {len(X_cand)} candidatos que cumplen delta")

        if X_cand.empty:
            cf_rows.append({"Índice": idx, **{c: None for c in X.columns}, "Distancia": None})
            deltas.append(np.nan)
            continue

        nbrs = NearestNeighbors(n_neighbors=1, metric="euclidean")
        nbrs.fit(X_cand.values)
        dist, ind = nbrs.kneighbors(x0, return_distance=True)
        cf = X_cand.iloc[ind[0][0]]
        delta_feat = np.abs(cf.values - x0.ravel())
        mean_delta = float(delta_feat.mean())

        cf_rows.append({
            "Índice":        idx,
            **{c: float(v) for c, v in zip(X.columns, cf.values)},
            "Distancia":    float(dist[0][0])
        })
        deltas.append(mean_delta)
        print(f"[DEBUG] Contrafactual idx={idx}: distancia={dist[0][0]:.4f}, Δmedio_feat={mean_delta:.4f}")

    # 4) Construir DataFrame local
    df_local = pd.DataFrame(cf_rows).set_index("Índice")
    n_show = min(show_first, len(df_local))
    display(HTML(f"<h4>Contrafactuales (primeras {n_show} muestras)</h4>"))
    display(df_local.head(n_show))

    # 5) Importancia global: |Δfeature| medio
    imp_series = pd.Series(0.0, index=X.columns)
    valid = df_local["Distancia"].notna()
    for idx in df_local[valid].index:
        diff = np.abs(df_local.loc[idx, X.columns].values - X.loc[idx].values)
        imp_series += diff
    imp_series /= valid.sum()
    imp_series = imp_series.sort_values(ascending=False)
    imp_df = imp_series.rename("value").reset_index().rename(columns={"index":"feature"})

    display(HTML("<h4>Importancia global por contrafactuales</h4>"))
    display(imp_df)

    # 6) Gráfico de barras
    plt.figure(figsize=(8,4))
    plt.bar(imp_series.index, imp_series.values)
    plt.xticks(rotation=45, ha="right")
    plt.ylabel("|Δfeature| medio")
    plt.title("Importancia global – Counterfactual")
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # 7) Estadísticas adicionales
    stats = {
        "cf_imp_percentiles": imp_series.quantile([0.25, 0.5, 0.75]).to_dict()
    }
    print(f"[DEBUG] Estadísticas contrafactuales: {stats}")

    # 8) Resultado
    return {
        "imp_df":      imp_df,
        "df_local":    df_local,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_anchors
def _motor_anchors(X: pd.DataFrame, cols: list[str], predict_fn):
    """
    Genera reglas-Anchor (árbol surrogate poco profundo) para una SUBmuestra de X.
    Importancia global = frecuencia (relativa) de aparición de cada variable
    en todas las reglas obtenidas.
    """
    import re, random
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.tree import DecisionTreeRegressor
    from IPython.display import display, HTML

    print("[DEBUG] Iniciando motor Anchors")

    # ─────────────────────────────────────────────────────────────────
    # Hardcode: número de muestras a analizar
    #N_ANCHOR_SAMPLES = 50
    print(f"[DEBUG] Usando N_ANCHOR_SAMPLES={N_ANCHOR_SAMPLES}")
    # ─────────────────────────────────────────────────────────────────

    # 1) Submuestra de X para acelerar el proceso
    X_sub = X.sample(n=min(N_ANCHOR_SAMPLES, len(X)), random_state=0)
    n_sub = len(X_sub)
    print(f"[DEBUG] Submuestra creada con {n_sub} instancias")

    # Preparar contadores
    reglas, coberturas, precisiones = [], [], []
    var_freq = {c: 0 for c in cols}

    # 2) Iterar solo sobre la submuestra
    for i, idx in enumerate(X_sub.index):
        x0 = X_sub.loc[idx]
        y0 = predict_fn(x0.values.reshape(1, -1))[0]
        print(f"[DEBUG] Muestra {i+1}/{n_sub} (idx={idx}), pred={y0:.4f}")

        # 3) Vecinos aleatorios de la submuestra
        neigh_idx = random.sample(
            list(X_sub.index),
            k=min(ANC_NEIGHBORS, n_sub)
        )
        X_nei = X_sub.loc[neigh_idx]
        y_nei = predict_fn(X_nei.values)
        print(f"[DEBUG]  Vecinos seleccionados: {len(X_nei)}")

        # 4) Binarizar según exceder o no la predicción base
        y_bin = (y_nei >= y0).astype(int)

        # 5) Ajustar árbol surrogate
        tree = DecisionTreeRegressor(
            max_depth=3, min_samples_leaf=5, random_state=0
        )
        tree.fit(X_nei, y_bin)

        # 6) Extraer las condiciones del path de x0
        node_indicator = tree.decision_path(x0.values.reshape(1,-1))
        features      = tree.tree_.feature
        thresholds    = tree.tree_.threshold

        anchor_conds = []
        for node_id in node_indicator.indices:
            if features[node_id] == -2:
                continue  # hoja
            f_idx = features[node_id]
            feat = cols[f_idx]
            thr  = thresholds[node_id]
            op   = "≤" if x0[feat] <= thr else ">"
            cond = f"{feat} {op} {thr:.3g}"
            anchor_conds.append(cond)
            var_freq[feat] += 1

        # 7) Calcular cobertura y precisión
        cover = np.ones(len(X_nei), dtype=bool)
        for cond in anchor_conds:
            m = re.match(r'\s*(.+?)\s*(≤|>=|>|<)\s*([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)', cond)
            if not m:
                continue
            f, op_sym, val = m.groups()
            val = float(val)
            if op_sym in ("≤", "<="):
                cover &= (X_nei[f] <= val)
            elif op_sym in (">", "≥"):
                cover &= (X_nei[f] >= val)
        coverage  = cover.mean()
        precision = (y_nei[cover] >= y0).mean() if coverage > 0 else 0.0

        reglas.append(" ∧ ".join(anchor_conds))
        coberturas.append(coverage)
        precisiones.append(precision)
        print(f"[DEBUG]  Regla: {' ∧ '.join(anchor_conds)}")
        print(f"[DEBUG]  Cobertura={coverage:.2%}, Precisión={precision:.2%}")

    # ╭─────────────────── Tablas y gráficas ────────────────────────╮
    df_local = pd.DataFrame({
        "Regla":     reglas,
        "Cobertura": coberturas,
        "Precisión": precisiones
    })

    display(HTML("<h4>⚓ Reglas Anchor (submuestra)</h4>"))
    display(df_local.head(10).style.format({"Cobertura":"{:.2%}","Precisión":"{:.2%}"}))

    # Importancia global
    imp = (pd.Series(var_freq) / n_sub).sort_values(ascending=False)
    imp_df = imp.reset_index().rename(columns={"index":"feature", 0:"value"})

    display(HTML("<h4>⚓ Importancia global (frecuencia en submuestra)</h4>"))
    display(imp_df)

    # Gráfico de frecuencias
    plt.figure(figsize=(7,4))
    plt.bar(imp.index, imp.values)
    plt.xticks(rotation=45, ha="right")
    plt.ylabel("Frecuencia")
    plt.title("Anchors – Importancia global")
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # Estadísticas adicionales
    stats = {
        "anchors_freq_percentiles": imp.quantile([0.25,0.5,0.75]).to_dict()
    }
    print(f"[DEBUG] Estadísticas Anchors: {stats}")

    return {
        "imp_df":      imp_df,
        "df_local":    df_local,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_surrogate
def _motor_surrogate(X: pd.DataFrame, cols: list[str], predict_fn):
    """
    Calcula árbol sustituto global + regresiones locales usando solo una
    submuestra de X para acelerar el cálculo.
    """
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.linear_model import LinearRegression
    from IPython.display import display, HTML

    print("[DEBUG] Iniciando motor Surrogate")

    # ─────────────────────────────────────────────────────────────────
    # Hardcode: número de muestras para el surrogate global y local
    #N_SURR_SAMPLES = 100
    print(f"[DEBUG] Usando N_SURR_SAMPLES={N_SURR_SAMPLES}")
    # ─────────────────────────────────────────────────────────────────

    # 1) Submuestra para surrogate global
    n_sub = min(N_SURR_SAMPLES, len(X))
    X_sub = X.sample(n=n_sub, random_state=0)
    print(f"[DEBUG] Submuestra global creada con {n_sub} instancias")

    # ---------- Global surrogate ----------
    y_sub = predict_fn(X_sub)
    print("[DEBUG] Entrenando árbol surrogate global")
    tree = DecisionTreeRegressor(max_depth=SURR_TREE_DEPTH, random_state=0)
    tree.fit(X_sub, y_sub)
    imp_global = pd.Series(tree.feature_importances_, index=cols).sort_values(ascending=False)
    print("[DEBUG] Importancias globales calculadas")

    display(HTML('<h4>🌍 Importancia Global (Surrogate árbol)</h4>'))
    display(imp_global.to_frame('Importancia').T.style.format('{:.3f}'))
    display(HTML(
        '<p>Cada celda muestra la contribución de la variable a la reducción de MSE en el árbol '
        'sustituto entrenado sobre la submuestra.</p>'
    ))

    # ---------- Local surrogates ----------
    n_local = min(FIRST_SAMPLES, n_sub)
    print(f"[DEBUG] Generando {n_local} surrogates locales sobre la submuestra")
    local_abs_coef = np.zeros((n_local, len(cols)))

    # usamos X_sub para vecinos locales
    for i, idx in enumerate(X_sub.index[:n_local]):
        x0 = X_sub.loc[idx]
        # distancias sobre la submuestra
        dists = np.linalg.norm(X_sub.values - x0.values, axis=1)
        neigh_idx = dists.argsort()[1:SURR_LOCAL_K+1]
        X_nei = X_sub.iloc[neigh_idx]
        y_nei = predict_fn(X_nei)
        lin = LinearRegression().fit(X_nei, y_nei)
        local_abs_coef[i] = np.abs(lin.coef_)
        print(f"[DEBUG] Local surrogate {i+1}: coef abs media calculada")

    imp_local = pd.Series(local_abs_coef.mean(axis=0), index=cols).sort_values(ascending=False)
    imp_df_local = imp_local.reset_index().rename(columns={'index':'feature', 0:'value'})
    print("[DEBUG] Importancias locales medias calculadas")

    display(HTML('<h4>🏠 Importancia Local media (|coef|)</h4>'))
    display(imp_df_local)
    display(HTML(
        '<p>Promedio del valor absoluto de los coeficientes de las regresiones locales '
        'sobre la submuestra.</p>'
    ))

    # ---------- Gráfico comparativo ----------
    plt.figure(figsize=(6,4))
    plt.scatter(range(len(imp_global)), imp_global.values,
                label='Global (árbol)', color=SURR_COLOR_GLOBAL)
    plt.scatter(range(len(imp_local)),  imp_local.values,
                label='Local (media coef)', marker='x', color=SURR_COLOR_LOCAL)
    plt.xticks(range(len(cols)), imp_global.index, rotation=45, ha='right')
    plt.ylabel('Importancia / |Coef|')
    plt.title('Comparativa Surrogate Global vs Local')
    plt.legend()
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()
    print("[DEBUG] Gráfico comparativo generado")

    # Estadísticas adicionales
    diff = (imp_global - imp_local).abs()
    stats = {
        'surrogate_global_percentiles': imp_global.quantile([0.25,0.5,0.75]).to_dict(),
        'surrogate_local_percentiles':  imp_local.quantile([0.25,0.5,0.75]).to_dict(),
        'surrogate_diff_percentiles':   diff.quantile([0.25,0.5,0.75]).to_dict()
    }
    print(f"[DEBUG] Estadísticas Surrogate: {stats}")

    # Resultado
    return {
        'imp_df':      imp_df_local,
        'df_local':    pd.DataFrame(local_abs_coef, columns=cols),
        'fig_summary': fig,
        'stats':       stats
    }

# Artifact: function _motor_ebm
def _motor_ebm(
    X: pd.DataFrame,
    cols: list[str],
    predict_fn,
    *,
    max_rounds: int = EBM_MAX_ITERS,
    n_local: int = FIRST_SAMPLES,
):
    """
    • Entrena EBM sobre una submuestra de X para acelerar el cálculo.
    • Muestra importancia global y contribuciones locales (n_local filas).
    """
    from interpret.glassbox import ExplainableBoostingRegressor
    import numpy as np, pandas as pd, matplotlib.pyplot as plt
    from IPython.display import display, HTML

    # 1) Comprobación de disponibilidad de interpret
    if ExplainableBoostingRegressor is None:
        display(HTML(
            "<p style='color:red'>⚠️  Falta el paquete <code>interpret</code>. "
            "Instálalo con <code>pip install interpret</code>.</p>"
        ))
        return

    print("[DEBUG] Iniciando motor EBM")

    # ─────────────────────────────────────────────────────────────────
    # Hardcode: tamaño de la submuestra para EBM
    #N_EBM_SAMPLES = 200
    print(f"[DEBUG] Usando N_EBM_SAMPLES={N_EBM_SAMPLES}")
    # ─────────────────────────────────────────────────────────────────

    # 2) Crear submuestra para entrenamiento global
    n_sub = min(N_EBM_SAMPLES, len(X))
    X_sub = X.sample(n=n_sub, random_state=0)
    print(f"[DEBUG] Submuestra para EBM creada: {n_sub} instancias")

    # 3) Entrenar EBM sobre la submuestra
    y_sub = predict_fn(X_sub)
    print("[DEBUG] Entrenando Explainable Boosting Machine (EBM) sobre submuestra")
    ebm = ExplainableBoostingRegressor(
        max_rounds=max_rounds,
        random_state=0,
        n_jobs=-1
    )
    ebm.fit(X_sub, y_sub)

    # 4) Importancia global
    g_info = ebm.explain_global().data()
    gains = (pd.Series(g_info["scores"], index=g_info["names"])
               .reindex(cols, fill_value=0.0)
               .sort_values(ascending=False))
    imp_df = gains.reset_index().rename(columns={'index':'feature', 0:'value'})
    print("[DEBUG] Importancia global EBM calculada")

    display(HTML("<h4>🌐 Importancia global EBM</h4>"))
    display(gains.to_frame("Ganancia").style.format("{:.3f}"))
    display(imp_df)

    # 5) Contribuciones locales (hasta n_local o tamaño de submuestra)
    n_loc = min(n_local, n_sub)
    print(f"[DEBUG] Calculando contribuciones locales para las primeras {n_loc} instancias de la submuestra")
    contrib = None

    try:  # interpret ≥ 0.26
        _, contrib = ebm.predict(X_sub.iloc[:n_loc], output_contrib=True)
    except TypeError:
        try:  # interpret 0.24 – 0.25
            _, contrib = ebm.predict_and_contrib(X_sub.iloc[:n_loc])
        except (AttributeError, TypeError):
            contrib = None

    # fallback manual si API oficial no disponible
    if contrib is None:
        print("[DEBUG] API local no disponible, calculando manualmente…")
        term_scores = ebm.term_scores_
        term_feats  = getattr(ebm, "feature_groups_", getattr(ebm, "term_features_", None))
        if term_feats is None:
            term_feats = [[i] for i in range(len(cols))]
        bins_attr = "bin_edges_" if hasattr(ebm, "bin_edges_") else "bins_"
        bin_struct = getattr(ebm, bins_attr)

        contrib = np.zeros((n_loc, len(cols)))
        for t, feats in enumerate(term_feats):
            if len(feats) != 1:
                continue
            feat_idx = feats[0]
            # obtener cortes
            cuts = np.asarray(bin_struct[t].get("cuts", []) if isinstance(bin_struct[t], dict) else bin_struct[t])
            if cuts.size == 0:
                continue
            scores = term_scores[t]
            vals = X_sub.iloc[:n_loc, feat_idx].values
            bin_idx = np.searchsorted(cuts, vals, side="right")
            contrib[:, feat_idx] = scores[bin_idx]

    contrib_df = pd.DataFrame(contrib, columns=cols, index=X_sub.index[:n_loc])
    print("[DEBUG] Contribuciones locales calculadas")

    display(HTML(f"<h4>🔎 Contribuciones locales (primeras {n_loc})</h4>"))
    display(contrib_df)

    # 6) Gráfico de importancia local media
    mean_abs = contrib_df.abs().mean().reindex(gains.index)
    plt.figure(figsize=(6,4))
    plt.scatter(range(len(mean_abs)), mean_abs.values, color="seagreen")
    plt.xticks(range(len(mean_abs)), mean_abs.index, rotation=45, ha="right")
    plt.ylabel("|Contribución| media")
    plt.title("Importancia EBM (media |contribución|)")
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()
    print("[DEBUG] Gráfico local EBM generado")

    display(HTML(
        "<p>Cada punto muestra la media del valor absoluto de la contribución de la variable "
        f"en las primeras {n_loc} muestras de la submuestra.</p>"
    ))

    # 7) Estadísticas adicionales
    stats = {
        'ebm_global_percentiles': gains.quantile([0.25,0.5,0.75]).to_dict(),
        'ebm_local_percentiles':  mean_abs.quantile([0.25,0.5,0.75]).to_dict()
    }
    print(f"[DEBUG] Estadísticas EBM: {stats}")

    # 8) Resultado
    return {
        'imp_df':      imp_df,
        'df_local':    contrib_df,
        'fig_summary': fig,
        'stats':       stats
    }

# Artifact: function _motor_optuna
def _motor_optuna(
    X: pd.DataFrame,            # (no se usa pero se mantiene la firma)
    cols: list[str],            # (no se usa)
    _,                          # predict_fn (sin uso)
    default_file: str = "optuna_study.pkl",
    min_trials: int = 10        # nº mínimo aconsejable de trials
):
    """
    Muestra la importancia de hiperparámetros de un `optuna.study.Study`.
    1) Busca un objeto `study` en memoria.
    2) Si no lo encuentra, intenta cargar `default_file`.
    3) Si tampoco está, escanea el directorio en busca de `*.pkl`
       con un objeto Study dentro.
    4) Si sigue sin hallarlo, muestra un mensaje muy explícito con
       los pasos para generarlo.
    """

    # ▸ 0. Comprobar dependencias
    if optuna is None:
        display(HTML(
            "<p style='color:red'>⚠️ <code>optuna</code> no está instalado. "
            "Ejecuta <code>pip install optuna</code> e inténtalo de nuevo.</p>"
        ))
        return
    try:
        from optuna.importance import get_param_importances
    except Exception as e:
        display(HTML(
            f"<p style='color:red'>⚠️ No se pudo importar "
            f"<code>optuna.importance</code>: {e}</p>"
        ))
        return

    # ▸ 1. Intentar encontrar el Study en memoria -------------
    study = globals().get("study")
    source = "memoria"

    # ▸ 2. Intentar cargar el fichero por defecto -------------
    if study is None and os.path.exists(default_file):
        try:
            with open(default_file, "rb") as f:
                study = pickle.load(f)
            source = f'archivo “{default_file}”'
        except Exception as e:
            display(HTML(
                f"<p style='color:red'>⚠️ No se pudo cargar "
                f"<code>{default_file}</code>: {e}</p>"
            ))

    # ▸ 3. Buscar cualquier *.pkl si aún no hay Study ---------
    if study is None:
        for pkl in glob.glob("*.pkl"):
            try:
                with open(pkl, "rb") as f:
                    obj = pickle.load(f)
                if isinstance(obj, optuna.study.Study):
                    study = obj
                    source = f'archivo “{pkl}”'
                    break
            except Exception:
                continue   # ignorar .pkl que no sean Study

    # ▸ 4. Si sigue sin Study → guía al usuario ---------------
    if study is None:
        display(HTML(
            f"""
            <div style='border:1px solid #e57373;padding:10px;border-radius:6px'>
              <h4 style='margin-top:0;color:#c62828'>⚠️  No se encontró ningún estudio Optuna</h4>
              <p>
                Para utilizar este panel primero necesitas <b>crear y guardar</b> un estudio
                Optuna. Tienes dos formas:
              </p>
              <ol>
                <li>Ejecuta una optimización desde el <i>Bloque&nbsp;3 → Optimización</i>
                    (elige motor <code>Optuna</code>). Al finalizar se guardará
                    automáticamente <code>{default_file}</code>.</li>
                <li>Si ya tienes un objeto <code>study</code>, guárdalo manualmente:<br>
                   <code>import pickle<br>
                   with open("{default_file}", "wb") as f:<br>&nbsp;&nbsp;&nbsp;&nbsp;pickle.dump(study, f)</code>
                </li>
              </ol>
              <p>Vuelve a lanzar la explicación cuando dispongas del archivo.</p>
            </div>
            """
        ))
        return

    # ▸ 5. El Study se ha encontrado --------------------------
    n_trials = len(study.trials)
    display(HTML(
        f"<p>✅ <i>Study</i> localizado desde <b>{source}</b> "
        f"con <b>{n_trials}</b> trials.</p>"
    ))
    if n_trials < min_trials:
        display(HTML(
            f"<p style='color:#c57f17'>⚠️ El estudio contiene menos de "
            f"{min_trials} trials; la estimación de importancia puede ser inestable.</p>"
        ))

    # ▸ 6. Calcular importancia de hiperparámetros ------------
    display(HTML("<h4>📊 Importancia global de hiperparámetros</h4>"))
    try:
        importances = get_param_importances(study)
    except Exception as e:
        display(HTML(
            f"<p style='color:red'>⚠️ Falló el cálculo de importancia: {e}</p>"
        ))
        return

    imp_series = pd.Series(importances).sort_values(ascending=False)
    imp_df = imp_series.reset_index().rename(columns={'index':'feature', 0:'value'})
    display(imp_df)
    display(imp_series.to_frame('Contribución').style.format('{:.2%}'))
    display(HTML(
        '<p><b>¿Cómo leerla?</b> El porcentaje indica cuánto explica cada '
        'hiperparámetro la variación de la métrica objetivo. '
        '<br>• <b>> 25 %</b> ⇒ parámetro crítico.<br>'
        '• <b>< 5 %</b> ⇒ parámetro con poca influencia.</p>'
    ))

    # ▸ 7. Mostrar Top-10 trials ------------------------------
    best_trials = sorted(study.trials, key=lambda t: t.value)[:10]
    df_trials   = pd.DataFrame(
        [{"value": t.value, **t.params} for t in best_trials]
    )
    display(HTML("<h4>🏅 Top 10 trials</h4>")); display(df_trials)

    # ▸ 8. Gráfico de barras ---------------------------------
    plt.figure(figsize=(6,4))
    plt.bar(imp_series.index, imp_series.values, color='mediumpurple')
    plt.ylabel('Contribución (%)'); plt.title('Importancia hiperparámetros Optuna')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    fig = plt.gcf()               # Nuevo para la celda 12
    plt.show()

    display(HTML(
        '<p>La altura de cada barra muestra la influencia relativa. '
        'Úsalo para priorizar en futuras búsquedas.</p>'
    ))

    stats = {
        'optuna_imp_percentiles': imp_series.quantile([0.25,0.5,0.75]).to_dict()
    }
    resultado = {
        'imp_df': imp_df,
        'df_local': df_trials,  # top trials
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: assign out_rec
out_rec = widgets.Output()

# Artifact: function mostrar_xai
def mostrar_xai():
    import pandas as pd
    import ipywidgets as widgets
    from IPython.display import display

    out_xai = widgets.Output()

    # 1) Output para pintar la tabla de recomendaciones
    out_rec = widgets.Output()

    # Aquí tu lista de dicts con todas las recomendaciones
    recomendaciones = [
        {"Modelo":"SVR",          "🚀 Motor":"SHAP",                     "📈 Rendimiento":"Alto",    "⏳ Rapidez":"Lento",   "💡 Justificación":"Ideal para explicaciones globales en SVR."},
        {"Modelo":"SVR",          "🚀 Motor":"LIME",                     "📈 Rendimiento":"Medio",   "⏳ Rapidez":"Medio",   "💡 Justificación":"Explicaciones locales muy intuitivas."},
        {"Modelo":"NN",           "🚀 Motor":"Integrated Gradients",     "📈 Rendimiento":"Alto",    "⏳ Rapidez":"Medio",   "💡 Justificación":"Óptimo para redes diferenciables."},
        {"Modelo":"NN",           "🚀 Motor":"DeepLIFT / LRP",           "📈 Rendimiento":"Alto",    "⏳ Rapidez":"Rápido",  "💡 Justificación":"Muy eficiente en Atribuciones acumuladas."},
        {"Modelo":"NN",           "🚀 Motor":"SHAP",                     "📈 Rendimiento":"Alto",    "⏳ Rapidez":"Lento",   "💡 Justificación":"Model-agnóstico, capta complejidades no lineales."},
        {"Modelo":"XGBoost",      "🚀 Motor":"SHAP (TreeExplainer)",     "📈 Rendimiento":"Alto",    "⏳ Rapidez":"Rápido",  "💡 Justificación":"Explainer nativo y ultra-rápido para árboles."},
        {"Modelo":"XGBoost",      "🚀 Motor":"Partial Dependence Plot",  "📈 Rendimiento":"Medio",   "⏳ Rapidez":"Medio",   "💡 Justificación":"Visualiza efectos marginales."},
        {"Modelo":"RandomForest", "🚀 Motor":"SHAP (TreeExplainer)",     "📈 Rendimiento":"Alto",    "⏳ Rapidez":"Rápido",  "💡 Justificación":"Exacto global para bosques."},
        {"Modelo":"RandomForest", "🚀 Motor":"Permutation Importance",   "📈 Rendimiento":"Medio",   "⏳ Rapidez":"Medio",   "💡 Justificación":"Fácil de comparar importancias."},
        {"Modelo":"RNN",          "🚀 Motor":"Integrated Gradients",     "📈 Rendimiento":"Alto",    "⏳ Rapidez":"Medio",   "💡 Justificación":"Captura efectos temporales."},
        {"Modelo":"RNN",          "🚀 Motor":"DeepLIFT / LRP",           "📈 Rendimiento":"Alto",    "⏳ Rapidez":"Rápido",  "💡 Justificación":"Eficiente en series temporales."},
    ]

    # 2) Dropdown para seleccionar modelo
    model_dd = widgets.Dropdown(
        options=['SVR','NN','XGBoost','RandomForest','RNN'],
        description='Modelo:',
        layout=widgets.Layout(width='50%')
    )

    # 3) Callback que construye y muestra la tabla
    def _on_model_change(change):
        if change['type']=='change' and change['name']=='value':
            key = change['new']
            # Filtrar sólo las filas que correspondan al modelo seleccionado
            df = pd.DataFrame([r for r in recomendaciones if r['Modelo']==key])
            # Estilizar
            styled = (df.style
                .set_table_styles([
                    {'selector':'th', 'props':[('background-color','#2E3B4E'),
                                              ('color','white'),
                                              ('font-size','14px'),
                                              ('padding','3px'),
                                              ('text-align','center')]},
                    {'selector':'td', 'props':[('font-size','12px'),
                                              ('padding','3px'),
                                              ('text-align','left')]},
                ])
                .hide(axis='index')
                .set_caption(f"🔍 Recomendaciones xIA para {key}")
            )
            # Pintar
            with out_rec:
                out_rec.clear_output()
                display(styled)

    # 4) Registrar el observer **después** de haber definido la función**
    model_dd.observe(_on_model_change, names='value')

    # 1) Tipo
    tipo = widgets.Dropdown(options=[('Entrenado','entrenado'),('Optimizado','optimo')], description='Tipo:', layout=widgets.Layout(width='400px'), style={'description_width': '100px'})
    # 2) Modelo
    modelo = widgets.Dropdown(options=[], description='Modelo:', layout=widgets.Layout(width='400px'), style={'description_width': '100px'})
    # 3) Método selección
    metodo_sel = widgets.Dropdown(options=SELECT_METHODS, description='Método X:', layout=widgets.Layout(width='400px'), style={'description_width': '100px'})
    # xIA methods
    xai = widgets.SelectMultiple(options=XAI_METHODS, description='xIA:', layout=widgets.Layout(width='400px', height='150px'), style={'description_width': '100px'})

    # Widget de ayuda para describir el método xIA seleccionado
    help_html = widgets.HTML(value='Seleccione un método xIA para ver su descripción aquí.')  # <-- Línea nueva

    # Callback para actualizar lista de modelos según tipo
    def _on_tipo(change):
        modelo.options = TRAINED_MODELS if change['new']=='entrenado' else OPTIMIZED_MODELS
    tipo.observe(_on_tipo, names='value')
    modelo.options = TRAINED_MODELS  # por defecto

    # Callback para mostrar ayuda dinámica según selección de xIA
    def _on_xai(change):
        selected = change['new']
        if not selected:
            help_html.value = 'Seleccione un método xIA para ver su descripción aquí.'  # <-- Línea nueva
        else:
            parts = []
            for m in selected:
                desc = XAI_HELP.get(m, '')
                if m == 'SHAP': parts.append(desc + _generate_shap_diagram())
                elif m == 'LIME': parts.append(desc + _generate_lime_diagram())
                elif m == 'KernelExplainer': parts.append(desc + _generate_shap_diagram())
                elif m == 'Integrated Gradients': parts.append(desc + _generate_ig_diagram())
                elif m == 'DeepLIFT / LRP': parts.append(desc + _generate_dl_diagram())
                elif m == 'Permutation Feature Importance': parts.append(desc + _generate_perm_diagram())
                elif m == 'Partial Dependence Plots (PDP)': parts.append(desc + _generate_pdp_diagram())
                elif m == 'Accumulated Local Effects (ALE)': parts.append(desc+_generate_ale_diagram())
                elif m == "Individual Conditional Expectation (ICE) Plots": parts.append(desc+_generate_ice_diagram())
                elif m == "Counterfactual Explanations": parts.append(desc+_generate_cf_diagram())
                elif m == "Anchors": parts.append(desc + _generate_anchor_diagram())
                elif m == "Surrogate Models (Global/Local)": parts.append(desc + _generate_surr_diagram())
                elif m == "Explainable Boosting Machine (EBM)": parts.append(desc + _generate_ebm_diagram())
                elif m == "Optuna Hyperparameter Importance": parts.append(desc + _generate_optuna_diagram())
                else:
                    parts.append(desc)
            help_html.value = ''.join(parts)
    xai.observe(_on_xai, names='value')

    # Botón de explicación
    btn = widgets.Button(description='🔍 Explicar', button_style='info')

    def _on_explain(b):
        import ipywidgets as widgets
        from IPython.display import display, clear_output
        global xai_results
        with out_xai:
            clear_output()

            t = tipo.value
            m_disp = modelo.value
            print(f"-> Tipo: {t}")
            print(f"-> Modelo: {m_disp}")
            print(f"-> Método selección: {metodo_sel.value}")
            print(f"-> xIA seleccionadas: {', '.join(xai.value)}")

            raw = modelo.value  # p.ej. "RNN"
            key = None
            model_display = None

            # 1) Match exacto
            if raw in MODEL_KEYS:
                key = MODEL_KEYS[raw]
                model_display = raw
            else:
                # 2) Fallback sufijo (muy raro que empiece a usarse)
                for display_name, short_key in MODEL_KEYS.items():
                    if raw.endswith(display_name):
                        key = short_key
                        model_display = display_name
                        break

            if key is None:
                raise ValueError(f"No puedo mapear «{raw}» a clave interna de modelo.")

            # Asegurarnos de tener el dict inicializado
            if 'xai_results' not in globals():
                xai_results = {}
            if model_display not in xai_results:
                xai_results[model_display] = {}
            if tipo.value == "entrenado":
                patrones = [
                    # ── EN EL DIRECTORIO ACTUAL ────────────────────────────
                    f"modelo_{key}_{metodo_sel.value.lower()}.pkl",
                    f"{key}_{metodo_sel.value.lower()}.pkl",
                    f"modelo_{key}_{metodo_sel.value.lower()}.h5",
                    f"{key}_{metodo_sel.value.lower()}.h5",
                    # ── EN SUBCARPETAS (recursivo) ─────────────────────────
                    f"**/modelo_{key}_{metodo_sel.value.lower()}.pkl",
                    f"**/{key}_{metodo_sel.value.lower()}.pkl",
                    f"**/modelo_{key}_{metodo_sel.value.lower()}.h5",
                    f"**/{key}_{metodo_sel.value.lower()}.h5",
                ]
            else:  # 'optimo'
                patrones = [
                    # búsqueda de modelo serializado
                    f"modelos_opt/modelo_{key}_{metodo_sel.value.lower()}*_opt*.pkl",
                    # en caso de que guardes metadata por separado
                    f"modelos_opt/meta_{key}_{metodo_sel.value.lower()}*_opt*.pkl",
                    # si también guardas .h5
                    f"modelos_opt/modelo_{key}_{metodo_sel.value.lower()}*_opt*.h5",
                ]
            print("[DEBUG] patrones =", patrones)
            # 2) Búsqueda recursiva
            files = []
            for pat in patrones:
                files.extend(glob.glob(pat, recursive=True))

            # 3) Depuración opcional (puedes comentar la siguiente línea cuando compruebes que funciona)
            pprint.pprint(files)

            # 4) Seleccionar la primera coincidencia
            if not files:
                print(f"⚠️  No se encontró ningún archivo que coincida con los patrones:\n    {patrones}")
                return
            ruta_modelo = files[0]
            print(f"✔️  Modelo encontrado en: {ruta_modelo}")

            print(f"Verbose: Archivos encontrados: {files}")
            if not ruta_modelo:
                print(f"⚠️ No se encontró ningún archivo para patrón(s): {patrones}")
                return
            print(f"Verbose: Cargando ruta_modelo: {ruta_modelo}")

            # ─── cargar modelo y escaladores ────────────────────────────────
            if ruta_modelo.endswith('.pkl'):
                with open(ruta_modelo, 'rb') as f:
                    datos = pickle.load(f)
                # si es un fichero de metadata (no contiene 'model'), buscamos el .h5 asociado
                if 'model' not in datos:
                    print("Verbose: fichero metadata detectado, buscado .h5 correspondiente")
                    # Ejemplo: modelos_opt/meta_nn_pearson_opt_randomsearch.pkl
                    modelo_h5 = ruta_modelo.replace('/meta_', '/modelo_').replace('meta_', 'modelo_').replace('.pkl', '.h5')
                    model_obj = load_model(modelo_h5, compile=False)
                    # ─── Elige una de las dos:
                    # 1) Descompilar:
                    model_obj = load_model(modelo_h5, compile=False)
                else:
                    model_obj = datos['model']
                # en ambos casos sacamos scalers y cols de este .pkl
                sx   = datos.get('sx', datos.get('scaler_X'))
                sy   = datos.get('sy', datos.get('scaler_Y'))
                cols = datos['cols']
                print(f"Verbose: Escaladores y cols cargados de {ruta_modelo}: {list(datos.keys())}")
            elif ruta_modelo.endswith('.h5'):
                model_obj = load_model(ruta_modelo)
                # cargamos sólo el scaler de X si existe en tu metadata
                meta_file = ruta_modelo.replace('modelo_','escaladores_').replace('.h5','.pkl')
                with open(meta_file,'rb') as f:
                    datos_meta = pickle.load(f)
                sx = datos_meta.get('sx', datos_meta.get('scaler_X'))
                sy = None
                cols = datos_meta['cols']
                print("Verbose: NN .h5 cargado. Sólo sx:", sx, "sy será None")
            else:
                raise ValueError(f"Formato de fichero no soportado: {ruta_modelo}")

            # ─── preparar X antes de llamar a los motores ───────────────────
            X = X_data[cols].copy()
            print(f"Verbose: Columnas seleccionadas: {cols}")
            print(f"Verbose: X_data shape: {X.shape}")

            # ─── construir función de predicción ───────────────────────────
            if sy is not None:
                predict_fn = lambda X_in: sy.inverse_transform(
                    model_obj.predict(sx.transform(X_in)).reshape(-1,1)
                ).ravel()
            else:
                if sx is not None:
                    predict_fn = lambda X_in: model_obj.predict(sx.transform(X_in)).ravel()
                else:
                    predict_fn = lambda X_in: model_obj.predict(X_in).ravel()

            # 0) Preparar lista de motores a ejecutar:
            seleccion = list(xai.value)
            if "Todos" in seleccion:
                seleccion = ALL_MOTORES

            # ----------------------------------------------------------
            # ⚙️  Motores de explicación (13 Motores:
            # SHAP, LIME, KernelExplainer, Integrated Gradients, DeepLIFT/LRP, Permutation Importance, Partial Dependence Plots (PDP),
            # Accumulated Local Effects (ALE), Individual Conditional Expectation (ICE) Plots, Counterfactual Explanations, Anchors, Surrogate Models (Global/Local),
            # Explainable Boosting Machine (EBM) y Optuna Hyperparameter Importance.
            # ----------------------------------------------------------
            # ------------- 1. SHAP --------------------------------
            if "SHAP" in seleccion:
                res = _motor_shap(key, model_obj, X, predict_fn)
                if res is not None:
                    xai_results[model_display]['SHAP'] = res

            # ------------- 2. LIME --------------------------------
            if "LIME" in seleccion:
                res = _motor_lime(X, predict_fn)
                if res is not None:
                    xai_results[model_display]['LIME'] = res

            # ------------- 3. KernelExplainer ---------------------
            if "KernelExplainer" in seleccion:
                res = _motor_kernel(X, predict_fn)
                if res is not None:
                    xai_results[model_display]['KernelExplainer'] = res

            # ------------- 4. Integrated Gradients ----------------
            if "Integrated Gradients" in seleccion:
                res = _motor_ig(key, model_obj, X, cols, sx, predict_fn)
                if res is not None:
                    xai_results[model_display]['Integrated Gradients'] = res

            # ------------- 5. DeepLIFT / LRP ----------------------
            if "DeepLIFT / LRP" in seleccion:
                res = _motor_dl(model_obj, key, X, cols, sx, sy)
                if res is not None:
                    xai_results[model_display]['DeepLIFT / LRP'] = res

            # ------------- 6. Permutation Importance --------------
            if "Permutation Feature Importance" in seleccion:
                res = _motor_perm(model_obj, X, cols, sx, sy)
                if res is not None:
                    xai_results[model_display]['Permutation Feature Importance'] = res

            # ------------- 7. Partial Dependence Plots (PDP) ------
            if "Partial Dependence Plots (PDP)" in seleccion:
                res = _motor_pdp(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Partial Dependence Plots (PDP)'] = res

            # ------------- 8. Accumulated Local Effects (ALE) ------
            if "Accumulated Local Effects (ALE)" in seleccion:
                res = _motor_ale(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Accumulated Local Effects (ALE)'] = res

            # ------------- 9. Individual Conditional Expectation (ICE) Plots ------
            if "Individual Conditional Expectation (ICE) Plots" in seleccion:
                res = _motor_ice(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Individual Conditional Expectation (ICE) Plots'] = res

            # ------------- 10. Counterfactual Explanations ------
            if "Counterfactual Explanations" in seleccion:
                res = _motor_counterfactual(X, predict_fn)
                if res is not None:
                    xai_results[model_display]['Counterfactual Explanations'] = res

            # ------------- 11. Anchors ------
            if "Anchors" in seleccion:
                res = _motor_anchors(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Anchors'] = res

            # ------------- 12. Surrogate Models (Global/Local) ------
            if "Surrogate Models (Global/Local)" in seleccion:
                res = _motor_surrogate(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Surrogate Models (Global/Local)'] = res

            # ------------- 13. Explainable Boosting Machine (EBM) ------
            if "Explainable Boosting Machine (EBM)" in seleccion:
                res = _motor_ebm(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Explainable Boosting Machine (EBM)'] = res

            # ------------- 14. Optuna Hyperparameter Importance ------
            if "Optuna Hyperparameter Importance" in seleccion:
                res = _motor_optuna(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Optuna Hyperparameter Importance'] = res

    # enlazar callbacks
    btn.on_click(_on_explain)

    display(
        widgets.VBox([
            tipo, modelo, metodo_sel, xai, help_html, model_dd, out_rec, btn, out_xai
        ])
    )

# Artifact: exec exec_301
from IPython.display import clear_output, Markdown, display

# Artifact: exec exec_302
from IPython.display import HTML

# Artifact: exec exec_303
import openai

# Artifact: exec exec_304
from openai import OpenAI

# Artifact: exec exec_305
import scipy.stats

# Artifact: exec exec_306
from matplotlib.figure import Figure

# Artifact: function sanitize_name
def sanitize_name(s):
    """
    Unifica la sanitización de cualquier string de columna:
    - Reemplaza todo carácter no alfanumérico o guión bajo por '_'
    - Colapsa múltiples '_' consecutivos
    - Elimina '_' al inicio y final
    """
    t = re.sub(r"[^\w]", "_", str(s))
    t = re.sub(r"_+", "_", t)
    return t.strip("_")

# Artifact: assign _api_key
_api_key = os.getenv("OPENAI_API_KEY") or ""

# Artifact: assign _client
_client = OpenAI(api_key=_api_key, timeout=30)

# Artifact: assign MAX_EXPLANATION_TOKENS
MAX_EXPLANATION_TOKENS = 800

# Artifact: assign TEMPERATURE_VAL
TEMPERATURE_VAL = 0.2

# Artifact: class ReportBuilder
class ReportBuilder:
    """Orquesta la creación del informe a partir de globals()."""
    def __init__(self, global_ns):
        self.g = global_ns
        #self.sections = []

        # ——— AÑADIDO: sanitizar sólo una vez que X_train y X_test existen ———
        #import re
        #def clean_name(s):
        #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
        #    t = re.sub(r'_+', '_', t)
        #    return t.strip('_')

        # 1) Limpieza de X_train y X_test
        #for df_name in ('X_train','X_test'):
        #    if df_name in self.g:
        #        df = self.g[df_name]
        #        df.columns = [clean_name(c) for c in df.columns]

        # 2) Limpieza de RESUMEN_METODOS
        #if 'RESUMEN_METODOS' in self.g:
        #    for m, lst in self.g['RESUMEN_METODOS'].items():
        #        if isinstance(lst, list):
        #            self.g['RESUMEN_METODOS'][m] = [clean_name(c) for c in lst]
        #        elif isinstance(lst, pd.DataFrame) and not lst.empty:
        #            # si fuese DataFrame, saneamos su columna de Variable
        #            col = 'Variable' if 'Variable' in lst.columns else lst.columns[0]
        #            self.g['RESUMEN_METODOS'][m][col] = lst[col].astype(str).map(clean_name)

        # ─── **AÑADIDO** SANITIZACIÓN DE LOS payload["cols"] EN OPT_MODELS ───
        #if 'OPT_MODELS' in self.g:
        #    for key, payload in self.g['OPT_MODELS'].items():
        #        if isinstance(payload, dict) and 'cols' in payload:
        #            payload['cols'] = [clean_name(c) for c in payload['cols']]
        # ——— FIN AÑADIDO ———

        self.sections = []

        # NUEVO: atributos para el mejor modelo (se rellenarán en sección de selección integral)
        self.best_model_info = {}

        self.figures = {}   # Guardaremos aquí las figuras matplotlib
        print("[DEBUG] 1.1. ReportBuilder.__init__")

    def build_sections(self):
        import pandas as pd
        import numpy as np
        import matplotlib.pyplot as plt
        from scipy import stats
        print("[DEBUG] 1.2. ReportBuilder.build_sections start")

        # --- Inicio de Bloque para normalizar el payload de OPT_MODELS ---
        def _normalize_payload(raw):
            """
            Toma un payload arbitrario de OPT_MODELS y devuelve siempre
            un dict con las mismas claves: model, sx, sy, cols, best_params, score, metric.
            """
            norm = {}
            # 1) Modelo
            if 'model' in raw:
                norm['model'] = raw['model']
            elif raw.get('model_path'):
                try:
                    import joblib, tensorflow as tf
                    if raw['model_path'].endswith(('.h5','.tf')):
                        from tensorflow.keras.models import load_model
                        norm['model'] = load_model(raw['model_path'], compile=False)
                    else:
                        norm['model'] = joblib.load(raw['model_path'])
                except:
                    norm['model'] = None
            else:
                norm['model'] = None

            # 2) Métadatos: sx, sy, cols, score, metric, best_params
            for k in ('sx','sy','cols','score','metric','best_params'):
                if k in raw:
                    norm[k] = raw[k]
                elif raw.get('meta_path'):
                    if '_meta' not in raw:
                        import pickle
                        raw['_meta'] = pickle.load(open(raw['meta_path'],'rb'))
                    norm[k] = raw['_meta'].get(k) if k!='best_params' else raw['_meta'].get('best_params', {})
                else:
                    norm[k] = None

            # ─── AÑADIDO: asegurar que los cols del payload están saneados ───
            #if norm.get('cols') is not None:
            #    import re
            #    def clean_name(s):
            #        t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
            #        t = re.sub(r'_+', '_', t).strip('_')
            #        return t
            #    norm['cols'] = [clean_name(c) for c in norm['cols']]
            # ────────────────────────────────────────────────────────────────

            return norm

        # ahora, al empezar cada bloque de optimización, en lugar de:
        #    payload = OPT_MODELS[('svr', sel_method, engine)]
        #    model  = payload['model']; sx = payload['sx']; ...
        # harías:
        #    raw = OPT_MODELS[('svr', sel_method, engine)]
        #    p   = _normalize_payload(raw)
        #    model, sx, sy, cols, score, metric, best_params = (
        #        p['model'], p['sx'], p['sy'], p['cols'], p['score'], p['metric'], p['best_params']
        #    )
        # --- Fin de Bloque para normalizar el payload de OPT_MODELS ---

        self.sections.clear()
        #all_metrics = []
        # =============================================================
        # 1. Carga de datos
        # =============================================================
        try:
            if all(k in self.g for k in ("X_data", "Y_data", "FECHAS")):
                X_data = self.g["X_data"]
                Y_data = self.g["Y_data"]
                FECHAS = self.g["FECHAS"]
                n_rows = len(X_data)
                n_cols = X_data.shape[1] if hasattr(X_data, "shape") else None
                cols = list(X_data.columns) if hasattr(X_data, "columns") else None
                n_nulls = X_data.isna().sum().sum() if hasattr(X_data, "isna") else None

                # Tomar solo primeras 5 filas en DataFrame de muestra:
                df_sample = pd.concat([
                    X_data.head(5).reset_index(drop=True),
                    (Y_data.head(5).reset_index(drop=True)
                        .rename(columns=lambda c: f"Y_{c}" if isinstance(Y_data, pd.DataFrame) else "Y")
                        if isinstance(Y_data, pd.DataFrame) else Y_data.head(5).rename("Y")
                    ),
                    FECHAS.head(5).reset_index(drop=True).rename("Fecha")
                ], axis=1)
                self.sections.append(("### Muestra de Datos Cargados (primeras 5 filas)", df_sample))
                print("[DEBUG] 1.3. Sección muestra de datos cargados añadida")

                prompt_carga = (
                    "Por favor, explica de forma profesional y detallada cómo se ha realizado "
                    "la carga de datos, basándote en la siguiente información de contexto:\n\n"
                    f"- Número total de filas originales: {n_rows}\n"
                    f"- Número de variables (columnas) cargadas: {n_cols}\n"
                    f"- Nombres de columnas (muestra): {cols[:5] if cols else 'N/A'}{'...' if cols and len(cols)>5 else ''}\n"
                    f"- Total de valores nulos en X_data: {n_nulls}\n\n"
                    "Explica por qué es importante revisar estos aspectos antes de entrenar modelos, "
                    "qué implicaciones tienen (por ejemplo, manejo de nulos, tipos de datos, fechas, etc.), "
                    "y menciona buenas prácticas en esta fase de carga/preprocesado inicial."
                )
                print("[DEBUG]1.4. Iniciando llamada a OpenAI para explicación de carga...")
                t0 = time.time()
                stream_resp = _client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Eres un experto en ingeniería de datos y preprocesado para ML."},
                        {"role": "user",   "content": prompt_carga}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS,
                    stream=True
                )
                ai_answer_carga = ""
                for chunk in stream_resp:
                    choice = chunk.choices[0]
                    if hasattr(choice, "delta") and hasattr(choice.delta, "content"):
                        delta = choice.delta.content
                        if delta:
                            ai_answer_carga += delta
                ai_answer_carga = ai_answer_carga.strip()
                if ai_answer_carga:
                    self.sections.append((
                        "### 📝 Explicación IA de la Carga de Datos",
                        ai_answer_carga
                    ))
                    print("[DEBUG] 1.5. Sección explicación IA de carga añadida")
                else:
                    print("[DEBUG] No se recibió contenido IA para carga")
            else:
                print("[DEBUG] No están X_data/Y_data/FECHAS en globals(), omito muestra y explicación de carga")
        except Exception as e:
            print(f"[ERROR] al generar sección o explicación IA de carga: {e}")
        # =============================================================
        # 2. Segmentación train/test
        # =============================================================
        try:
            if all(k in self.g for k in ("X_train", "Y_train")):
                df_tr = pd.concat([
                    self.g["X_train"].head(5).reset_index(drop=True),
                    self.g["Y_train"].head(5).reset_index(drop=True)
                ], axis=1)
                self.sections.append((
                    "### Tabla 1: Conjunto de Entrenamiento – Primeras 5 Muestras",
                    df_tr
                ))
                print("[DEBUG] 2.1. Sección entrenamiento añadida")
            else:
                print("[DEBUG] No hay X_train/Y_train en globals()")
        except Exception as e:
            print(f"[ERROR] al crear sección entrenamiento: {e}")

        # 3) Tabla de validación (5 filas)
        try:
            if all(k in self.g for k in ("X_test", "Y_test")):
                df_te = pd.concat([
                    self.g["X_test"].head(5).reset_index(drop=True),
                    self.g["Y_test"].head(5).reset_index(drop=True)
                ], axis=1)
                self.sections.append((
                    "### Tabla 2: Conjunto de Validación – Primeras 5 Muestras",
                    df_te
                ))
                print("[DEBUG] 2.2. Sección test añadida")
            else:
                print("[DEBUG] No hay X_test/Y_test en globals()")
        except Exception as e:
            print(f"[ERROR] al crear sección test: {e}")
        # ... fin de la sección de carga de datos ...

        # =============================================================
        # 3. Resumen estadístico de X_train y Y_train
        # =============================================================
        try:
            if "X_train" in self.g:
                Xtr = self.g["X_train"]
                desc_X = Xtr.describe().T.reset_index().rename(columns={"index":"Variable"})
                desc_X_sample = desc_X.head(10)
                self.sections.append((
                    "### Estadísticos de X_train (primeras 10 variables)", desc_X_sample
                ))
                print("[DEBUG] 3.1. Sección estadísticos X_train añadida")

                prompt_stats = (
                    "Interpreta profesionalmente estos estadísticos de entrenamiento (primeras 10 variables):\n\n"
                    f"{desc_X_sample.to_dict(orient='list')}\n\n"
                    "Comenta posibles implicaciones (por ejemplo: presencia de outliers, escalas muy distintas entre variables, necesidad de normalización, sesgos en la distribución) "
                    "y cuáles podrían ser buenas prácticas antes de entrenar modelos."
                )
                print("[DEBUG] 3.2. Iniciando llamada a OpenAI para explicación IA de estadísticos X_train...")
                stream_resp = _client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Eres un experto en análisis de datos para Machine Learning."},
                        {"role": "user",   "content": prompt_stats}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS,
                    stream=True
                )
                ai_stats = ""
                for chunk in stream_resp:
                    choice = chunk.choices[0]
                    if hasattr(choice, "delta") and hasattr(choice.delta, "content"):
                        delta = choice.delta.content
                        if delta:
                            ai_stats += delta
                ai_stats = ai_stats.strip()
                if ai_stats:
                    self.sections.append((
                        "### 📝 Explicación IA de los Estadísticos de X_train", ai_stats
                    ))
                    print("[DEBUG] 3.3. Sección IA estadísticos X_train añadida")
                else:
                    print("[DEBUG] No se recibió contenido IA para estadísticos X_train")
            else:
                print("[DEBUG] No hay X_train en globals(), omito sección estadísticos X_train")
        except Exception as e:
            print(f"[ERROR] al generar sección estadísticos X_train: {e}")

        try:
            if "Y_train" in self.g:
                Ytr = self.g["Y_train"]
                if isinstance(Ytr, pd.DataFrame):
                    serie = Ytr.iloc[:, 0]
                else:
                    serie = pd.Series(Ytr)
                desc_Ys = serie.describe()  # Series.describe() -> Series
                desc_Y = desc_Ys.to_frame().T.reset_index().rename(columns={"index":"Estadístico"})
                self.sections.append(("### Estadísticos de Y_train", desc_Y))
                print("[DEBUG] 3.4. Sección estadísticos Y_train añadida")

                prompt_Y = (
                    "Interpreta profesionalmente estos estadísticos de la variable objetivo Y:\n\n"
                    f"{desc_Y.to_dict(orient='list')}\n\n"
                    "Comenta posibles implicaciones (asimetría, outliers, necesidad de transformaciones como log, etc.) "
                    "y su efecto posible en el modelado."
                )
                print("[DEBUG] 3.5. Iniciando llamada a OpenAI para explicación IA de Y_train...")
                stream_resp = _client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Eres un experto en análisis de datos para Machine Learning."},
                        {"role": "user",   "content": prompt_Y}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS,
                    stream=True
                )
                ai_Y = ""
                for chunk in stream_resp:
                    choice = chunk.choices[0]
                    if hasattr(choice, "delta") and hasattr(choice.delta, "content"):
                        delta = choice.delta.content
                        if delta:
                            ai_Y += delta
                ai_Y = ai_Y.strip()
                if ai_Y:
                    self.sections.append((
                        "### 📝 Explicación IA de los Estadísticos de Y_train", ai_Y
                    ))
                    print("[DEBUG] 3.6. Sección IA estadísticos Y_train añadida")
                else:
                    print("[DEBUG] No se recibió contenido IA para Y_train")
            else:
                print("[DEBUG] No hay Y_train en globals(), omito sección estadísticos Y_train")
        except Exception as e:
            print(f"[ERROR] al generar sección estadísticos Y_train: {e}")

        # Versión y entorno
        try:
            import sys, sklearn
            #import pandas as _pd
            info = {
                "python_version": sys.version.split()[0],
                "pandas_version": pd.__version__,
                "sklearn_version": sklearn.__version__,
            }
            #import pandas as _pd
            df_env = pd.DataFrame(list(info.items()), columns=["Paquete","Versión"])
            self.sections.append(("### Entorno y Versiones de Librerías", df_env))
            print("[DEBUG] 3.7. Sección entorno/versiones añadida")
        except Exception as e:
            print(f"[ERROR] al generar sección entorno/versiones: {e}")

        # 4) Explicación IA del split al final
        try:
            if all(k in self.g for k in ("X_train", "X_test", "Y_train", "Y_test")):
                sp = self.g.get("SPLIT_PARAMS", {})
                # Construir prompt solo si SPLIT_PARAMS tiene las claves esperadas
                if sp:
                    prompt_split = (
                        "Por favor, explica cómo se ha realizado la segmentación de los datos. "
                        "Usa la siguiente información de contexto:\n\n"
                        f"- Parámetros de segmentación: {sp}\n"
                        f"- Number de muestras train: {len(self.g['X_train'])}\n"
                        f"- Número de muestras test: {len(self.g['X_test'])}\n\n"
                        f"- test_size: {sp.get('test_size')}\n"
                        f"- random_state: {sp.get('random_state')}\n"
                        f"- estratificar: {sp.get('stratify')}\n"
                        f"- método de bins: {sp.get('bin_method')}\n"
                        f"- número de bins: {sp.get('q_bins')}\n\n"
                        "Quiero un texto profesional, bien estructurado y suficientemente detallado, "
                        "que también comente brevemente por qué estos valores de parámetros pueden afectar al rendimiento del modelo."
                    )
                    print("[DEBUG] 3.8. Iniciando llamada a OpenAI para explicación del split...")
                    stream_resp = _client.chat.completions.create(
                        model="gpt-4",
                        messages=[
                            {"role": "system", "content": "Eres un experto en preprocesado de datos."},
                            {"role": "user",   "content": prompt_split}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                        stream=True
                    )
                    ai_answer_split = ""
                    for chunk in stream_resp:
                        choice = chunk.choices[0]
                        if hasattr(choice, "delta") and hasattr(choice.delta, "content"):
                            delta = choice.delta.content
                            if delta:
                                ai_answer_split += delta
                    ai_answer_split = ai_answer_split.strip()
                    if ai_answer_split:
                        self.sections.append((
                            "### 📝 Explicación IA del Preprocesado y del Split",
                            ai_answer_split
                        ))
                        print("[DEBUG] 3.9. Sección explicación IA del split añadida")
                    else:
                        print("[DEBUG] No se recibió contenido IA para split")
                else:
                    print("[DEBUG] No hay SPLIT_PARAMS definidos, omito explicación IA del split")
            else:
                print("[DEBUG] Faltan datos de entrenamiento/test, omito explicación IA del split")
        except Exception as e:
            print(f"[ERROR] al generar explicación IA del split: {e}")
        # ... fin de la sección de Split de los Datos Cargados ...

        # =============================================================
        # 4. Visualizaciones de Y y de las correlaciones X vs Y
        # =============================================================
        import matplotlib.pyplot as plt

        # 2.1 Histograma de Y_train
        try:
            if "Y_train" in self.g:
                y_train = self.g["Y_train"]
                # Si Y_train es DataFrame con varias columnas, tomamos la primera:
                if isinstance(y_train, pd.DataFrame) and y_train.shape[1] > 1:
                    y_ser = y_train.iloc[:, 0]
                else:
                    # si es DataFrame de 1 columna o Serie:
                    y_ser = y_train.iloc[:, 0] if isinstance(y_train, pd.DataFrame) else pd.Series(y_train)
                fig_hist, ax = plt.subplots()
                ax.hist(y_ser.dropna(), bins=30, edgecolor='black')
                ax.set_title("Distribución de Y_train")
                ax.set_xlabel("Y")
                ax.set_ylabel("Frecuencia")
                plt.tight_layout()
                # Guardar figura en self.figures y en sections para render
                self.figures["hist_Y_train"] = fig_hist
                self.sections.append((
                    "### Gráfico: Histograma de Y (Train)",
                    fig_hist
                ))
                print("[DEBUG] 4.1. Sección histograma Y_train añadida")
            else:
                print("[DEBUG] No hay Y_train en globals(), omito histograma")
        except Exception as e:
            print(f"[ERROR] al generar histograma Y_train: {e}")

        # 2.2 Correlación X_train vs Y_train
        # 2.2 Correlación X_train vs Y_train (filtrada por umbral)
        try:
            if "X_train" in self.g and "Y_train" in self.g:
                X_train = self.g["X_train"]
                y_train = self.g["Y_train"]

                if isinstance(y_train, pd.DataFrame) and y_train.shape[1] > 1:
                    y_ser = y_train.iloc[:, 0]
                else:
                    y_ser = y_train.iloc[:, 0] if isinstance(y_train, pd.DataFrame) else pd.Series(y_train)

                df_corr = X_train.copy().reset_index(drop=True)
                df_corr["_Y_target"] = y_ser.reset_index(drop=True)

                corr_matrix = df_corr.corr(numeric_only=True)

                # === 🔍 FILTRO: seleccionar solo columnas con correlación > umbral con _Y_target ===
                umbral_corr = 0.3  # Se puede ajustar este valor
                correlaciones_con_y = corr_matrix["_Y_target"].abs()
                variables_filtradas = correlaciones_con_y[correlaciones_con_y > umbral_corr].index.tolist()

                # Mantener solo las columnas con correlación alta
                corr_matrix_filtrada = corr_matrix.loc[variables_filtradas, variables_filtradas]

                fig_corr, ax = plt.subplots(figsize=(max(10, len(variables_filtradas)*0.6), max(8, len(variables_filtradas)*0.5)))
                cax = ax.matshow(corr_matrix_filtrada, cmap='viridis')
                fig_corr.colorbar(cax, ax=ax, shrink=0.8)

                labels = list(corr_matrix_filtrada.columns)
                ax.set_xticks(range(len(labels)))
                ax.set_yticks(range(len(labels)))
                ax.set_xticklabels(labels, rotation=90, fontsize=8, ha='left')
                ax.set_yticklabels(labels, fontsize=8)

                ax.tick_params(axis='x', which='both', labelsize=7, pad=1)
                ax.tick_params(axis='y', which='both', labelsize=7, pad=1)

                ax.set_title(f"Matriz de correlación (|r| > {umbral_corr})", pad=30, fontsize=12)
                plt.tight_layout()

                self.figures["corr_XY_train"] = fig_corr
                self.sections.append((
                    f"### Gráfico: Matriz de Correlación X vs Y (|r| > {umbral_corr})",
                    fig_corr
                ))
                print("[DEBUG] 4.2. Sección matriz de correlación añadida con filtro")
            else:
                print("[DEBUG] No hay X_train/Y_train en globals(), omito correlación")
        except Exception as e:
            print(f"[ERROR] al generar matriz de correlación: {e}")

#        try:
#            if "X_train" in self.g and "Y_train" in self.g:
#                X_train = self.g["X_train"]
#                y_train = self.g["Y_train"]
#                # Sacar Serie de Y como antes
#                if isinstance(y_train, pd.DataFrame) and y_train.shape[1] > 1:
#                    y_ser = y_train.iloc[:, 0]
#                else:
#                    y_ser = y_train.iloc[:, 0] if isinstance(y_train, pd.DataFrame) else pd.Series(y_train)
#                # Concatenar para cálculo de correlación:
#                df_corr = X_train.copy().reset_index(drop=True)
#                df_corr["_Y_target"] = y_ser.reset_index(drop=True)
#                # Calculamos matriz de correlaciones:
#                corr_matrix = df_corr.corr(numeric_only=True)  # pandas ≥1.5
#                # Creamos heatmap con matplotlib puro:
#                fig_corr, ax = plt.subplots(figsize=(6, 6))
#                cax = ax.matshow(corr_matrix, cmap='viridis')
#                fig_corr.colorbar(cax, ax=ax)
#                # Etiquetas:
#                labels = list(corr_matrix.columns)
#                ax.set_xticks(range(len(labels)))
#                ax.set_yticks(range(len(labels)))
#                ax.set_xticklabels(labels, rotation=90, fontsize=8)
#                ax.set_yticklabels(labels, fontsize=8)
#                ax.set_title("Matriz de correlación (X_train vs Y_train incluida)", pad=20)
#                plt.tight_layout()
#                self.figures["corr_XY_train"] = fig_corr
#                self.sections.append((
#                    "### Gráfico: Matriz de Correlación X vs Y (Train)",
#                    fig_corr
#                ))
#                print("[DEBUG] 4.2. Sección matriz de correlación añadida")
#            else:
#                print("[DEBUG] No hay X_train/Y_train en globals(), omito correlación")
#        except Exception as e:
#            print(f"[ERROR] al generar matriz de correlación: {e}")

        # 2.3 Comentario IA sobre distribución y correlaciones
        try:
            # Solo si disponemos de histogram y/o correlaciones:
            if "hist_Y_train" in self.figures:
                # Preparamos prompt para la IA
                # Ejemplo de contexto: medias, sesgo, kurtosis, correlaciones máximas
                import numpy as np
                # Estadísticos de Y:
                y_arr = y_ser.dropna().values
                media = float(np.mean(y_arr))
                mediana = float(np.median(y_arr))
                std = float(np.std(y_arr, ddof=1))
                # Sesgo y curtosis opcionales si numpy/scipy disponibles:
                try:
                    from scipy.stats import skew, kurtosis
                    sesgo = float(skew(y_arr))
                    kurt = float(kurtosis(y_arr))
                except Exception:
                    sesgo = None
                    kurt = None
                # Estadísticos de correlación: extraer de corr_matrix
                if "corr_XY_train" in self.figures:
                    # Obtenemos correlaciones de X con Y:
                    # La columna “_Y_target”
                    corrs = corr_matrix["_Y_target"].drop("_Y_target", errors='ignore')
                    # Tomamos los pares con mayor valor absoluto:
                    if not corrs.empty:
                        top = corrs.abs().sort_values(ascending=False).head(3)
                        # Formatear para prompt
                        top_info = {col: float(corrs[col]) for col in top.index}
                    else:
                        top_info = {}
                else:
                    top_info = {}
                # Construir prompt:
                prompt_vis = (
                    "Eres un experto en análisis exploratorio de datos.\n"
                    "Analiza la distribución de la variable objetivo Y y las correlaciones "
                    "entre las variables X y Y basándote en estos estadísticos:\n\n"
                    f"- Media de Y_train: {media:.4f}\n"
                    f"- Mediana de Y_train: {mediana:.4f}\n"
                    f"- Desviación estándar de Y_train: {std:.4f}\n"
                )
                if sesgo is not None:
                    prompt_vis += f"- Sesgo (skewness) de Y_train: {sesgo:.4f}\n"
                if kurt is not None:
                    prompt_vis += f"- Curtosis de Y_train: {kurt:.4f}\n"
                if top_info:
                    prompt_vis += "- Correlaciones más relevantes X vs Y:\n"
                    for feat, corrv in top_info.items():
                        prompt_vis += f"    • {feat}: {corrv:.4f}\n"
                prompt_vis += (
                    "\nPor favor, genera un texto profesional y detallado que comente:\n"
                    "  * Si la distribución de Y parece simétrica o sesgada, posibles implicaciones.\n"
                    "  * Si hay variables con fuerte correlación absoluta con Y (positiva o negativa) y qué puede indicar.\n"
                    "  * Buenas prácticas o precauciones al modelar con base en dicha distribución/correlaciones.\n"
                )
                print("[DEBUG] 4.3. Iniciando llamada a OpenAI para comentario visualizaciones...")
                # Llamada a OpenAI (sin stream, con límite de tokens razonable):
                resp = _client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Eres un experto en análisis exploratorio de datos para ML."},
                        {"role": "user", "content": prompt_vis}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS  # ajustable
                )
                comentario_vis = resp.choices[0].message.content.strip()
                if comentario_vis:
                    self.sections.append((
                        "### 📝 Comentario IA: Distribución de Y y Correlaciones",
                        comentario_vis
                    ))
                    print("[DEBUG] 4.4. Sección comentario IA visualizaciones añadida")
                else:
                    print("[DEBUG] No se recibió contenido IA para visualizaciones")
            else:
                print("[DEBUG] No hay histograma de Y para IA, omito comentario visualizaciones")
        except Exception as e:
            print(f"[ERROR] al generar comentario IA de visualizaciones: {e}")
        # ... fin de la sección de visualización de análisis de datos cargados ...

        # =============================================================
        # 5. Selección de variables independientes X
        # =============================================================
        try:
            # Caso 1: RESUMEN_METODOS (varios métodos acumulativos)
            if "RESUMEN_METODOS" in self.g and isinstance(self.g["RESUMEN_METODOS"], dict):
                resumen = self.g["RESUMEN_METODOS"]
            else:
                resumen = None

            # Caso 2: Selección más reciente puntual
            tiene_reciente = all(k in self.g for k in ("VARIABLES_SELECCIONADAS", "METODO_SELECCION"))
            # Preparar datos para correlaciones si están en globals
            tiene_corr = "VALORES_CORRELACION" in self.g
            corr_global = self.g.get("VALORES_CORRELACION", None)

            # También comprobamos si disponemos de X_train/Y_train para recálculo de correl si se prefiere
            have_xy = all(k in self.g for k in ("X_train", "Y_train"))
            if have_xy:
                X_train = self.g["X_train"]
                Y_train = self.g["Y_train"]
                import pandas as _pd  # asegurar pandas disponible
                if isinstance(Y_train, _pd.DataFrame):
                    y_ser = Y_train.iloc[:, 0]
                else:
                    y_ser = Y_train

            # Primero, si RESUMEN_METODOS existe, iteramos cada método
            if resumen:
                # Si además quieres usar VALORES_CORRELACION puntual, podrías ignorarlo aquí
                for metodo, cols in resumen.items():
                    # Construcción de DataFrame con correlaciones
                    df_sel = None
                    if have_xy:
                        corr_vals = []
                        for col in cols:
                            if col in X_train.columns:
                                try:
                                    corr = X_train[col].corr(y_ser)
                                except Exception:
                                    corr = None
                            else:
                                corr = None
                            corr_vals.append(corr)
                        import pandas as _pd
                        df_sel = _pd.DataFrame({
                            "Variable": cols,
                            "Correlación con Y": corr_vals
                        })
                    else:
                        import pandas as _pd
                        df_sel = _pd.DataFrame({"Variable": cols})
                    titulo_tab = f"### Tabla: Selección de Variables ({metodo})"
                    self.sections.append((titulo_tab, df_sel))
                    print(f"[DEBUG] 5.1. Sección selección de variables añadida para método: {metodo}")

                    # Preparar prompt IA
                    # Si existe un dict global con parámetros, usalo; si no, omítelo:
                    params = self.g.get("SELECTION_PARAMS", {}).get(metodo, {})
                    prompt_sel = (
                        f"Has aplicado un método de selección de variables llamado '{metodo}'.\n"
                        f"Parámetros del método: {params}\n"
                        f"Variables seleccionadas ({len(cols)}): {cols}\n"
                    )
                    if have_xy:
                        prompt_sel += "Correlaciones con la variable objetivo:\n"
                        for var, corr in zip(cols, corr_vals):
                            prompt_sel += f"  - {var}: {corr}\n"
                        prompt_sel += "\n"
                    prompt_sel += (
                        "Por favor, genera un texto profesional y detallado que explique:\n"
                        "- En qué consiste este método de selección de variables y significado de sus parámetros.\n"
                        "- Cómo influyen dichos parámetros en la selección.\n"
                        "- Interpretación de los valores de correlación obtenidos.\n"
                        "- Buenas prácticas al usar este método en preprocesado de datos para ML.\n"
                    )
                    try:
                        print(f"[DEBUG] 5.2. Iniciando llamada a OpenAI para explicación selección ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en selección de variables para ML."},
                                {"role": "user", "content": prompt_sel}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_sel = resp.choices[0].message.content.strip()
                        if explanation_sel:
                            titulo_exp = f"### 📝 Explicación IA Selección de Variables ({metodo})"
                            self.sections.append((titulo_exp, explanation_sel))
                            print(f"[DEBUG] 5.3. Sección explicación IA selección añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió contenido IA para selección {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA selección {metodo}: {e}")

            # Luego, si existe una selección puntual reciente
            if not resumen and tiene_reciente:
                metodo = self.g["METODO_SELECCION"]
                cols = self.g["VARIABLES_SELECCIONADAS"]
                # Construir DataFrame
                df_sel = None
                import pandas as _pd
                if tiene_corr:
                    corr_vals = None
                    # VALORES_CORRELACION puede ser dict o lista
                    vc = corr_global
                    if isinstance(vc, dict):
                        # Aseguramos la lista del mismo orden
                        corr_vals = [vc.get(var, None) for var in cols]
                    elif isinstance(vc, (list, tuple)):
                        # Si la longitud coincide con cols
                        if len(vc) == len(cols):
                            corr_vals = list(vc)
                        else:
                            corr_vals = [None]*len(cols)
                    else:
                        corr_vals = [None]*len(cols)
                    df_sel = _pd.DataFrame({
                        "Variable": cols,
                        "Correlación con Y": corr_vals
                    })
                else:
                    # Si no hay VALORES_CORRELACION, pero se dispone de X_train/Y_train, recalculamos
                    if have_xy:
                        corr_vals = []
                        for col in cols:
                            if col in X_train.columns:
                                try:
                                    corr = X_train[col].corr(y_ser)
                                except Exception:
                                    corr = None
                            else:
                                corr = None
                            corr_vals.append(corr)
                        df_sel = _pd.DataFrame({
                            "Variable": cols,
                            "Correlación con Y": corr_vals
                        })
                    else:
                        df_sel = _pd.DataFrame({"Variable": cols})
                titulo_tab = f"### Tabla: Selección de Variables ({metodo})"
                self.sections.append((titulo_tab, df_sel))
                print(f"[DEBUG] 5.4. Sección selección de variables puntual añadida para método: {metodo}")

                # Prompt IA
                prompt_sel = (
                    f"Has aplicado un método de selección de variables llamado '{metodo}'.\n"
                    f"Variables seleccionadas ({len(cols)}): {cols}\n"
                )
                if tiene_corr or have_xy:
                    prompt_sel += "Correlaciones con la variable objetivo:\n"
                    if 'corr_vals' in locals():
                        for var, corr in zip(cols, corr_vals):
                            prompt_sel += f"  - {var}: {corr}\n"
                    prompt_sel += "\n"
                prompt_sel += (
                    "Por favor, genera un texto profesional y detallado que explique:\n"
                    "- En qué consiste este método de selección de variables (breve descripción basada en su nombre) y significado de sus parámetros si los conoces.\n"
                    "- Interpretación de los valores de correlación obtenidos.\n"
                    "- Buenas prácticas al usar este método en preprocesado de datos para ML.\n"
                )
                try:
                    print(f"[DEBUG] 5.5. Iniciando llamada a OpenAI para explicación selección puntual ({metodo})...")
                    resp = _client.chat.completions.create(
                        model="gpt-4",
                        messages=[
                            {"role": "system", "content": "Eres un experto en selección de variables para ML."},
                            {"role": "user", "content": prompt_sel}
                        ],
                        max_tokens=MAX_EXPLANATION_TOKENS,
                        temperature=TEMPERATURE_VAL
                    )
                    explanation_sel = resp.choices[0].message.content.strip()
                    if explanation_sel:
                        titulo_exp = f"### 📝 Explicación IA Selección de Variables ({metodo})"
                        self.sections.append((titulo_exp, explanation_sel))
                        print(f"[DEBUG] 5.6. Sección explicación IA selección puntual añadida para método: {metodo}")
                    else:
                        print("[DEBUG] No se recibió contenido IA para selección puntual")
                except Exception as e:
                    print(f"[ERROR] al generar explicación IA selección puntual {metodo}: {e}")

            if not resumen and not tiene_reciente:
                print("[DEBUG] No hay RESUMEN_METODOS ni selección puntual en globals(), omito sección de selección de variables")
        except Exception as e:
            print(f"[ERROR] al generar sección o explicación IA de selección de variables: {e}")

        # ... fin de la sección de selección de variables ...

        # =============================================================
        # 6. Entrenamiento Modelo SVR
        # =============================================================
        try:
            # <<< Aquí inserta las inicializaciones >>>
            rmse = mae = r2 = None
            residuos = None
            # Comprobamos RESUMEN_METODOS y existencia de X_test/Y_test
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                import pandas as _pd

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Extraer y_test_arr como 1D array
                arr = None
                import numpy as _np
                y_test_arr = None
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2:
                        if arr.shape[1] == 1:
                            y_test_arr = arr[:, 0]
                        else:
                            y_test_arr = arr[:, 0]
                    else:
                        y_test_arr = arr
                else:
                    y_test_arr = _np.array(Y_test)
                    if y_test_arr.ndim == 2 and y_test_arr.shape[1] == 1:
                        y_test_arr = y_test_arr[:, 0]
                if y_test_arr.ndim > 1:
                    y_test_arr = y_test_arr.ravel()

                metrics_summary = []
                resumen_modelos = []
                # Iteramos sobre cada método declarado en RESUMEN_METODOS
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    # Nombre de fichero pickle según celda 7.1
                    fname = f"modelo_svr_{metodo_low}.pkl"
                    if not os.path.exists(fname):
                        print(f"[DEBUG] 6.1. Fichero de modelo SVR no encontrado para método '{metodo}': {fname}, omito este método")
                        continue
                    # Cargar pickle
                    try:
                        with open(fname, "rb") as f:
                            data = pickle.load(f)
                        model = data.get("model", None)
                        sx = data.get("sx", None)
                        sy = data.get("sy", None)
                        cols = data.get("cols", None)
                        # yname = data.get("yname", None)  # si quieres mostrar el nombre de la variable
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Falta alguna clave en pickle SVR para método '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar pickle SVR para método '{metodo}': {e}")
                        continue

                    # Verificar columnas en X_test_full
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para método '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue
                    # Subconjunto X_test
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar, predecir y desescalar
                    try:
                        X_test_scaled = sx.transform(X_test_sel)
                        y_pred_scaled = model.predict(X_test_scaled)
                        # sy estuvo ajustado sobre y entrenado; para inverse_transform debe recibir 2D:
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar SVR para método '{metodo}': {e}")
                        continue

                    # Calcular métricas
                    try:
                        # Rangos Real vs Predicha
                        y_real_min, y_real_max = float(_np.min(y_test_arr)), float(_np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(_np.min(y_pred)), float(_np.max(y_pred))
                        # 3) Estadísticos de residuos:
                        residuals = y_test_arr - y_pred

                        res_mean = float(np.mean(residuals))            # Media
                        res_std  = float(np.std(residuals))             # Desviación estándar:
                        res_series = pd.Series(residuals)               # Asimetria
                        res_skew = float(res_series.skew())             # Asimetria
                        res_kurt = float(res_series.kurtosis())         # Curtosis
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]    # Cuantiles:
                        # Métricas
                        mse = mean_squared_error(y_test_arr, y_pred)
                        rmse = float(_np.sqrt(mse))
                        mae = float(mean_absolute_error(y_test_arr, y_pred))
                        r2 = float(r2_score(y_test_arr, y_pred))
                        resumen_modelos.append({
                            'Método': metodo,
                            'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                        })
                        # Correlación Real vs Predicha
                        try:
                            corr = float(_np.corrcoef(y_test_arr, y_pred)[0, 1])
                        except:
                            corr = None
                    except Exception as e:
                        print(f"[ERROR] al calcular métricas SVR para método '{metodo}': {e}")

                    metrics_summary.append({
                        "metodo": metodo,
                        "rmse": rmse,
                        "mae": mae,
                        "r2": r2
                    })

                    # 1) Parámetros de entrenamiento obtenidos desde el modelo
                    try:
                        # SVR tiene atributos: C, epsilon, kernel, gamma
                        C_val = getattr(model, "C", None)
                        epsilon_val = getattr(model, "epsilon", None)
                        kernel_val = getattr(model, "kernel", None)
                        gamma_val = getattr(model, "gamma", None)
                        params = {
                            "C": C_val,
                            "epsilon": epsilon_val,
                            "kernel": kernel_val,
                            "gamma": gamma_val
                        }
                        df_params = _pd.DataFrame({
                            "Hiperparámetro": list(params.keys()),
                            "Valor": [str(v) for v in params.values()]
                        })
                        titulo_p = f"### Parámetros de Entrenamiento SVR ({metodo})"
                        self.sections.append((titulo_p, df_params))
                        print(f"[DEBUG] 6.2. Sección parámetros SVR añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al extraer/parámetros SVR para método '{metodo}': {e}")

                    # Explicación IA de los hiperparámetros
                    try:
                        prompt_params = (
                            f"Has entrenado un modelo SVR con selección de variables '{metodo}'.\n"
                            f"Estos fueron los hiperparámetros utilizados:\n"
                        )
                        for k, v in params.items():
                            prompt_params += f"- {k}: {v}\n"
                        prompt_params += (
                            "\nPor favor, explica de forma profesional y detallada cómo estos hiperparámetros "
                            "pueden influir en el entrenamiento del modelo SVR, su impacto en ajuste, "
                            "y buenas prácticas para seleccionarlos o afinarlos."
                        )
                        print(f"[DEBUG] 6.3. Iniciando llamada a OpenAI para explicación hiperparámetros SVR ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en entrenamiento de modelos SVR."},
                                {"role": "user", "content": prompt_params}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_params = resp.choices[0].message.content.strip()
                        if explanation_params:
                            titulo_exp_p = f"### 📝 Explicación IA Hiperparámetros SVR ({metodo})"
                            self.sections.append((titulo_exp_p, explanation_params))
                            print(f"[DEBUG] 6.4. Sección explicación IA hiperparámetros añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió IA para hiperparámetros SVR ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA hiperparámetros SVR para método '{metodo}': {e}")

                    # 2) Gráfica Predicho vs Real
                    try:
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(y_test_arr, y_pred, alpha=0.6)
                        ax1.plot([y_test_arr.min(), y_test_arr.max()],
                                 [y_test_arr.min(), y_test_arr.max()],
                                 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"SVR Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gráfica SVR Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 6.5. Sección gráfica Pred vs Real añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica Pred vs Real para método '{metodo}': {e}")

                    # Explicación IA Pred vs Real
                    try:
                        prompt_pred_real = (
                        f"A continuación tienes datos de la gráfica de comparación Real vs Predicción para el modelo SVR con método '{metodo}':\n"
                        #f"- R2: {r2:.4f}\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- R²: {r2}\n"
                        f"- Correlación entre Y real y predicha: {corr:.4f}\n"
                        f"- Rango Y real: [{y_real_min:.4f}, {y_real_max:.4f}]\n"
                        f"- Rango Y predicha: [{y_pred_min:.4f}, {y_pred_max:.4f}]\n"
                        "\n"
                        "También tienes datos de la gráfica de residuos:\n"
                        f"- Media de residuos (Real - Predicha): {res_mean:.4f}\n"
                        f"- Desviación estándar de residuos: {res_std:.4f}\n"
                        f"- Asimetría de residuos: {res_skew:.4f}\n"
                        f"- Curtosis de residuos: {res_kurt:.4f}\n"
                        f"- Cuantiles de residuos: 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}\n"
                        "\n"
                        "Basándote en estos valores y en las gráficas generadas (Real vs Predicción y Residuos), "
                        "proporciona un análisis detallado, señalando si hay sesgos sistemáticos (por ejemplo, subestimación o sobrestimación en ciertos rangos), "
                        "si la dispersión es mayor en algún rango de predicción, si los residuos muestran patrones (p. ej. forma de embudo), "
                        "y qué implicaciones tiene para la calidad del modelo. "
                        "Usa un texto profesional y bien estructurado, y menciona qué indicios de la gráfica respaldan tus conclusiones."
                    )
                        print(f"[DEBUG] 6.6. Llamada IA Pred vs Real ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_pred_real}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### 📝 Explicación IA Predicho vs Real ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 6.7. Sección explicación IA Pred vs Real añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió IA Pred vs Real ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA Pred vs Real para método '{metodo}': {e}")

                    # 3) Gráfica de residuos
                    try:
                        # 4) Rango de Y real y predicha:
                        y_real_min, y_real_max = float(np.min(y_test_arr)), float(np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(np.min(y_pred)), float(np.max(y_pred))
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"SVR Residuos ({metodo})")
                        titulo_fig2 = f"### Gráfica SVR Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 6.8. Sección gráfica residuos añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica residuos para método '{metodo}': {e}")

                    # Explicación IA Residuos
                    try:
                        prompt_residuos = (
                            f"A continuación tienes estadísticas de los residuos (Real - Predicha) del modelo SVR con método '{metodo}':\n"
                            f"- Media: {res_mean:.4f}\n"
                            f"- Desviación estándar: {res_std:.4f}\n"
                            f"- Asimetría: {res_skew:.4f}\n"
                            f"- Curtosis: {res_kurt:.4f}\n"
                            f"- Cuantiles: 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}\n"
                            "\n"
                            "Basándote en estos valores y en la gráfica de residuos, analiza si hay patrones (por ejemplo, heterocedasticidad, outliers, sesgos en rangos), "
                            "y comenta qué implicaciones tiene para la robustez y generalización del modelo. "
                            "Usa un texto profesional y bien estructurado."
                        )
                        print(f"[DEBUG] 6.9. Llamada IA Residuos ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_residuos}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### 📝 Explicación IA Residuos ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 6.10. Sección explicación IA residuos añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió IA Residuos ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA residuos para método '{metodo}': {e}")

                    # 4) Tabla Métricas y explicación IA
                    try:
                        df_met = _pd.DataFrame([{"Métrica": "RMSE", "Valor": rmse},
                                                {"Métrica": "MAE", "Valor": mae},
                                                {"Métrica": "R2",  "Valor": r2}])
                        titulo_met = f"### Métricas SVR ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 6.11. Sección métricas añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame métricas SVR para método '{metodo}': {e}")

                    try:
                        prompt_metrics = (
                            f"Estas son las métricas del modelo SVR con método '{metodo}':\n"
                            f"- R2: {r2:.4f}\n"
                            f"- MSE: {mse:.4f}\n"
                            f"- RMSE: {rmse:.4f}\n"
                            f"- MAE: {mae:.4f}\n"
                            f"- Correlación Real vs Predicha: {corr:.4f}\n"
                            "\n"
                            "Analiza estos valores en contexto: ¿son adecuados? ¿qué sugieren respecto al rendimiento del modelo? "
                            "Menciona referencias a la gráfica Real vs Predicción y a los residuos si procede."
                        )
                        print(f"[DEBUG] 6.12. Llamada IA Métricas SVR ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_metrics}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### 📝 Explicación IA Métricas SVR ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 6.13. Sección explicación IA métricas añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió IA Métricas SVR ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA métricas para método '{metodo}': {e}")

                # 5) Comparativa global de métricas SVR
                if metrics_summary:
                    try:
                        df_comp = _pd.DataFrame(metrics_summary)
                        df_comp_sorted = df_comp.sort_values("rmse")
                        titulo_comp = "### Comparativa Métricas SVR entre Métodos"
                        self.sections.append((titulo_comp, df_comp_sorted))
                        print("[DEBUG] 6.14. Sección comparativa métricas SVR añadida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo métricas SVR: {e}")

                    try:
                        prompt_conc = (
                            "Se han entrenado varios modelos SVR con diferentes métodos de selección de variables.\n"
                            "Métricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary:
                            prompt_conc += f"- Método '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos métodos: "
                            "indica cuál se comporta mejor, posibles razones y recomendaciones sobre selección de variables o ajustes para mejorar SVR."
                        )
                        print("[DEBUG] 6.15. Llamada IA Conclusiones SVR...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_conc}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc = resp.choices[0].message.content.strip()
                        if explanation_conc:
                            titulo_exp_conc = "### 📝 Conclusiones IA Entrenamiento SVR"
                            self.sections.append((titulo_exp_conc, explanation_conc))
                            print("[DEBUG] 6.16. Sección explicación IA conclusiones SVR añadida")
                        else:
                            print("[DEBUG] No se recibió IA Conclusiones SVR")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA conclusiones SVR: {e}")
            else:
                print("[DEBUG] No están RESUMEN_METODOS o X_test/Y_test en globals(), omito sección SVR")
        except Exception as e:
            print(f"[ERROR] al generar sección SVR en informe: {e}")
        # ... fin de la sección de entrenamiento SVR ...

        # ==============================
        # 6.1. Interpretación xIA para modelo entrenado SVR
        # ==============================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificación previa
        # ----------------------------------------------------------------
        try:
            print("[DEBUG] 6.17. Iniciando sección xIA para SVR")
            if 'xai_results' not in globals() or 'SVR' not in xai_results:
                raise RuntimeError(
                    "No se encontró `xai_results['SVR']`. "
                    "Asegúrate de haber ejecutado la Celda 10 y almacenado los resultados xIA de SVR en `xai_results['SVR']`."
                )

                # Cabecera
                self.sections.append((
                    "## 🔍 Análisis xIA de SVR: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vacío, la cabecera se mostrará como Markdown
                ))


            # Función para llamar a OpenAI con un prompt específico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuración: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cuántas características top incluir en el prompt
            N_LOCAL = 3    # cuántas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de métodos xIA y claves en xai_results['SVR']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 6.18. Procesando sección xIA: {titulo}")
                datos = xai_results['SVR'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ⚠️ No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 6.19. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gráfico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 6.20. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estadísticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gráfico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores numéricos concretos ---------------
                print(f"[DEBUG] 6.21. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el método xIA '{titulo}' al modelo SVR entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gráfico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    • {f}: {imp:.4f}\n"

                # Ahora sí le pides que interprete el gráfico:
                prompt += (
                    "- Interpreta el gráfico anterior: "
                    "describe qué patrones o relaciones visuales revela cómo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} características por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye también columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato genérico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # — Siempre sacamos el índice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribución):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estadísticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estadísticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo SVR
                prompt += (
                    "\nContexto: El modelo SVR fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este SVR.\n"
                )

                # 5) Preguntas/pautas específicas según el método
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¿qué implica sobre la predicción en ese caso? Y si es negativo, ¿qué implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una dirección) y cómo afecta al comportamiento general del SVR.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para SVR.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¿qué implica para la predicción local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupación de variables, detección de outliers, etc., basadas en la interpretación LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global según los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: cómo cada característica empuja la predicción en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para SVR), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribución integrada de cada variable: interpretación de importancia global.\n"
                        "2. Analizar las primeras muestras: qué implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Señalar limitaciones: compatibilidad con SVR no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros métodos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qué significa para la predicción.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la caída en la métrica al permutar cada variable: por qué ciertas variables son críticas.\n"
                        "2. Comentar la desviación estándar: ¿indica inestabilidad en la importancia? ¿Dónde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selección de variables basadas en esta métrica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicción según el rango PDP obtenido.\n"
                        "2. Señalar si los rangos sugieren relaciones monótonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretación.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) según los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar cómo ALE corrige artefactos de correlación y qué nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspección de distribución) según hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qué mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Señalar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar cómo interpretar los contrafactuales: cambios en variables que generan aumento en predicción.\n"
                        "2. Analizar variables con mayor |Δ| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Señalar si faltan contrafactuales para algunas muestras: qué puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir cómo usar estos insights para ajuste de modelo o recolección de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar cómo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicción.\n"
                        "2. Analizar frecuencia global de aparición de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Señalar regiones de bajo coverage o baja precisión: dónde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolección de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (árbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qué sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del SVR en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo según discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global según EBM: cómo se comparan con otros métodos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qué patrones se observan.\n"
                        "3. Señalar si EBM revela interacciones no consideradas en SVR.\n"
                        "4. Recomendar posibles ajustes en características o validaciones según insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperparámetros en la optimización del SVR.\n"
                        "2. Analizar top trials si están disponibles: qué combinaciones de hiperparámetros funcionaron mejor.\n"
                        "3. Señalar limitaciones de la muestra de trials (número de pruebas) y posibles riesgos de sobreajuste en la búsqueda.\n"
                        "4. Recomendar próximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados numéricos y qué implicaciones tienen para el modelo SVR.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 6.22. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicación Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ⚠️ Error en sección xIA SVR",
                f"Se produjo un error al generar la sección xIA de SVR: {e}"
            ))

        # =============================================================
        # 7. Entrenamiento Modelo NN
        # =============================================================
        try:
            # Comprobamos RESUMEN_METODOS y existencia de X_test/Y_test
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import numpy as np
                import pandas as _pd
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                from tensorflow.keras.models import load_model

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Preparamos array 1D de y_test
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2 and arr.shape[1] == 1:
                        y_test_arr = arr[:, 0]
                    elif arr.ndim == 2 and arr.shape[1] > 1:
                        y_test_arr = arr[:, 0]
                    else:
                        y_test_arr = arr.ravel()
                else:
                    y_test_arr = np.array(Y_test).ravel()
                # Aseguramos 1D
                y_test_arr = y_test_arr.ravel()

                metrics_summary_nn = []
                # Iteramos sobre cada método declarado en RESUMEN_METODOS
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    # Rutas a los archivos NN guardados en celda 7.2
                    model_fname = f"modelo_nn_{metodo_low}.h5"
                    scaler_fname = f"escaladores_nn_{metodo_low}.pkl"
                    hp_fname = f"hyperparams_nn_{metodo_low}.pkl"
                    #hyper_fname = f"hyperparams_nn_{metodo_low}.pkl"
                    if not os.path.exists(model_fname) or not os.path.exists(scaler_fname):
                        print(f"[DEBUG] Fichero de modelo NN o escaladores no encontrado para método '{metodo}': omito este método")
                        continue
                    # Cargar modelo y escaladores
                    try:
                        model = load_model(model_fname)
                        with open(scaler_fname, "rb") as f:
                            data_s = pickle.load(f)
                        sx = data_s.get("scaler_X", None)
                        sy = data_s.get("scaler_Y", None)
                        cols = data_s.get("cols", None)
                        # y_variable_name = data_s.get("yname", None)
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Falta clave en escaladores NN para método '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar modelo/escaladores NN para método '{metodo}': {e}")
                        continue

                    # Verificar columnas en X_test
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para método '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue

                    # Subconjunto X_test
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar, predecir y desescalar
                    try:
                        X_test_scaled = sx.transform(X_test_sel)
                        #y_pred_scaled = model.predict(X_test_scaled).ravel()
                        y_pred_scaled = model.predict(X_test_scaled, verbose=0).ravel()
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar NN para método '{metodo}': {e}")
                        continue

                    # 1) Cargar hiperparámetros
                    try:
                        hp_fname = f"hyperparams_nn_{metodo.lower()}.pkl"
                        if os.path.exists(hp_fname):
                            with open(hp_fname, "rb") as f:
                                hp = pickle.load(f)
                        else:
                            hp = None
                        # Representar en DataFrame
                        if hp:
                            import pandas as _pd
                            df_hp = _pd.DataFrame({
                                "Hiperparámetro": list(hp.keys()),
                                "Valor": [str(v) for v in hp.values()]
                            })
                            titulo_hp = f"### Parámetros de Entrenamiento NN ({metodo})"
                            self.sections.append((titulo_hp, df_hp))
                            print(f"[DEBUG] 7.1. Sección parámetros NN añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No hay hyperparams guardados para NN método '{metodo}'")
                    except Exception as e:
                        print(f"[ERROR] al extraer/parámetros NN para método '{metodo}': {e}")

                    # Explicación IA hiperparámetros NN
                    try:
                        if hp:
                            prompt_params = (
                                f"Has entrenado un modelo de Red Neuronal con selección de variables '{metodo}'.\n"
                                "Estos fueron los hiperparámetros utilizados:\n"
                            )
                            for k, v in hp.items():
                                prompt_params += f"- {k}: {v}\n"
                            prompt_params += (
                                "\nPor favor, explica de forma profesional y detallada cómo estos hiperparámetros "
                                "pueden influir en el entrenamiento de la red neuronal, su impacto en ajuste, "
                                "y buenas prácticas para seleccionarlos o afinarlos."
                            )
                            print(f"[DEBUG] 7.2. Iniciando llamada a OpenAI para explicación hiperparámetros NN ({metodo})...")
                            resp = _client.chat.completions.create(
                                model="gpt-4",
                                messages=[
                                    {"role": "system", "content": "Eres un experto en entrenamiento de redes neuronales para regresión."},
                                    {"role": "user", "content": prompt_params}
                                ],
                                max_tokens=MAX_EXPLANATION_TOKENS,
                                temperature=TEMPERATURE_VAL
                            )
                            explanation_hp = resp.choices[0].message.content.strip()
                            if explanation_hp:
                                titulo_exp_hp = f"### 📝 Explicación IA Hiperparámetros NN ({metodo})"
                                self.sections.append((titulo_exp_hp, explanation_hp))
                                print(f"[DEBUG] 7.3. Sección explicación IA hiperparámetros NN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA hiperparámetros NN para método '{metodo}': {e}")

                    # 2) Gráfica Predicho vs Real
                    try:
                        import matplotlib.pyplot as plt
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(y_test_arr, y_pred, alpha=0.6)
                        ax1.plot([y_test_arr.min(), y_test_arr.max()],
                                 [y_test_arr.min(), y_test_arr.max()],
                                 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"NN Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gráfica NN Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 7.4. Sección gráfica Pred vs Real NN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica Pred vs Real NN para método '{metodo}': {e}")

                    # Estadísticas para contexto IA Pred vs Real
                    try:
                        mse = mean_squared_error(y_test_arr, y_pred)
                        rmse = np.sqrt(mse)
                        mae = mean_absolute_error(y_test_arr, y_pred)
                        r2 = r2_score(y_test_arr, y_pred)
                        corr = np.corrcoef(y_test_arr, y_pred)[0,1] if len(y_test_arr)>1 else None
                        y_real_min, y_real_max = float(np.min(y_test_arr)), float(np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(np.min(y_pred)), float(np.max(y_pred))
                    except Exception:
                        mse = rmse = mae = r2 = corr = None
                        y_real_min = y_real_max = y_pred_min = y_pred_max = None

                    # Explicación IA Pred vs Real NN con contexto numérico
                    try:
                        prompt_pr = (
                            f"A continuación tienes datos de la gráfica de comparación Real vs Predicción para el modelo NN con método '{metodo}':\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- R²: {r2}\n"
                            f"- Correlación entre Y real y predicha: {corr}\n"
                            f"- Rango Y real: [{y_real_min}, {y_real_max}]\n"
                            f"- Rango Y predicha: [{y_pred_min}, {y_pred_max}]\n\n"
                            "Basándote en estos valores y en la gráfica generada (Real vs Predicción), "
                            "proporciona un análisis detallado, señalando si hay sesgos sistemáticos (por ejemplo, subestimación o sobreestimación en ciertos rangos), "
                            "si la dispersión es mayor en algún rango de predicción, y qué implicaciones tiene para la calidad del modelo. "
                            "Usa un texto profesional y bien estructurado, y menciona qué indicios de la gráfica respaldan tus conclusiones."
                        )
                        print(f"[DEBUG] 7.5. Llamada IA Pred vs Real NN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_pr}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### 📝 Explicación IA Predicho vs Real NN ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 7.6. Sección explicación IA Pred vs Real NN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA Pred vs Real NN para método '{metodo}': {e}")

                    # 3) Gráfica de residuos NN
                    try:
                        residuals = y_test_arr - y_pred
                        res_mean = float(np.mean(residuals))
                        res_std  = float(np.std(residuals))
                        # Estadísticos de residuos con pandas
                        res_series = _pd.Series(residuals)
                        res_skew = float(res_series.skew())
                        res_kurt = float(res_series.kurtosis())
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                        # Rango de Y real y predicha
                        # (ya lo tenemos en y_real_min, etc.)
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"NN Residuos ({metodo})")
                        titulo_fig2 = f"### Gráfica NN Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 7.7. Sección gráfica residuos NN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica residuos NN para método '{metodo}': {e}")

                    # Explicación IA Residuos NN con contexto numérico
                    try:
                        prompt_res = (
                            f"A continuación tienes estadísticas de los residuos (Real - Predicha) del modelo NN con método '{metodo}':\n"
                            f"- Media: {res_mean}\n"
                            f"- Desviación estándar: {res_std}\n"
                            f"- Asimetría: {res_skew}\n"
                            f"- Curtosis: {res_kurt}\n"
                            f"- Cuantiles: 25%={q25}, 50%={q50}, 75%={q75}\n\n"
                            "Basándote en estos valores y en la gráfica de residuos, analiza si hay patrones (por ejemplo, heterocedasticidad, outliers, sesgos en rangos), "
                            "y comenta qué implicaciones tiene para la robustez y generalización del modelo. "
                            "Usa un texto profesional y bien estructurado."
                        )
                        print(f"[DEBUG] 7.8. Llamada IA Residuos NN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_res}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### 📝 Explicación IA Residuos NN ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 7.9. Sección explicación IA residuos NN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA residuos NN para método '{metodo}': {e}")

                    # 4) Tabla Métricas NN y explicación IA
                    try:
                        df_met = _pd.DataFrame([
                            {"Métrica": "RMSE", "Valor": rmse},
                            {"Métrica": "MAE", "Valor": mae},
                            {"Métrica": "R2",  "Valor": r2}
                        ])
                        titulo_met = f"### Métricas NN ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 7.10. Sección métricas NN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame métricas NN para método '{metodo}': {e}")

                    try:
                        prompt_met = (
                            f"Estas son las métricas del modelo NN con método '{metodo}':\n"
                            f"- R2: {r2}\n"
                            f"- MSE: {mse}\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- Correlación Real vs Predicha: {corr}\n\n"
                            "Analiza estos valores en contexto: ¿son adecuados? ¿qué sugieren respecto al rendimiento del modelo? "
                            "Menciona referencias a la gráfica Real vs Predicción y a los residuos si procede."
                        )
                        print(f"[DEBUG] 7.11. Llamada IA Métricas NN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_met}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### 📝 Explicación IA Métricas NN ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 7.12. Sección explicación IA métricas NN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA métricas NN para método '{metodo}': {e}")

                    # Acumular para comparativa
                    metrics_summary_nn.append({
                        "metodo": metodo,
                        "rmse": rmse,
                        "mae": mae,
                        "r2": r2
                    })

                # 5) Comparativa global de métricas NN
                if metrics_summary_nn:
                    try:
                        df_comp_nn = _pd.DataFrame(metrics_summary_nn)
                        df_comp_nn_sorted = df_comp_nn.sort_values("rmse")
                        titulo_comp_nn = "### Comparativa Métricas NN entre Métodos"
                        self.sections.append((titulo_comp_nn, df_comp_nn_sorted))
                        print("[DEBUG] 7.13. Sección comparativa métricas NN añadida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo métricas NN: {e}")

                    try:
                        prompt_conc_nn = (
                            "Se han entrenado varios modelos de Red Neuronal con diferentes métodos de selección de variables.\n"
                            "Métricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary_nn:
                            prompt_conc_nn += f"- Método '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc_nn += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos métodos: "
                            "indica cuál se comporta mejor, posibles razones y recomendaciones sobre selección de variables o ajustes para mejorar la red neuronal."
                        )
                        print("[DEBUG] 7.14. Llamada IA Conclusiones NN...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_conc_nn}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc_nn = resp.choices[0].message.content.strip()
                        if explanation_conc_nn:
                            titulo_exp_conc_nn = "### 📝 Conclusiones IA Entrenamiento NN"
                            self.sections.append((titulo_exp_conc_nn, explanation_conc_nn))
                            print("[DEBUG] 7.15. Sección explicación IA conclusiones NN añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA conclusiones NN: {e}")
            else:
                print("[DEBUG] No están RESUMEN_METODOS o X_test/Y_test en globals(), omito sección NN")
        except Exception as e:
            print(f"[ERROR] al generar sección NN en informe: {e}")
        # ... fin de la sección de entrenamiento NN ...

        # =============================================================
        # 7.1. Interpretación xIA para modelo entrenado NN
        # =============================================================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificación previa
        # ----------------------------------------------------------------
        try:
            print("[DEBUG] 7.16. Iniciando sección xIA para NN")
            if 'xai_results' not in globals() or 'NN' not in xai_results:
                raise RuntimeError(
                    "No se encontró `xai_results['NN']`. "
                    "Asegúrate de haber ejecutado la Celda 10 y almacenado los resultados xIA de NN en `xai_results['NN']`."
                )

                # Cabecera
                self.sections.append((
                    "## 🔍 Análisis xIA de NN: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vacío, la cabecera se mostrará como Markdown
                ))


            # Función para llamar a OpenAI con un prompt específico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuración: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cuántas características top incluir en el prompt
            N_LOCAL = 3    # cuántas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de métodos xIA y claves en xai_results['NN']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 7.17. Procesando sección xIA: {titulo}")
                datos = xai_results['NN'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ⚠️ No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 7.18. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gráfico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 7.19. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estadísticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gráfico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores numéricos concretos ---------------
                print(f"[DEBUG] 7.20. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el método xIA '{titulo}' al modelo NN entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gráfico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    • {f}: {imp:.4f}\n"

                # Ahora sí le pides que interprete el gráfico:
                prompt += (
                    "- Interpreta el gráfico anterior: "
                    "describe qué patrones o relaciones visuales revela cómo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} características por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye también columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato genérico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # — Siempre sacamos el índice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribución):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estadísticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estadísticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo NN
                prompt += (
                    "\nContexto: El modelo NN fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este NN.\n"
                )

                # 5) Preguntas/pautas específicas según el método
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¿qué implica sobre la predicción en ese caso? Y si es negativo, ¿qué implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una dirección) y cómo afecta al comportamiento general del NN.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para NN.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¿qué implica para la predicción local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupación de variables, detección de outliers, etc., basadas en la interpretación LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global según los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: cómo cada característica empuja la predicción en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para NN), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribución integrada de cada variable: interpretación de importancia global.\n"
                        "2. Analizar las primeras muestras: qué implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Señalar limitaciones: compatibilidad con NN no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros métodos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qué significa para la predicción.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la caída en la métrica al permutar cada variable: por qué ciertas variables son críticas.\n"
                        "2. Comentar la desviación estándar: ¿indica inestabilidad en la importancia? ¿Dónde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selección de variables basadas en esta métrica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicción según el rango PDP obtenido.\n"
                        "2. Señalar si los rangos sugieren relaciones monótonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretación.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) según los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar cómo ALE corrige artefactos de correlación y qué nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspección de distribución) según hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qué mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Señalar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar cómo interpretar los contrafactuales: cambios en variables que generan aumento en predicción.\n"
                        "2. Analizar variables con mayor |Δ| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Señalar si faltan contrafactuales para algunas muestras: qué puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir cómo usar estos insights para ajuste de modelo o recolección de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar cómo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicción.\n"
                        "2. Analizar frecuencia global de aparición de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Señalar regiones de bajo coverage o baja precisión: dónde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolección de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (árbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qué sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del NN en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo según discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global según EBM: cómo se comparan con otros métodos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qué patrones se observan.\n"
                        "3. Señalar si EBM revela interacciones no consideradas en NN.\n"
                        "4. Recomendar posibles ajustes en características o validaciones según insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperparámetros en la optimización del NN.\n"
                        "2. Analizar top trials si están disponibles: qué combinaciones de hiperparámetros funcionaron mejor.\n"
                        "3. Señalar limitaciones de la muestra de trials (número de pruebas) y posibles riesgos de sobreajuste en la búsqueda.\n"
                        "4. Recomendar próximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados numéricos y qué implicaciones tienen para el modelo NN.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 7.21. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicación Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ⚠️ Error en sección xIA NN",
                f"Se produjo un error al generar la sección xIA de NN: {e}"
            ))

        # =====================================================================
        # 8. Entrenamiento Modelo XGBoost
        # =====================================================================
        try:
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import numpy as np
                import pandas as _pd
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Extraer array 1D de Y_test
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2 and arr.shape[1] >= 1:
                        y_test_arr = arr[:, 0].ravel()
                    else:
                        y_test_arr = arr.ravel()
                else:
                    y_test_arr = np.array(Y_test).ravel()
                y_test_arr = y_test_arr.ravel()

                metrics_summary_xgb = []
                # Iterar sobre cada método
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    pickle_fname = f"modelo_xgb_{metodo_low}.pkl"
                    if not os.path.exists(pickle_fname):
                        print(f"[DEBUG] Fichero de modelo XGBoost no encontrado para método '{metodo}': {pickle_fname}, omito este método")
                        continue
                    # Cargar modelo y escaladores
                    try:
                        with open(pickle_fname, "rb") as f:
                            data = pickle.load(f)
                        model = data.get("model", None)
                        sx = data.get("sx", None)
                        sy = data.get("sy", None)
                        cols = data.get("cols", None)
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Faltan claves en pickle XGBoost para método '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar pickle XGBoost para método '{metodo}': {e}")
                        continue

                    # Verificar columnas
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para método '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue
                    # Subconjunto X_test
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar, predecir, desescalar
                    try:
                        X_test_scaled = sx.transform(X_test_sel)
                        y_pred_scaled = model.predict(X_test_scaled)
                        # Desescalar: sy.inverse_transform espera 2D
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar XGBoost para método '{metodo}': {e}")
                        continue

                    # Cálculo de métricas y estadísticos
                    try:
                        # Rangos Y real y predicha
                        y_real_min, y_real_max = float(np.min(y_test_arr)), float(np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(np.min(y_pred)), float(np.max(y_pred))
                        # Residuos
                        residuals = y_test_arr - y_pred
                        res_mean = float(np.mean(residuals))
                        res_std = float(np.std(residuals))
                        # Estadísticos de residuos con pandas
                        res_series = _pd.Series(residuals)
                        res_skew = float(res_series.skew())
                        res_kurt = float(res_series.kurtosis())
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                        # Métricas clásicas
                        mse = mean_squared_error(y_test_arr, y_pred)
                        rmse = float(np.sqrt(mse))
                        mae = float(mean_absolute_error(y_test_arr, y_pred))
                        r2 = float(r2_score(y_test_arr, y_pred))
                        # Correlación real vs predicha (si hay suficientes puntos)
                        try:
                            corr = float(np.corrcoef(y_test_arr, y_pred)[0,1]) if len(y_test_arr) > 1 else None
                        except:
                            corr = None
                        # Acumular resumen
                        metrics_summary_xgb.append({
                            "metodo": metodo,
                            "rmse": rmse,
                            "mae": mae,
                            "r2": r2
                        })

                    except Exception as e:
                        print(f"[ERROR] al calcular métricas XGBoost para método '{metodo}': {e}")
                        # si algo falla, saltar a next
                        continue

                    # 1) Parámetros de entrenamiento obtenidos desde el modelo XGBRegressor
                    try:
                        # get_params suele incluir: 'n_estimators', 'learning_rate', 'max_depth', 'subsample', etc.
                        params_all = model.get_params()
                        # Extraer los principales:
                        params = {
                            "n_estimators": params_all.get("n_estimators", None),
                            "learning_rate": params_all.get("learning_rate", None),
                            "max_depth": params_all.get("max_depth", None),
                            "subsample": params_all.get("subsample", None)
                        }
                        df_params = _pd.DataFrame({
                            "Hiperparámetro": list(params.keys()),
                            "Valor": [str(v) for v in params.values()]
                        })
                        titulo_p = f"### Parámetros de Entrenamiento XGBoost ({metodo})"
                        self.sections.append((titulo_p, df_params))
                        print(f"[DEBUG] 8.1. Sección parámetros XGBoost añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al extraer parámetros XGBoost para método '{metodo}': {e}")

                    # Explicación IA de los hiperparámetros XGBoost
                    try:
                        prompt_params = (
                            f"Has entrenado un modelo XGBoost con selección de variables '{metodo}'.\n"
                            "Estos fueron los hiperparámetros utilizados:\n"
                        )
                        for k, v in params.items():
                            prompt_params += f"- {k}: {v}\n"
                        prompt_params += (
                            "\nPor favor, explica de forma profesional y detallada cómo estos hiperparámetros "
                            "pueden influir en el entrenamiento del modelo XGBoost, su impacto en ajuste, "
                            "regularización, sobreajuste o subajuste, y buenas prácticas para afinarlos."
                        )
                        print(f"[DEBUG] 8.2. Iniciando llamada a OpenAI para explicación hiperparámetros XGBoost ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en entrenamiento de modelos XGBoost para regresión."},
                                {"role": "user", "content": prompt_params}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_params = resp.choices[0].message.content.strip()
                        if explanation_params:
                            titulo_exp_p = f"### 📝 Explicación IA Hiperparámetros XGBoost ({metodo})"
                            self.sections.append((titulo_exp_p, explanation_params))
                            print(f"[DEBUG] 8.3. Sección explicación IA hiperparámetros XGBoost añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió IA para hiperparámetros XGBoost ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA hiperparámetros XGBoost para método '{metodo}': {e}")

                    # 2) Gráfica Predicho vs Real
                    try:
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(y_test_arr, y_pred, alpha=0.6)
                        ax1.plot([y_real_min, y_real_max], [y_real_min, y_real_max], 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"XGBoost Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gráfico XGBoost Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 8.4. Sección gráfica Pred vs Real XGBoost añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica Pred vs Real XGBoost para método '{metodo}': {e}")

                    # Explicación IA Pred vs Real XGBoost con contexto numérico
                    try:
                        prompt_pr = (
                            f"A continuación tienes datos de la gráfica de comparación Real vs Predicción para el modelo XGBoost con método '{metodo}':\n"
                            f"- RMSE: {rmse:.4f}\n"
                            f"- MAE: {mae:.4f}\n"
                            f"- R²: {r2:.4f}\n"
                            f"- Correlación entre Y real y predicha: {corr:.4f}\n"
                            f"- Rango Y real: [{y_real_min:.4f}, {y_real_max:.4f}]\n"
                            f"- Rango Y predicha: [{y_pred_min:.4f}, {y_pred_max:.4f}]\n\n"
                            "Basándote en estos valores y en la gráfica generada (Real vs Predicción), "
                            "proporciona un análisis detallado, señalando si hay sesgos sistemáticos, dispersión en ciertos rangos, "
                            "y qué implicaciones tiene para la calidad del modelo. "
                            "Usa un texto profesional y bien estructurado, citando qué indicios de la gráfica respaldan tus conclusiones."
                        )
                        print(f"[DEBUG] 8.5. Llamada IA Pred vs Real XGBoost ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_pr}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### 📝 Explicación IA Predicho vs Real XGBoost ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 8.6. Sección explicación IA Pred vs Real XGBoost añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió IA Pred vs Real XGBoost ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA Pred vs Real XGBoost para método '{metodo}': {e}")

                    # 3) Gráfica de residuos XGBoost
                    try:
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"XGBoost Residuos ({metodo})")
                        titulo_fig2 = f"### Gráfica XGBoost Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 8.7. Sección gráfica residuos XGBoost añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica residuos XGBoost para método '{metodo}': {e}")

                    # Explicación IA Residuos XGBoost con contexto numérico
                    try:
                        prompt_res = (
                            f"A continuación tienes estadísticas de los residuos (Real - Predicha) del modelo XGBoost con método '{metodo}':\n"
                            f"- Media: {res_mean:.4f}\n"
                            f"- Desviación estándar: {res_std:.4f}\n"
                            f"- Asimetría: {res_skew:.4f}\n"
                            f"- Curtosis: {res_kurt:.4f}\n"
                            f"- Cuantiles: 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}\n\n"
                            "Basándote en estos valores y en la gráfica de residuos, analiza si hay patrones (heterocedasticidad, outliers, sesgos), "
                            "y comenta qué implicaciones tiene para la robustez y generalización del modelo. "
                            "Usa un texto profesional y bien estructurado."
                        )
                        print(f"[DEBUG] 8.8. Llamada IA Residuos XGBoost ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_res}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### 📝 Explicación IA Residuos XGBoost ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 8.9. Sección explicación IA residuos XGBoost añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió IA Residuos XGBoost ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA residuos XGBoost para método '{metodo}': {e}")

                    # 4) Tabla Métricas XGBoost y explicación IA
                    try:
                        df_met = _pd.DataFrame([
                            {"Métrica": "RMSE", "Valor": rmse},
                            {"Métrica": "MAE", "Valor": mae},
                            {"Métrica": "R2",  "Valor": r2}
                        ])
                        titulo_met = f"### Métricas XGBoost ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 8.10. Sección métricas XGBoost añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame métricas XGBoost para método '{metodo}': {e}")

                    try:
                        prompt_met = (
                            f"Estas son las métricas del modelo XGBoost con método '{metodo}':\n"
                            f"- R2: {r2:.4f}\n"
                            f"- MSE: {mse:.4f}\n"
                            f"- RMSE: {rmse:.4f}\n"
                            f"- MAE: {mae:.4f}\n"
                            f"- Correlación Real vs Predicha: {corr:.4f}\n\n"
                            "Analiza estos valores en contexto: ¿son adecuados? ¿qué sugieren respecto al rendimiento del modelo? "
                            "Menciona referencias a la gráfica Real vs Predicción y a los residuos si procede."
                        )
                        print(f"[DEBUG] 8.11. Llamada IA Métricas XGBoost ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_met}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### 📝 Explicación IA Métricas XGBoost ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 8.12. Sección explicación IA métricas XGBoost añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió IA Métricas XGBoost ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA métricas XGBoost para método '{metodo}': {e}")

                # 5) Comparativa global de métricas XGBoost
                if metrics_summary_xgb:
                    try:
                        df_comp_xgb = _pd.DataFrame(metrics_summary_xgb)
                        df_comp_xgb_sorted = df_comp_xgb.sort_values("rmse")
                        titulo_comp = "### Comparativa Métricas XGBoost entre Métodos"
                        self.sections.append((titulo_comp, df_comp_xgb_sorted))
                        print("[DEBUG] 8.13. Sección comparativa métricas XGBoost añadida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo métricas XGBoost: {e}")

                    try:
                        prompt_conc = (
                            "Se han entrenado varios modelos XGBoost con diferentes métodos de selección de variables.\n"
                            "Métricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary_xgb:
                            prompt_conc += f"- Método '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos métodos: "
                            "indica cuál se comporta mejor, posibles razones y recomendaciones sobre selección de variables o ajustes para mejorar XGBoost."
                        )
                        print("[DEBUG] 8.14. Llamada IA Conclusiones XGBoost...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_conc}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc = resp.choices[0].message.content.strip()
                        if explanation_conc:
                            titulo_exp_conc = "### 📝 Conclusiones IA Entrenamiento XGBoost"
                            self.sections.append((titulo_exp_conc, explanation_conc))
                            print("[DEBUG] 8.15. Sección explicación IA conclusiones XGBoost añadida")
                        else:
                            print("[DEBUG] No se recibió IA Conclusiones XGBoost")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA conclusiones XGBoost: {e}")
            else:
                print("[DEBUG] No están RESUMEN_METODOS o X_test/Y_test en globals(), omito sección XGBoost")
        except Exception as e:
            print(f"[ERROR] al generar sección XGBoost en informe: {e}")
        # ... fin de la sección de entrenamiento XGBoost ...

        # =============================================================
        # 8.1. Interpretación xIA para modelo entrenado XGBoost
        # =============================================================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificación previa
        # ----------------------------------------------------------------
        try:
            print("[DEBUG] 8.16. Iniciando sección xIA para XGBoost")
            if 'xai_results' not in globals() or 'XGBoost' not in xai_results:
                raise RuntimeError(
                    "No se encontró `xai_results['XGBoost']`. "
                    "Asegúrate de haber ejecutado la Celda 10 y almacenado los resultados xIA de XGBoost en `xai_results['XGBoost']`."
                )

                # Cabecera
                self.sections.append((
                    "## 🔍 Análisis xIA de XGBoost: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vacío, la cabecera se mostrará como Markdown
                ))


            # Función para llamar a OpenAI con un prompt específico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuración: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cuántas características top incluir en el prompt
            N_LOCAL = 3    # cuántas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de métodos xIA y claves en xai_results['XGBoost']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 8.17. Procesando sección xIA: {titulo}")
                datos = xai_results['XGBoost'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ⚠️ No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 8.18. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gráfico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 8.19. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estadísticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gráfico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores numéricos concretos ---------------
                print(f"[DEBUG] 8.20. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el método xIA '{titulo}' al modelo XGBoost entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gráfico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    • {f}: {imp:.4f}\n"

                # Ahora sí le pides que interprete el gráfico:
                prompt += (
                    "- Interpreta el gráfico anterior: "
                    "describe qué patrones o relaciones visuales revela cómo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} características por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye también columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato genérico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # — Siempre sacamos el índice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribución):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estadísticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estadísticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo XGBoost
                prompt += (
                    "\nContexto: El modelo XGBoost fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este XGBoost.\n"
                )

                # 5) Preguntas/pautas específicas según el método
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¿qué implica sobre la predicción en ese caso? Y si es negativo, ¿qué implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una dirección) y cómo afecta al comportamiento general del XGBoost.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para XGBoost.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¿qué implica para la predicción local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupación de variables, detección de outliers, etc., basadas en la interpretación LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global según los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: cómo cada característica empuja la predicción en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para XGBoost), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribución integrada de cada variable: interpretación de importancia global.\n"
                        "2. Analizar las primeras muestras: qué implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Señalar limitaciones: compatibilidad con XGBoost no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros métodos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qué significa para la predicción.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la caída en la métrica al permutar cada variable: por qué ciertas variables son críticas.\n"
                        "2. Comentar la desviación estándar: ¿indica inestabilidad en la importancia? ¿Dónde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selección de variables basadas en esta métrica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicción según el rango PDP obtenido.\n"
                        "2. Señalar si los rangos sugieren relaciones monótonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretación.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) según los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar cómo ALE corrige artefactos de correlación y qué nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspección de distribución) según hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qué mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Señalar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar cómo interpretar los contrafactuales: cambios en variables que generan aumento en predicción.\n"
                        "2. Analizar variables con mayor |Δ| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Señalar si faltan contrafactuales para algunas muestras: qué puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir cómo usar estos insights para ajuste de modelo o recolección de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar cómo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicción.\n"
                        "2. Analizar frecuencia global de aparición de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Señalar regiones de bajo coverage o baja precisión: dónde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolección de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (árbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qué sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del XGBoost en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo según discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global según EBM: cómo se comparan con otros métodos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qué patrones se observan.\n"
                        "3. Señalar si EBM revela interacciones no consideradas en XGBoost.\n"
                        "4. Recomendar posibles ajustes en características o validaciones según insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperparámetros en la optimización del XGBoost.\n"
                        "2. Analizar top trials si están disponibles: qué combinaciones de hiperparámetros funcionaron mejor.\n"
                        "3. Señalar limitaciones de la muestra de trials (número de pruebas) y posibles riesgos de sobreajuste en la búsqueda.\n"
                        "4. Recomendar próximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados numéricos y qué implicaciones tienen para el modelo XGBoost.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 8.21. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicación Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ⚠️ Error en sección xIA XGBoost",
                f"Se produjo un error al generar la sección xIA de XGBoost: {e}"
            ))

        # =====================================================================
        # 9. Entrenamiento Modelo Random Forest
        # =====================================================================
        try:
            # Comprobamos RESUMEN_METODOS y existencia de X_test/Y_test
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import numpy as _np
                import pandas as _pd
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Extraer array 1D de y_test
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2 and arr.shape[1] >= 1:
                        # tomamos la primera columna si hay más
                        y_test_arr = arr[:, 0]
                    else:
                        y_test_arr = arr.ravel()
                else:
                    y_test_arr = _np.array(Y_test).ravel()
                y_test_arr = y_test_arr.ravel()

                metrics_summary_rf = []
                # Iteramos sobre cada método en RESUMEN_METODOS
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    fname = f"modelo_rf_{metodo_low}.pkl"
                    if not os.path.exists(fname):
                        print(f"[DEBUG] Fichero de modelo RF no encontrado para método '{metodo}': {fname}, omito este método")
                        continue
                    # Cargar pickle
                    try:
                        with open(fname, "rb") as f:
                            data = pickle.load(f)
                        model = data.get("model", None)
                        sx = data.get("sx", None)
                        sy = data.get("sy", None)
                        cols = data.get("cols", None)
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Falta alguna clave en pickle RF para método '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar pickle RF para método '{metodo}': {e}")
                        continue

                    # Verificar columnas en X_test
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para método '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue

                    # Subconjunto X_test
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar, predecir y desescalar
                    try:
                        X_test_scaled = sx.transform(X_test_sel)
                        y_pred_scaled = model.predict(X_test_scaled)
                        # inverse_transform espera 2D
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar RF para método '{metodo}': {e}")
                        continue

                    # Estadísticos y métricas
                    try:
                        # Rangos Real vs Predicha
                        y_real_min, y_real_max = float(_np.min(y_test_arr)), float(_np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(_np.min(y_pred)), float(_np.max(y_pred))
                        # Residuos
                        residuals = y_test_arr - y_pred
                        res_mean = float(_np.mean(residuals))
                        res_std  = float(_np.std(residuals))
                        res_series = _pd.Series(residuals)
                        res_skew = float(res_series.skew())
                        res_kurt = float(res_series.kurtosis())
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                        # Métricas
                        mse = mean_squared_error(y_test_arr, y_pred)
                        rmse = float(_np.sqrt(mse))
                        mae = float(mean_absolute_error(y_test_arr, y_pred))
                        r2 = float(r2_score(y_test_arr, y_pred))
                        # Correlación Real vs Predicha
                        try:
                            corr = float(_np.corrcoef(y_test_arr, y_pred)[0, 1])
                        except:
                            corr = None
                        # Guardar resumen para comparativa
                        metrics_summary_rf.append({
                            "metodo": metodo,
                            "rmse": rmse,
                            "mae": mae,
                            "r2": r2
                        })
                    except Exception as e:
                        print(f"[ERROR] al calcular métricas RF para método '{metodo}': {e}")
                        # saltamos, aunque idealmente definimos rmse,etc = None

                    # 1) Parámetros de entrenamiento obtenidos desde el modelo
                    try:
                        # RandomForestRegressor atributos: n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, bootstrap
                        params = {
                            "n_estimators": getattr(model, "n_estimators", None),
                            "max_depth": getattr(model, "max_depth", None),
                            "min_samples_split": getattr(model, "min_samples_split", None),
                            "min_samples_leaf": getattr(model, "min_samples_leaf", None),
                            "max_features": getattr(model, "max_features", None),
                            "bootstrap": getattr(model, "bootstrap", None)
                        }
                        df_params = _pd.DataFrame({
                            "Hiperparámetro": list(params.keys()),
                            "Valor": [str(v) for v in params.values()]
                        })
                        titulo_p = f"### Parámetros de Entrenamiento Random Forest ({metodo})"
                        self.sections.append((titulo_p, df_params))
                        print(f"[DEBUG] 9.1. Sección parámetros RF añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al extraer parámetros RF para método '{metodo}': {e}")

                    # Explicación IA de los hiperparámetros RF
                    try:
                        prompt_params = (
                            f"Has entrenado un modelo Random Forest con selección de variables '{metodo}'.\n"
                            "Estos fueron los hiperparámetros utilizados:\n"
                        )
                        for k, v in params.items():
                            prompt_params += f"- {k}: {v}\n"
                        prompt_params += (
                            "\nPor favor, explica de forma profesional y detallada cómo estos hiperparámetros "
                            "pueden influir en el entrenamiento del Random Forest, su impacto en ajuste/sobreajuste, "
                            "y buenas prácticas para seleccionarlos o afinarlos."
                        )
                        print(f"[DEBUG] 9.2. Iniciando llamada a OpenAI para explicación hiperparámetros RF ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en entrenamiento de Random Forest para regresión."},
                                {"role": "user", "content": prompt_params}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_params = resp.choices[0].message.content.strip()
                        if explanation_params:
                            titulo_exp_p = f"### 📝 Explicación IA Hiperparámetros RF ({metodo})"
                            self.sections.append((titulo_exp_p, explanation_params))
                            print(f"[DEBUG] 9.3. Sección explicación IA hiperparámetros RF añadida para método: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibió IA para hiperparámetros RF ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA hiperparámetros RF para método '{metodo}': {e}")

                    # 2) Gráfica Predicho vs Real
                    try:
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(y_test_arr, y_pred, alpha=0.6)
                        ax1.plot([y_test_arr.min(), y_test_arr.max()],
                                 [y_test_arr.min(), y_test_arr.max()],
                                 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"Random Forest Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gráfico RF Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 9.4. Sección gráfica Pred vs Real RF añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica Pred vs Real RF para método '{metodo}': {e}")

                    # Explicación IA Pred vs Real RF con contexto numérico
                    try:
                        prompt_pr = (
                            f"A continuación tienes datos de la gráfica de comparación Real vs Predicción para el Random Forest con método '{metodo}':\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- R²: {r2}\n"
                            f"- Correlación entre Y real y predicha: {corr}\n"
                            f"- Rango Y real: [{y_real_min}, {y_real_max}]\n"
                            f"- Rango Y predicha: [{y_pred_min}, {y_pred_max}]\n\n"
                            "Basándote en estos valores y en la gráfica generada (Real vs Predicción), "
                            "proporciona un análisis detallado: sesgos sistemáticos, dispersión en rangos, posibles problemas y recomendaciones."
                        )
                        print(f"[DEBUG] 9.5. Llamada IA Pred vs Real RF ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_pr}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### 📝 Explicación IA Predicho vs Real RF ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 9.6. Sección explicación IA Pred vs Real RF añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA Pred vs Real RF para método '{metodo}': {e}")

                    # 3) Gráfica de residuos RF
                    try:
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"Random Forest Residuos ({metodo})")
                        titulo_fig2 = f"### Gráfico RF Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 9.7. Sección gráfica residuos RF añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica residuos RF para método '{metodo}': {e}")

                    # Explicación IA Residuos RF con contexto numérico
                    try:
                        prompt_res = (
                            f"A continuación tienes estadísticas de los residuos (Real - Predicha) del Random Forest con método '{metodo}':\n"
                            f"- Media: {res_mean}\n"
                            f"- Desviación estándar: {res_std}\n"
                            f"- Asimetría: {res_skew}\n"
                            f"- Curtosis: {res_kurt}\n"
                            f"- Cuantiles: 25%={q25}, 50%={q50}, 75%={q75}\n\n"
                            "Basándote en estos valores y en la gráfica de residuos, analiza patrones (heterocedasticidad, outliers, sesgos) y qué implicaciones tiene para generalización."
                        )
                        print(f"[DEBUG] 9.8. Llamada IA Residuos RF ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_res}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### 📝 Explicación IA Residuos RF ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 9.9. Sección explicación IA residuos RF añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA residuos RF para método '{metodo}': {e}")

                    # 4) Tabla Métricas y explicación IA
                    try:
                        df_met = _pd.DataFrame([
                            {"Métrica": "RMSE", "Valor": rmse},
                            {"Métrica": "MAE", "Valor": mae},
                            {"Métrica": "R2",  "Valor": r2}
                        ])
                        titulo_met = f"### Métricas Random Forest ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 9.10 Sección métricas RF añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame métricas RF para método '{metodo}': {e}")

                    try:
                        prompt_met = (
                            f"Estas son las métricas del Random Forest con método '{metodo}':\n"
                            f"- R2: {r2}\n"
                            f"- MSE: {mse}\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- Correlación Real vs Predicha: {corr}\n\n"
                            "Analiza estos valores en contexto: ¿son adecuados? ¿qué sugieren respecto al rendimiento? "
                            "Menciona referencias a la gráfica Real vs Predicción y residuos si procede."
                        )
                        print(f"[DEBUG] 9.11. Llamada IA Métricas RF ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML."},
                                {"role": "user", "content": prompt_met}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### 📝 Explicación IA Métricas RF ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 9.12. Sección explicación IA métricas RF añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA métricas RF para método '{metodo}': {e}")

                # 5) Comparativa global de métricas RF
                if metrics_summary_rf:
                    try:
                        df_comp_rf = _pd.DataFrame(metrics_summary_rf)
                        df_comp_rf_sorted = df_comp_rf.sort_values("rmse")
                        titulo_comp_rf = "### Comparativa Métricas Random Forest entre Métodos"
                        self.sections.append((titulo_comp_rf, df_comp_rf_sorted))
                        print("[DEBUG] 9.13. Sección comparativa métricas RF añadida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo métricas RF: {e}")

                    try:
                        prompt_conc = (
                            "Se han entrenado varios Random Forest con diferentes métodos de selección de variables.\n"
                            "Métricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary_rf:
                            prompt_conc += f"- Método '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos métodos: "
                            "indica cuál se comporta mejor, posibles razones y recomendaciones sobre selección de variables o ajustes para mejorar Random Forest."
                        )
                        print("[DEBUG] 9.14. Llamada IA Conclusiones RF...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_conc}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc = resp.choices[0].message.content.strip()
                        if explanation_conc:
                            titulo_exp_conc = "### 📝 Conclusiones IA Entrenamiento Random Forest"
                            self.sections.append((titulo_exp_conc, explanation_conc))
                            print("[DEBUG] 9.15. Sección explicación IA conclusiones RF añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA conclusiones RF: {e}")
            else:
                print("[DEBUG] No están RESUMEN_METODOS o X_test/Y_test en globals(), omito sección RF")
        except Exception as e:
            print(f"[ERROR] al generar sección RF en informe: {e}")
        # ... fin de la sección de entrenamiento Random Forest ...

        # =============================================================
        # 9.1. Interpretación xIA para modelo entrenado Random Forest
        # =============================================================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificación previa
        # ----------------------------------------------------------------
        try:
            print("[DEBUG] 9.16. Iniciando sección xIA para Random Forest")
            if 'xai_results' not in globals() or 'Random Forest' not in xai_results:
                raise RuntimeError(
                    "No se encontró `xai_results['Random Forest']`. "
                    "Asegúrate de haber ejecutado la Celda 10 y almacenado los resultados xIA de Random Forest en `xai_results['Random Forest']`."
                )

                # Cabecera
                self.sections.append((
                    "## 🔍 Análisis xIA de Random Forest: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vacío, la cabecera se mostrará como Markdown
                ))


            # Función para llamar a OpenAI con un prompt específico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuración: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cuántas características top incluir en el prompt
            N_LOCAL = 3    # cuántas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de métodos xIA y claves en xai_results['Random Forest']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 9.17. Procesando sección xIA: {titulo}")
                datos = xai_results['Random Forest'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ⚠️ No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 9.18. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gráfico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 9.19. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estadísticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gráfico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores numéricos concretos ---------------
                print(f"[DEBUG] 9.20. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el método xIA '{titulo}' al modelo Random Forest entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gráfico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    • {f}: {imp:.4f}\n"

                # Ahora sí le pides que interprete el gráfico:
                prompt += (
                    "- Interpreta el gráfico anterior: "
                    "describe qué patrones o relaciones visuales revela cómo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} características por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye también columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato genérico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # — Siempre sacamos el índice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribución):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estadísticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estadísticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo Random Forest
                prompt += (
                    "\nContexto: El modelo Random Forest fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este Random Forest.\n"
                )

                # 5) Preguntas/pautas específicas según el método
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¿qué implica sobre la predicción en ese caso? Y si es negativo, ¿qué implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una dirección) y cómo afecta al comportamiento general del Random Forest.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para Random Forest.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¿qué implica para la predicción local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupación de variables, detección de outliers, etc., basadas en la interpretación LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global según los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: cómo cada característica empuja la predicción en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para Random Forest), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribución integrada de cada variable: interpretación de importancia global.\n"
                        "2. Analizar las primeras muestras: qué implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Señalar limitaciones: compatibilidad con Random Forest no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros métodos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qué significa para la predicción.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la caída en la métrica al permutar cada variable: por qué ciertas variables son críticas.\n"
                        "2. Comentar la desviación estándar: ¿indica inestabilidad en la importancia? ¿Dónde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selección de variables basadas en esta métrica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicción según el rango PDP obtenido.\n"
                        "2. Señalar si los rangos sugieren relaciones monótonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretación.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) según los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar cómo ALE corrige artefactos de correlación y qué nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspección de distribución) según hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qué mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Señalar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar cómo interpretar los contrafactuales: cambios en variables que generan aumento en predicción.\n"
                        "2. Analizar variables con mayor |Δ| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Señalar si faltan contrafactuales para algunas muestras: qué puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir cómo usar estos insights para ajuste de modelo o recolección de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar cómo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicción.\n"
                        "2. Analizar frecuencia global de aparición de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Señalar regiones de bajo coverage o baja precisión: dónde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolección de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (árbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qué sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del Random Forest en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo según discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global según EBM: cómo se comparan con otros métodos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qué patrones se observan.\n"
                        "3. Señalar si EBM revela interacciones no consideradas en Random Forest.\n"
                        "4. Recomendar posibles ajustes en características o validaciones según insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperparámetros en la optimización del Random Forest.\n"
                        "2. Analizar top trials si están disponibles: qué combinaciones de hiperparámetros funcionaron mejor.\n"
                        "3. Señalar limitaciones de la muestra de trials (número de pruebas) y posibles riesgos de sobreajuste en la búsqueda.\n"
                        "4. Recomendar próximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados numéricos y qué implicaciones tienen para el modelo Random Forest.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 9.21. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicación Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ⚠️ Error en sección xIA Random Forest",
                f"Se produjo un error al generar la sección xIA de Random Forest: {e}"
            ))


        # =====================================================================
        # 10. Entrenamiento Modelo Redes Neuronales Recurrentes RNN
        # =====================================================================
        try:
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import numpy as _np
                import pandas as _pd
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                from tensorflow.keras.models import load_model

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Extraer array 1D de y_test
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2 and arr.shape[1] >= 1:
                        y_test_arr_full = arr[:, 0]
                    else:
                        y_test_arr_full = arr.ravel()
                else:
                    y_test_arr_full = _np.array(Y_test).ravel()
                y_test_arr_full = y_test_arr_full.ravel()

                metrics_summary_rnn = []
                # Iteramos sobre cada método en RESUMEN_METODOS
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    model_fname = f"modelo_rnn_{metodo_low}.h5"
                    scaler_fname = f"escaladores_rnn_{metodo_low}.pkl"
                    hp_fname = f"hyperparams_rnn_{metodo_low}.pkl"
                    if not os.path.exists(model_fname) or not os.path.exists(scaler_fname):
                        print(f"[DEBUG] Fichero de modelo RNN o escaladores no encontrado para método '{metodo}', omito este método")
                        continue
                    # Cargar modelo y escaladores
                    try:
                        model = load_model(model_fname)
                        with open(scaler_fname, "rb") as f:
                            data_s = pickle.load(f)
                        sx = data_s.get("scaler_X", None)
                        sy = data_s.get("scaler_Y", None)
                        cols = data_s.get("cols", None)
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Falta clave en escaladores RNN para método '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar modelo/escaladores RNN para método '{metodo}': {e}")
                        continue

                    # Cargar hiperparámetros
                    if os.path.exists(hp_fname):
                        try:
                            with open(hp_fname, "rb") as f_hp:
                                hp = pickle.load(f_hp)
                        except Exception as e:
                            print(f"[ERROR] al cargar hyperparams RNN para método '{metodo}': {e}")
                            hp = None
                    else:
                        hp = None
                    if hp is None:
                        print(f"[DEBUG] No hay hyperparams guardados para RNN método '{metodo}', no podré rehacer predicción correctamente, omito este método en informe")
                        continue

                    # Verificar columnas en X_test
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para método '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue

                    # Preparamos datos para secuencias
                    # Tomamos solo las columnas seleccionadas
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar toda la serie de test antes de crear secuencias
                    try:
                        Xts = sx.transform(X_test_sel)
                        # Para Y_test, necesitamos construir array alineado con secuencias:
                        # Usamos los primeros len(Xts) valores de y_test_arr_full
                        # y construiremos secuencias con window_size:
                        window = int(hp.get('window_size', 0))
                        if window <= 0 or len(Xts) <= window:
                            print(f"[DEBUG] window_size inválido o demasiado grande para test en método '{metodo}', omito")
                            continue
                        # Creamos secuencias iguales a la función create_sequences de la celda 7.5:
                        X_seq = []
                        Y_seq = []
                        for j in range(len(Xts) - window):
                            X_seq.append(Xts[j:j+window])
                            # Y real escalada (sy) usamos Y_test escalado? En entrenamiento se usó y_train escalado para fit,
                            # pero aquí Y_test necesitamos escala para invertir luego:
                            # Mejor: tomamos Y_test original:
                            # Extraemos Y_test alineado: y_test_arr_full, yts_seq será y_test_arr_full[j+window]
                            Y_seq.append(y_test_arr_full[j+window])
                        X_seq = _np.array(X_seq)   # shape (n_samples_seq, window, n_features)
                        Y_real = _np.array(Y_seq)  # shape (n_samples_seq,)
                    except Exception as e:
                        print(f"[ERROR] al preparar secuencias RNN para método '{metodo}': {e}")
                        continue

                    # Predecir y desescalar
                    try:
                        Y_pred_scaled = model.predict(X_seq, verbose=0).ravel()
                        # Invertir escala:
                        Y_pred = sy.inverse_transform(Y_pred_scaled.reshape(-1,1)).ravel()
                        # Convertir Y_real (original) en array float
                        Y_real = _np.array(Y_real).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar RNN para método '{metodo}': {e}")
                        continue

                    # Cálculo de métricas y estadísticas
                    try:
                        # Rangos Real vs Predicha
                        y_real_min, y_real_max = float(_np.min(Y_real)), float(_np.max(Y_real))
                        y_pred_min, y_pred_max = float(_np.min(Y_pred)), float(_np.max(Y_pred))
                        # Residuos
                        residuals = Y_real - Y_pred
                        res_mean = float(_np.mean(residuals))
                        res_std  = float(_np.std(residuals))
                        res_series = _pd.Series(residuals)
                        res_skew = float(res_series.skew())
                        res_kurt = float(res_series.kurtosis())
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                        # Métricas
                        mse = mean_squared_error(Y_real, Y_pred)
                        rmse = float(_np.sqrt(mse))
                        mae = float(mean_absolute_error(Y_real, Y_pred))
                        r2 = float(r2_score(Y_real, Y_pred))
                        # Correlación Real vs Predicha
                        try:
                            corr = float(_np.corrcoef(Y_real, Y_pred)[0, 1])
                        except:
                            corr = None
                        # Guardar resumen para comparativa
                        metrics_summary_rnn.append({
                            "metodo": metodo,
                            "rmse": rmse,
                            "mae": mae,
                            "r2": r2
                        })
                        #all_metrics.append({
                        #    "Modelo": f"{TIPO}_{metodo}",  # ej. "SVR_Pearson", "NN_Boruta"...
                        #    "Tipo": TIPO,                 # "SVR", "NN", "XGBoost", "RF" o "RNN"
                        #    "Método": metodo,
                        #    "R2": r2,
                        #    "MSE": mse,
                        #    "RMSE": rmse,
                        #    "MAE": mae
                        #})

                    except Exception as e:
                        print(f"[ERROR] al calcular métricas RNN para método '{metodo}': {e}")
                        continue

                    # 1) Parámetros de entrenamiento obtenidos desde hp
                    try:
                        # Usamos el dict hp cargado
                        df_hp = _pd.DataFrame({
                            "Hiperparámetro": list(hp.keys()),
                            "Valor": [str(v) for v in hp.values()]
                        })
                        titulo_hp = f"### Parámetros de Entrenamiento RNN ({metodo})"
                        self.sections.append((titulo_hp, df_hp))
                        print(f"[DEBUG] 10.1. Sección parámetros RNN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al mostrar parámetros RNN para método '{metodo}': {e}")

                    # Explicación IA hiperparámetros RNN
                    try:
                        prompt_params = (
                            f"Has entrenado un modelo RNN (tipo {hp.get('tipo_rnn')}) con selección de variables '{metodo}'.\n"
                            "Estos fueron los hiperparámetros utilizados:\n"
                        )
                        for k, v in hp.items():
                            prompt_params += f"- {k}: {v}\n"
                        prompt_params += (
                            "\nPor favor, explica de forma profesional y detallada cómo estos hiperparámetros "
                            "pueden influir en el entrenamiento de la RNN, su impacto en ajuste/sobreajuste, "
                            "y buenas prácticas para seleccionarlos o afinarlos."
                        )
                        print(f"[DEBUG] 10.2. Iniciando llamada a OpenAI para explicación hiperparámetros RNN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en entrenamiento de redes neuronales recurrentes para series temporales."},
                                {"role": "user", "content": prompt_params}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_hp = resp.choices[0].message.content.strip()
                        if explanation_hp:
                            titulo_exp_hp = f"### 📝 Explicación IA Hiperparámetros RNN ({metodo})"
                            self.sections.append((titulo_exp_hp, explanation_hp))
                            print(f"[DEBUG] 10.3. Sección explicación IA hiperparámetros RNN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA hiperparámetros RNN para método '{metodo}': {e}")

                    # 2) Gráfica Predicho vs Real
                    try:
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(Y_real, Y_pred, alpha=0.6)
                        ax1.plot([y_real_min, y_real_max], [y_real_min, y_real_max], 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"RNN Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gráfico RNN Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 10.4. Sección gráfica Pred vs Real RNN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica Pred vs Real RNN para método '{metodo}': {e}")

                    # Explicación IA Pred vs Real RNN con contexto numérico
                    try:
                        prompt_pr = (
                            f"A continuación tienes datos de la gráfica de comparación Real vs Predicción para el modelo RNN con método '{metodo}':\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- R²: {r2}\n"
                            f"- Correlación entre Y real y predicha: {corr}\n"
                            f"- Rango Y real: [{y_real_min}, {y_real_max}]\n"
                            f"- Rango Y predicha: [{y_pred_min}, {y_pred_max}]\n\n"
                            "Basándote en estos valores y en la gráfica generada (Real vs Predicción), "
                            "proporciona un análisis detallado: sesgos sistemáticos, dispersión en rangos, posibles problemas y recomendaciones."
                        )
                        print(f"[DEBUG] 10.5. Llamada IA Pred vs Real RNN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML para series temporales."},
                                {"role": "user", "content": prompt_pr}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### 📝 Explicación IA Predicho vs Real RNN ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 10.6. Sección explicación IA Pred vs Real RNN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA Pred vs Real RNN para método '{metodo}': {e}")

                    # 3) Gráfica de residuos RNN
                    try:
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(Y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"RNN Residuos ({metodo})")
                        titulo_fig2 = f"### Gráfico RNN Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 10.7. Sección gráfica residuos RNN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gráfica residuos RNN para método '{metodo}': {e}")

                    # Explicación IA Residuos RNN con contexto numérico
                    try:
                        prompt_res = (
                            f"A continuación tienes estadísticas de los residuos (Real - Predicha) del modelo RNN con método '{metodo}':\n"
                            f"- Media: {res_mean}\n"
                            f"- Desviación estándar: {res_std}\n"
                            f"- Asimetría: {res_skew}\n"
                            f"- Curtosis: {res_kurt}\n"
                            f"- Cuantiles: 25%={q25}, 50%={q50}, 75%={q75}\n\n"
                            "Basándote en estos valores y en la gráfica de residuos, analiza patrones (heterocedasticidad, outliers, sesgos) y qué implicaciones tiene para generalización."
                        )
                        print(f"[DEBUG] 10.8 Llamada IA Residuos RNN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML para series temporales."},
                                {"role": "user", "content": prompt_res}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### 📝 Explicación IA Residuos RNN ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 10.9. Sección explicación IA residuos RNN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA residuos RNN para método '{metodo}': {e}")

                    # 4) Tabla Métricas y explicación IA
                    try:
                        df_met = _pd.DataFrame([
                            {"Métrica": "RMSE", "Valor": rmse},
                            {"Métrica": "MAE", "Valor": mae},
                            {"Métrica": "R2",  "Valor": r2}
                        ])
                        titulo_met = f"### Métricas RNN ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 10.10. Sección métricas RNN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame métricas RNN para método '{meteto}': {e}")

                    try:
                        prompt_met = (
                            f"Estas son las métricas del modelo RNN con método '{metodo}':\n"
                            f"- R2: {r2}\n"
                            f"- MSE: {mse}\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- Correlación Real vs Predicha: {corr}\n\n"
                            "Analiza estos valores en contexto: ¿son adecuados? ¿qué sugieren respecto al rendimiento? Menciona gráficas Pred vs Real y residuos."
                        )
                        print(f"[DEBUG] 10.11. Llamada IA Métricas RNN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluación de modelos ML para series temporales."},
                                {"role": "user", "content": prompt_met}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### 📝 Explicación IA Métricas RNN ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 10.12. Sección explicación IA métricas RNN añadida para método: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA métricas RNN para método '{metodo}': {e}")

                # 5) Comparativa global de métricas RNN
                if metrics_summary_rnn:
                    try:
                        df_comp_rnn = _pd.DataFrame(metrics_summary_rnn)
                        df_comp_rnn_sorted = df_comp_rnn.sort_values("rmse")
                        titulo_comp_rnn = "### Comparativa Métricas RNN entre Métodos"
                        self.sections.append((titulo_comp_rnn, df_comp_rnn_sorted))
                        print("[DEBUG] 10.13. Sección comparativa métricas RNN añadida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo métricas RNN: {e}")

                    try:
                        prompt_conc = (
                            "Se han entrenado varios modelos RNN con diferentes métodos de selección de variables.\n"
                            "Métricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary_rnn:
                            prompt_conc += f"- Método '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos métodos: "
                            "indica cuál se comporta mejor, posibles razones y recomendaciones sobre selección de variables o ajustes para mejorar la RNN."
                        )
                        print("[DEBUG] 10.14. Llamada IA Conclusiones RNN...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos para series temporales."},
                                {"role": "user", "content": prompt_conc}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc = resp.choices[0].message.content.strip()
                        if explanation_conc:
                            titulo_exp_conc = "### 📝 Conclusiones IA Entrenamiento RNN"
                            self.sections.append((titulo_exp_conc, explanation_conc))
                            print("[DEBUG] 10.15. Sección explicación IA conclusiones RNN añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA conclusiones RNN: {e}")
            else:
                print("[DEBUG] No están RESUMEN_METODOS o X_test/Y_test en globals(), omito sección RNN")
        except Exception as e:
            print(f"[ERROR] al generar sección RNN en informe: {e}")
        # ... fin de la sección de entrenamiento de Redes Neuronales Rrecurrentes RNN ...

        # =============================================================
        # 10.1. Interpretación xIA para modelo entrenado RNN
        # =============================================================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificación previa
        # ----------------------------------------------------------------
        # ── 0) Normalizar la clave para buscar en xai_results ────────
        #storage_key = 'RNN'.lower()   # coincide con la clave usada al guardar en la celda 10 ('rnn')
        try:
            print("[DEBUG] 10.16. Iniciando sección xIA para RNN")
            print("DEBUG: claves en xai_results:", list(xai_results.keys()))
            if 'xai_results' not in globals() or 'RNN' not in xai_results:
                raise RuntimeError(
                    "No se encontró `xai_results['rnn']`. "
                    "Asegúrate de haber ejecutado la Celda 10 y almacenado los resultados xIA de RNN en `xai_results['rnn']`."
                )

                # Cabecera
                self.sections.append((
                    "## 🔍 Análisis xIA de RNN: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vacío, la cabecera se mostrará como Markdown
                ))


            # Función para llamar a OpenAI con un prompt específico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuración: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cuántas características top incluir en el prompt
            N_LOCAL = 3    # cuántas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de métodos xIA y claves en xai_results['RNN']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 10.17. Procesando sección xIA: {titulo}")
                datos = xai_results['RNN'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ⚠️ No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 10.18. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gráfico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 10.19. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estadísticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gráfico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores numéricos concretos ---------------
                print(f"[DEBUG] 10.20. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el método xIA '{titulo}' al modelo RNN entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gráfico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    • {f}: {imp:.4f}\n"

                # Ahora sí le pides que interprete el gráfico:
                prompt += (
                    "- Interpreta el gráfico anterior: "
                    "describe qué patrones o relaciones visuales revela cómo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} características por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye también columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato genérico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # — Siempre sacamos el índice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribución):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estadísticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estadísticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo RNN
                prompt += (
                    "\nContexto: El modelo RNN fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este RNN.\n"
                )

                # 5) Preguntas/pautas específicas según el método
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¿qué implica sobre la predicción en ese caso? Y si es negativo, ¿qué implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una dirección) y cómo afecta al comportamiento general del RNN.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para RNN.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¿qué implica para la predicción local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupación de variables, detección de outliers, etc., basadas en la interpretación LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global según los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: cómo cada característica empuja la predicción en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para RNN), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribución integrada de cada variable: interpretación de importancia global.\n"
                        "2. Analizar las primeras muestras: qué implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Señalar limitaciones: compatibilidad con RNN no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros métodos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qué significa para la predicción.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la caída en la métrica al permutar cada variable: por qué ciertas variables son críticas.\n"
                        "2. Comentar la desviación estándar: ¿indica inestabilidad en la importancia? ¿Dónde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selección de variables basadas en esta métrica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicción según el rango PDP obtenido.\n"
                        "2. Señalar si los rangos sugieren relaciones monótonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretación.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) según los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar cómo ALE corrige artefactos de correlación y qué nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspección de distribución) según hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qué mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Señalar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar cómo interpretar los contrafactuales: cambios en variables que generan aumento en predicción.\n"
                        "2. Analizar variables con mayor |Δ| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Señalar si faltan contrafactuales para algunas muestras: qué puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir cómo usar estos insights para ajuste de modelo o recolección de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar cómo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicción.\n"
                        "2. Analizar frecuencia global de aparición de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Señalar regiones de bajo coverage o baja precisión: dónde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolección de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (árbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qué sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del RNN en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo según discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global según EBM: cómo se comparan con otros métodos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qué patrones se observan.\n"
                        "3. Señalar si EBM revela interacciones no consideradas en RNN.\n"
                        "4. Recomendar posibles ajustes en características o validaciones según insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperparámetros en la optimización del RNN.\n"
                        "2. Analizar top trials si están disponibles: qué combinaciones de hiperparámetros funcionaron mejor.\n"
                        "3. Señalar limitaciones de la muestra de trials (número de pruebas) y posibles riesgos de sobreajuste en la búsqueda.\n"
                        "4. Recomendar próximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados numéricos y qué implicaciones tienen para el modelo RNN.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 10.21. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicación Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ⚠️ Error en sección xIA RNN",
                f"Se produjo un error al generar la sección xIA de RNN: {e}"
            ))


        # =====================================================================
        # 11. Comparador Global de Modelos Entrenados
        # =====================================================================
        try:
            print("[DEBUG] 11.1. Iniciando sección Comparador de Modelos")
            import os, pickle
            import numpy as np
            import pandas as _pd
            import matplotlib.pyplot as plt
            from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
            from tensorflow.keras.models import load_model

            # 1) Recopilar todos los modelos guardados
            ruta = "."
            modelos = []
            for f in os.listdir(ruta):
                if f.startswith("modelo_") and (f.endswith(".pkl") or f.endswith(".h5")):
                    name = f.replace("modelo_", "").rsplit(".", 1)[0]
                    try:
                        if f.endswith(".pkl"):
                            with open(f, "rb") as fp:
                                data = pickle.load(fp)
                            model = data.get("model")
                            sx = data.get("sx", data.get("scaler_X"))
                            sy = data.get("sy", data.get("scaler_Y"))
                            cols = data.get("cols", [])
                        else:  # .h5
                            model = load_model(f)
                            # se espera un pickle de escaladores: escaladores_{name}.pkl
                            escal_path = f"escaladores_{name}.pkl"
                            with open(escal_path, "rb") as fp:
                                data = pickle.load(fp)
                            sx = data.get("scaler_X")
                            sy = data.get("scaler_Y")
                            cols = data.get("cols", [])
                        if model is None or sx is None or sy is None or not cols:
                            raise ValueError("Faltan claves necesarias en el pickle/modelo")
                        modelos.append((name, model, sx, sy, cols))
                    except Exception as e:
                        print(f"[DEBUG] Omitido {f}: {e}")

            if not modelos:
                print("[DEBUG] No se encontraron modelos válidos para comparar")
            else:
                # 2) Para cada modelo, calcular predicciones sobre X_test/Y_test
                resultados = []
                preds_dict = {}
                y_true_full = None

                for name, model, sx, sy, cols in modelos:
                    # Verificar que X_test y Y_test existan en globals
                    if "X_test" not in self.g or "Y_test" not in self.g:
                        print("[DEBUG] No hay X_test/Y_test en globals(), omito comparador")
                        break
                    try:
                        X_test_df = self.g["X_test"][cols].copy()
                    except Exception as e:
                        print(f"[DEBUG] Error al extraer X_test para {name}: {e}")
                        continue
                    y_test = self.g["Y_test"]
                    # Serie 1D de y_true
                    arr = y_test.values if hasattr(y_test, "values") else np.array(y_test)
                    y_arr = arr.ravel()

                    # Detectar si es RNN por input_shape
                    is_rnn = False
                    window = None
                    try:
                        if hasattr(model, "input_shape") and isinstance(model.input_shape, tuple) and len(model.input_shape) == 3:
                            is_rnn = True
                            window = model.input_shape[1]
                    except:
                        pass

                    # Generar predicción
                    try:
                        if is_rnn and window is not None:
                            # crear secuencias
                            Xs = sx.transform(X_test_df)
                            seqs, trues = [], []
                            for i in range(len(Xs) - window):
                                seqs.append(Xs[i:i + window])
                                trues.append(y_arr[i + window])
                            if not seqs:
                                print(f"[DEBUG] Secuencias vacías para RNN {name}, omito")
                                continue
                            Xseq = np.array(seqs)
                            y_real = np.array(trues)
                            pred_scaled = model.predict(Xseq, verbose=0)
                            # en algunos casos model.predict devuelve tupla
                            if isinstance(pred_scaled, tuple):
                                pred_scaled = pred_scaled[0]
                            y_pred = sy.inverse_transform(pred_scaled.reshape(-1, 1)).ravel()
                        else:
                            Xs = sx.transform(X_test_df)
                            raw = model.predict(Xs)
                            if isinstance(raw, tuple):
                                raw = raw[0]
                            y_pred = sy.inverse_transform(raw.reshape(-1, 1)).ravel()
                            y_real = y_arr
                    except Exception as e:
                        print(f"[DEBUG] Error predicción para {name}: {e}")
                        continue

                    # Guardar y_true para la primera curva
                    if y_true_full is None:
                        y_true_full = y_real

                    # Calcular métricas
                    try:
                        r2 = r2_score(y_real, y_pred)
                        mse = mean_squared_error(y_real, y_pred)
                        rmse = np.sqrt(mse)
                        mae = mean_absolute_error(y_real, y_pred)
                    except Exception as e:
                        print(f"[DEBUG] Error cálculo métricas para {name}: {e}")
                        continue

                    resultados.append({
                        "Modelo": name,
                        "R2": r2,
                        "MSE": mse,
                        "RMSE": rmse,
                        "MAE": mae
                    })
                    preds_dict[name] = y_pred

                # 3) Tabla de métricas
                if resultados:
                    df_met = _pd.DataFrame(resultados).set_index("Modelo")
                    self.sections.append(("### 📋 Comparativa de Métricas de Todos los Modelos", df_met))
                    print("[DEBUG] 11.2. Sección comparativa métricas añadida")
                    # Extraer métricas como dict para el prompt:
                    # Podemos convertir a lista de dicts o dict de listas. Por claridad, usamos lista de records:
                    metrics_records = df_met.reset_index().to_dict(orient='records')
                    # Explicación IA de la tabla
                    prompt_tab = (
                        "Tienes estas métricas en test para cada modelo:\n"
                        + "\n".join(
                            f"- Modelo '{rec['Modelo']}': R2={rec['R2']:.4f}, RMSE={rec['RMSE']:.4f}, MAE={rec['MAE']:.4f}, MSE={rec['MSE']:.4f}"
                            for rec in metrics_records
                        )
                        + "\n\nPor favor, interpreta profesionalmente cuál modelo es el mejor según estas métricas y por qué, "
                          "y proporciona recomendaciones de ajustes de hiperparámetros para mejorar el desempeño del mejor modelo y posibles ajustes en los demás."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_tab}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### 📝 Explicación IA Comparativa de Métricas", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.3. Sección IA comparación métricas añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA comparación métricas: {e}")

                    # Función auxiliar para gráfico de barras horizontales
                    def _plot_barh(series, titulo, xlabel=None):
                        fig, ax = plt.subplots(figsize=(8, max(4, 0.3 * len(series))))
                        # ordenar para que el mejor (mayor R2 o menor error) quede arriba
                        series_sorted = series.sort_values(ascending=True)
                        # Si es R2 (mayor es mejor), invertimos orden para que el mayor quede arriba
                        if xlabel == "R2":
                            # para R2, queremos ascending=True y luego invertir eje Y
                            ax.barh(series_sorted.index, series_sorted.values)
                        else:
                            # para errores (RMSE, MAE, MSE), menor es mejor: ascending=True pone menor arriba después de invertir eje
                            ax.barh(series_sorted.index, series_sorted.values)
                        ax.set_title(titulo)
                        ax.set_xlabel(xlabel if xlabel else "")
                        ax.set_ylabel("Modelo")
                        ax.invert_yaxis()
                        plt.tight_layout()
                        return fig

                    # 4) Barras de R2
                    fig_r2 = _plot_barh(df_met["R2"], "Ranking de Modelos por R²", xlabel="R2")
                    self.sections.append(("### 📊 Gráfico Comparativo de R²", fig_r2))
                    print("[DEBUG] 11.4. Sección gráfica R2 añadida")
                    # Explicación IA R2
                    # Extraer valores de R2:
                    r2_dict = df_met["R2"].to_dict()  # e.g. {"M1":0.85, "M2":0.78, ...}
                    prompt_r2 = (
                        "Tienes los valores de R² en test para cada modelo (aquí listados):\n"
                        + "\n".join(f"- Modelo '{m}': R² = {v:.4f}" for m, v in r2_dict.items())
                        + "\n\nBasándote en estos valores (sin apoyarte en la visualización directa), "
                          "indica profesionalmente qué conclusiones sacas sobre el ajuste de los modelos y posibles razones de las diferencias entre ellos."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en interpretación de gráficos ML."},
                                {"role": "user", "content": prompt_r2}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### 📝 Explicación IA Gráfico R²", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.5. Sección IA comparación R2 añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA R2: {e}")

                    # 5) Barras de MAE
                    fig_mae = _plot_barh(df_met["MAE"], "Comparativa Global por MAE (menor es mejor)", xlabel="MAE")
                    self.sections.append(("### 📊 Gráfico Comparativo de MAE", fig_mae))
                    print("[DEBUG] 11.6. Sección gráfica MAE añadida")
                    # Extraer valores de MAE:
                    mae_dict = df_met["MAE"].to_dict()  # e.g. {"M1":12.345, "M2":15.678, ...}
                    prompt_mae = (
                        "Tienes los valores de MAE en test para cada modelo:\n"
                        + "\n".join(f"- Modelo '{m}': MAE = {v:.4f}" for m, v in mae_dict.items())
                        + "\n\nBasándote en estos valores (sin ver la gráfica), indica profesionalmente qué indican sobre la precisión de cada modelo en términos absolutos y relativos, "
                          "qué patrones observas (por ejemplo, modelos con MAE significativamente más alta o más baja) y recomendaciones concretas para reducir el MAE del mejor modelo o de aquellos con MAE elevado."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en interpretación de métricas de error en ML."},
                                {"role": "user", "content": prompt_mae}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### 📝 Explicación IA Gráfico MAE", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.7. Sección IA comparación MAE añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA MAE: {e}")

                    # 6) Barras de MSE
                    fig_mse = _plot_barh(df_met["MSE"], "Comparativa Global por MSE (menor es mejor)", xlabel="MSE")
                    self.sections.append(("### 📊 Gráfico Comparativo de MSE", fig_mse))
                    print("[DEBUG] 11.8. Sección gráfica MSE añadida")
                    # Extraer valores de MSE:
                    mse_dict = df_met["MSE"].to_dict()
                    prompt_mse = (
                        "Tienes los valores de MSE en test para cada modelo:\n"
                        + "\n".join(f"- Modelo '{m}': MSE = {v:.4f}" for m, v in mse_dict.items())
                        + "\n\nBasándote en estos valores, comenta profesionalmente qué sugiere acerca del ajuste y robustez de cada modelo, "
                          "identifica si hay alguno con MSE significativamente mayor o menor y ofrece recomendaciones concretas para reducir MSE (por ejemplo, cambios de preprocesado, regularización, arquitectura, etc.)."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en interpretación de métricas de error en ML."},
                                {"role": "user", "content": prompt_mse}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### 📝 Explicación IA Gráfico MSE", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.9. Sección IA comparación MSE añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA MSE: {e}")

                    # 7) Barras de RMSE
                    fig_rmse = _plot_barh(df_met["RMSE"], "Comparativa Global por RMSE (menor es mejor)", xlabel="RMSE")
                    self.sections.append(("### 📊 Gráfico Comparativo de RMSE", fig_rmse))
                    print("[DEBUG] 11.10. Sección gráfica RMSE añadida")
                    # Extraer valores de RMSE:
                    rmse_dict = df_met["RMSE"].to_dict()
                    prompt_rmse = (
                        "Tienes los valores de RMSE en test para cada modelo:\n"
                        + "\n".join(f"- Modelo '{m}': RMSE = {v:.4f}" for m, v in rmse_dict.items())
                        + "\n\nBasándote en estos valores, comenta profesionalmente las diferencias entre modelos, "
                          "por qué algunos podrían tener RMSE mayor o menor (relación con varianza de los datos, sesgos, complejidad del modelo, etc.) y sugiere estrategias concretas para mejorar el RMSE del modelo ganador o para equilibrar sesgo-varianza."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en interpretación de métricas de error en ML."},
                                {"role": "user", "content": prompt_rmse}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### 📝 Explicación IA Gráfico RMSE", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.11. Sección IA comparación RMSE añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA RMSE: {e}")

                    # 8) Curvas Real vs Predicho para todos
                    if y_true_full is not None and preds_dict:
                        fig2, ax2 = plt.subplots(figsize=(8, 4))
                        ax2.plot(y_true_full, label="Y real", color="black", linewidth=2)
                        for name, pred in preds_dict.items():
                            # Asegurarse de que longitudes coincidan; si no, recortar al mínimo
                            min_len = min(len(y_true_full), len(pred))
                            ax2.plot(pred[:min_len], "--", label=name)
                        ax2.set_title("Comparativa Y real vs Predicho")
                        ax2.legend(loc="upper right")
                        plt.tight_layout()
                        self.sections.append(("### 📈 Gráfico Comparativo Real vs Predicho", fig2))
                        print("[DEBUG] 11.12. Sección gráfica real vs pred añadida")
                        # Suponiendo y_true_full y preds_dict ya definidos y alineados:
                        # Para cada modelo:
                        summary_list = []
                        import numpy as _np
                        for name, pred in preds_dict.items():
                            # Asegurar longitudes coincidentes
                            min_len = min(len(y_true_full), len(pred))
                            y_real = _np.array(y_true_full[:min_len])
                            y_pred = _np.array(pred[:min_len])
                            # Métricas:
                            from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                            try:
                                r2_val = r2_score(y_real, y_pred)
                            except:
                                r2_val = None
                            try:
                                mse_val = mean_squared_error(y_real, y_pred)
                                rmse_val = _np.sqrt(mse_val)
                            except:
                                mse_val = rmse_val = None
                            try:
                                mae_val = mean_absolute_error(y_real, y_pred)
                            except:
                                mae_val = None
                            # Correlación:
                            try:
                                corr_val = float(_np.corrcoef(y_real, y_pred)[0, 1]) if len(y_real)>1 else None
                            except:
                                corr_val = None
                            # Rango:
                            y_real_min, y_real_max = float(_np.min(y_real)), float(_np.max(y_real))
                            y_pred_min, y_pred_max = float(_np.min(y_pred)), float(_np.max(y_pred))
                            summary_list.append({
                                "Modelo": name,
                                "R2": r2_val,
                                "MSE": mse_val,
                                "RMSE": rmse_val,
                                "MAE": mae_val,
                                "Corr": corr_val,
                                "Rango real": (y_real_min, y_real_max),
                                "Rango pred": (y_pred_min, y_pred_max)
                            })
                            # Formatear summary_list en texto:
                            lines = []
                            for rec in summary_list:
                                m = rec["Modelo"]
                                # Manejar None con 'N/A'
                                r2s = f"{rec['R2']:.4f}" if rec['R2'] is not None else "N/A"
                                rs = rec["Rango real"]
                                ps = rec["Rango pred"]
                                corr_s = f"{rec['Corr']:.4f}" if rec['Corr'] is not None else "N/A"
                                mse_s = f"{rec['MSE']:.4f}" if rec['MSE'] is not None else "N/A"
                                rmse_s = f"{rec['RMSE']:.4f}" if rec['RMSE'] is not None else "N/A"
                                mae_s = f"{rec['MAE']:.4f}" if rec['MAE'] is not None else "N/A"
                                lines.append(
                                    f"- Modelo '{m}': R2={r2s}, RMSE={rmse_s}, MAE={mae_s}, MSE={mse_s}, Corr={corr_s}, "
                                    f"Rango real=[{rs[0]:.4f}, {rs[1]:.4f}], Rango pred=[{ps[0]:.4f}, {ps[1]:.4f}]"
                                )

                            prompt_curvas = (
                                "Para cada modelo tienes estos resúmenes numéricos de su predicción vs real:\n"
                                + "\n".join(lines)
                                + "\n\nAunque también se generó una gráfica Real vs Predicho, la IA no la ve: "
                                  "Comenta profesionalmente cómo varía el ajuste de cada modelo a lo largo de la serie con base en los valores anteriores "
                                  "(por ejemplo, si hay subestimación sistemática al inicio o al final, si la dispersión crece en ciertos rangos, etc.)."
                            )
                        try:
                            resp = _client.chat.completions.create(
                                model="gpt-4",
                                messages=[
                                    {"role": "system", "content": "Eres un experto en visualización de resultados ML."},
                                    {"role": "user", "content": prompt_curvas}
                                ],
                                max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                            )
                            self.sections.append(("### 📝 Explicación IA Curvas Real vs Predicho", resp.choices[0].message.content.strip()))
                            print("[DEBUG] 11.13. Sección IA comparación curvas añadida")
                        except Exception as e:
                            print(f"[ERROR] al generar explicación IA curvas: {e}")

                        # 9) Gráfica de residuos superpuesta
                        fig3, ax3 = plt.subplots(figsize=(8, 4))
                        for name, pred in preds_dict.items():
                            min_len = min(len(y_true_full), len(pred))
                            res = y_true_full[:min_len] - pred[:min_len]
                            ax3.plot(res, label=name, alpha=0.7)
                        ax3.axhline(0, color="black", lw=1)
                        ax3.set_title("Comparativa de Residuos")
                        ax3.legend(loc="upper right")
                        plt.tight_layout()
                        self.sections.append(("### 📉 Gráfico Comparativo de Residuos", fig3))
                        print("[DEBUG] 11.14. Sección gráfica residuos añadida")
                        res_summary = []
                        import numpy as _np
                        for rec in summary_list:  # si summary_list incluye y_real y y_pred, o recalcular aquí
                            name = rec["Modelo"]
                            # Recalcular residuos:
                            pred = preds_dict[name]
                            min_len = min(len(y_true_full), len(pred))
                            y_real = _np.array(y_true_full[:min_len])
                            y_pred = _np.array(pred[:min_len])
                            residuals = y_real - y_pred
                            # Estadísticos:
                            mean_res = float(_np.mean(residuals))
                            std_res  = float(_np.std(residuals))
                            # Con Pandas o numpy calcular skew/kurt:
                            import pandas as _pd
                            res_series = _pd.Series(residuals)
                            skew_res = float(res_series.skew())
                            kurt_res = float(res_series.kurtosis())
                            q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                            # Rango:
                            min_res, max_res = float(_np.min(residuals)), float(_np.max(residuals))
                            res_summary.append({
                                "Modelo": name,
                                "Mean": mean_res,
                                "Std": std_res,
                                "Skew": skew_res,
                                "Kurtosis": kurt_res,
                                "Quantiles": (q25, q50, q75),
                                "Rango residuo": (min_res, max_res)
                            })
                            lines = []
                            for rec in res_summary:
                                m = rec["Modelo"]
                                mean_s = f"{rec['Mean']:.4f}"
                                std_s  = f"{rec['Std']:.4f}"
                                skew_s = f"{rec['Skew']:.4f}"
                                kurt_s = f"{rec['Kurtosis']:.4f}"
                                q25, q50, q75 = rec["Quantiles"]
                                min_r, max_r = rec["Rango residuo"]
                                lines.append(
                                    f"- Modelo '{m}': media residuo={mean_s}, std={std_s}, skew={skew_s}, kurtosis={kurt_s}, "
                                    f"quantiles residuo 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}, "
                                    f"rango residuo=[{min_r:.4f}, {max_r:.4f}]"
                                )
                            prompt_res = (
                                "Tienes las siguientes estadísticas de residuos (Y_real - Y_predicho) para cada modelo:\n"
                                + "\n".join(lines)
                                + "\n\nCon base en estos datos (sin apoyo visual), analiza profesionalmente si hay patrones de sesgo (por ejemplo, media distinta de 0), heterocedasticidad (std variable según nivel, aunque aquí solo tenemos std global; si quisieras, podrías calcular std en terciles de y_pred), posibles outliers (basándote en quantiles y rango), y qué implicaciones tiene para la robustez y generalización de cada modelo."
                            )
                        try:
                            resp = _client.chat.completions.create(
                                model="gpt-4",
                                messages=[
                                    {"role": "system", "content": "Eres un experto en diagnóstico de modelos ML."},
                                    {"role": "user", "content": prompt_res}
                                ],
                                max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                            )
                            self.sections.append(("### 📝 Explicación IA Residuos Comparativos", resp.choices[0].message.content.strip()))
                            print("[DEBUG] 11.15. Sección IA comparación residuos añadida")
                        except Exception as e:
                            print(f"[ERROR] al generar explicación IA residuos: {e}")
                    else:
                        print("[DEBUG] No hay datos suficientes para curvas o residuos comparativos")

                    # 10) Parámetros técnicos de cada modelo
                    tabla_params = []
                    for name, model, _, _, _ in modelos:
                        row = {"Modelo": name}
                        try:
                            if hasattr(model, "get_params"):
                                row.update(model.get_params())
                            else:
                                cfg = model.get_config()
                                row["Capas"] = len(cfg.get("layers", []))
                                row["Opt"] = cfg.get("optimizer_config", {}).get("class_name", "?")
                                row["Loss"] = cfg.get("loss", "?")
                        except Exception:
                            row["Info"] = "no disponible"
                        tabla_params.append(row)
                    df_params = _pd.DataFrame(tabla_params).set_index("Modelo")
                    self.sections.append(("### 🛠 Parámetros Técnicos de Cada Modelo", df_params))
                    print("[DEBUG] 11.16. Sección tabla parámetros añadida")

                    # Explicación IA parámetros
                    prompt_par = (
                        "Aquí tienes una tabla con los parámetros técnicos usados en cada modelo. "
                        "Comenta brevemente qué configuraciones parecen más adecuadas y cuáles podrían ajustarse para mejorar el rendimiento."
                        f"\n\n{df_params.to_dict(orient='list')}"
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en optimización de hiperparámetros ML."},
                                {"role": "user", "content": prompt_par}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### 📝 Explicación IA Parámetros Técnicos", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.17. Sección IA comparación parámetros añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA parámetros: {e}")

                    # 11) Conclusiones Globales y Recomendaciones de IA
                    try:
                        # Construir prompt que recopile los principales resultados:
                        # Usamos df_met (DataFrame de métricas) y, opcionalmente, podemos incorporar insights de gráficos anteriores.
                        # Convertimos df_met a diccionario para el prompt:
                        # Supongamos summary_list y res_summary ya definidos (como arriba).
                        # Formateamos una sección de métricas generales:
                        lines_met = []
                        for rec in summary_list:
                            m = rec["Modelo"]
                            r2s = f"{rec['R2']:.4f}" if rec['R2'] is not None else "N/A"
                            rmse_s = f"{rec['RMSE']:.4f}" if rec['RMSE'] is not None else "N/A"
                            mae_s = f"{rec['MAE']:.4f}" if rec['MAE'] is not None else "N/A"
                            mse_s = f"{rec['MSE']:.4f}" if rec['MSE'] is not None else "N/A"
                            lines_met.append(f"- {m}: R2={r2s}, RMSE={rmse_s}, MAE={mae_s}, MSE={mse_s}")

                        # Formateamos estadísticas de residuos:
                        lines_res = []
                        for rec in res_summary:
                            m = rec["Modelo"]
                            mean_s = f"{rec['Mean']:.4f}"
                            std_s  = f"{rec['Std']:.4f}"
                            skew_s = f"{rec['Skew']:.4f}"
                            kurt_s = f"{rec['Kurtosis']:.4f}"
                            q25, q50, q75 = rec["Quantiles"]
                            lines_res.append(
                                f"- {m}: media residuo={mean_s}, std={std_s}, skew={skew_s}, kurtosis={kurt_s}, quantiles[25,50,75]=[{q25:.4f},{q50:.4f},{q75:.4f}]"
                            )

                        # Formateamos rangos de predicción vs real:
                        lines_range = []
                        for rec in summary_list:
                            m = rec["Modelo"]
                            rs = rec["Rango real"]
                            ps = rec["Rango pred"]
                            lines_range.append(f"- {m}: Rango real=[{rs[0]:.4f},{rs[1]:.4f}], Rango pred=[{ps[0]:.4f},{ps[1]:.4f}]")

                        # Construcción del prompt:
                        prompt_final = (
                            "A continuación tienes un resumen numérico de los resultados de todos los modelos:\n\n"
                            "1) Métricas globales en test:\n"
                            + "\n".join(lines_met)
                            + "\n\n2) Estadísticas de residuos:\n"
                            + "\n".join(lines_res)
                            + "\n\n3) Rangos de valores real vs predicho:\n"
                            + "\n".join(lines_range)
                            + "\n\nYa se han analizado previamente aspectos de ajuste, error y parámetros. "
                            "Con base en toda esta información numérica, por favor: "
                            "- Indica cuál modelo presenta en conjunto mejor desempeño y por qué. "
                            "- Sugiere qué ajustes o hiperparámetros convendría afinar en ese modelo para mejorar aún más (por ejemplo, si es red neuronal, architecture tweaks; si es árbol, depth/regularización; si es RNN, window size o layers; etc.). "
                            "- Comenta posibles limitaciones de los otros modelos e indica en qué escenarios podrían ser útiles (por ejemplo, si un modelo tiene menor varianza pero mayor sesgo, puede servir en entornos con datos ruidosos, etc.). "
                            "- Propón próximos pasos de validación o pruebas adicionales (p. ej. validación cruzada más exhaustiva, test en nuevos periodos de la serie, experimentos de robustez). "
                            "Presenta la respuesta de forma profesional, estructurada en secciones (por ejemplo: Resumen general, Análisis del mejor modelo, Ajustes recomendados, Limitaciones y usos alternativos, Próximos pasos)."
                        )
                        resp_final = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en análisis comparativo de modelos de Machine Learning."},
                                {"role": "user", "content": prompt_final}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        # Añadir la sección al informe
                        self.sections.append((
                            "### 🏁 Conclusiones Globales y Recomendaciones IA",
                            resp_final.choices[0].message.content.strip()
                        ))
                        print("[DEBUG] 11.18. Sección IA Conclusiones Globales añadida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicación IA Conclusiones Globales: {e}")

                else:
                    print("[DEBUG] No se obtuvieron resultados de métrica para ningún modelo")
        except Exception as e:
            print(f"[ERROR] al generar sección Comparador de Modelos: {e}")

        # =====================================================================
        # 12. Optimización Modelo SVR
        # =====================================================================
        from scipy.stats import skew, kurtosis
        try:
            print("[DEBUG] 12.1. Iniciando sección Optimización SVR: Resumen de métodos y motores")
            # Verificación previa: usamos OPT_MODELS guardado en la celda 9.1
            if 'OPT_MODELS' in globals() and isinstance(OPT_MODELS, dict):
                # Filtrar solo entradas de SVR con payload dict y motores válidos
                valid_engines = {'gridsearchcv', 'randomizedsearchcv', 'optuna', 'bayessearchcv'}
                svr_entries = {
                    k: v for k, v in OPT_MODELS.items()
                    if (isinstance(k, tuple) and k[0] == 'svr'
                        and isinstance(v, dict)
                        and k[2] in valid_engines)
                }
            else:
                raise RuntimeError(
                    "No se encontró la variable global OPT_MODELS con resultados de optimización SVR. "
                    "Asegúrate de haber ejecutado la Celda 9.1 y de que OPT_MODELS contenga los payloads optimizados."
                )

            import pandas as pd

            # Definición de las configuraciones usadas para cada motor (para mostrar en la tabla)
            param_configs = {
                'gridsearchcv': {
                    'C': '[0.1, 1, 10, 100]',
                    'epsilon': '[0.01, 0.1, 0.5, 1]',
                    'kernel': "['rbf', 'linear']"
                },
                'randomizedsearchcv': {
                    'C': 'np.logspace(-1, 2, 20)',
                    'epsilon': 'np.logspace(-2, 0, 20)',
                    'kernel': "['rbf', 'linear']"
                },
                'optuna': {
                    'C': 'Float(0.1, 100, log=True)',
                    'epsilon': 'Float(0.01, 1.0, log=True)',
                    'kernel': "Categorical(['rbf','linear'])"
                },
                'bayessearchcv': {
                    'C': 'Real(0.1, 100, prior="log-uniform")',
                    'epsilon': 'Real(0.01, 1.0, prior="log-uniform")',
                    'kernel': 'Categorical(["rbf","linear"])'
                }
            }

            summary_records = []
            # Recorremos cada dupla (metodo, motor)
            for (model_type, sel_method, engine), payload in svr_entries.items():
                print(f"[DEBUG] 12.2. Agregando registro resumen: {sel_method} / {engine}")
                model = payload.get('model')
                score = payload.get('score')
                metric = payload.get('metric')

                # Parámetros usados para la búsqueda según motor
                config_used = param_configs.get(engine, {})

                # Hiperparámetros óptimos extraídos del modelo
                best_params = {param: getattr(model, param, None) for param in ['C', 'epsilon', 'kernel']}

                # Construir fila
                row = {
                    'Selección X': sel_method,
                    'Motor': engine,
                    'Métrica': metric,
                    'Score': score,
                }

                # Añadir configuración de búsqueda
                for k, v in config_used.items():
                    row[f'Grid_{k}'] = v
                # Añadir mejores hiperparámetros
                for k, v in best_params.items():
                    row[f'Best_{k}'] = v

                summary_records.append(row)

            # Crear DataFrame
            df_summary = pd.DataFrame(summary_records)
            print("[DEBUG] 12.3. df_summary.columns:", df_summary.columns.tolist())
            # Reordenar columnas para claridad
            desired_cols = [
                'Selección X', 'Motor', 'Métrica', 'Score',
                'Grid_C', 'Grid_epsilon', 'Grid_kernel',
                'Best_C', 'Best_epsilon', 'Best_kernel'
            ]
            available_cols = [c for c in desired_cols if c in df_summary.columns]
            if not available_cols:
                print("[WARNING] Ninguna de las columnas deseadas está presente en df_summary; mostrando todo el DataFrame.")
                df_to_show = df_summary
            else:
                df_to_show = df_summary[available_cols]

            # Añadir sección de tabla al informe
            self.sections.append((
                "### SVR Optimización: Resumen de Métodos y Motores",
                df_to_show.reset_index(drop=True)
            ))
            # ----------------------- 0. Análisis Generativo con OpenAI -------------------------------------------------
            # Preparar función de llamada a OpenAI
            def call_openai_explanation(prompt: str, model="gpt-4"):
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un experto en optimización de hiperparámetros de modelos de ML. "
                                "Proporciona análisis profundo, interpretaciones y recomendaciones." )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS
                    )
                    return response.choices[0].message.content.strip()
                except Exception as e:
                    return f"[Error llamando a OpenAI: {e}]"

            # Construir prompt con contexto y todos los registros
            records_text = []
            for rec in summary_records:
                part = (f"Método X: {rec['Selección X']}, Motor: {rec['Motor']}, Métrica: {rec['Métrica']}, Score: {rec['Score']:.4f}, "
                        f"Configuración de búsqueda: C={rec.get('Grid_C')}, epsilon={rec.get('Grid_epsilon')}, kernel={rec.get('Grid_kernel')}. "
                        f"Hiperparámetros óptimos: C={rec.get('Best_C')}, epsilon={rec.get('Best_epsilon')}, kernel={rec.get('Best_kernel')}.")
                records_text.append(part)
            prompt = (
                "He obtenido los siguientes resultados de optimización para SVR:\n" +
                "\n".join(records_text) +
                "\n\n" +
                "1. Explica el funcionamiento y la estrategia de búsqueda de cada motor (GridSearchCV, RandomizedSearchCV, Optuna, BayesSearchCV).\n" +
                "2. Analiza comparativamente los scores obtenidos por cada optimización y justifica cuál es la mejor configuración.\n" +
                "3. Ofrece recomendaciones de posibles mejoras cambiando parámetros de ajuste u otros factores para incrementar el desempeño."
            )
            print("[DEBUG] 12.4. Llamando a OpenAI para análisis generativo SVR optimización")
            generative_analysis = call_openai_explanation(prompt)
            self.sections.append((
                "### SVR Optimización: Análisis Generativo",
                generative_analysis
            ))
            # ---- Fin bloque 0 ----

            # --- 1. Curvas de Ajuste Real vs. Predicho y de Residuos ---
            print("[DEBUG] 12.5. Iniciando sección Calidad Ajuste SVR optimizado")
            # Seleccionar mejor registro por Score
            best_rec = max(summary_records, key=lambda x: x['Score'])
            sel_method, engine = best_rec['Selección X'], best_rec['Motor']

            # ——— 1.1 Normalizar payload ———
            payload_raw = OPT_MODELS[('svr', sel_method, engine)]
            p           = _normalize_payload(payload_raw)

            model, sx, sy, raw_cols = p['model'], p['sx'], p['sy'], p['cols']
            score, metric           = p['score'], p['metric']
            best_params             = p['best_params']
            # ——— Fin normalización ———

            # ——— 1.1.1 Sanitización y filtro unificado de columnas ———
            sanitized_cols = [sanitize_name(c) for c in raw_cols]
            missing = set(sanitized_cols) - set(X_test.columns)
            if missing:
                print(f"[WARNING] SVR omitido estas columnas por no existir en X_test: {sorted(missing)}")
            cols_valid = [c for c in sanitized_cols if c in X_test.columns]

            # Reemplaza cualquier X_test_sel previo por esta versión saneada
            X_test_sel = X_test[cols_valid].copy()
            # ——— Fin de sanitización ———

            # ——— 1.1.1 Saneamiento y filtro de columnas ———
            #import re
            #def clean_name(s):
            #    # idéntico a tu celda 9.x
            #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
            #    t = re.sub(r'_+', '_', t)
            #    return t.strip('_')

            # Limpio cada nombre y luego lo filtro
            #cols = [ clean_name(c) for c in raw_cols ]
            #cols_valid = [c for c in cols if c in X_test.columns]
            #missing = set(cols) - set(cols_valid)
            #if missing:
            #    print(f"[WARNING] SVR omitido estas columnas por no existir en X_test: {sorted(missing)}")

            # Ahora ya puedo indexar con total seguridad
            #X_test_sel = X_test[cols_valid].copy()
            y_true     = Y_test.values.ravel()
            X_test_scaled = sx.transform(X_test_sel)
            y_pred     = sy.inverse_transform(
                            model.predict(X_test_scaled).reshape(-1,1)
                        ).ravel()
            # ——— Fin saneamiento SVR ———

            # ——— 1.1 Normalizar payload
            #payload_raw        = OPT_MODELS[('svr', sel_method, engine)]
            #p                  = _normalize_payload(payload_raw)

            #model, sx, sy, cols = p['model'], p['sx'], p['sy'], p['cols']
            #score, metric      = p['score'], p['metric']
            #best_params        = p['best_params']
            # ——— Fin normalización

            # ——— Unificar saneamiento de columnas según entrenamiento ———
            #import re
            #def clean_name(s):
            #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
            #    t = re.sub(r'_+', '_', t)
            #    return t.strip('_')

            #cols = [ clean_name(c) for c in cols ]
            # ——— Fin unificación ———

            # Preparar datos de prueba
            #X_test_sel = X_test[cols].copy()
            #y_true = Y_test.values.ravel()
            #X_test_scaled = sx.transform(X_test_sel)
            #y_pred = sy.inverse_transform(model.predict(X_test_scaled).reshape(-1,1)).ravel()

            # Cálculo de residuos y estadísticas
            residuals = y_true - y_pred
            mean_res = float(np.mean(residuals))
            std_res = float(np.std(residuals))
            skew_res = float(skew(residuals))
            kurt_res = float(kurtosis(residuals))
            q25, q50, q75 = [float(x) for x in np.quantile(residuals, [0.25, 0.5, 0.75])]

            # Gráfica Predicho vs Real
            fig1, ax1 = plt.subplots(figsize=(6,4))
            ax1.scatter(y_true, y_pred, alpha=0.6)
            ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
            ax1.set_xlabel("Y real")
            ax1.set_ylabel("Y predicho")
            ax1.set_title(f"SVR Optimizado (Mejor: {sel_method}-{engine}) Predicho vs Real")
            self.sections.append((
                f"### SVR Optimizado: Predicho vs Real ({sel_method}-{engine})", fig1
            ))

            # Gráfica Residuos
            fig2, ax2 = plt.subplots(figsize=(6,4))
            ax2.scatter(y_pred, residuals, alpha=0.6)
            ax2.axhline(0, color='r', linestyle='--', lw=2)
            ax2.set_xlabel("Y predicho")
            ax2.set_ylabel("Residuo")
            ax2.set_title(f"SVR Optimizado (Mejor) Residuos ({sel_method}-{engine})")
            self.sections.append((
                f"### SVR Optimizado: Residuos ({sel_method}-{engine})", fig2
            ))

            # Tabla de estadísticas de residuos
            df_stats = pd.DataFrame({
                'Métrica': ['Media', 'Desviación', 'Skew', 'Kurtosis', '25%', '50%', '75%'],
                'Valor': [mean_res, std_res, skew_res, kurt_res, q25, q50, q75]
            })
            self.sections.append((
                f"### SVR Optimizado: Estadísticas de Residuos ({sel_method}-{engine})", df_stats
            ))

            # Análisis generativo de calidad de ajuste
            prompt2 = (
                f"Para el mejor modelo SVR optimizado con selección {sel_method} y motor {engine}, "
                f"tienes los siguientes datos:\n"
                f"- Rango Y real: [{float(y_true.min()):.4f}, {float(y_true.max()):.4f}]\n"
                f"- Rango Y pred: [{float(y_pred.min()):.4f}, {float(y_pred.max()):.4f}]\n"
                f"- Estadísticas residuos: media={mean_res:.4f}, std={std_res:.4f}, skew={skew_res:.4f}, kurtosis={kurt_res:.4f}, "
                f"quantiles 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}.\n\n"
                "1. Analiza la calidad del ajuste basándote en la gráfica Predicho vs Real y la de residuos.\n"
                "2. Comenta sobre sesgos sistemáticos, heterocedasticidad y normalidad de errores.\n"
                "3. Ofrece recomendaciones para mejorar el fit si hay problemas detectados."
            )
            analysis2 = call_openai_explanation(prompt2)
            self.sections.append((
                "### SVR Optimizado: Análisis Calidad Ajuste", analysis2
            ))
            # ---- Fin bloque 1 ----

            # --- 2. Importancia Relativa de Hiperparámetros ---
            import seaborn as sns
            # 2.1 Heatmap Score vs Best_C y Best_epsilon
            heat = df_summary.pivot(index='Best_C', columns='Best_epsilon', values='Score')
            fig_heat, ax_heat = plt.subplots(figsize=(6,5))
            sns.heatmap(heat, annot=True, fmt='.4f', ax=ax_heat)
            ax_heat.set_title('SVR Optimizado: Heatmap Score vs C y ε')
            self.sections.append((
                '### SVR Optimizado: Heatmap Score vs C y ε', fig_heat
            ))

            # 2.2 Sensibilidad ±10%
            sens = []
            for rec in summary_records:
                for param in ['C','epsilon']:
                    base = rec[f'Best_{param}']
                    if base is None: continue
                    for factor,label in [(1.1,'+10%'),(0.9,'-10%')]:
                        sens.append({
                            'Parámetro':param,
                            'Cambio':label,
                            '% Score':rec['Score']*(factor-1)*100,
                            'Selección X':rec['Selección X'],
                            'Motor':rec['Motor']
                        })
            df_sens = pd.DataFrame(sens)
            fig_sens, ax_sens = plt.subplots(figsize=(6,4))
            sns.barplot(data=df_sens, x='% Score', y='Parámetro', hue='Cambio', ax=ax_sens)
            ax_sens.set_title('SVR Opt: Sensibilidad Score ±10%')
            self.sections.append((
                '### SVR Optimizado: Sensibilidad del Score', fig_sens
            ))

            # 2.3 Análisis IA de Importancia
            def call_openai_explanation(prompt, model='gpt-4'):
                resp = _client.chat.completions.create(
                    model=model,
                    messages=[
                        {'role':'system','content':'Eres un experto en análisis de hiperparámetros de ML.'},
                        {'role':'user','content':prompt}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS
                )
                return resp.choices[0].message.content.strip()

            lines = [f"{r['Parámetro']} {r['Cambio']} => {r['% Score']:.2f}%" for r in sens]
            prompt_param = (
                "Sensibilidad de Score al ±10% en C y ε:\n" + "\n".join(lines) +
                "\n\nExplica qué hiperparámetro impulsa más mejora y por qué, y sugiere focos de tuning."    )
            print("[DEBUG] 12.6. Llamando IA importancia hiperparámetros")
            analysis_hp = call_openai_explanation(prompt_param)
            self.sections.append((
                '### SVR Optimizado: IA Importancia Hiperparámetros', analysis_hp
            ))
            # ---- Fin bloque 2 ----

            # --- 3. Distribución de Métricas en Validación Cruzada ---
            from sklearn.model_selection import cross_validate
            import seaborn as sns
            print("[DEBUG] 12.7. Calculando distribución de métricas CV para el mejor modelo optimizado")

            # 3. Identificar mejor modelo optimizado
            best_rec       = max(summary_records, key=lambda x: x['Score'])
            sel_method_cv, engine_cv = best_rec['Selección X'], best_rec['Motor']

            # --- Normalizar extracción de payload ---
            payload_raw_cv = OPT_MODELS[('svr', sel_method_cv, engine_cv)]
            p_cv           = _normalize_payload(payload_raw_cv)
            model_cv, sx_cv, sy_cv, cols_cv = (
                p_cv['model'], p_cv['sx'], p_cv['sy'], p_cv['cols']
            )
            # ----------------------------------------

            # Preparar datos de entrenamiento escalados
            X_cv = X_train[cols_cv].copy()
            y_cv = Y_train.values.ravel()
            X_cv_scaled = sx_cv.transform(X_cv)

            # Cross-validate con múltiples métricas
            cv_results = cross_validate(
                model_cv, X_cv_scaled, y_cv,
                cv=5,
                scoring={
                    'r2':'r2',
                    'neg_mse':'neg_mean_squared_error',
                    'neg_mae':'neg_mean_absolute_error'
                },
                return_train_score=False
            )

            # Procesar resultados
            r2_scores   = cv_results['test_r2']
            mse_scores  = [-v for v in cv_results['test_neg_mse']]
            mae_scores  = [-v for v in cv_results['test_neg_mae']]
            rmse_scores = np.sqrt(mse_scores)

            df_cv = pd.DataFrame({
                'R2': r2_scores,
                'MSE': mse_scores,
                'MAE': mae_scores,
                'RMSE': rmse_scores
            })

            # 3.1 Boxplot de métricas por fold
            fig_cv, ax_cv = plt.subplots(figsize=(6, 4))
            sns.boxplot(data=df_cv, ax=ax_cv)
            ax_cv.set_title('SVR Optimizado: Distribución de Métricas CV')
            self.sections.append((
                '### SVR Optimizado: Distribución de Métricas CV', fig_cv
            ))

            # 3.2 Tabla con media ± desviación
            stats_cv = df_cv.agg(['mean', 'std']).T.reset_index().rename(columns={
                'index':'Métrica', 'mean':'Media', 'std':'Desviación'
            })
            self.sections.append((
                '### SVR Optimizado: Estadísticas CV por Fold', stats_cv
            ))

            # 3.3 Análisis Generativo IA de estabilidad
            prompt_cv = (
                f"Valores CV por fold (R2: {r2_scores.tolist()}, MAE: {mae_scores}, RMSE: {rmse_scores}).\n"
                "¿Qué nos dice la dispersión sobre la estabilidad del modelo?"
            )
            print("[DEBUG] 12.8. Llamando IA para estabilidad en CV")
            analysis_cv = call_openai_explanation(prompt_cv)
            self.sections.append((
                '### SVR Optimizado: Análisis Estabilidad CV', analysis_cv
            ))
            # ---- Fin bloque 3 ----

            # --- 4. Sección Calidad Ajuste Mejor Modelo Optimizado SVR ---
            # --- 4.1. Curvas de Aprendizaje y Validación para SVR Optimizado ---
            from sklearn.model_selection import learning_curve, validation_curve
            print("[DEBUG] 12.9. Calculando curvas de aprendizaje y validación para SVR optimizado")

            # 4.1 Seleccionar el mejor payload para curvas de aprendizaje
            best_rec       = max(summary_records, key=lambda x: x['Score'])
            sel_method, engine = best_rec['Selección X'], best_rec['Motor']

            # --- Normalizamos la extracción del payload ---
            payload_raw    = OPT_MODELS[('svr', sel_method, engine)]
            p              = _normalize_payload(payload_raw)
            model, sx, sy, cols = p['model'], p['sx'], p['sy'], p['cols']
            # -----------------------------------------------

            # Preparar datos de entrenamiento
            X_train_sel = X_train[cols].copy()
            y_train = Y_train.values.ravel()
            X_train_scaled = sx.transform(X_train_sel)

            # Curva de aprendizaje (R²)
            train_sizes, train_scores, val_scores = learning_curve(
                model, X_train_scaled, y_train,
                cv=3, scoring='r2', train_sizes=np.linspace(0.1, 1.0, 5), n_jobs=-1
            )
            train_mean = np.mean(train_scores, axis=1)
            val_mean = np.mean(val_scores, axis=1)
            fig_lc, ax_lc = plt.subplots(figsize=(6, 4))
            ax_lc.plot(train_sizes, train_mean, 'o-', label='Train R²')
            ax_lc.plot(train_sizes, val_mean, 'o-', label='CV R²')
            ax_lc.set_title('Curva de Aprendizaje SVR Optimizado')
            ax_lc.set_xlabel('Tamaño del set de entrenamiento')
            ax_lc.set_ylabel('R²')
            ax_lc.legend()
            self.sections.append((
                '### SVR Optimizado: Curva de Aprendizaje', fig_lc
            ))

            # --- 4.2. Curva de validación para hiperparámetro C
            param_range_C = np.logspace(-1, 2, 5)
            train_scores_C, val_scores_C = validation_curve(
                model, X_train_scaled, y_train,
                param_name='C', param_range=param_range_C,
                cv=3, scoring='r2', n_jobs=-1
            )
            fig_vc_C, ax_vc_C = plt.subplots(figsize=(6, 4))
            ax_vc_C.plot(param_range_C, np.mean(train_scores_C, axis=1), 'o-', label='Train R²')
            ax_vc_C.plot(param_range_C, np.mean(val_scores_C, axis=1), 'o-', label='CV R²')
            ax_vc_C.set_xscale('log')
            ax_vc_C.set_title('Curva de Validación: C')
            ax_vc_C.set_xlabel('C')
            ax_vc_C.set_ylabel('R²')
            ax_vc_C.legend()
            self.sections.append((
                '### SVR Optimizado: Curva de Validación C', fig_vc_C
            ))

            # --- 4.3. Curva de validación para hiperparámetro epsilon
            param_range_e = np.logspace(-2, 0, 5)
            train_scores_e, val_scores_e = validation_curve(
                model, X_train_scaled, y_train,
                param_name='epsilon', param_range=param_range_e,
                cv=3, scoring='r2', n_jobs=-1
            )
            fig_vc_e, ax_vc_e = plt.subplots(figsize=(6, 4))
            ax_vc_e.plot(param_range_e, np.mean(train_scores_e, axis=1), 'o-', label='Train R²')
            ax_vc_e.plot(param_range_e, np.mean(val_scores_e, axis=1), 'o-', label='CV R²')
            ax_vc_e.set_xscale('log')
            ax_vc_e.set_title('Curva de Validación: Epsilon')
            ax_vc_e.set_xlabel('Epsilon')
            ax_vc_e.set_ylabel('R²')
            ax_vc_e.legend()
            self.sections.append((
                '### SVR Optimizado: Curva de Validación Epsilon', fig_vc_e
            ))

            # --- 4.4. Interpretación IA de las Curvas de Aprendizaje y Validación ---
            # Extraemos estadísticas para el prompt
            lc_train = train_mean.tolist()
            lc_val   = val_mean.tolist()
            vc_C_train = np.mean(train_scores_C, axis=1).tolist()
            vc_C_val   = np.mean(val_scores_C, axis=1).tolist()
            vc_e_train = np.mean(train_scores_e, axis=1).tolist()
            vc_e_val   = np.mean(val_scores_e, axis=1).tolist()
            sizes = train_sizes.tolist()
            C_vals = param_range_C.tolist()
            e_vals = param_range_e.tolist()

            prompt_curvas = (
                "He generado para el SVR optimizado las siguientes curvas:\n"
                f"- Curva de Aprendizaje (R²): tamaños={sizes}, train={lc_train}, CV={lc_val}\n"
                f"- Curva de Validación para C (R²): C={C_vals}, train={vc_C_train}, CV={vc_C_val}\n"
                f"- Curva de Validación para ε (R²): ε={e_vals}, train={vc_e_train}, CV={vc_e_val}\n\n"
                "1. Interpreta cada curva: ¿qué nos dice sobre sesgo (under-/overfitting) y varianza?\n"
                "2. Señala si hay señales de under-/overfitting o alta varianza según cada gráfica.\n"
                "3. Concluye recomendaciones generales para mejorar el aprendizaje (por ejemplo, ajustar C, ε, más datos, regularización, etc.)."
            )

            print("[DEBUG] 12.10. Llamando a OpenAI para interpretación IA de curvas")
            analisis_curvas = call_openai_explanation(prompt_curvas)
            self.sections.append((
                "### SVR Optimizado: Interpretación IA de Curvas",
                analisis_curvas
            ))
            # ---- Fin bloque 4 ----

            # --- 5. Curvas de Calibración y Predicción de Intervalos ---
            from sklearn.calibration import calibration_curve
            print("[DEBUG] 12.11. Calculando curva de calibración y predicción de intervalos para el mejor modelo optimizado SVR")

            # Identificar mejor modelo optimizado
            best_rec_ci       = max(summary_records, key=lambda x: x['Score'])
            sel_method_ci, engine_ci = best_rec_ci['Selección X'], best_rec_ci['Motor']

            # --- Normalizamos la extracción del payload ---
            payload_raw_ci   = OPT_MODELS[('svr', sel_method_ci, engine_ci)]
            p_ci             = _normalize_payload(payload_raw_ci)
            model_ci, sx_ci, sy_ci, cols_ci = p_ci['model'], p_ci['sx'], p_ci['sy'], p_ci['cols']
            # -----------------------------------------------

            # Preparar datos de prueba
            X_test_ci = X_test[cols_ci].copy()
            y_true_ci = Y_test.values.ravel()
            X_test_scaled_ci = sx_ci.transform(X_test_ci)

            # ── Predicción raw ──
            y_pred_raw_ci = model_ci.predict(X_test_scaled_ci)

            # ── Desescalado (si tienes sy_ci) ──
            if sy_ci is not None:
                # sy_ci es tu StandardScaler para y
                y_pred_ci = sy_ci.inverse_transform(
                    y_pred_raw_ci.reshape(-1,1)
                ).ravel()
            else:
                y_pred_ci = y_pred_raw_ci.ravel()

            # 5.1 Curva de calibración (binned reliability plot para regresión)
            import pandas as _pd
            bins = 10
            print("[DEBUG] 12.12. Calculando curva de calibración manual para regresión SVR optimizado")
            df_cal = _pd.DataFrame({'y_pred': y_pred_ci, 'y_true': y_true_ci})
            # Crear bins según cuantiles en predicción
            try:
                df_cal['bin'] = _pd.qcut(df_cal['y_pred'], q=bins, duplicates='drop')
            except Exception:
                df_cal['bin'] = _pd.cut(df_cal['y_pred'], bins=bins)
            # Agrupar para obtener promedio predicho vs observado
            #grp = df_cal.groupby('bin').agg({'y_pred': 'mean', 'y_true': 'mean'})
            grp = df_cal.groupby('bin', observed=True).agg({'y_pred': 'mean', 'y_true': 'mean'})
            prob_pred = grp['y_pred'].values
            prob_true = grp['y_true'].values
            fig_cal, ax_cal = plt.subplots(figsize=(6, 4))
            ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2)
            ax_cal.plot([prob_pred.min(), prob_pred.max()], [prob_pred.min(), prob_pred.max()], 'k--')
            ax_cal.set_xlabel('Predicción promedio en bin')
            ax_cal.set_ylabel('Valor real promedio')
            ax_cal.set_title('SVR Optimizado: Curva de Calibración')
            self.sections.append((
                '### SVR Optimizado: Curva de Calibración', fig_cal
            ))

            # 5.2 Intervalos de predicción ±1 STD de residuos
            residuals_ci = y_true_ci - y_pred_ci
            std_res_ci = np.std(residuals_ci)
            upper = y_pred_ci + std_res_ci
            lower = y_pred_ci - std_res_ci
            fig_int, ax_int = plt.subplots(figsize=(6, 4))
            ax_int.plot(y_true_ci, label='Y real')
            ax_int.plot(y_pred_ci, label='Predicción')
            ax_int.fill_between(range(len(y_pred_ci)), lower, upper, alpha=0.3, label='±1 STD residuo')
            ax_int.set_xlabel('Índice de muestra')
            ax_int.set_ylabel('Valor')
            ax_int.set_title('SVR Optimizado: Intervalos de Predicción')
            ax_int.legend()
            self.sections.append((
                '### SVR Optimizado: Intervalos de Predicción', fig_int
            ))

            # 5.3 Análisis Generativo IA de incertidumbre y calibración
            prompt_ci = (
                f"Curva de calibración (prob_pred: {prob_pred.tolist()}, prob_true: {prob_true.tolist()}) y "
                f"intervalos de predicción ±1 STD (std_res={std_res_ci:.4f}).\n"
                "1. ¿Son fiables los intervalos de incertidumbre?"
                "2. ¿Observas infravaloración de errores altos?"
            )
            print("[DEBUG] 12.13. Llamando IA para análisis de incertidumbre y calibración SVR")
            analysis_ci = call_openai_explanation(prompt_ci)
            self.sections.append((
                '### SVR Optimizado: Análisis de Incertidumbre y Calibración', analysis_ci
            ))
            # ---- Fin bloque 5 ----

            # --- Sección 6: Resumen Ejecutivo y Road-Map de Siguientes Pasos ---
            # 6.1. Bloque Markdown con puntos clave para stakeholders
            summary_md = (
                "**Puntos Clave:**\n"
                f"- **Mejor combinación:** {sel_method_ci}-{engine_ci} con score={best_rec_ci['Score']:.4f}.\n"
                f"- **Grado de robustez:** Variabilidad CV={val_mean.std():.4f}, residuos (std={std_res_ci:.4f}).\n"
                f"- **Puntos débiles:** identificar picos de error y alta varianza en ciertos rangos.\n"
                f"- **Recomendaciones inmediatas:** ampliar CV, explorar HalvingGridSearchCV, recolectar más datos."
            )
            self.sections.append((
                '### Resumen Ejecutivo y Road-Map', summary_md
            ))

            # 6.2. Análisis Generativo IA para desarrollar cada punto clave y generar resumen ejecutivo
            prompt_exec = (
                "Eres un investigador científico para el Instituto de Procesos Sostenibles de la Universidad de Valladolid. "
                "A continuación se presentan los puntos clave de la optimización SVR:\n"
                f"{summary_md}\n"
                "Desarrolla un análisis detallado en párrafos separados para cada punto (Mejor combinación, Grado de robustez, Puntos débiles, Recomendaciones inmediatas), "
                "y finaliza con un resumen ejecutivo de 3 párrafos resumiendo hallazgos y próximos pasos para los stakeholders."
            )
            print("[DEBUG] 12.14. Llamando IA para Resumen Ejecutivo y Road-Map SVR optimización")
            analysis_exec = call_openai_explanation(prompt_exec)
            self.sections.append((
                '### Resumen Ejecutivo IA', analysis_exec
            ))

        except Exception as e:
            self.sections.append((
                "### ⚠️ Error en sección Optimización SVR",
                f"Se produjo un error al generar el resumen de métodos y motores: {e}"
            ))

        # =============================================================================
        # 13. Optimización Modelo Optimización NN
        # =============================================================================
        try:
            print("[DEBUG] 13.1. Iniciando sección Optimización NN: Resumen de métodos y motores")
            # Verificación previa: usamos OPT_MODELS guardado en la celda 9.2
            if 'OPT_MODELS' in globals() and isinstance(OPT_MODELS, dict):
                valid_engines = {'randomsearch', 'bayesianoptimization', 'hyperband', 'optuna'}
                nn_entries = {
                    k: v for k, v in OPT_MODELS.items()
                    if (isinstance(k, tuple) and k[0] == 'nn' and isinstance(v, dict) and k[2] in valid_engines)
                }
            else:
                raise RuntimeError(
                    "No se encontró la variable global OPT_MODELS con resultados de optimización NN. "
                    "Asegúrate de haber ejecutado la Celda 9.2 y de que OPT_MODELS contenga los payloads optimizados."
                )

            import pickle
            import pandas as pd
            import numpy as np
            import matplotlib.pyplot as plt
            import seaborn as sns
            from scipy.stats import skew, kurtosis
            from tensorflow.keras.models import load_model
            import tensorflow as tf
            from tensorflow import keras
            from tensorflow.keras import layers as keras_layers
            from scikeras.wrappers import KerasRegressor
            from sklearn.model_selection import learning_curve

            #import re

            #def _clean_col(name):
            #    # sustituye [, ], <, >, % por _
            #    return re.sub(r'[\[\]<>%]', '_', str(name))

            # ——— 1.1.1 Sanitización y filtro unificado de columnas ———
            #sanitized_cols = [sanitize_name(c) for c in raw_cols]
            #missing = set(sanitized_cols) - set(X_test.columns)
            #if missing:
            #    print(f"[WARNING] SVR omitido estas columnas por no existir en X_test: {sorted(missing)}")
            #cols_valid = [c for c in sanitized_cols if c in X_test.columns]

            #X_test_sel = X_test[cols_valid].copy()

            # Parámetros de búsqueda usados en cada motor (para documentar)
            param_configs = {
                'randomsearch': { 'layers': 'hp.Int("layers", 1, max_layers)', 'units': 'hp.Int("units_i", min_units, max_units)', 'dropout': 'hp.Float("dropout_i", 0.0, max_dropout)' },
                'bayesianoptimization': { 'layers': 'hp.Int("layers", 1, max_layers)', 'units': 'hp.Int("units_i", min_units, max_units)', 'dropout': 'hp.Float("dropout_i", 0.0, max_dropout)' },
                'hyperband': { 'layers': 'hp.Int("layers", 1, max_layers)', 'units': 'hp.Int("units_i", min_units, max_units)', 'dropout': 'hp.Float("dropout_i", 0.0, max_dropout)' },
                'optuna': { 'layers': 'suggest_int("n_layers", 1, max_layers)', 'units': 'suggest_int("n_units_l{i}", min_units, max_units)', 'dropout': 'suggest_float("dropout_l{i}", 0.0, max_dropout)' }
            }

            summary_records = []
            # Iterar cada combinación método/motor
            for (_, sel_method, engine), payload in nn_entries.items():
                print(f"[DEBUG] 13.2. Agregando registro resumen NN: {sel_method} / {engine}")

                # 1) métricas
                score = payload.get('score')
                metric = payload.get('metric')

                # Parámetros de búsqueda documentados
                config_used = param_configs.get(engine, {})

                # 3) hiperparámetros óptimos
                if engine in ("randomsearch","bayesianoptimization","hyperband"):
                    best_params = {
                        "layers":  payload.get("layers"),
                        "neurons": payload.get("neurons"),
                        "dropout": payload.get("dropout"),
                        "epochs":  payload.get("epochs")
                    }
                else:  # optuna
                    best_params = {
                        "layers":  payload.get("n_layers"),
                        "neurons": payload.get("n_units_l0"),
                        "dropout": payload.get("dropout_l0"),
                        "epochs":  payload.get("epochs")
                    }

                # Construir fila de resumen
                row = {
                    'Selección X': sel_method,
                    'Motor': engine,
                    'Métrica': metric,
                    'Score': score
                }
                # Añadir configuración de búsqueda al row
                for k, v in config_used.items():
                    row[f'Config_{k}'] = v
                # Añadir mejores hiperparámetros al row
                for k, v in best_params.items():
                    row[f'Best_{k}'] = v

                summary_records.append(row)

            # Crear DataFrame de resumen y reordenar columnas
            df_summary_nn = pd.DataFrame(summary_records)
            desired_cols = [
                'Selección X', 'Motor', 'Métrica', 'Score',
                'Config_layers', 'Config_units', 'Config_dropout',
                'Best_layers', 'Best_neurons', 'Best_dropout', 'Best_epochs'
            ]
            available_cols = [c for c in desired_cols if c in df_summary_nn.columns]
            df_to_show_nn = df_summary_nn[available_cols] if available_cols else df_summary_nn

            # Añadir sección de tabla al informe
            self.sections.append((
                "### NN Optimización: Resumen de Métodos y Motores",
                df_to_show_nn.reset_index(drop=True)
            ))

            # ————— Preselección global del mejor modelo NN —————
            if df_summary_nn['Métrica'].iloc[0] == 'R2':
                idx_best_nn = df_summary_nn['Score'].idxmax()
            else:
                idx_best_nn = df_summary_nn['Score'].idxmin()

            best_entry_nn = df_summary_nn.loc[idx_best_nn]
            sel_method_nn = best_entry_nn['Selección X']
            engine_nn     = best_entry_nn['Motor']

            payload_raw = OPT_MODELS[('nn', sel_method, engine)]
            p = _normalize_payload(payload_raw)
            model        = p['model']
            sx, sy, cols = p['sx'], p['sy'], p['cols']
            score, metric, best_params = p['score'], p['metric'], p['best_params']

            # Precargo payload_best para usar en todos los bloques
            payload_best = p    # ya tienes el payload “normalizado” en p, no necesitas nn_entries aquí

            # --- 0. Análisis Generativo IA de Tabla de Resumen ---
            def call_openai_explanation(prompt: str, model="gpt-4"):
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un experto en optimización de redes neuronales. "
                                "Analiza los resultados y ofrece conclusiones detalladas." )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS
                    )
                    return response.choices[0].message.content.strip()
                except Exception as e:
                    print(f"[DEBUG] ¡Exception atrapada en Optimización NN!: {type(e).__name__}: {e}")
                    return f"[Error llamando a OpenAI: {e}]"

            # Construir prompt a partir de summary_records
            records_text = []
            for rec in summary_records:
                records_text.append(
                    f"Método X: {rec['Selección X']}, Motor: {rec['Motor']}, "
                    f"Métrica: {rec['Métrica']}, Score: {rec['Score']:.4f}, "
                    f"Config: layers={rec.get('Config_layers')}, units={rec.get('Config_units')}, dropout={rec.get('Config_dropout')}, "
                    f"Best: layers={rec.get('Best_layers')}, neurons={rec.get('Best_neurons')}, "
                    f"dropout={rec.get('Best_dropout')}, epochs={rec.get('Best_epochs')}"
                )
            prompt = (
                "He obtenido los siguientes resultados de optimización para la Red Neuronal:\n"
                + "\n".join(records_text)
                + "\n\n"
                + "1. Describe e interpreta cada combinación método/motor.\n"
                + "2. Señala cuál configuración ofrece mejor desempeño y por qué.\n"
                + "3. Proporciona recomendaciones para futuros ajustes de HPO."
            )
            print("[DEBUG] 13.3. Llamando IA para análisis generativo NN optimización")
            generative_analysis_nn = call_openai_explanation(prompt)
            self.sections.append((
                "### NN Optimización: Análisis Generativo",
                generative_analysis_nn
            ))
            # --- Fin Bloque 0 ---

            # --- 1. Curvas de Ajuste Real vs. Predicho y Residuos ---
            print("[DEBUG] 13.4. Entrando en Bloque 1: Curvas Predicho vs Real")
            from scipy.stats import skew, kurtosis
            # Seleccionar mejor configuración según Score
            if df_summary_nn.empty:
                raise RuntimeError("No hay registros de optimización NN para generar curvas.")
            # Definir criterio de ordenamiento: maximizar R2, minimizar errores
            if df_summary_nn['Métrica'].iloc[0] == 'R2':
                idx_best = df_summary_nn['Score'].idxmax()
            else:
                idx_best = df_summary_nn['Score'].idxmin()
            best_row = df_summary_nn.loc[idx_best]
            sel_method = best_row['Selección X']
            engine = best_row['Motor']

            # ——— 1.1 Normalizar payload
            payload_raw   = OPT_MODELS[('nn', sel_method, engine)]
            p             = _normalize_payload(payload_raw)

            model         = p['model']
            sx, sy, cols  = p['sx'], p['sy'], p['cols']
            score, metric = p['score'], p['metric']
            best_params   = p['best_params']

            import tensorflow as tf  # necesario para custom_objects al cargar el modelo
            from tensorflow.keras.models import load_model

            # ——— Sanitización unificada de columnas para NN ———
            # 1) Partimos de `cols` (payload['cols'])
            raw_cols_nn = cols  # o p['cols'] si lo extraes ahí mismo

            # 2) Aplicamos `sanitize_name` a cada nombre
            sanitized_cols = [sanitize_name(c) for c in raw_cols_nn]

            # 3) Detectamos columnas faltantes en X_test
            missing = set(sanitized_cols) - set(X_test.columns)
            if missing:
                print(f"[WARNING] NN omitido estas columnas por no existir en X_test: {sorted(missing)}")

            # 4) Nos quedamos solo con las columnas válidas
            cols_valid = [c for c in sanitized_cols if c in X_test.columns]

            # 5) Selección segura de test y predicción
            X_test_sel    = X_test[cols_valid].copy()

            # Preparar datos de prueba
            # — SANITIZACIÓN DE cols antes de indexar X_test
            #cols_clean = [_clean_col(c) for c in cols]
            #X_test_sel = X_test[cols_clean].copy()
            #X_test_sel = X_test[cols].copy()
            y_true = Y_test.values.ravel()
            if sx is not None:
                X_test_scaled = sx.transform(X_test_sel)
            else:
                # No se encontró scaler, usar datos sin transformar
                X_test_scaled = X_test_sel.values
                raw_pred = model.predict(X_test_scaled).ravel()
            if sy is not None:
                # Aplicar inverse transform si existe scaler de salida
                y_pred = sy.inverse_transform(raw_pred.reshape(-1,1)).ravel()
            else:
                y_pred = raw_pred

            # Gráfica Predicho vs Real
            fig1, ax1 = plt.subplots(figsize=(6,4))
            ax1.scatter(y_true, y_pred, alpha=0.6)
            ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
            ax1.set_xlabel("Y real"); ax1.set_ylabel("Y predicho")
            ax1.set_title(f"NN Optimizado ({sel_method}-{engine}) Predicho vs Real")
            self.sections.append((
                f"### NN Optimización: Predicho vs Real ({sel_method}-{engine})", fig1
            ))

            # Gráfica Residuos
            residuals = y_true - y_pred
            fig2, ax2 = plt.subplots(figsize=(6,4))
            ax2.scatter(y_pred, residuals, alpha=0.6)
            ax2.axhline(0, color='r', linestyle='--', lw=2)
            ax2.set_xlabel("Y predicho"); ax2.set_ylabel("Residuo")
            ax2.set_title(f"NN Optimizado ({sel_method}-{engine}) Residuos")
            self.sections.append((
                f"### NN Optimización: Residuos ({sel_method}-{engine})", fig2
            ))

            # Tabla de estadísticas de residuos
            stats_df = pd.DataFrame({
                'Métrica': ['Media', 'Desviación', 'Skew', 'Kurtosis', '25%', '50%', '75%'],
                'Valor': [residuals.mean(), residuals.std(), skew(residuals), kurtosis(residuals), *np.quantile(residuals, [0.25,0.5,0.75])]
            })
            self.sections.append((
                f"### NN Optimización: Estadísticas de Residuos ({sel_method}-{engine})", stats_df
            ))

            # --- Análisis Generativo IA de Curvas de Ajuste (NN) ---
            # Construimos un único f-string multilínea para asegurar que todo el texto llegue al modelo
            prompt_curvas = f"""
            Para el mejor modelo NN optimizado con selección {sel_method} y motor {engine} tenemos los siguientes datos:
            - Rango Y real: [{float(y_true.min()):.4f}, {float(y_true.max()):.4f}]
            - Rango Y predicho: [{float(y_pred.min()):.4f}, {float(y_pred.max()):.4f}]
            - Estadísticas de residuos:
              • media = {residuals.mean():.4f}
              • std   = {residuals.std():.4f}
              • skew  = {skew(residuals):.4f}
              • kurtosis = {kurtosis(residuals):.4f}
              • quantiles: 25%={float(np.quantile(residuals, 0.25)):.4f},
                          50%={float(np.quantile(residuals, 0.50)):.4f},
                          75%={float(np.quantile(residuals, 0.75)):.4f}

            1. Analiza detalladamente la gráfica Predicho vs Real: di si hay desviaciones sistemáticas, cuán cerca están los puntos de la diagonal, y si observas heterocedasticidad o patrones claros.
            2. Analiza la gráfica de residuos: describe la dispersión, si hay colas pesadas o asimetrías.
            3. Comenta sobre la normalidad de los errores y posibles fuentes de sesgo.
            4. Propón recomendaciones prácticas para mejorar el ajuste (p. ej. refinar hiperparámetros, transformar variables, etc.).
            """
            analysis_curvas = call_openai_explanation(prompt_curvas)
            self.sections.append((
                "### NN Optimización: Análisis Curvas Ajuste", analysis_curvas
            ))
            # --- Fin bloque 1 ---

            # --- 2. Importancia Relativa de Hiperparámetros ---
            # 2.1 Heatmap Score vs Best_layers y Best_neurons
            heat_nn = df_summary_nn.pivot(index='Best_layers', columns='Best_neurons', values='Score')
            fig_heat_nn, ax_heat_nn = plt.subplots(figsize=(6,5))
            sns.heatmap(heat_nn, annot=True, fmt='.4f', ax=ax_heat_nn)
            ax_heat_nn.set_title('NN Optimizado: Heatmap Score vs Capas y Neuronas')
            self.sections.append((
                '### NN Optimizado: Heatmap Score vs Capas y Neuronas', fig_heat_nn
            ))

            # 2.2 Sensibilidad ±10%
            sens_nn = []
            for rec in summary_records:
                for param in ['layers','neurons']:
                    base = rec.get(f'Best_{param}')
                    if base is None: continue
                    for factor,label in [(1.1,'+10%'),(0.9,'-10%')]:
                        sens_nn.append({
                            'Parámetro': param,
                            'Cambio': label,
                            '% Score': rec['Score'] * (factor - 1) * 100,
                            'Selección X': rec['Selección X'],
                            'Motor': rec['Motor']
                        })
            df_sens_nn = pd.DataFrame(sens_nn)
            fig_sens_nn, ax_sens_nn = plt.subplots(figsize=(6,4))
            sns.barplot(data=df_sens_nn, x='% Score', y='Parámetro', hue='Cambio', ax=ax_sens_nn)
            ax_sens_nn.set_title('NN Opt: Sensibilidad Score ±10%')
            self.sections.append((
                '### NN Optimizado: Sensibilidad del Score', fig_sens_nn
            ))

            # 2.3 Análisis IA de Importancia Relativa
            lines_nn = [f"{r['Parámetro']} {r['Cambio']} => {r['% Score']:.2f}%" for r in sens_nn]
            prompt_hp_nn = (
                "Sensibilidad de Score al ±10% en Capas y Neuronas:\n" +
                "\n".join(lines_nn) +
                "\n\nExplica qué hiperparámetro impulsa más mejora y por qué, y sugiere focos de tuning futuros para la red neuronal."
            )
            print("[DEBUG] 13.5. Llamando IA importancia hiperparámetros NN")
            analysis_hp_nn = call_openai_explanation(prompt_hp_nn)
            self.sections.append((
                '### NN Optimizado: IA Importancia Hiperparámetros', analysis_hp_nn
            ))
            # --- Fin bloque 2 ---

            # --- 3. Distribución de Métricas en Validación Cruzada (manual para Keras NN) ---
            print("[DEBUG] 13.6. Calculando distribución de métricas CV para el mejor modelo NN optimizado (manual)")

            from sklearn.model_selection import KFold

            # Identificar mejor configuración NN
            if df_summary_nn['Métrica'].iloc[0] == 'R2':
                idx_best = df_summary_nn['Score'].idxmax()
            else:
                idx_best = df_summary_nn['Score'].idxmin()
            row_best = df_summary_nn.loc[idx_best]
            sel_method_cv, engine_cv = row_best['Selección X'], row_best['Motor']

            # ——— 1.1 Normalizar payload
            payload_raw = OPT_MODELS[('nn', sel_method, engine)]
            p           = _normalize_payload(payload_raw)

            model        = p['model']
            sx, sy, cols = p['sx'], p['sy'], p['cols']
            score        = p['score']
            metric       = p['metric']
            best_params  = p['best_params']

            # Cargar metadatos y mejor modelo
            payload_cv  = nn_entries[('nn', sel_method_cv, engine_cv)]
            best_params = {
                'layers':  payload_cv.get('layers')   or payload_cv.get('n_layers'),
                'neurons': payload_cv.get('neurons')  or payload_cv.get('n_units_l0'),
                'dropout': payload_cv.get('dropout')  or payload_cv.get('dropout_l0'),
                'epochs':  payload_cv.get('epochs')
            }

            # Preparar datos
            sx_cv, sy_cv, cols_cv = (
                payload_cv.get('sx'),
                payload_cv.get('sy'),
                payload_cv.get('cols'),
            )

            # ——— Sanitización y filtro unificado de columnas para CV en NN ———
            # 1) Partimos de cols_cv (del payload normalizado)
            raw_cols_cv = cols_cv

            # 2) Aplicamos sanitize_name a cada nombre
            sanitized_cols_cv = [sanitize_name(c) for c in raw_cols_cv]

            # 3) Detectamos columnas faltantes en X_train
            missing_cv = set(sanitized_cols_cv) - set(X_train.columns)
            if missing_cv:
                print(f"[WARNING] NN omitido estas columnas en CV por no existir en X_train: {sorted(missing_cv)}")

            # 4) Nos quedamos solo con las que sí existen
            cols_cv_valid = [c for c in sanitized_cols_cv if c in X_train.columns]

            # 5) Ahora indexamos sin NameError
            X_cv = X_train[cols_cv_valid].copy()
            y_cv = Y_train.values.ravel()
            X_cv_scaled = sx_cv.transform(X_cv.values) if sx_cv is not None else X_cv.values


            # — SANITIZACIÓN DE cols_cv antes de indexar X_train
            #cols_cv_clean = [_clean_col(c) for c in cols_cv]
            #X_cv = X_train[cols_cv_clean].copy()
            #X_cv = X_train[cols_cv].copy()
            #y_cv = Y_train.values.ravel()
            #X_cv_scaled = sx_cv.transform(X_cv) if sx_cv is not None else X_cv.values

            # Manual K-Fold CV
            kf = KFold(n_splits=5, shuffle=True, random_state=42)
            r2_scores, mse_scores, mae_scores = [], [], []
            for train_idx, val_idx in kf.split(X_cv_scaled):
                X_tr, X_val = X_cv_scaled[train_idx], X_cv_scaled[val_idx]
                y_tr, y_val = y_cv[train_idx], y_cv[val_idx]
                # Reconstruir modelo con mejores hiperparámetros
                model_cv_fold = keras.Sequential()
                model_cv_fold.add(layers.Input(shape=(X_tr.shape[1],)))
                for _ in range(int(best_params['layers'])):
                    model_cv_fold.add(layers.Dense(int(best_params['neurons']), activation='relu'))
                    model_cv_fold.add(layers.Dropout(float(best_params['dropout'])))
                model_cv_fold.add(layers.Dense(1))
                model_cv_fold.compile(optimizer='adam', loss='mse')
                model_cv_fold.fit(X_tr, y_tr, epochs=int(best_params['epochs']), verbose=0)
                preds = model_cv_fold.predict(X_val).ravel()
                r2_scores.append(r2_score(y_val, preds))
                mse_scores.append(mean_squared_error(y_val, preds))
                mae_scores.append(mean_absolute_error(y_val, preds))
            rmse_scores = [np.sqrt(m) for m in mse_scores]

            # DataFrame de resultados CV
            import pandas as pd
            cv_df_nn = pd.DataFrame({'R2': r2_scores, 'MSE': mse_scores, 'MAE': mae_scores, 'RMSE': rmse_scores})

            # 3.1 Boxplot métricas por fold
            fig_cv_nn, ax_cv_nn = plt.subplots(figsize=(6,4))
            sns.boxplot(data=cv_df_nn, ax=ax_cv_nn)
            ax_cv_nn.set_title('NN Optimizado: Distribución de Métricas CV')
            self.sections.append((
                '### NN Optimizado: Distribución de Métricas CV', fig_cv_nn
            ))
            # 3.2 Tabla media ± desviación
            stats_cv_nn = cv_df_nn.agg(['mean','std']).T.reset_index().rename(columns={'index':'Métrica','mean':'Media','std':'Desviación'})
            self.sections.append((
                '### NN Optimizado: Estadísticas CV por Fold', stats_cv_nn
            ))
            # 3.3 Análisis IA de estabilidad
            import numpy as np
            # Generar prompt con máximo contexto
            hyperparams = best_params
            # Estadísticas agregadas para IA
            data_summary = (
                f"- R2: media={cv_df_nn['R2'].mean():.4f}, std={cv_df_nn['R2'].std():.4f}\n"
                f"- MSE: media={cv_df_nn['MSE'].mean():.4f}, std={cv_df_nn['MSE'].std():.4f}\n"
                f"- MAE: media={cv_df_nn['MAE'].mean():.4f}, std={cv_df_nn['MAE'].std():.4f}\n"
                f"- RMSE: media={cv_df_nn['RMSE'].mean():.4f}, std={cv_df_nn['RMSE'].std():.4f}"
            )
            prompt_cv_nn = (
                f"Para la red neuronal optimizada con método '{sel_method_cv}' y motor '{engine_cv}', "
                f"se realizó una validación cruzada de 5 folds obteniendo los siguientes scores por fold:\n"
                f"- R2: {r2_scores}\n"
                f"- MSE: {mse_scores}\n"
                f"- MAE: {mae_scores}\n"
                f"- RMSE: {rmse_scores}\n\n"
                f"Resumen estadístico por métrica:\n{data_summary}\n\n"
                "Los hiperparámetros óptimos usados fueron:\n"
                f"- Capas: {hyperparams['layers']}\n"
                f"- Neuronas: {hyperparams['neurons']}\n"
                f"- Dropout: {hyperparams['dropout']}\n"
                f"- Épocas: {hyperparams['epochs']}\n\n"
                "1. Analiza detalladamente la dispersión de cada métrica por fold y comenta sobre la robustez del modelo.\n"
                "2. Identifica posibles fuentes de variabilidad y su impacto en la generalización.\n"
                "3. Sugiere acciones concretas para mejorar la estabilidad del modelo "
                "(p.ej., regularización adicional, recopilación de más datos, ajustes de HPO, etc.)."
            )
            print("[DEBUG] 13.7. Llamando IA para estabilidad en CV NN (manual)")

            analysis_cv_nn = call_openai_explanation(prompt_cv_nn)
            self.sections.append((
                '### NN Optimizado: Análisis Estabilidad CV', analysis_cv_nn
            ))
            # --- Fin bloque 3 ---

            # --- 4. Curvas de Aprendizaje y Validación para NN Optimizado ---
            print("[DEBUG] 13.8. Bloque 4: Curvas de Aprendizaje para NN optimizado sin wrapper SKLearn")

            import pickle, numpy as np
            from sklearn.model_selection import KFold

            # --- normalizo payload para extraer modelo y scalers ---
            payload_raw = OPT_MODELS[('nn', sel_method_nn, engine_nn)]
            p           = _normalize_payload(payload_raw)

            model_best  = p['model']
            sx          = p['sx']
            sy          = p['sy']
            cols        = p['cols']

            # 1) Limpia nombres de columnas
            sanitized_cols = [sanitize_name(c) for c in cols]

            # 2) Filtra solo las que existen en X_train
            effective_cols = [c for c in sanitized_cols if c in X_train.columns]
            missing = set(sanitized_cols) - set(effective_cols)
            if missing:
                print(f"[WARNING] NN omitido estas columnas en entrenamiento: {sorted(missing)}")

            # 3) Construye la matriz de entrenamiento
            X_tr = X_train[effective_cols].values

            #cols_clean = [_clean_col(c) for c in cols]
            #X_tr = X_train[cols_clean].values
            #X_tr = X_train[cols].values
            y_tr = Y_train.values.ravel()
            X_tr_scaled = sx.transform(X_tr) if sx is not None else X_tr
            # ——— EXTRAER HIPERPARÁMETROS NORMALIZADOS ———
            # payload_raw ya lo habrás definido así:
            # payload_raw = OPT_MODELS[('nn', sel_method_nn, engine_nn)]
            p = _normalize_payload(payload_raw)
            best = p['best_params']
            layers_opt  = int(best.get('layers',         1))   # por defecto 1 capa si no está
            neurons_opt = int(best.get('units',         32))   # por defecto 32 neuronas
            dropout_opt = float(best.get('dropout_rate', 0.0)) # por defecto 0.0 de dropout
            #epochs_opt  = int(best.get('epochs',        10))   # por defecto 10 épocas
            epochs_opt = min(int(best.get('epochs', 10)), 5)  # máx 5 para acelerar ⚠️ Justificación: Al ser solo para validación de curvas, no necesitamos convergencia perfecta.

            # Determinar mejor índice según métrica
            # En lugar de mirar en df_nn, usas directamente:
            if best_entry_nn['Métrica'].upper() == 'R2':
                best_idx = idx_best_nn  # ya lo tienes
            else:
                best_idx = idx_best_nn

            # Y cuando necesites la ruta:
            # Normaliza el payload para extraer todo en variables claras
            payload_raw = OPT_MODELS[('nn', sel_method_nn, engine_nn)]
            p           = _normalize_payload(payload_raw)

            model_best  = p['model']
            sx          = p['sx']
            sy          = p['sy']
            cols        = p['cols']

            # 4.1 Curva de Aprendizaje manual
            #train_fracs = np.linspace(0.1,1.0,5)
            train_fracs = np.linspace(0.1, 1.0, 3)  # [0.1, 0.55, 1.0]  ⚠️ Justificación: Permite evaluar comportamiento inicial, medio y completo con solo 3 puntos.
            train_scores, cv_scores = [], []
            #kf = KFold(n_splits=3, shuffle=True, random_state=42)
            kf = KFold(n_splits=2, shuffle=True, random_state=42)     # ⚠️ Justificación: 2-fold ya permite evaluar generalización y reduce el número de ciclos casi a la mitad.
            for frac in train_fracs:
                n = int(len(X_tr_scaled)*frac)
                X_sub, y_sub = X_tr_scaled[:n], y_tr[:n]
                s_tr, s_val = [], []
                for tr_idx, val_idx in kf.split(X_sub):
                    Xt, Xv = X_sub[tr_idx], X_sub[val_idx]
                    yt, yv = y_sub[tr_idx], y_sub[val_idx]
                    # Reentrenar modelo con los mismos HPO optimizados
                    m = keras.Sequential()
                    m.add(keras.Input(shape=(X_tr_scaled.shape[1],)))
                    for _ in range(layers_opt):
                        m.add(keras_layers.Dense(neurons_opt, activation='relu'))
                        m.add(keras_layers.Dropout(dropout_opt))
                    m.add(keras_layers.Dense(1))
                    m.compile(optimizer='adam', loss='mse')
                    m.fit(Xt, yt, epochs=epochs_opt, batch_size=32, verbose=0)
                    s_tr.append(r2_score(yt, m.predict(Xt).ravel()))
                    s_val.append(r2_score(yv, m.predict(Xv).ravel()))
                train_scores.append(np.mean(s_tr))
                cv_scores.append(np.mean(s_val))
            fig_lc, ax_lc = plt.subplots(figsize=(6,4))
            ax_lc.plot(train_fracs*len(X_tr_scaled), train_scores, 'o-', label='Train R²')
            ax_lc.plot(train_fracs*len(X_tr_scaled), cv_scores,    'o-', label='CV R²')
            ax_lc.set_title('NN Optimizado: Curva de Aprendizaje')
            ax_lc.set_xlabel('Número de muestras de entrenamiento')
            ax_lc.set_ylabel('R²')
            ax_lc.legend()
            self.sections.append((
                '### NN Optimizado: Curva de Aprendizaje', fig_lc
            ))

            # 4.2 Curva de validación para Layers
            #param_L = list(range(1, min(6, X_tr_scaled.shape[1]+1)))
            param_L = list(range(1, 4))  # solo 1 a 3 capas ⚠️ Justificación: Reduce significativamente las combinaciones sin comprometer la visualización de tendencias.
            scores_tr_L, scores_cv_L = [], []
            for L in param_L:
                st, sv = [], []
                for ti, vi in kf.split(X_tr_scaled):
                    Xt, Xv = X_tr_scaled[ti], X_tr_scaled[vi]
                    yt, yv = y_tr[ti], y_tr[vi]
                    m = keras.Sequential()
                    m.add(keras.Input(shape=(X_tr_scaled.shape[1],)))
                    for _ in range(L):
                        m.add(keras_layers.Dense(neurons_opt, activation='relu'))
                        m.add(keras_layers.Dropout(dropout_opt))
                    m.add(keras_layers.Dense(1))
                    m.compile(optimizer='adam', loss='mse')
                    m.fit(Xt, yt, epochs=epochs_opt, batch_size=32, verbose=0)
                    st.append(r2_score(yt, m.predict(Xt).ravel()))
                    sv.append(r2_score(yv, m.predict(Xv).ravel()))
                scores_tr_L.append(np.mean(st))
                scores_cv_L.append(np.mean(sv))
            fig_vL, ax_vL = plt.subplots(figsize=(6,4))
            ax_vL.plot(param_L, scores_tr_L, 'o-', label='Train R²')
            ax_vL.plot(param_L, scores_cv_L,'o-', label='CV R²')
            ax_vL.set_title('NN Opt: Curva Validación Layers')
            ax_vL.set_xlabel('Layers')
            ax_vL.set_ylabel('R²')
            ax_vL.legend()
            self.sections.append((
                '### NN Optimizado: Curva Validación Layers', fig_vL
            ))

            # 4.3 Curva de validación para Neurons
            #param_N = list(np.linspace(10, X_tr_scaled.shape[1]*50, 5, dtype=int))
            param_N = list(np.linspace(10, X_tr_scaled.shape[1]*20, 3, dtype=int))  # solo 3 valores de neuronas  ⚠️ Justificación: Reduce significativamente las combinaciones sin comprometer la visualización de tendencias.
            scores_tr_N, scores_cv_N = [], []
            for N in param_N:
                st, sv = [], []
                for ti, vi in kf.split(X_tr_scaled):
                    Xt, Xv = X_tr_scaled[ti], X_tr_scaled[vi]
                    yt, yv = y_tr[ti], y_tr[vi]
                    m = keras.Sequential()
                    m.add(keras.Input(shape=(X_tr_scaled.shape[1],)))
                    for _ in range(layers_opt):
                        m.add(keras_layers.Dense(N, activation='relu'))
                        m.add(keras_layers.Dropout(dropout_opt))
                    m.add(keras_layers.Dense(1))
                    m.compile(optimizer='adam', loss='mse')
                    m.fit(Xt, yt, epochs=epochs_opt, batch_size=32, verbose=0)
                    st.append(r2_score(yt, m.predict(Xt).ravel()))
                    sv.append(r2_score(yv, m.predict(Xv).ravel()))
                scores_tr_N.append(np.mean(st))
                scores_cv_N.append(np.mean(sv))
            fig_vN, ax_vN = plt.subplots(figsize=(6,4))
            ax_vN.plot(param_N, scores_tr_N, 'o-', label='Train R²')
            ax_vN.plot(param_N, scores_cv_N,'o-', label='CV R²')
            ax_vN.set_title('NN Opt: Curva Validación Neurons')
            ax_vN.set_xlabel('Neurons')
            ax_vN.set_ylabel('R²')
            ax_vN.legend()
            self.sections.append((
                '### NN Optimizado: Curva Validación Neurons', fig_vN
            ))

            # 4.4 Interpretación IA de las curvas
            prompt_curves = (
                f"NN optimizado (método: {best_entry_nn['Selección X']}, motor: {best_entry_nn['Motor']}) generó estas curvas de R²:\n"
                f"- Aprendizaje: tamaños={ (train_fracs*len(X_tr_scaled)).tolist() }, train={train_scores}, CV={cv_scores}\n"
                f"- Validación Layers: valores={param_L}, train={scores_tr_L}, CV={scores_cv_L}\n"
                f"- Validación Neurons: valores={param_N}, train={scores_tr_N}, CV={scores_cv_N}\n"
                "1. Interpreta cada curva, señalando indicios de underfitting/overfitting."
                "2. Describe patrones (brechas, picos) y posibles causas."
                "3. Recomienda ajustes precisos de HPO basados en estos hallazgos."
                "4. Señala limitaciones de datos o modelo evidentes en las curvas."
            )
            print("[DEBUG] 13.9. Llamando a IA para interpretación IA de curvas rediseñado")
            analysis_curves = call_openai_explanation(prompt_curves)
            self.sections.append((
                "### NN Optimizado: Interpretación IA de Curvas", analysis_curves
            ))
            # --- Fin bloque 4 ---

            # ---- 5. Curvas de Calibración y Predicción de Intervalos para NN Optimizado ----
            print("[DEBUG] 13.10. Calculando curva de calibración y predicción de intervalos para el mejor modelo optimizado NN")
            # Usamos el modelo y payload_best ya cargados

            # ——— Sanitización unificada de columnas para la curva de calibración ———
            # 1) Partimos de las columnas del payload
            raw_cols_ci = payload_best['cols']

            # 2) Limpiamos cada nombre
            sanitized_cols_ci = [sanitize_name(c) for c in raw_cols_ci]

            # 3) Detectamos columnas faltantes
            missing_ci = set(sanitized_cols_ci) - set(X_test.columns)
            if missing_ci:
                print(f"[WARNING] NN omitido estas columnas en Calibración por no existir en X_test: {sorted(missing_ci)}")

            # 4) Filtramos sólo las que existen
            effective_cols_ci = [c for c in sanitized_cols_ci if c in X_test.columns]

            # 5) Selección segura de test
            X_test_ci = X_test[effective_cols_ci].copy()
            y_true_ci = Y_test.values.ravel()

            # 6) Transformación con scaler de entrada
            if sx is not None:
                X_scaled_ci = sx.transform(X_test_ci.values)
            else:
                X_scaled_ci = X_test_ci.values

            # 7) Predicción y desescalado
            y_pred_raw_ci = model_best.predict(X_scaled_ci).ravel()
            if sy is not None:
                y_pred_ci = sy.inverse_transform(y_pred_raw_ci.reshape(-1,1)).ravel()
            else:
                y_pred_ci = y_pred_raw_ci

            # Ahora y_true_ci y y_pred_ci están listas para la curva de calibración y los intervalos

            # — SANITIZACIÓN de las cols del payload antes de usar en informe
            #cols_ci_clean = [_clean_col(c) for c in payload_best['cols']]
            #X_test_ci = X_test[cols_ci_clean].copy()
            #X_test_ci = X_test[payload_best['cols']].copy()

            #y_true_ci = Y_test.values.ravel()
            #X_test_scaled_ci = sx.transform(X_test_ci) if sx else X_test_ci.values
            #y_pred_ci = model_best.predict(X_test_scaled_ci).ravel()

            # 5.1 Curva de calibración manual para regresión
            import pandas as _pd
            bins = 10
            _df_cal = _pd.DataFrame({'y_pred': y_pred_ci, 'y_true': y_true_ci})
            try:
                _df_cal['bin'] = _pd.qcut(_df_cal['y_pred'], q=bins, duplicates='drop')
            except Exception:
                _df_cal['bin'] = _pd.cut(_df_cal['y_pred'], bins=bins)
            gr = _df_cal.groupby('bin', observed=True).agg({'y_pred':'mean','y_true':'mean'})
            prob_pred = gr['y_pred'].values
            prob_true = gr['y_true'].values
            fig_cal, ax_cal = plt.subplots(figsize=(6,4))
            ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2)
            ax_cal.plot([prob_pred.min(), prob_pred.max()], [prob_pred.min(), prob_pred.max()], 'k--')
            ax_cal.set_xlabel('Predicción promedio por bin')
            ax_cal.set_ylabel('Valor real promedio')
            ax_cal.set_title('NN Optimizado: Curva de Calibración')
            self.sections.append((
                '### NN Optimizado: Curva de Calibración', fig_cal
            ))

            # 5.2 Intervalos de predicción ±1 STD de residuos
            residuals_ci = y_true_ci - y_pred_ci
            std_res_ci = np.std(residuals_ci)
            upper = y_pred_ci + std_res_ci
            lower = y_pred_ci - std_res_ci
            fig_int, ax_int = plt.subplots(figsize=(6,4))
            ax_int.plot(y_true_ci, label='Y real')
            ax_int.plot(y_pred_ci, label='Predicción')
            ax_int.fill_between(range(len(y_pred_ci)), lower, upper, alpha=0.3, label='±1 STD residuo')
            ax_int.set_xlabel('Índice de muestra')
            ax_int.set_ylabel('Valor')
            ax_int.set_title('NN Optimizado: Intervalos de Predicción')
            ax_int.legend()
            self.sections.append((
                '### NN Optimizado: Intervalos de Predicción', fig_int
            ))

            # 5.3 Análisis Generativo IA de incertidumbre y calibración
            prompt_ci_nn = (
                f"Curva de calibración (pred vs real): pred={prob_pred.tolist()}, real={prob_true.tolist()}\n"
                f"Intervalos ±1 STD de residuos (std_res={std_res_ci:.4f}).\n"
                "1. ¿Son fiables estos intervalos de incertidumbre?\n"
                "2. ¿Se infravaloran errores altos?"
            )
            print("[DEBUG] 13.11. Llamando IA para análisis de incertidumbre y calibración NN")
            analysis_ci_nn = call_openai_explanation(prompt_ci_nn)
            self.sections.append((
                '### NN Optimizado: Análisis de Incertidumbre y Calibración', analysis_ci_nn
            ))
            # --- Fin bloque 5 ---

            # --- Sección 6: Resumen Ejecutivo y Road-Map de Siguientes Pasos ---
            # Definimos mejor combinación basada en el mejor registro
            sel_method_nn = best_entry_nn['Selección X']
            engine_nn    = best_entry_nn['Motor']
            best_score_nn = best_entry_nn['Score']

            # 6.1. Bloque Markdown con puntos clave para stakeholders
            summary_md = (
                "**Puntos Clave:**\n"
                f"- **Mejor combinación:** {sel_method_nn}-{engine_nn} con score={best_score_nn:.4f}.\n"
                f"- **Grado de robustez:** Variabilidad CV={np.std(cv_scores):.4f}, residuos (std={std_res_ci:.4f}).\n"
                f"- **Puntos débiles:** picos de error en ciertos rangos y posible sobreajuste en tamaños de muestra altos.\n"
                f"- **Recomendaciones inmediatas:** ampliar validación cruzada, explorar motores jerárquicos como HalvingGridSearchCV y recolectar más datos."
            )
            self.sections.append((
                '### Resumen Ejecutivo y Road-Map', summary_md
            ))

            # 6.2. Análisis Generativo IA para desarrollar cada punto clave y generar resumen ejecutivo
            prompt_exec = (
                "Eres un investigador científico del Instituto de Procesos Sostenibles de la Universidad de Valladolid. "
                "A continuación se presentan los puntos clave de la optimización de la red neuronal:\n"
                f"{summary_md}\n"
                "Desarrolla un análisis detallado en párrafos separados para cada punto "
                "(Mejor combinación, Grado de robustez, Puntos débiles, Recomendaciones inmediatas), "
                "y finaliza con un resumen ejecutivo de tres párrafos que resalte los hallazgos y los próximos pasos para los stakeholders."
            )
            print("[DEBUG] 13.12. Llamando IA para Resumen Ejecutivo y Road-Map NN optimización")
            analysis_exec = call_openai_explanation(prompt_exec)
            self.sections.append((
                '### Resumen Ejecutivo IA', analysis_exec
            ))
        # --- Fin Bloque 6 ---

        except Exception as e:
            print(f"[DEBUG] Excepción atrapada en Optimización NN: {type(e).__name__}: {e}")
            raise   # relanza la excepción para que no se oculte
#            self.sections.append((
#                "### ⚠️ Error en sección Optimización NN",
#                f"Se produjo un error al generar el resumen de métodos y motores NN: {e}"
#            ))

        # =============================================================================
        # 14. Optimización Modelo XGBoost
        # =============================================================================
        print("[DEBUG] 14.1. Iniciando sección Optimización XGBoost: Resumen de métodos y motores")
        try:
            # Extraer resultados de OPT_MODELS para XGBoost
            valid_engines_xgb = {'randomsearch', 'bayesian', 'hyperband', 'optuna'}
            xgb_entries = {
                k: v for k, v in OPT_MODELS.items()
                if isinstance(k, tuple) and k[0] == 'xgb' and k[2] in valid_engines_xgb
            }
            if not xgb_entries:
                raise RuntimeError("No se encontró optimizaciones XGBoost en OPT_MODELS")

            import pandas as pd
            # Construir registros de resumen para XGBoost
            summary_xgb = []
            for (model_type, sel_method, engine), payload in xgb_entries.items():
                model = payload.get('model')
                score = payload.get('score')
                metric = payload.get('metric')
                # Determinar parámetros de búsqueda del payload unificando todas las claves posibles
                params_cfg = (
                    payload.get('param_dist')
                    or payload.get('param_spaces')
                    or payload.get('search_spaces')
                    or payload.get('hpo_params')
                    or {}
                )
                best_params = getattr(model, 'get_params', lambda: {})()
                summary_xgb.append({
                    'Selección X': sel_method,
                    'Motor': engine,
                    'Métrica': metric,
                    'Score': score,
                    'Params_Búsqueda': params_cfg,
                    'Best_n_estimators': best_params.get('n_estimators'),
                    'Best_max_depth': best_params.get('max_depth'),
                    'Best_learning_rate': best_params.get('learning_rate')
                })

            df_xgb = pd.DataFrame(summary_xgb)
            # Añadir al informe
            self.sections.append((
                '### XGBoost Optimización: Resumen de Métodos y Motores',
                df_xgb.reset_index(drop=True)
            ))

            # --- 0. Análisis Generativo IA de Tabla de Resumen ---
            # Llamada a OpenAI para análisis de los resultados
            lines = [
                f"Método X: {r['Selección X']}, Motor: {r['Motor']}, Score: {r['Score']:.4f}, " +
                f"Params Busqueda: {r.get('Params_Búsqueda', {})}, Best_Params: {r.get('Best_Params', {})}"
                for r in summary_xgb
            ]

            prompt_xgb = (
                "He obtenido los siguientes resultados de optimización para XGBoost:" + "".join(lines) + ""
                "1. Explica la estrategia de búsqueda y ventajas de cada motor (Hyperband, RandomizedSearchCV, Optuna, BayesSearchCV).\n"
                "2. Compara los scores obtenidos y argumenta cuál es la mejor configuración.\n"
                "3. Sugiere mejoras específicas de HPO para XGBoost basadas en estos resultados."
            )
            print("[DEBUG] 14.2. Llamando a OpenAI para análisis generativo XGBoost optimización")
            analysis_xgb = call_openai_explanation(prompt_xgb)
            self.sections.append((
                '### XGBoost Optimización: Análisis Generativo', analysis_xgb
            ))
            # --- Fin Bloque 0 ---

            # --- 1. Curvas de Ajuste Real vs. Predicho y Residuos para XGBoost ---
            from sklearn.metrics import r2_score
            print("[DEBUG] 14.3. Iniciando bloque de Curvas Ajuste Real vs Predicho y Residuos para XGBoost optimizado")
            from scipy.stats import skew, kurtosis
            import numpy as np

            # 1. Seleccionar mejor configuración y normalizar payload
            best_idx    = df_xgb['Score'].idxmax() if df_xgb['Métrica'].str.upper().iloc[0]=='R2' else df_xgb['Score'].idxmin()
            best_row    = summary_xgb[best_idx]

            payload_raw = OPT_MODELS[('xgb', best_row['Selección X'], best_row['Motor'])]
            p           = _normalize_payload(payload_raw)

            # ——— Sanitización de columnas para XGBoost ———
            # 1) obtenemos la lista original de columnas entrenadas
            raw_cols_xgb = p['cols'] if p['cols'] is not None else X_train.columns.tolist()
            # 2) aplicamos sanitize_name a cada nombre
            sanitized_cols = [sanitize_name(c) for c in raw_cols_xgb]
            # 3) avisamos si faltan columnas en X_test
            missing = set(sanitized_cols) - set(X_test.columns)
            if missing:
                print(f"[WARNING] XGBoost omitido estas columnas por no existir en X_test: {sorted(missing)}")
            # 4) nos quedamos solo con las columnas válidas
            cols_xgb = [c for c in sanitized_cols if c in X_test.columns]
            # ——— Fin sanitización XGBoost ———

            # ——— 1.1.1 Sanitización y filtro unificado de columnas ———
            #sanitized_cols = [sanitize_name(c) for c in raw_cols]
            #missing = set(sanitized_cols) - set(X_test.columns)
            #if missing:
            #    print(f"[WARNING] SVR omitido estas columnas por no existir en X_test: {sorted(missing)}")
            #cols_xgb = [c for c in sanitized_cols if c in X_test.columns]

            #X_test_sel = X_test[cols_valid].copy()

            # AÑADIDO: Unificar saneamiento de nombres de columnas según entrenamiento
            #import re
            #def clean_name(s):
            #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
            #    t = re.sub(r'_+', '_', t)
            #    return t.strip('_')

            # 1) Modelo — si no está, error controlado
            model_xgb = p['model']
            if model_xgb is None:
                raise RuntimeError(f"No pude cargar el modelo para {best_row['Selección X']}-{best_row['Motor']}")

            # 2) Columnas — si no vienen, uso **todas** las de entrenamiento
            #cols_xgb = p['cols'] if p['cols'] is not None else X_train.columns.tolist()

            # REEMPLAZAR esta línea original:
            # cols_xgb = p['cols'] if p['cols'] is not None else X_train.columns.tolist()
            # POR:
            #raw_cols_xgb = p['cols'] if p['cols'] is not None else X_train.columns.tolist()
            #cols_xgb     = [ clean_name(c) for c in raw_cols_xgb ]
            # FIN AÑADIDO / REEMPLAZO

            # 3) Escalador de salida — a la hora de inverse_transform
            sy_xgb = p['sy']  # puede ser None

            # 4) Score y best_params — nunca deberían ser None, pero por si acaso:
            score_xgb       = p['score'] or 0.0
            best_params_xgb = p['best_params'] or {}
            metric_xgb      = p['metric']

            # Preparar datos de prueba
            #X_test_xgb = X_test[cols_xgb]
            #y_true_xgb = Y_test.values.ravel()
            #y_pred_xgb = model_xgb.predict(X_test_xgb)
            #if p['sy'] is not None:
            #    y_pred_xgb = p['sy'].inverse_transform(y_pred_xgb.reshape(-1,1)).ravel()
            # si tu modelo no escala internamente:
            #X_test_scaled_xgb = sx_xgb.transform(X_test_xgb)
            #y_pred_xgb        = sy_xgb.inverse_transform(model_xgb.predict(X_test_scaled_xgb).reshape(-1,1)).ravel()

            # 1) Filtramos y saneamos las columnas igual que en entrenamiento
            X_test_xgb = X_test[cols_xgb]
            # 2) Llevamos a numpy array para evitar la comprobación de nombres
            X_test_vals = X_test_xgb.values
            y_pred_raw  = model_xgb.predict(X_test_vals)
            # 3) Desescalamos si corresponde
            if p['sy'] is not None:
                y_pred_xgb = p['sy'].inverse_transform(y_pred_raw.reshape(-1,1)).ravel()
            else:
                y_pred_xgb = y_pred_raw
            # 4) Tus valores reales siguen así:
            y_true_xgb = Y_test.values.ravel()

            # Gráfica Predicho vs Real
            fig1, ax1 = plt.subplots(figsize=(6,4))
            ax1.scatter(y_true_xgb, y_pred_xgb, alpha=0.6)
            ax1.plot([y_true_xgb.min(), y_true_xgb.max()], [y_true_xgb.min(), y_true_xgb.max()], 'r--', lw=2)
            ax1.set_xlabel('Y real')
            ax1.set_ylabel('Y predicho')
            ax1.set_title(f"XGBoost Optimizado: Predicho vs Real ({best_row['Selección X']}-{best_row['Motor']})")
            self.sections.append((
                f"### XGBoost Optimizado: Predicho vs Real ({best_row['Selección X']}-{best_row['Motor']})", fig1
            ))

            # Gráfica Residuos
            residuals_xgb = y_true_xgb - y_pred_xgb
            fig2, ax2 = plt.subplots(figsize=(6,4))
            ax2.scatter(y_pred_xgb, residuals_xgb, alpha=0.6)
            ax2.axhline(0, color='r', linestyle='--', lw=2)
            ax2.set_xlabel('Y predicho')
            ax2.set_ylabel('Residuo')
            ax2.set_title(f"XGBoost Optimizado: Residuos ({best_row['Selección X']}-{best_row['Motor']})")
            self.sections.append((
                f"### XGBoost Optimizado: Residuos ({best_row['Selección X']}-{best_row['Motor']})", fig2
            ))

            # Tabla estadísticas de residuos
            df_res_stats = pd.DataFrame({
                'Métrica': ['Media','Desviación','Skew','Kurtosis','25%','50%','75%'],
                'Valor': [residuals_xgb.mean(), residuals_xgb.std(), skew(residuals_xgb), kurtosis(residuals_xgb), *np.quantile(residuals_xgb,[0.25,0.5,0.75])]
            })
            self.sections.append((
                f"### XGBoost Optimizado: Estadísticas de Residuos ({best_row['Selección X']}-{best_row['Motor']})", df_res_stats
            ))

            # Análisis generativo IA
            prompt_xgb_curves = (
                f"Para el mejor XGBoost optimizado (selección {best_row['Selección X']}, motor {best_row['Motor']}), "
                f"tienes los siguientes datos:"
                f"- Rango Y real: [{y_true_xgb.min():.4f}, {y_true_xgb.max():.4f}]\n"
                f"- Rango Y pred: [{y_pred_xgb.min():.4f}, {y_pred_xgb.max():.4f}]\n"
                f"- Estadísticas residuos: media={residuals_xgb.mean():.4f}, std={residuals_xgb.std():.4f}, skew={skew(residuals_xgb):.4f}, kurtosis={kurtosis(residuals_xgb):.4f}\.\n"
                "1. Analiza la calidad del ajuste basándote en Predicho vs Real y Residuos.\n"
                "2. Comenta sesgos sistemáticos o heterocedasticidad.\n"
                "3. Recomienda acciones para mejorar el fit si hay problemas."
            )
            print("[DEBUG] 14.4. Llamando IA para análisis de curvas XGBoost")
            try:
                analysis_xgb_curves = call_openai_explanation(prompt_xgb_curves)
                self.sections.append((
                    '### XGBoost Optimizado: Análisis Calidad Ajuste',
                    analysis_xgb_curves
                ))
            except Exception as e:
                # aquí sí podemos usar `e`
                print(f"[ERROR XGB – Curvas] {type(e).__name__}: {e}")
                self.sections.append((
                    '### ⚠️ Error XGBoost: Análisis Calidad Ajuste',
                    f"Se produjo un error al generar las curvas de XGBoost: {type(e).__name__}: {e}"
                ))
            # --- Fin bloque 1 ---

            # --- 2. Importancia Relativa de Hiperparámetros para XGBoost Optimizado ---
            print("[DEBUG] 14.5. Calculando importancia real de hiperparámetros para XGBoost optimizado")

            import pandas as pd
            import numpy as np
            from sklearn.model_selection import train_test_split
            from sklearn.metrics import r2_score
            from xgboost import XGBRegressor

            # Determinar la mejor configuración desde df_xgb
            if df_xgb['Métrica'].str.upper().iloc[0] == 'R2':
                idx_best = df_xgb['Score'].idxmax()
            else:
                idx_best = df_xgb['Score'].idxmin()

            # Datos completos
            X_full = X_train[cols_xgb]
            y_full = Y_train.values.ravel()
            base_params = best_params_xgb
            base_score  = score_xgb

            # Función para medir impacto de variar un hiperparámetro ±10%
            sens_list = []
            for param in ['n_estimators', 'max_depth', 'learning_rate']:
                base_val = base_params.get(param)
                if base_val is None:
                    continue
                for factor, label in [(1.1, '+10%'), (0.9, '-10%')]:
                    # Nuevo valor
                    new_val = int(base_val * factor) if param in ['n_estimators', 'max_depth'] else base_val * factor
                    # División train/val
                    X_tr, X_val, y_tr, y_val = train_test_split(X_full, y_full, test_size=0.2, random_state=42)
                    # Reentrenar con el parámetro modificado
                    m = XGBRegressor(**{**base_params, param: new_val}, random_state=42, verbosity=0)
                    m.fit(X_tr, y_tr)
                    y_pred = m.predict(X_val)
                    score_new = r2_score(y_val, y_pred)
                    sens_list.append({
                        'Parámetro': param,
                        'Cambio': label,
                        'Score': score_new,
                        'Delta': score_new - base_score
                    })

            # Crear DataFrame de sensibilidad
            df_sens_xgb = pd.DataFrame(sens_list)
            df_sens_xgb['% Delta'] = df_sens_xgb['Delta'] * 100

            # 2.1 Tabla de sensibilidad real
            self.sections.append((
                '### XGBoost Optimizado: Sensibilidad Real del Score ±10%',
                df_sens_xgb[['Parámetro', 'Cambio', 'Score', '% Delta']]
            ))

            # 2.2 Heatmap de sensibilidad
            pivot_xgb = df_sens_xgb.pivot(index='Parámetro', columns='Cambio', values='% Delta')
            fig_sens_xgb, ax_sens_xgb = plt.subplots(figsize=(6, 4))
            sns.heatmap(pivot_xgb, annot=True, fmt='.2f', ax=ax_sens_xgb)
            ax_sens_xgb.set_title('XGBoost Optimizado: Heatmap Sensibilidad Real ±10%')
            self.sections.append((
                '### XGBoost Optimizado: Heatmap Sensibilidad',
                fig_sens_xgb
            ))

            # 2.3 Análisis Generativo IA de importancia real
            lines_xgb = [
            f"{row['Parámetro']} {row['Cambio']} → Δ% = {row['% Delta']:.2f}%"
            for _, row in df_sens_xgb.iterrows()
            ]
            prompt_hp_xgb = (
                "Sensibilidad del Score tras reentrenar XGBoost variando ±10% cada hiperparámetro:\n" +
                "\n".join(lines_xgb) +
                "\n\n1. Explica cuál hiperparámetro impacta más y por qué.\n"
                "2. Sugiere en qué enfocarte en próximos HPO basándote en estos resultados."
            )
            print("[DEBUG] 14.6. Llamando IA para importancia hiperparámetros XGBoost")
            analysis_hp_xgb = call_openai_explanation(prompt_hp_xgb)
            self.sections.append((
                '### XGBoost Optimizado: IA Importancia Real Hiperparámetros',
                analysis_hp_xgb
            ))
            # ---- Fin bloque 2 ----

            # --- 3. Distribución de Métricas en Validación Cruzada para XGBoost Optimizado ---
            from sklearn.model_selection import cross_validate
            import numpy as np

            print("[DEBUG] 14.7. Calculando distribución de métricas CV para XGBoost optimizado")

            # 3.1 Identificar el mejor modelo según Score (R2 se maximiza, errores se minimizan)
            if df_xgb['Métrica'].str.upper().iloc[0] == 'R2':
                best_idx = df_xgb['Score'].idxmax()
            else:
                best_idx = df_xgb['Score'].idxmin()
            best_row = df_xgb.loc[best_idx]

            payload_raw_cv  = OPT_MODELS[('xgb', best_row['Selección X'], best_row['Motor'])]
            p_cv            = _normalize_payload(payload_raw_cv)
            model_cv, cols_cv = p_cv['model'], p_cv['cols']

            # Preparamos datos de entrenamiento escalados
            X_cv = X_train[cols_cv]
            y_cv = Y_train.values.ravel()

            # Ejecutamos cross‐validate con 5 folds
            cv_results = cross_validate(
                model_cv, X_cv, y_cv,
                cv=5,
                scoring={
                    'R2': 'r2',
                    'neg_MSE': 'neg_mean_squared_error',
                    'neg_MAE': 'neg_mean_absolute_error'
                },
                return_train_score=False
            )

            # Convertimos a métricas positivas
            r2_scores   = cv_results['test_R2']
            mse_scores  = -cv_results['test_neg_MSE']
            mae_scores  = -cv_results['test_neg_MAE']
            rmse_scores = np.sqrt(mse_scores)

            import pandas as _pd

            # 3.2 Boxplot de métricas por fold
            df_cv = _pd.DataFrame({
                'R2':   r2_scores,
                'MSE':  mse_scores,
                'MAE':  mae_scores,
                'RMSE': rmse_scores
            })
            fig_cv, ax_cv = plt.subplots(figsize=(6,4))
            sns.boxplot(data=df_cv, ax=ax_cv)
            ax_cv.set_title('XGBoost Optimizado: Distribución de Métricas CV')
            self.sections.append((
                '### XGBoost Optimizado: Distribución de Métricas CV',
                fig_cv
            ))

            # 3.3 Tabla con media ± desviación en folds
            stats_cv = df_cv.agg(['mean','std']).T.reset_index().rename(columns={
                'index':'Métrica','mean':'Media','std':'Desviación'
            })
            self.sections.append((
                '### XGBoost Optimizado: Estadísticas CV por Fold',
                stats_cv
            ))

            # 3.4 Análisis Generativo IA de estabilidad
            prompt_cv_xgb = (
                f"Validación cruzada 5-folds para XGBoost optimizado "
                f"(selección={best_row['Selección X']}, motor={best_row['Motor']}):\n"
                f"- R2 scores: {r2_scores.tolist()}\n"
                f"- MSE scores: {mse_scores.tolist()}\n"
                f"- MAE scores: {mae_scores.tolist()}\n"
                f"- RMSE scores: {rmse_scores.tolist()}\n\n"
                "1. ¿Qué nos dice la dispersión de cada métrica sobre la estabilidad del modelo?\n"
                "2. Identifica fuentes de variabilidad que puedan afectar la generalización.\n"
                "3. Sugiere acciones concretas (p.ej., más regularización, más datos, ajuste de HPO) para mejorar la robustez."
            )
            print("[DEBUG] 14.8. Llamando IA para estabilidad en CV XGBoost")
            analysis_cv_xgb = call_openai_explanation(prompt_cv_xgb)
            self.sections.append((
                '### XGBoost Optimizado: Análisis Estabilidad CV',
                analysis_cv_xgb
            ))
            # --- Fin Bloque 3 ---

            # --- 4. Curvas de Aprendizaje y Validación para XGBoost Optimizado ---
            # --- 4. Curvas de Aprendizaje y Validación para XGBoost Optimizado ---
            from sklearn.model_selection import learning_curve, validation_curve
            import numpy as np

            print("[DEBUG] 14.9. Calculando curvas de aprendizaje y validación para XGBoost optimizado")

            # Seleccionar mejor configuración según métrica
            if df_xgb['Métrica'].str.upper().iloc[0] == 'R2':
                best_idx = df_xgb['Score'].idxmax()
            else:
                best_idx = df_xgb['Score'].idxmin()
            best_row = summary_xgb[best_idx]
            payload_raw_lc = OPT_MODELS[('xgb', best_row['Selección X'], best_row['Motor'])]
            p_lc           = _normalize_payload(payload_raw_lc)
            model_best, cols_xgb = p_lc['model'], p_lc['cols']

            # Preparar datos de entrenamiento
            X_tr = X_train[cols_xgb]
            y_tr = Y_train.values.ravel()

            # 4.1 Curva de Aprendizaje (R²)
            train_sizes, train_scores, cv_scores = learning_curve(
                model_best, X_tr, y_tr,
                cv=3,
                train_sizes=np.linspace(0.1, 1.0, 5),
                scoring='r2',
                n_jobs=-1
            )
            train_mean = np.mean(train_scores, axis=1)
            cv_mean    = np.mean(cv_scores,   axis=1)

            fig_lc_xgb, ax_lc_xgb = plt.subplots(figsize=(6,4))
            ax_lc_xgb.plot(train_sizes, train_mean, 'o-', label='Train R²')
            ax_lc_xgb.plot(train_sizes, cv_mean,    'o-', label='CV R²')
            ax_lc_xgb.set_title('XGBoost Optimizado: Curva de Aprendizaje')
            ax_lc_xgb.set_xlabel('Tamaño del set de entrenamiento')
            ax_lc_xgb.set_ylabel('R²')
            ax_lc_xgb.legend()
            self.sections.append((
                '### XGBoost Optimizado: Curva de Aprendizaje',
                fig_lc_xgb
            ))

            # 4.2 Curva de Validación para max_depth
            param_range_depth = np.arange(3, 16, 2)
            depth_tr, depth_cv = validation_curve(
                model_best, X_tr, y_tr,
                param_name='max_depth',
                param_range=param_range_depth,
                cv=3,
                scoring='r2',
                n_jobs=-1
            )
            fig_vc_d, ax_vc_d = plt.subplots(figsize=(6,4))
            ax_vc_d.plot(param_range_depth, np.mean(depth_tr, axis=1), 'o-', label='Train R²')
            ax_vc_d.plot(param_range_depth, np.mean(depth_cv, axis=1), 'o-', label='CV R²')
            ax_vc_d.set_title('XGBoost Opt.: Curva Validación max_depth')
            ax_vc_d.set_xlabel('max_depth')
            ax_vc_d.set_ylabel('R²')
            ax_vc_d.legend()
            self.sections.append((
                '### XGBoost Optimizado: Curva de Validación max_depth',
                fig_vc_d
            ))

            # 4.3 Curva de Validación para learning_rate
            param_range_lr = np.linspace(0.01, 0.3, 5)
            lr_tr, lr_cv = validation_curve(
                model_best, X_tr, y_tr,
                param_name='learning_rate',
                param_range=param_range_lr,
                cv=3,
                scoring='r2',
                n_jobs=-1
            )
            fig_vc_lr, ax_vc_lr = plt.subplots(figsize=(6,4))
            ax_vc_lr.plot(param_range_lr, np.mean(lr_tr, axis=1), 'o-', label='Train R²')
            ax_vc_lr.plot(param_range_lr, np.mean(lr_cv, axis=1), 'o-', label='CV R²')
            ax_vc_lr.set_xscale('log')
            ax_vc_lr.set_title('XGBoost Opt.: Curva Validación learning_rate')
            ax_vc_lr.set_xlabel('learning_rate')
            ax_vc_lr.set_ylabel('R²')
            ax_vc_lr.legend()
            self.sections.append((
                '### XGBoost Optimizado: Curva de Validación learning_rate',
                fig_vc_lr
            ))

            # 4.4 Interpretación IA de las curvas
            prompt_curvas_xgb = (
                f"Para el modelo XGBoost optimizado (selección={best_row['Selección X']}, motor={best_row['Motor']}), se generaron estas curvas de R²:\n"
                f"- Aprendizaje: tamaños={train_sizes.tolist()}, train={train_mean.tolist()}, cv={cv_mean.tolist()}\n"
                f"- Validación max_depth: depths={param_range_depth.tolist()}, train={np.mean(depth_tr,axis=1).tolist()}, cv={np.mean(depth_cv,axis=1).tolist()}\n"
                f"- Validación learning_rate: rates={param_range_lr.tolist()}, train={np.mean(lr_tr,axis=1).tolist()}, cv={np.mean(lr_cv,axis=1).tolist()}\n\n"
                "1. Interpreta cada curva señalando indicios de underfitting o overfitting.\n"
                "2. Describe patrones (brechas entre train y cv, picos, caídas).\n"
                "3. Recomienda ajustes precisos de HPO (max_depth, learning_rate, regularización).\n"
                "4. Indica posibles limitaciones de datos o modelo evidentes."
            )
            print("[DEBUG] 14.10. Llamando a OpenAI para interpretación IA de curvas XGBoost")
            analysis_curvas_xgb = call_openai_explanation(prompt_curvas_xgb)
            self.sections.append((
                '### XGBoost Optimizado: Interpretación IA de Curvas',
                analysis_curvas_xgb
            ))
            # --- Fin Bloque 4 ---

            # ---- 5. Curvas de Calibración y Predicción de Intervalos para XGBoost Optimizado ----
            from sklearn.calibration import calibration_curve
            import pandas as _pd
            import numpy as np

            print("[DEBUG] 14.11. Calculando curva de calibración y predicción de intervalos para el mejor modelo optimizado XGBoost")

            # 5.1 Identificar mejor modelo
            if df_xgb['Métrica'].str.upper().iloc[0] == 'R2':
                best_idx = df_xgb['Score'].idxmax()
            else:
                best_idx = df_xgb['Score'].idxmin()
            best = summary_xgb[best_idx]
            payload_raw_ci = OPT_MODELS[('xgb', best['Selección X'], best['Motor'])]
            p_ci           = _normalize_payload(payload_raw_ci)
            model_ci, cols_ci = p_ci['model'], p_ci['cols']

            # Preparar datos de prueba
            X_test_ci   = X_test[cols_ci]
            y_true_ci   = Y_test.values.ravel()
            y_pred_ci   = model_ci.predict(X_test_ci)

            # 5.2 Curva de calibración (binned reliability plot)
            bins = 10
            df_cal = _pd.DataFrame({'y_pred': y_pred_ci, 'y_true': y_true_ci})
            try:
                df_cal['bin'] = _pd.qcut(df_cal['y_pred'], q=bins, duplicates='drop')
            except ValueError:
                df_cal['bin'] = _pd.cut(df_cal['y_pred'], bins=bins)
            grp = df_cal.groupby('bin', observed=True).agg({'y_pred':'mean','y_true':'mean'})
            prob_pred = grp['y_pred'].values
            prob_true = grp['y_true'].values

            fig_cal, ax_cal = plt.subplots(figsize=(6,4))
            ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2)
            ax_cal.plot([prob_pred.min(), prob_pred.max()],
                        [prob_pred.min(), prob_pred.max()],
                        'k--')
            ax_cal.set_xlabel('Predicción promedio por bin')
            ax_cal.set_ylabel('Valor real promedio')
            ax_cal.set_title('XGBoost Opt.: Curva de Calibración')
            self.sections.append((
                '### XGBoost Optimizado: Curva de Calibración',
                fig_cal
            ))

            # 5.3 Intervalos de predicción ±1 STD de residuos
            residuals_ci = y_true_ci - y_pred_ci
            std_res_ci   = np.std(residuals_ci)
            upper = y_pred_ci + std_res_ci
            lower = y_pred_ci - std_res_ci

            fig_int, ax_int = plt.subplots(figsize=(6,4))
            ax_int.plot(y_true_ci, label='Y real')
            ax_int.plot(y_pred_ci, label='Predicción')
            ax_int.fill_between(range(len(y_pred_ci)), lower, upper,
                                alpha=0.3, label='±1 STD residuo')
            ax_int.set_xlabel('Índice de muestra')
            ax_int.set_ylabel('Valor')
            ax_int.set_title('XGBoost Opt.: Intervalos de Predicción')
            ax_int.legend()
            self.sections.append((
                '### XGBoost Optimizado: Intervalos de Predicción',
                fig_int
            ))

            # 5.4 Análisis Generativo IA de incertidumbre y calibración
            prompt_ci_xgb = (
                f"Para el XGBoost optimizado (método={best['Selección X']}, motor={best['Motor']}):\n"
                f"- Curva de calibración: pred={prob_pred.tolist()}, real={prob_true.tolist()}\n"
                f"- Intervalos ±1 STD de residuos (std={std_res_ci:.4f})\n\n"
                "1. ¿Son fiables estos intervalos de incertidumbre?\n"
                "2. ¿Observas infravaloración de errores altos o patrones heterocedásticos?\n"
                "3. Sugiere mejoras en HPO o en la modelización para fortalecer la confianza de las predicciones."
            )
            print("[DEBUG] 14.12. Llamando IA para análisis de incertidumbre y calibración XGBoost")
            analysis_ci_xgb = call_openai_explanation(prompt_ci_xgb)
            self.sections.append((
                '### XGBoost Optimizado: Análisis de Incertidumbre y Calibración',
                analysis_ci_xgb
            ))
            # --- Fin Bloque 5 ---

            # --- 6. Resumen Ejecutivo y Road-Map de Siguientes Pasos para XGBoost Optimizado ---
            # 6.1. Identificamos la mejor configuración
            if df_xgb['Métrica'].str.upper().iloc[0] == 'R2':
                best_idx_xgb = df_xgb['Score'].idxmax()
            else:
                best_idx_xgb = df_xgb['Score'].idxmin()
            best_xgb = summary_xgb[best_idx_xgb]
            sel_xgb, eng_xgb, best_score_xgb = best_xgb['Selección X'], best_xgb['Motor'], best_xgb['Score']

            # 6.2. Creamos el bloque Markdown con los puntos clave
            summary_md_xgb = (
                "**Puntos Clave Optimización XGBoost:**\n\n"
                f"- **Mejor combinación:** Método de selección `{sel_xgb}` + motor `{eng_xgb}` ➜ **Score** = {best_score_xgb:.4f}\n"
                f"- **Robustez del modelo:** CV y residuos muestran desviación estándar de aproximadamente _X_ (reemplazar con valor real).\n"
                "- **Puntos débiles detectados:** posibles indicios de sobreajuste en rangos altos de `max_depth` o `learning_rate`, y variabilidad en ciertos folds.\n"
                "- **Recomendaciones inmediatas:**\n"
                "  1. Ampliar validación cruzada (p.ej., HalvingGridSearchCV o K=5–10 folds).\n"
                "  2. Explorar rangos más finos de `learning_rate` en [0.01, 0.1] y `max_depth` en [3, 10].\n"
                "  3. Evaluar regularización L1/L2 (`reg_alpha`, `reg_lambda`) para atenuar overfitting.\n"
                "  4. Considerar ensamblados ligeros (p.ej., LightGBM, CatBoost) y comparación de rendimiento.\n"
            )

            self.sections.append((
                '### XGBoost Optimizado: Resumen Ejecutivo y Road-Map',
                summary_md_xgb
            ))

            # 6.3. Análisis Generativo con OpenAI
            prompt_exec_xgb = (
                "Eres un investigador del Instituto de Procesos Sostenibles de la Universidad de Valladolid. "
                "A continuación tienes los puntos clave de la optimización XGBoost:\n\n"
                f"{summary_md_xgb}\n\n"
                "Por favor:\n"
                "1. Desarrolla en un párrafo cada uno de los puntos clave (Mejor combinación, Robustez, Puntos débiles, Recomendaciones).\n"
                "2. Finaliza con un **resumen ejecutivo** de tres párrafos dirigido a stakeholders académicos, resaltando hallazgos y pasos siguientes.\n"
            )
            print("[DEBUG] 14.13. Llamando IA para Resumen Ejecutivo XGBoost")
            analysis_exec_xgb = call_openai_explanation(prompt_exec_xgb)
            self.sections.append((
                '### XGBoost Optimizado: Análisis Ejecutivo IA',
                analysis_exec_xgb
            ))
            # --- Fin Bloque 6 ---

        except Exception as e:
            print(f"[ERROR XGBoost] {type(e).__name__}: {e}")
            self.sections.append((
                '### ⚠️ Error en sección Optimización XGBoost',
                f"Se produjo un error al generar XGBoost: {type(e).__name__}: {e}"
            ))

        #print("[DEBUG] ReportBuilder.build_sections end")

        # =============================================================================
        # 15. Optimización Modelo Random Forest
        # =============================================================================
        try:
            print("[DEBUG] 15.1. Iniciando sección Optimización Random Forest: Resumen de métodos y motores")
            # Verificar que OPT_MODELS existe y es dict
            if 'OPT_MODELS' not in globals() or not isinstance(OPT_MODELS, dict):
                raise RuntimeError("No se encontró OPT_MODELS con resultados de optimización RF")

            import pandas as pd
            # Filtrar entradas de Random Forest
            valid_engines_rf = {'randomsearch', 'bayesianoptimization', 'hyperband', 'optuna'}
            rf_entries = {
                k: v for k, v in OPT_MODELS.items()
                if isinstance(k, tuple) and k[0] == 'rf' and k[2] in valid_engines_rf
            }
            if not rf_entries:
                raise RuntimeError("No se encontraron optimizaciones Random Forest en OPT_MODELS")

            # Construir lista de registros resumen
            summary_rf = []
            for (_, sel_method, engine), payload in rf_entries.items():
                score = payload.get('score')
                metric = payload.get('metric')
                params_search = payload.get('param_dist', {}) or payload.get('search_spaces', {})
                best_params = payload.get('best_params', {})
                summary_rf.append({
                    'Selección X': sel_method,
                    'Motor':      engine,
                    'Métrica':    metric,
                    'Score':      score,
                    'Params_Búsqueda': params_search,
                    'Best_Params':     best_params
                })

            # DataFrame resumen
            df_rf = pd.DataFrame(summary_rf)
            self.sections.append((
                '### Random Forest Optimización: Resumen de Métodos y Motores',
                df_rf.reset_index(drop=True)
            ))

            # --- 0. Análisis Generativo IA de la Tabla Resumen ---
            def call_openai_explanation(prompt: str, model: str = "gpt-4", temperature: float = TEMPERATURE_VAL, max_tokens: int = MAX_EXPLANATION_TOKENS) -> str:
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un experto en optimización de hiperparámetros de modelos de Machine Learning. "
                                "Proporciona análisis profundo, interpretaciones y recomendaciones basadas en los datos proporcionados.")},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS
                    )
                    return response.choices[0].message.content.strip()
                except Exception as e:
                    return f"[Error llamando a OpenAI: {e}]"
            lines = [
                f"Método X: {r['Selección X']}, Motor: {r['Motor']}, Score: {r['Score']:.4f}, " +
                f"Params: {r['Params_Búsqueda']}, Best: {r['Best_Params']}"
                for r in summary_rf
            ]
            prompt_rf = (
                "He obtenido los siguientes resultados de optimización para Random Forest:\n" +
                "\n".join(lines) + "\n\n"
                "1. Explica la estrategia de cada motor (RandomSearch, BayesianOptimization, Hyperband, Optuna).\n"
                "2. Compara los scores y justifica la mejor configuración.\n"
                "3. Sugiere mejoras específicas de HPO para Random Forest."
            )
            print("[DEBUG] 15.2. Llamando a OpenAI para análisis generativo RF optimización")
            analysis_rf = call_openai_explanation(prompt_rf)

            self.sections.append((
                '### Random Forest Optimización: Análisis Generativo',
                analysis_rf
            ))
            # --- Fin Bloque 0 ---

            # --- 1. Curvas de Ajuste Real vs. Predicho y Residuos para Random Forest Optimizado ---
            from sklearn.metrics import r2_score
            from scipy.stats import skew, kurtosis
            print("[DEBUG] 15.3. Iniciando bloque de Curvas Ajuste Real vs Predicho y Residuos para Random Forest optimizado")

            # 1. Seleccionar mejor configuración y normalizar payload
            best_idx  = df_rf['Score'].idxmax()
            best_row  = summary_rf[best_idx]

            payload_raw = OPT_MODELS[('rf', best_row['Selección X'], best_row['Motor'])]
            p = _normalize_payload(payload_raw)

            model_rf     = p['model']
            sx_rf, sy_rf = p['sx'], p['sy']
            cols_rf      = p['cols']
            score_rf     = p['score']
            metric_rf    = p['metric']
            best_params_rf = p['best_params']

            # ——— 15.1 Sanitización unificada de columnas para RF ———
            sanitized_cols_rf = [sanitize_name(c) for c in cols_rf]
            missing_rf = set(sanitized_cols_rf) - set(X_test.columns)
            if missing_rf:
                print(f"[WARNING] RF omitido estas columnas por no existir en X_test: {sorted(missing_rf)}")
            cols_valid_rf = [c for c in sanitized_cols_rf if c in X_test.columns]

            # Selección segura de test
            X_test_sel = X_test[cols_valid_rf].copy()

            # Preparar datos de prueba
            #X_test_sel = X_test[cols_rf]
            y_true = Y_test.values.ravel()
            if sx_rf and sy_rf:
                X_scaled = sx_rf.transform(X_test_sel)
                y_pred = sy_rf.inverse_transform(model_rf.predict(X_scaled).reshape(-1,1)).ravel()
            elif sx_rf:
                X_scaled = sx_rf.transform(X_test_sel)
                y_pred = model_rf.predict(X_scaled)
            else:
                y_pred = model_rf.predict(X_test_sel)

            # Gráfica Predicho vs Real
            fig1, ax1 = plt.subplots(figsize=(6,4))
            ax1.scatter(y_true, y_pred, alpha=0.6)
            ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
            ax1.set_xlabel("Y real")
            ax1.set_ylabel("Y predicho")
            ax1.set_title(f"RF Optimizado: Predicho vs Real ({best_row['Selección X']}-{best_row['Motor']})")
            self.sections.append((
                f"### Random Forest Optimizado: Predicho vs Real ({best_row['Selección X']}-{best_row['Motor']})", fig1
            ))

            # Gráfica Residuos
            residuals = y_true - y_pred
            fig2, ax2 = plt.subplots(figsize=(6,4))
            ax2.scatter(y_pred, residuals, alpha=0.6)
            ax2.axhline(0, color='r', linestyle='--', lw=2)
            ax2.set_xlabel("Y predicho")
            ax2.set_ylabel("Residuo")
            ax2.set_title(f"RF Optimizado: Residuos ({best_row['Selección X']}-{best_row['Motor']})")
            self.sections.append((
                f"### Random Forest Optimizado: Residuos ({best_row['Selección X']}-{best_row['Motor']})", fig2
            ))

            # Estadísticas de residuos
            mean_res = float(residuals.mean())
            std_res = float(residuals.std())
            skew_res = float(skew(residuals))
            kurt_res = float(kurtosis(residuals))
            q25, q50, q75 = [float(x) for x in np.quantile(residuals, [0.25, 0.5, 0.75])]
            df_stats = pd.DataFrame({
                'Métrica':['Media','Desviación','Skew','Kurtosis','25%','50%','75%'],
                'Valor':[mean_res,std_res,skew_res,kurt_res,q25,q50,q75]
            })
            self.sections.append((
                f"### Random Forest Optimizado: Estadísticas de Residuos ({best_row['Selección X']}-{best_row['Motor']})", df_stats
            ))

            # Análisis generativo IA de calidad de ajuste
            print("[DEBUG] 15.4. Llamando IA para análisis de curvas Random Forest")
            prompt_curves_rf = (
                f"Para el Random Forest optimizado (selección {best_row['Selección X']}, motor {best_row['Motor']}), tiene:\n"
                f"- Rango Y real: [{y_true.min():.4f}, {y_true.max():.4f}]\n"
                f"- Rango Y pred: [{y_pred.min():.4f}, {y_pred.max():.4f}]\n"
                f"- Residuales: media={mean_res:.4f}, std={std_res:.4f}, skew={skew_res:.4f}, kurtosis={kurt_res:.4f}, quantiles 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}.\n"
                "1. Analiza la gráfica Predicho vs Real y comenta sobre sesgo o varianza.\n"
                "2. Interpreta la distribución de residuos: sesgos sistemáticos, heterocedasticidad y normalidad.\n"
                "3. Sugiere acciones para mejorar el ajuste si detectas problemas (p.ej. más árboles, regularización, más datos...)."
            )
            analysis_curves_rf = call_openai_explanation(prompt_curves_rf)
            self.sections.append((
                '### Random Forest Optimizado: Análisis Calidad Ajuste', analysis_curves_rf
            ))
            # --- Fin bloque 1 ---

            # --- 2. Importancia Relativa de Hiperparámetros para Random Forest Optimizado ---
            from sklearn import utils
            import seaborn as sns

            print("[DEBUG] 15.5. Iniciando bloque de Importancia Relativa de Hiperparámetros para RF optimizado")

            # Construir matriz Score vs n_estimators y max_depth para heatmap
            # (si existen ambos hiperparámetros en Best_Params)
            params_for_heat = ['n_estimators', 'max_depth']
            heat_records = []
            for r in summary_rf:
                bp = r['Best_Params']
                if all(p in bp for p in params_for_heat):
                    heat_records.append({
                        'n_estimators': bp['n_estimators'],
                        'max_depth':    bp['max_depth'],
                        'Score':        r['Score']
                    })
            if heat_records:
                df_heat = pd.DataFrame(heat_records)
                heat = df_heat.pivot(index='n_estimators', columns='max_depth', values='Score')
                fig_heat, ax_heat = plt.subplots(figsize=(6,5))
                sns.heatmap(heat, annot=True, fmt='.4f', ax=ax_heat)
                ax_heat.set_title('RF Optimizado: Heatmap Score vs n_estimators y max_depth')
                self.sections.append((
                    '### RF Optimizado: Heatmap Score vs n_estimators & max_depth', fig_heat
                ))

            # Sensibilidad ±10% sobre cada hiperparámetro de cada entrada
            sens = []
            for r in summary_rf:
                base_score = r['Score']
                bp = r['Best_Params']
                for param, base_val in bp.items():
                    if isinstance(base_val, (int, float)):
                        for factor, label in [(1.1, '+10%'), (0.9, '-10%')]:
                            sens.append({
                                'Parámetro': param,
                                'Cambio':    label,
                                '% Δ Score': (base_score * factor - base_score) / abs(base_score) * 100,
                                'Selección X': r['Selección X'],
                                'Motor':      r['Motor']
                            })
            if sens:
                df_sens = pd.DataFrame(sens)
                fig_sens, ax_sens = plt.subplots(figsize=(6,4))
                sns.barplot(data=df_sens, x='% Δ Score', y='Parámetro', hue='Cambio', ax=ax_sens)
                ax_sens.set_title('RF Optimizado: Sensibilidad del Score ±10%')
                self.sections.append((
                    '### RF Optimizado: Sensibilidad del Score', fig_sens
                ))

            # IA: explicar qué parámetro impulsa más mejora y por qué
            print("[DEBUG] 15.6. Llamando IA para importancia de hiperparámetros RF")
            lines = [f"{row['Parámetro']} {row['Cambio']} → {row['% Δ Score']:.2f}%"
                    for row in sens if row['Selección X']==best_row['Selección X'] and row['Motor']==best_row['Motor']]
            prompt_hp_rf = (
                "Sensibilidad del Score al ±10% para el mejor RF optimizado "
                f"(selección {best_row['Selección X']}, motor {best_row['Motor']}):\n" +
                "\n".join(lines) +
                "\n\n1. ¿Qué hiperparámetro impulsa más la mejora y por qué?\n"
                "2. Sugiere focos de ajuste prioritarios basados en esta sensibilidad."
            )
            analysis_hp_rf = call_openai_explanation(prompt_hp_rf)
            self.sections.append((
                '### RF Optimizado: IA Importancia Hiperparámetros', analysis_hp_rf
            ))
            # ---- Fin bloque 2 ----

            # --- 3. Distribución de Métricas en Validación Cruzada para Random Forest Optimizado ---
            from sklearn.model_selection import cross_validate
            print("[DEBUG] 15.7. Calculando distribución de métricas CV para Random Forest optimizado")

            # Identificar mejor configuración
            best_idx_rf = df_rf['Score'].idxmax()
            best_row_rf = summary_rf[best_idx_rf]

            payload_raw = OPT_MODELS[('rf', best_row_rf['Selección X'], best_row_rf['Motor'])]
            p = _normalize_payload(payload_raw)

            model_cv = p['model']
            sx_cv    = p['sx']
            cols_cv  = p['cols']

            # Preparar datos de entrenamiento escalados
            X_cv = X_train[cols_cv].copy()
            y_cv = Y_train.values.ravel()
            if sx_cv:
                X_cv_scaled = sx_cv.transform(X_cv)
            else:
                X_cv_scaled = X_cv

            # Cross-validate con métricas múltiples
            cv_results_rf = cross_validate(
                model_cv, X_cv_scaled, y_cv,
                cv=5,
                scoring={
                    'r2':'r2',
                    'neg_mse':'neg_mean_squared_error',
                    'neg_mae':'neg_mean_absolute_error'
                },
                return_train_score=False
            )

            # Procesar resultados
            r2_scores_rf  = cv_results_rf['test_r2']
            mse_scores_rf = [-v for v in cv_results_rf['test_neg_mse']]
            mae_scores_rf = [-v for v in cv_results_rf['test_neg_mae']]
            rmse_scores_rf = np.sqrt(mse_scores_rf)

            df_cv_rf = pd.DataFrame({
                'R2': r2_scores_rf,
                'MSE': mse_scores_rf,
                'MAE': mae_scores_rf,
                'RMSE': rmse_scores_rf
            })

            # 3.1 Boxplot de métricas por fold
            fig_cv_rf, ax_cv_rf = plt.subplots(figsize=(6,4))
            sns.boxplot(data=df_cv_rf, ax=ax_cv_rf)
            ax_cv_rf.set_title('RF Optimizado: Distribución de Métricas CV')
            self.sections.append((
                '### Random Forest Optimizado: Distribución de Métricas CV', fig_cv_rf
            ))

            # 3.2 Tabla con media ± desviación
            stats_cv_rf = df_cv_rf.agg(['mean','std']).T.reset_index().rename(columns={
                'index':'Métrica','mean':'Media','std':'Desviación'
            })
            self.sections.append((
                '### Random Forest Optimizado: Estadísticas CV por Fold', stats_cv_rf
            ))

            # 3.3 Análisis Generativo IA de Estabilidad CV
            print("[DEBUG] 15.8. Llamando IA para estabilidad CV Random Forest")
            prompt_cv_rf = (
                f"Validación cruzada 5 folds RF optimizado (Selección {best_row_rf['Selección X']}, Motor {best_row_rf['Motor']}):\n"
                f"- R2 por fold: {r2_scores_rf.tolist()} \n"
                f"- MAE por fold: {mae_scores_rf}\n"
                f"- RMSE por fold: {rmse_scores_rf}\n"
                "Analiza la dispersión de cada métrica y comenta sobre la estabilidad y generalización del modelo."
            )
            analysis_cv_rf = call_openai_explanation(prompt_cv_rf)
            self.sections.append((
                '### Random Forest Optimizado: Análisis Estabilidad CV', analysis_cv_rf
            ))
            # --- Fin Bloque 3 ---

            # --- 4. Curvas de Aprendizaje y Validación para Random Forest Optimizado ---
            from sklearn.model_selection import learning_curve, validation_curve
            import numpy as np

            print("[DEBUG] 15.9. Iniciando bloque de Curvas de Aprendizaje y Validación para Random Forest optimizado")

            # Seleccionar mejor configuración según Score
            best_idx = df_rf['Score'].idxmax()
            best_row = summary_rf[best_idx]

            payload_raw = OPT_MODELS[('rf', best_row['Selección X'], best_row['Motor'])]
            p = _normalize_payload(payload_raw)

            model_rf = p['model']
            sx_rf    = p['sx']
            cols_rf  = p['cols']

            # Preparar datos de entrenamiento escalados
            X_train_sel = X_train[cols_rf]
            y_train = Y_train.values.ravel()
            X_train_scaled = sx_rf.transform(X_train_sel) if sx_rf else X_train_sel

            # 4.1 Curva de Aprendizaje (R²)
            train_sizes, train_scores, val_scores = learning_curve(
                model_rf, X_train_scaled, y_train,
                cv=5, scoring='r2', train_sizes=np.linspace(0.1,1.0,5), n_jobs=-1
            )
            train_mean = np.mean(train_scores, axis=1)
            val_mean   = np.mean(val_scores,   axis=1)
            fig_lc, ax_lc = plt.subplots(figsize=(6,4))
            ax_lc.plot(train_sizes, train_mean, 'o-', label='Train R²')
            ax_lc.plot(train_sizes, val_mean,   'o-', label='CV R²')
            ax_lc.set_title('RF Optimizado: Curva de Aprendizaje')
            ax_lc.set_xlabel('Tamaño del set de entrenamiento')
            ax_lc.set_ylabel('R²')
            ax_lc.legend()
            self.sections.append((
                '### RF Optimizado: Curva de Aprendizaje', fig_lc
            ))

            # Función auxiliar para Curvas de Validación
            def plot_vc(param_name, param_range):
                  # Ajuste: validation_curve devuelve solo train_scores y test_scores
                train_scores_vc, val_scores_vc = validation_curve(
                    model_rf, X_train_scaled, y_train,
                    param_name=param_name, param_range=param_range,
                    cv=5, scoring='r2', n_jobs=-1
                )
                fig, ax = plt.subplots(figsize=(6,4))
                ax.plot(param_range, np.mean(train_scores_vc, axis=1), 'o-', label='Train R²')
                ax.plot(param_range, np.mean(val_scores_vc, axis=1), 'o-', label='CV R²')
                ax.set_title(f"RF Optimizado: Curva de Validación {param_name}")
                ax.set_xlabel(param_name)
                ax.set_ylabel('R²')
                if param_name == 'n_estimators':
                    ax.set_xscale('log')
                ax.legend()
                return fig, train_scores_vc, val_scores_vc

            # 4.2 Curva de Validación n_estimators
            param_range_n = np.arange(50, 501, 50)
            fig_vc_n, tsn, vsn = plot_vc('n_estimators', param_range_n)
            self.sections.append((
                '### RF Optimizado: Curva de Validación n_estimators', fig_vc_n
            ))

            # 4.3 Curva de Validación max_depth
            param_range_md = np.arange(3, 16, 2)
            fig_vc_md, tsm, vsm = plot_vc('max_depth', param_range_md)
            self.sections.append((
                '### RF Optimizado: Curva de Validación max_depth', fig_vc_md
            ))

            # 4.4 Interpretación IA de Curvas
            print("[DEBUG] 15.10. Llamando IA para análisis de curvas Random Forest")
            prompt_curvas_rf = (
                f"Random Forest optimizado (Selección {best_row['Selección X']}, Motor {best_row['Motor']}):\n"
                f"- Curva de Aprendizaje: tamaños={train_sizes.tolist()}, train={train_mean.tolist()}, cv={val_mean.tolist()}\n"
                f"- Curva de Validación n_estimators: {param_range_n.tolist()}, train={np.mean(tsn,axis=1).tolist()}, cv={np.mean(vsn,axis=1).tolist()}\n"
                f"- Curva de Validación max_depth: {param_range_md.tolist()}, train={np.mean(tsm,axis=1).tolist()}, cv={np.mean(vsm,axis=1).tolist()}\n\n"
                "1. Analiza cada curva e identifica underfitting o overfitting.\n"
                "2. Señala brechas clave entre entrenamiento y validación y su impacto en la generalización.\n"
                "3. Recomienda ajustes concretos de n_estimators y max_depth para mejorar el modelo."
            )
            analysis_vc_rf = call_openai_explanation(prompt_curvas_rf)
            self.sections.append((
                '### RF Optimizado: Interpretación IA de Curvas de Aprendizaje y Validación', analysis_vc_rf
            ))
            # --- Fin Bloque 4 ---

            # --- 5. Curvas de Calibración y Predicción de Intervalos para Random Forest Optimizado ---
            from sklearn.calibration import calibration_curve
            import pandas as _pd

            print("[DEBUG] 15.11. Iniciando bloque de Curvas de Calibración y Predicción de Intervalos para Random Forest optimizado")

            # Preparar datos de prueba
            y_true_rf = Y_test.values.ravel()
            y_pred_scaled = model_rf.predict(X_test[cols_rf])
            y_pred_rf = sy_rf.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel() if sy_rf else y_pred_scaled

            # 5.1 Curva de calibración (binned reliability plot para regresión)
            bins = 10
            df_cal = _pd.DataFrame({'y_pred': y_pred_rf, 'y_true': y_true_rf})
            try:
                df_cal['bin'] = _pd.qcut(df_cal['y_pred'], q=bins, duplicates='drop')
            except:
                df_cal['bin'] = _pd.cut(df_cal['y_pred'], bins=bins)
            grp = df_cal.groupby('bin', observed=True).agg({'y_pred': 'mean', 'y_true': 'mean'})
            prob_pred, prob_true = grp['y_pred'].values, grp['y_true'].values
            fig_cal, ax_cal = plt.subplots(figsize=(6, 4))
            ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2)
            ax_cal.plot([prob_pred.min(), prob_pred.max()], [prob_pred.min(), prob_pred.max()], 'k--')
            ax_cal.set_xlabel('Predicción promedio en bin')
            ax_cal.set_ylabel('Valor real promedio')
            ax_cal.set_title('RF Optimizado: Curva de Calibración')
            self.sections.append((
                '### RF Optimizado: Curva de Calibración', fig_cal
            ))

            # 5.2 Intervalos de predicción ±1 STD de residuos
            residuals_rf = y_true_rf - y_pred_rf
            std_res_rf = np.std(residuals_rf)
            upper_rf = y_pred_rf + std_res_rf
            lower_rf = y_pred_rf - std_res_rf
            fig_int, ax_int = plt.subplots(figsize=(6, 4))
            ax_int.plot(y_true_rf, label='Y real')
            ax_int.plot(y_pred_rf, label='Predicción')
            ax_int.fill_between(range(len(y_pred_rf)), lower_rf, upper_rf, alpha=0.3, label='±1 STD residuo')
            ax_int.set_xlabel('Índice de muestra')
            ax_int.set_ylabel('Valor')
            ax_int.set_title('RF Optimizado: Intervalos de Predicción')
            ax_int.legend()
            self.sections.append((
                '### RF Optimizado: Intervalos de Predicción', fig_int
            ))

            # 5.3 Análisis Generativo IA de Incertidumbre y Calibración
            print("[DEBUG] 15.12. Llamando IA para análisis de incertidumbre y calibración RF optimizado")
            prompt_ci_rf = (
                f"Curva de calibración (pred:{prob_pred.tolist()}, real:{prob_true.tolist()}) y "
                f"intervalos ±1 STD (std_res={std_res_rf:.4f}).\n"
                "1. Evalúa la fiabilidad de los intervalos de incertidumbre.\n"
                "2. Identifica infravaloración de errores altos o patrones de heterocedasticidad.\n"
                "3. Sugiere mejoras para la calibración y estimación de incertidumbre."
            )
            analysis_ci_rf = call_openai_explanation(prompt_ci_rf)
            self.sections.append((
                '### RF Optimizado: Análisis de Incertidumbre y Calibración', analysis_ci_rf
            ))
            # --- Fin Bloque 5 ---

            # --- 6. Resumen Ejecutivo y Road-Map de Siguientes Pasos para Random Forest Optimizado ---
            print("[DEBUG] 15.13. Iniciando bloque de Resumen Ejecutivo y Road-Map para Random Forest optimizado")
            # Variables clave
            sel_rf    = best_row['Selección X']
            eng_rf    = best_row['Motor']
            best_score_rf = best_row['Score']
            # Estadísticas de residuos y validación
            cv_std    = float(np.std(val_mean))
            res_std   = std_res_rf
            res_kurt  = kurtosis(residuals_rf)
            q25_rf, q50_rf, q75_rf = [float(x) for x in np.quantile(residuals_rf, [0.25,0.5,0.75])]

            summary_md_rf = (
                "**Puntos Clave Optimización Random Forest:**\n "
                f"- **Mejor combinación:** Selección `{sel_rf}` + motor `{eng_rf}` ➜ **Score** = {best_score_rf:.4f}\n"
                f"- **Robustez del modelo:** desviación estándar CV = {cv_std:.4f}, std residuos = {res_std:.4f}\n"
                f"- **Curtosis de residuos:** {res_kurt:.4f}, quantiles (25%,50%,75%) = ({q25_rf:.4f},{q50_rf:.4f},{q75_rf:.4f})\n"
                "- **Recomendaciones inmediatas:**\n"
                "  1. Ajustar `n_estimators` y `max_depth` según el balance sesgo-varianza observado.\n"
                "  2. Explorar regularización adicional (`min_samples_split`, `min_samples_leaf`) para reducir varianza.\n"
                "  3. Ampliar validación cruzada a 7–10 folds e incluir `oob_score` para medir robustez.\n"
                "  4. Considerar ensambles adicionales (e.g., GradientBoosting, LightGBM) para comparar rendimiento"
            )
            self.sections.append((
                '### RF Optimizado: Resumen Ejecutivo y Road-Map', summary_md_rf
            ))

            print("[DEBUG] 15.14. Llamando IA para Resumen Ejecutivo y Road-Map RF optimizado")
            prompt_exec_rf = (
                "Eres un investigador de Machine Learning avanzado. Basándote en los puntos clave de optimización:\n"
                f"{summary_md_rf}\n"
                "1. Desarrolla un análisis detallado en párrafos separados para cada punto clave.\n"
                "2. Propón un plan de acción prioritizado de 3–5 pasos claros para stakeholders.\n"
                "3. Finaliza con un breve resumen ejecutivo de 2–3 párrafos enfatizando impacto y próximos hitos."
            )
            analysis_exec_rf = call_openai_explanation(prompt_exec_rf)
            self.sections.append((
                '### RF Optimizado: Resumen Ejecutivo IA', analysis_exec_rf
            ))
            # --- Fin Bloque 6 ---

        except Exception as e:
            self.sections.append((
                '### ⚠️ Error en sección Optimización Random Forest',
                f"Se produjo un error en Optimización Random Forest: {e}"
            ))

        # =============================================================================
        # 16. Optimización Modelo RNN
        # =============================================================================
        import numpy as np
        # --- Bloque 0: Resumen Optimización RNN ---
        try:
            print("[DEBUG] 16.1. Bloque 0 Optimización RNN: Resumen de métodos y motores")

            # Función de invocación a OpenAI (igual que en SVR, NN, XGBoost, RF)
            def call_openai_explanation(prompt: str, model: str = "gpt-4") -> str:
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content":
                                "Eres un experto en optimización de hiperparámetros de redes neuronales recurrentes. "
                                "Analiza y ofrece conclusiones detalladas basadas en los datos proporcionados."
                            },
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS
                    )
                    return response.choices[0].message.content.strip()
                except Exception as e:
                    return f"[Error llamando a OpenAI: {e}]"

            # 0.1) Verificar resultados en OPT_MODELS
            if 'OPT_MODELS' not in globals() or not isinstance(OPT_MODELS, dict):
                raise RuntimeError("No se encontró OPT_MODELS con resultados de optimización RNN")

            valid_engines = {'RandomSearch', 'Bayesian', 'Hyperband', 'Optuna'}
            rnn_entries = {
                k: v for k, v in OPT_MODELS.items()
                if isinstance(k, tuple) and k[0] == 'rnn' and k[2] in valid_engines
            }
            if not rnn_entries:
                raise RuntimeError("No se encontraron optimizaciones RNN en OPT_MODELS")

            # ——— Normalizar payload del mejor RNN para todos los bloques ———
            # Elegimos la clave que maximiza/minimiza el score según la métrica
            # (usamos la misma lógica que df_sel, pero sobre rnn_entries)
            keys = list(rnn_entries.keys())
            scores = [rnn_entries[k]['score'] for k in keys]
            metrics = [rnn_entries[k].get('metric','').upper() for k in keys]
            if metrics[0] == 'R2':
                best_idx = int(np.argmax(scores))
            else:
                best_idx = int(np.argmin(scores))
            best_key = keys[best_idx]

            payload_raw      = OPT_MODELS[best_key]
            p                = _normalize_payload(payload_raw)
            model_rnn        = p['model']
            sx_rnn, sy_rnn   = p.get('sx'), p.get('sy')
            cols_rnn         = p['cols']
            score_rnn        = p['score']
            metric_rnn       = p['metric']
            best_params_rnn  = p['best_params']
            # ——— fin normalización ———

            # 0.2) Construir lista de registros resumen
            summary_records = []
            for (_, metodo, motor), payload in rnn_entries.items():
                score = payload.get('score')
                # Extraer hiperparámetros óptimos
                best_est = payload.get('best')
                if best_est is not None and hasattr(best_est, 'get_params'):
                    params = best_est.get_params()
                else:
                    params = payload.get('params', {}) or payload.get('best_params', {})

                # Sólo los hiperparámetros relevantes
                hp_keys = ['units', 'dropout_rate', 'learning_rate', 'epochs', 'batch_size']
                best_hp = {k: params.get(k) for k in hp_keys if k in params}

                # Añadir registro
                rec = {
                    'Método': metodo,
                    'Motor': motor,
                    'metric': payload.get('metric'),  # ← aquí incluyes la métrica
                    'Score': score
                }
                rec.update({f"Best_{k}": v for k, v in best_hp.items()})
                summary_records.append(rec)

            # 0.3) DataFrame de resumen
            df_rnn = pd.DataFrame(summary_records)
            df_rnn.rename(
                columns={col: col.replace("Best_", "") for col in df_rnn.columns if col.startswith("Best_")},
                inplace=True
            )
            self.sections.append((
                "### RNN Optimización: Resumen de Métodos y Motores",
                df_rnn
            ))

            # 0.4) Preparar prompt para IA
            prompt_lines = []
            for rec in summary_records:
                hp_str = ", ".join(f"{k}={rec[f'Best_{k}']}" for k in best_hp.keys())
                prompt_lines.append(
                    f"Método: {rec['Método']}, Motor: {rec['Motor']}, "
                    f"Score: {rec['Score']:.4f}, Hiperparámetros: {hp_str}"
                )
            prompt = (
                "He obtenido los siguientes resultados de optimización para el modelo RNN:\n\n"
                + "\n".join(prompt_lines)
                + "\n\n"
                "1. Describe en detalle las fortalezas y debilidades de cada motor de búsqueda "
                "(RandomSearch, Bayesian, Hyperband, Optuna) aplicado a RNN.\n"
                "2. Compara los scores y explica por qué una configuración es superior.\n"
                "3. Analiza el impacto de los hiperparámetros optimizados en entrenamiento y generalización.\n"
                "4. Propón estrategias avanzadas para mejorar la RNN "
                "(learning‐rate scheduling, regularización, early stopping, augmentation de series temporales).\n"
                "5. Sugiere un roadmap de próximos pasos para validar robustez y escalar el modelo."
            )

            print("[DEBUG] 16.2. Llamando a OpenAI para análisis generativo RNN optimización")
            analysis = call_openai_explanation(prompt)
            self.sections.append((
                "### RNN Optimización: Análisis Generativo",
                analysis
            ))
            # --- Fin Bloque 0 ---

            # --- 1. Curvas de Ajuste Real vs. Predicho y Residuos para Random Forest Optimizado ---
            try:
                print("[DEBUG] 16.3. Iniciando Bloque 1: Curvas Real vs Predicho y Residuos RNN Optimizado")

                # ========== Cargar modelo RNN entrenado desde metadatos ==========
                import pickle, glob

                # Buscar el archivo más reciente para el método y motor seleccionados
                archivos_meta = sorted(glob.glob(f"modelos_opt/rnn_{metodo.lower()}_{motor.lower()}_opt_*.pkl"))
                if not archivos_meta:
                    raise FileNotFoundError(f"No se encontró el archivo de metadatos para {metodo} + {motor}")
                archivo_meta = archivos_meta[-1]

                # Cargar metadatos
                with open(archivo_meta, "rb") as f:
                    metadata = pickle.load(f)

                # Reconstruir ruta al modelo .keras
                ts = metadata["fecha"]
                ruta_modelo = f"modelos_opt/rnn_{metodo.lower()}_{motor.lower()}_opt_{ts}.keras"

                # Cargar modelo
                model_rnn = load_model(ruta_modelo)


                import pickle
                from scipy.stats import skew, kurtosis
                from sklearn.metrics import r2_score
                import matplotlib.pyplot as plt
                from tensorflow.keras.models import load_model

                # 1.1 Seleccionar la mejor configuración según la métrica
                # Reconstruimos un pequeño DataFrame para elegir el mejor índice
                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
                df_sel = pd.DataFrame([
                    {
                        'Método': k[1],
                        'Motor':  k[2],
                        'Score':  v['score'],
                        'Métrica': v['metric']
                    }
                    for k, v in OPT_MODELS.items()
                    if k[0]=='rnn' and k[2] in valid_engines
                ])
                if df_sel.empty:
                    raise RuntimeError("No hay optimizaciones RNN registradas en OPT_MODELS")
                # Elegir mejor row
                if df_sel['Métrica'].str.upper().iloc[0] == 'R2':
                    idx_best = df_sel['Score'].idxmax()
                else:
                    idx_best = df_sel['Score'].idxmin()
                best_row = df_sel.loc[idx_best]
                metodo   = best_row['Método']
                motor    = best_row['Motor']

                # 1.1bis) Extraer los params del payload en lugar de Best_*
                payload    = OPT_MODELS[('rnn', metodo, motor)]
                # si guardaste 'params' en OPT_MODELS…
                params     = payload.get('params') or payload['best'].get_params()
                # sólo las cinco keys que nos interesan
                hp_keys    = ['units','dropout_rate','learning_rate','epochs','batch_size']
                best_params = { k: params[k] for k in hp_keys }

                # 1.2 Cargar payload y metadatos
                # Usamos el payload normalizado:
                model     = model_rnn
                sx        = sx_rnn
                sy        = sy_rnn
                cols      = cols_rnn

                # ——— Sanitización unificada de columnas para RNN ———
                raw_cols_rnn       = cols_rnn      # viene de _normalize_payload
                sanitized_cols_rnn = [sanitize_name(c) for c in raw_cols_rnn]
                effective_cols     = [c for c in sanitized_cols_rnn if c in X_test.columns]
                print(f"[DEBUG] 16.4. RNN cols esperadas: {len(raw_cols_rnn)}, sanitizadas válidas: {len(effective_cols)} → {effective_cols}")

                # ✔️ Se mantiene: comprobación del modelo
                from tensorflow.keras.models import Sequential
                if not isinstance(model_rnn, Sequential):
                    raise TypeError("[ERROR] El objeto 'model_rnn' no es un modelo válido de Keras. ¿Se ha sobrescrito accidentalmente?")

                # ========== Verificar columnas ==========
                expected_cols = cols_rnn
                actual_cols = [c for c in expected_cols if c in X_test.columns]
                print(f"[DEBUG] 16.5. RNN cols esperadas: {len(expected_cols)}, sanitizadas válidas: {len(actual_cols)} → {actual_cols}")

                if len(actual_cols) != len(expected_cols):
                    raise ValueError(
                        f"[ERROR] Las columnas del modelo RNN ({len(expected_cols)} esperadas) "
                        f"no coinciden con las disponibles en X_test ({len(actual_cols)} encontradas)."
                        f"\nEsperadas: {expected_cols}\nEncontradas: {actual_cols}"
                    )

                # ========== Escalar y preparar datos ==========
                X_test_sel_df = X_test[actual_cols]
                X_scaled = sx_rnn.transform(X_test_sel_df.values)
                print(f"[DEBUG] 16.6. X_scaled.shape = {X_scaled.shape}")
                print(f"[DEBUG] 16.7. n_samples = {X_scaled.shape[0]}, n_features = {X_scaled.shape[1]}")

                X3_test = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))
                print(f"[DEBUG] 16.8. X3_test.shape = {X3_test.shape}")
                print("[DEBUG] 16.9. Llamando a model_rnn.predict con entrada:", X3_test.shape)

                # ========== Predicción ==========
                y_pred_raw = model_rnn.predict(X3_test).ravel()

                print(f"[DEBUG] 16.10. X3_test.shape = {X3_test.shape}")
                print("[DEBUG] 16.11. Llamando a model_rnn.predict con entrada:", X3_test.shape)

                y_pred     = sy_rnn.inverse_transform(y_pred_raw.reshape(-1,1)).ravel() if sy_rnn else y_pred_raw
                y_true     = Y_test.values.ravel()

                # 1.4 Gráfica Predicho vs Real
                fig1, ax1 = plt.subplots(figsize=(6,4))
                ax1.scatter(y_true, y_pred, alpha=0.6)
                ax1.plot([y_true.min(), y_true.max()],
                        [y_true.min(), y_true.max()],
                        'r--', linewidth=2, label='Ideal')
                ax1.set_xlabel("Y real")
                ax1.set_ylabel("Y predicho")
                ax1.set_title(f"RNN Optimizado ({metodo}-{motor}) Predicho vs Real")
                ax1.legend()
                self.sections.append((
                    f"### RNN Optimizado: Predicho vs Real ({metodo}-{motor})",
                    fig1
                ))

                # 1.5 Gráfica de Residuos
                residuals = y_true - y_pred
                fig2, ax2 = plt.subplots(figsize=(6,4))
                ax2.scatter(y_pred, residuals, alpha=0.6)
                ax2.axhline(0, color='r', linestyle='--', linewidth=2)
                ax2.set_xlabel("Y predicho")
                ax2.set_ylabel("Residuo")
                ax2.set_title(f"RNN Optimizado ({metodo}-{motor}) Residuos")
                self.sections.append((
                    f"### RNN Optimizado: Residuos ({metodo}-{motor})",
                    fig2
                ))

                # 1.6 Tabla de estadísticas de residuos
                stats_df = pd.DataFrame({
                    'Métrica': ['Media', 'Desviación', 'Skew', 'Kurtosis', '25%', '50%', '75%'],
                    'Valor': [
                        residuals.mean(),
                        residuals.std(),
                        skew(residuals),
                        kurtosis(residuals),
                        *np.quantile(residuals, [0.25, 0.5, 0.75])
                    ]
                })
                self.sections.append((
                    f"### RNN Optimizado: Estadísticas de Residuos ({metodo}-{motor})",
                    stats_df
                ))

                # 1.7 Análisis generativo con IA
                prompt = (
                    f"Para el mejor RNN optimizado (Método={metodo}, Motor={motor}) tenemos:\n"
                    f"- Rango Y real: [{y_true.min():.4f}, {y_true.max():.4f}]\n"
                    f"- Rango Y predicho: [{y_pred.min():.4f}, {y_pred.max():.4f}]\n"
                    f"- Estadísticas de residuos: media={residuals.mean():.4f}, "
                    f"std={residuals.std():.4f}, skew={skew(residuals):.4f}, "
                    f"kurtosis={kurtosis(residuals):.4f}, "
                    f"quantiles25/50/75={[f'{q:.4f}' for q in np.quantile(residuals,[0.25,0.5,0.75])]}.\n\n"
                    "1. Analiza la calidad del ajuste considerando ambas gráficas: identifica sesgos o heterocedasticidad.\n"
                    "2. Comenta sobre la normalidad de los errores.\n"
                    "3. Propón ajustes de HPO o transformaciones de datos para mejorar la RNN."
                )
                print("[DEBUG] 16.12. Llamando a OpenAI para análisis de curvas RNN optimizado")
                analysis = call_openai_explanation(prompt)
                self.sections.append((
                    "### RNN Optimizado: Análisis Calidad Ajuste",
                    analysis
                ))

            except Exception as e:
                # 1) Imprime la excepción para trazar el error
                print(f"[DEBUG] Error Bloque 1 Optimización RNN: {e}")
                # 2) Luego sigues registrando la sección de error como antes
                self.sections.append((
                    "### ⚠️ Error Bloque 1 Optimización RNN",
                    f"Se produjo un error en Curvas Real vs Predicho y Residuos RNN: {e}"
                ))
            # --- Fin Bloque 1 ---
            # --- 2. Importancia Relativa de Hiperparámetros para RNN Optimizado ---
            try:
                print("[DEBUG] 16.13. Iniciando bloque 2: Importancia de Hiperparámetros RNN Optimizado")

                import seaborn as sns
                from sklearn.metrics import r2_score
                import pickle

                # --- a) Recuperar el best_row del bloque 1 ---
                # (Asegúrate de que best_row lo tienes en el scope, ó bien vuelve a
                #  reconstruir tu pequeño df_sel y lo vuelves a extraer)
                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
                df_sel = pd.DataFrame([
                    {'Método':k[1], 'Motor':k[2], 'Score':v['score'], 'Métrica':v['metric']}
                    for k,v in OPT_MODELS.items()
                    if k[0]=='rnn' and k[2] in valid_engines
                ])
                if df_sel['Métrica'].str.upper().iloc[0]=='R2':
                    idx_best = df_sel['Score'].idxmax()
                else:
                    idx_best = df_sel['Score'].idxmin()
                best_row = df_sel.loc[idx_best]

                # --- b) Recuperar payload y metadatos de OPT_MODELS ---
                key = ('rnn', best_row['Método'], best_row['Motor'])
                payload = OPT_MODELS[key]

                # 2.1) **Carga aquí** los scalers que guardaste
                # Usamos el payload normalizado:
                model     = model_rnn
                sx        = sx_rnn
                sy        = sy_rnn
                cols      = cols_rnn

                # 2.2) ahora extrae base_score y best_params
                base_score = payload['score']
                if 'params' in payload and payload['params']:
                    best_params = payload['params']
                else:
                    best_params = payload['best'].get_params()

                # ── Aquí definimos de nuevo los subsets ──
                X_train_sel = X_train[cols]
                Y_train_sel = Y_train.copy()
                X_test_sel  = X_test[cols]
                Y_test_sel  = Y_test.copy()

                # summary_records viene del bloque 0: lista de dicts con Método, Motor, Score y Best_<hp>
                # Lo transformamos en un DataFrame más “usable”
                df_hp = pd.DataFrame([
                    {
                        'Método'       : rec['Método'],
                        'Motor'        : rec['Motor'],
                        'Score'        : rec['Score'],
                        **{hp: rec[f"Best_{hp}"] for hp in ['units','dropout_rate','learning_rate','epochs','batch_size']
                          if f"Best_{hp}" in rec}
                    }
                    for rec in summary_records
                ])

                # 2.1 Heatmap Score vs combinación de dos parámetros continuos, p.e. learning_rate y dropout_rate
                heat_params = ['learning_rate','dropout_rate']
                heat_recs = []
                for _, row in df_hp.iterrows():
                    if all(p in row and pd.notna(row[p]) for p in heat_params):
                        heat_recs.append({
                            heat_params[0]: row[heat_params[0]],
                            heat_params[1]: row[heat_params[1]],
                            'Score':       row['Score']
                        })
                if heat_recs:
                    df_heat = pd.DataFrame(heat_recs)
                    heat = df_heat.pivot(index=heat_params[0], columns=heat_params[1], values='Score')
                    fig_heat, ax_heat = plt.subplots(figsize=(6,5))
                    sns.heatmap(heat, annot=True, fmt=".4f", ax=ax_heat)
                    ax_heat.set_title('RNN Optimizado: Heatmap Score vs learning_rate y dropout_rate')
                    self.sections.append((
                        "### RNN Optimizado: Heatmap Score vs learning_rate & dropout_rate",
                        fig_heat
                    ))

                # 2.2 Sensibilidad ±1% para cada hiperparámetro (reentrenando sobre TEST)
                sens = []
                #for param, base_val in best_params.items():
                for param, base_val in list(best_params.items())[:3]:  # ⚠️ limitar a 3 primeros hiperparámetros para evitar evaluar todos.
                    if isinstance(base_val, (int, float)):
                        #for factor, label in [(1.01, '+1%'), (0.99, '-1%')]:
                        for factor, label in [(1.05, '+5%'), (0.95, '-5%')]:      # Reducción del ±1% al ±5% para evaluar sensibilidad, disminuyendo ciclos de entrenamiento.
                            # Construye nuevos parámetros variando uno solo
                            new_params = best_params.copy()
                            new_params[param] = base_val * factor

                            # Reentrena el modelo con estos new_params
                            model = RNNRegressor(**new_params, sy=sy)
                            model.fit(
                                sx.transform(X_train_sel.values),
                                sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            )
                            # Evalúa en validación (o test, según prefieras)
                            # → aquí uso X_test_sel y Y_test en lugar de X_val_sel/Y_val
                            Xs = sx.transform(X_test_sel.values)
                            X3 = Xs.reshape((Xs.shape[0], 1, Xs.shape[1]))
                            y_hat_scaled = model.predict(Xs)        # el wrapper añade la dimensión del “timesteps=1”
                            y_hat        = sy.inverse_transform(y_hat_scaled.reshape(-1,1)).ravel()
                            new_score    = r2_score(Y_test.values.ravel(), y_hat)

                            sens.append({
                              'Parámetro': param,
                              'Cambio':    label,
                              '% Δ Score': (new_score - base_score) / abs(base_score) * 100,
                              #'% Δ Score': new_score - base_score,
                              'Motor':     best_row['Motor'],
                              'Método':    best_row['Método']
                          })
                if sens:
                    df_sens = pd.DataFrame(sens)
                    fig_sens, ax_sens = plt.subplots(figsize=(6,4))
                    sns.barplot(data=df_sens, x='% Δ Score', y='Parámetro', hue='Cambio', ax=ax_sens)
                    ax_sens.set_title('RNN Optimizado: Sensibilidad del Score ±1%')
                    self.sections.append((
                        "### RNN Optimizado: Sensibilidad del Score",
                        fig_sens
                    ))

                # 2.3 IA: análisis de importancia
                # Filtramos sólo para el mejor (best_row viene de bloque 1)
                lines = []
                for row in sens:
                    if row['Método']==best_row['Método'] and row['Motor']==best_row['Motor']:
                        lines.append(f"{row['Parámetro']} {row['Cambio']} → {row['% Δ Score']:.2f}%")
                prompt_hp_rnn = (
                    f"Sensibilidad del Score al ±10% para el mejor RNN optimizado "
                    f"(método {best_row['Método']}, motor {best_row['Motor']}):\n"
                    + "\n".join(lines)
                    + "\n\n1. ¿Qué hiperparámetro impulsa más la mejora y por qué?\n"
                    "2. Basándote en esta sensibilidad, ¿qué foco de ajuste priorizarías?"
                )
                print("[DEBUG] 16.14. Llamando a OpenAI para importancia de hiperparámetros RNN")
                analysis_hp_rnn = call_openai_explanation(prompt_hp_rnn)
                self.sections.append((
                    "### RNN Optimizado: IA Importancia Hiperparámetros",
                    analysis_hp_rnn
                ))

            except Exception as e:
                self.sections.append((
                    "### ⚠️ Error Bloque 2 Optimización RNN",
                    f"Se produjo un error en Importancia de Hiperparámetros RNN: {e}"
                ))
            # --- Fin Bloque 2 ---
            # --- 3. Distribución de Métricas en Validación Cruzada para RNN Optimizado ---
            try:
                print("[DEBUG] 16.15. Iniciando bloque 3: Distribución de Métricas CV para RNN Optimizado")

                import pickle
                from sklearn.model_selection import cross_validate
                from sklearn.pipeline import make_pipeline
                from sklearn.compose import TransformedTargetRegressor
                from sklearn.preprocessing import StandardScaler

                # 3.1) Recuperar payload y metadatos
                cols_cv = cols_rnn

                # 3.2) Pipeline: escalar X → RNNRegressor
                rnn_pipe = make_pipeline(
                    StandardScaler(),    # escala X dentro de cada fold
                    RNNRegressor()       # tu wrapper, sin pasar sy aquí
                )

                # 3.3) TransformedTargetRegressor: para escalar Y dentro de cada fold
                rnn_ttr = TransformedTargetRegressor(
                    regressor   = rnn_pipe,
                    transformer = StandardScaler()
                )

                # 3.4) Ejecutar cross_validate usando directamente el pipeline completo
                cv_results = cross_validate(
                    rnn_ttr,
                    X_train[cols_cv].values,
                    Y_train.values.ravel(),
                    #cv=5,
                    cv=3,                                      # AÑADIDO PARA ALIGERAR LOS CICLOS DE ENTRENAMIENTO CRUZADO
                    scoring={
                        'r2':      'r2',
                        'neg_mse': 'neg_mean_squared_error',
                        'neg_mae': 'neg_mean_absolute_error'
                    },
                    return_train_score=False
                )

                # 3.5) Formatear resultados
                r2_scores  = cv_results['test_r2']
                mse_scores = [-v for v in cv_results['test_neg_mse']]
                mae_scores = [-v for v in cv_results['test_neg_mae']]
                rmse_scores = np.sqrt(mse_scores)

                df_cv = pd.DataFrame({
                    'R2':   r2_scores,
                    'MSE':  mse_scores,
                    'MAE':  mae_scores,
                    'RMSE': rmse_scores
                })

                # 3.6) Boxplot
                fig_cv, ax_cv = plt.subplots(figsize=(6,4))
                sns.boxplot(data=df_cv, ax=ax_cv)
                ax_cv.set_title('RNN Optimizado: Distribución de Métricas CV')
                self.sections.append((
                    '### RNN Optimizado: Distribución de Métricas CV', fig_cv
                ))

                # 3.7) Tabla de media ± desviación
                stats_cv = df_cv.agg(['mean','std']).T.reset_index().rename(columns={
                    'index':'Métrica','mean':'Media','std':'Desviación'
                })
                self.sections.append((
                    '### RNN Optimizado: Estadísticas CV por Fold', stats_cv
                ))

                # 3.8) Análisis generativo
                prompt_cv = (
                    f"Validación cruzada 5 folds RNN optimizado (Método={best_row['Método']}, "
                    f"Motor={best_row['Motor']}):\n"
                    f"- R2 por fold: {r2_scores.tolist()}\n"
                    f"- MSE por fold: {mse_scores}\n"
                    f"- MAE por fold: {mae_scores}\n"
                    f"- RMSE por fold: {rmse_scores}\n\n"
                    "Analiza la estabilidad y generalización de la RNN basándote en la dispersión de cada métrica."
                )
                print("[DEBUG] 16.16. Llamando IA para estabilidad CV RNN optimizado")
                analysis_cv = call_openai_explanation(prompt_cv)
                self.sections.append((
                    '### RNN Optimizado: Análisis Estabilidad CV', analysis_cv
                ))

            except Exception as e:
                self.sections.append((
                    "### ⚠️ Error Bloque 3 Optimización RNN",
                    f"Se produjo un error en Distribución de Métricas CV RNN: {e}"
                ))
            # --- Fin Bloque 3 ---

            # --- 4. Curvas de Aprendizaje y Validación para RNN Optimizado ---
            # --- 4. Curvas de Aprendizaje y Validación para RNN Optimizado ---
            try:
                print("[DEBUG] 16.17. Iniciando Bloque 4: Curvas de Aprendizaje y Validación RNN Optimizado")
                import numpy as np
                from sklearn.model_selection import learning_curve, validation_curve
                from sklearn.pipeline import make_pipeline
                from sklearn.compose import TransformedTargetRegressor
                from sklearn.preprocessing import StandardScaler
                import matplotlib.pyplot as plt

                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
                df_sel = pd.DataFrame([
                    {'Método': k[1], 'Motor': k[2], 'Score': v['score'], 'Métrica': v['metric']}
                    for k,v in OPT_MODELS.items()
                    if k[0]=='rnn' and k[2] in valid_engines
                ])
                if df_sel['Métrica'].str.upper().iloc[0] == 'R2':
                    idx_best = df_sel['Score'].idxmax()
                else:
                    idx_best = df_sel['Score'].idxmin()
                best_row = df_sel.loc[idx_best]

                p = _normalize_payload(payload_raw)
                best_params = p.get('best_params', {})
                sx_rnn, sy_rnn = p['sx'], p['sy']
                cols_rnn = p['cols']
                model_rnn = p['model']

                if not best_params:
                    best_params = model_rnn.get_params()
                    print("[DEBUG] Se han obtenido best_params desde model.get_params()")

                # ⚠️ Reducción explícita de carga
                best_params['epochs'] = min(best_params.get('epochs', 100), 20)
                best_params['verbose'] = 0

                rnn_pipe = make_pipeline(
                    StandardScaler(),
                    RNNRegressor(**best_params)
                )
                rnn_ttr = TransformedTargetRegressor(regressor=rnn_pipe, transformer=StandardScaler())

                X_train_sel = X_train[cols_rnn].values[:250]  # ⚠️ limitar tamaño
                y_train = Y_train.values.ravel()[:250]

                from joblib import parallel_backend
                with parallel_backend('threading'):
                    train_sizes, train_scores, val_scores = learning_curve(
                        rnn_ttr, X_train_sel, y_train,
                        cv=2,  # ⚠️ menos folds
                        scoring='r2',
                        train_sizes=np.linspace(0.5, 1.0, 2),  # ⚠️ menos tamaños
                        n_jobs=1
                    )

                train_mean = np.mean(train_scores, axis=1)
                val_mean = np.mean(val_scores, axis=1)

                fig_lc, ax_lc = plt.subplots(figsize=(4.5,2.8))  # ⚠️ más pequeño
                ax_lc.plot(train_sizes, train_mean, 'o-', label='Train R²')
                ax_lc.plot(train_sizes, val_mean, 'o-', label='CV R²')
                ax_lc.set_title('RNN Optimizado: Curva de Aprendizaje')
                ax_lc.set_xlabel('Tamaño del set de entrenamiento')
                ax_lc.set_ylabel('R²')
                ax_lc.legend()
                self.sections.append((
                    '### RNN Optimizado: Curva de Aprendizaje', fig_lc
                ))

                if 'units' not in best_params:
                    raise KeyError("[ERROR] El parámetro 'units' no está presente en best_params. Claves disponibles: " + str(list(best_params.keys())))

                #units_range = np.unique(np.linspace(
                #    max(1, best_params['units']//2),
                #    best_params['units']*2,
                #    2, dtype=int  # ⚠️ solo dos valores
                #))
                #units_range = [best_params['units']]  # ⚠️ evitar validación pesada
                units = best_params['units']
                units_range = np.unique(np.linspace(max(1, units * 0.9), units * 1.1, 3, dtype=int))
                tu, vu = validation_curve(
                    rnn_ttr, X_train_sel, y_train,
                    param_name='regressor__rnnregressor__units',
                    param_range=units_range,
                    cv=2,
                    scoring='r2',
                    n_jobs=1
                )
                fig_uvc, ax_uvc = plt.subplots(figsize=(4.5,2.8))
                ax_uvc.plot(units_range, np.mean(tu,axis=1), 'o-', label='Train R²')
                ax_uvc.plot(units_range, np.mean(vu,axis=1), 'o-', label='CV R²')
                ax_uvc.set_title('RNN Optimizado: Curva de Validación units')
                ax_uvc.set_xlabel('units')
                ax_uvc.set_ylabel('R²')
                ax_uvc.legend()
                self.sections.append((
                    '### RNN Optimizado: Curva de Validación units', fig_uvc
                ))

                dr = best_params['dropout_rate']
                dr_range = np.linspace(max(0.0, dr-0.15), min(1.0, dr+0.15), 2)  # ⚠️ solo dos valores
                td, vd = validation_curve(
                    rnn_ttr, X_train_sel, y_train,
                    param_name='regressor__rnnregressor__dropout_rate',
                    param_range=dr_range,
                    cv=2,
                    scoring='r2',
                    n_jobs=1
                )
                fig_dvc, ax_dvc = plt.subplots(figsize=(4.5,2.8))
                ax_dvc.plot(dr_range, np.mean(td,axis=1), 'o-', label='Train R²')
                ax_dvc.plot(dr_range, np.mean(vd,axis=1), 'o-', label='CV R²')
                ax_dvc.set_title('RNN Optimizado: Curva de Validación dropout_rate')
                ax_dvc.set_xlabel('dropout_rate')
                ax_dvc.set_ylabel('R²')
                ax_dvc.legend()
                self.sections.append((
                    '### RNN Optimizado: Curva de Validación dropout_rate', fig_dvc
                ))

                prompt = (
                    f"Para la RNN optimizada (Método={best_row['Método']}, Motor={best_row['Motor']}):\n"
                    f"- Curva de Aprendizaje: tamaños={train_sizes if isinstance(train_sizes, list) else train_sizes.tolist()}, train R²={train_mean.tolist()}, cv R²={val_mean.tolist()}\n"
                    f"- Validación units: rango={units_range.tolist()}, train={np.mean(tu,axis=1).tolist()}, cv={np.mean(vu,axis=1).tolist()}\n"
                    f"- Validación dropout_rate: rango={dr_range.tolist()}, train={np.mean(td,axis=1).tolist()}, cv={np.mean(vd,axis=1).tolist()}\n\n"
                    "1. Identifica underfitting o overfitting en cada curva.\n"
                    "2. Señala brechas clave y su impacto en la generalización.\n"
                    "3. Recomienda ajustes de units y dropout_rate."
                )
                print("[DEBUG] 16.18. Llamando a OpenAI para análisis de Curvas de Aprendizaje y Validación RNN")
                analysis = call_openai_explanation(prompt)
                self.sections.append((
                    '### RNN Optimizado: Interpretación IA de Curvas', analysis
                ))

            except Exception as e:
                print("[DEBUG] Error en Bloque 4 Optimización RNN:", e)
                self.sections.append((
                    '### ⚠️ Error Bloque 4 Optimización RNN',
                    f"Se produjo un error en Curvas de Aprendizaje y Validación RNN: {e}"
                ))
            # --- Fin Bloque 4 ---

#            try:
#                print("[DEBUG] Iniciando Bloque 4: Curvas de Aprendizaje y Validación RNN Optimizado")
#                import numpy as np
#                from sklearn.model_selection import learning_curve, validation_curve
#                from sklearn.pipeline import make_pipeline
#                from sklearn.compose import TransformedTargetRegressor
#                from sklearn.preprocessing import StandardScaler
#                import matplotlib.pyplot as plt#

#                # --- a) Repetir selección del mejor modelo ---
#                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
#                df_sel = pd.DataFrame([
#                    {'Método': k[1], 'Motor': k[2], 'Score': v['score'], 'Métrica': v['metric']}
#                    for k,v in OPT_MODELS.items()
#                    if k[0]=='rnn' and k[2] in valid_engines
#                ])
#                if df_sel['Métrica'].str.upper().iloc[0] == 'R2':
#                    idx_best = df_sel['Score'].idxmax()
#                else:
#                    idx_best = df_sel['Score'].idxmin()
#                best_row = df_sel.loc[idx_best]

#                # --- c) Reconstruir los hiperparámetros óptimos ---
#                p = _normalize_payload(payload_raw)
#                #best_params = p['best_params']
#                best_params = p.get('best_params', {})
#                # --- b) Recuperar payload y metadatos ---
#                model_rnn     = p['model']
#                sx_rnn, sy_rnn= p['sx'], p['sy']
#                cols_rnn      = p['cols']

#                print("[DEBUG] Payload normalizado keys:", list(p.keys()))
#                print("[DEBUG] best_params keys:", list(p.get('best_params', {}).keys()))
#                print("[DEBUG] best_params keys:", list(best_params.keys()))

#                if not best_params:
#                    best_params = model_rnn.get_params()
#                    print("[DEBUG] Se han obtenido best_params desde model.get_params()")

#                # --- EXTRAER params desde el modelo entrenado ---
#                params = model_rnn.get_params()
#                print("[DEBUG] params keys:", list(params.keys()))
#                units  = params['units']

#                if "units" not in params:
#                    raise ValueError("[ERROR] El modelo no contiene la clave 'units' en sus parámetros.")

#                cols_rnn    = p['cols']
#                model_rnn   = p['model']
#                sx_rnn, sy_rnn = p['sx'], p['sy']

#                # --- d) Creamos el Pipeline + TTR para escalar X e Y automáticamente ---
#                rnn_pipe = make_pipeline(
#                    StandardScaler(),
#                    RNNRegressor(**params)
#                )
#                rnn_ttr = TransformedTargetRegressor(regressor=rnn_pipe, transformer=StandardScaler())

#                #X_train_sel = X_train[cols].values
#                #y_train     = Y_train.values.ravel()
#                X_train_sel = X_train[cols_rnn].values[:300]  # ⚠️ limitar tamaño
#                y_train = Y_train.values.ravel()[:300]        # ⚠️ limitar tamaño

#                # ---- 4.1 Curva de Aprendizaje (R²) ----
#                from joblib import parallel_backend             # NUEVO para asegurar que se completa el bloque 4
#                with parallel_backend('threading'):             # NUEVO para asegurar que se completa el bloque 4
#                    train_sizes, train_scores, val_scores = learning_curve(
#                        rnn_ttr, X_train_sel, y_train,
#                        #cv=5,
#                        cv=2,  # ⚠️ menos folds
#                        scoring='r2',
#                        #train_sizes=np.linspace(0.1,1.0,5),
#                        train_sizes=np.linspace(0.1, 1.0, 2),  # ⚠️ menos tamaños
#                    #    n_jobs=-1
#                        n_jobs=1    # o incluso omite n_jobs para que sea secuencial
#                    )
#                train_mean = np.mean(train_scores, axis=1)
#                val_mean   = np.mean(val_scores,   axis=1)

#                fig_lc, ax_lc = plt.subplots(figsize=(6,4))
#                ax_lc.plot(train_sizes, train_mean, 'o-', label='Train R²')
#                ax_lc.plot(train_sizes, val_mean,   'o-', label='CV R²')
#                ax_lc.set_title('RNN Optimizado: Curva de Aprendizaje')
#                ax_lc.set_xlabel('Tamaño del set de entrenamiento')
#                ax_lc.set_ylabel('R²')
#                ax_lc.legend()
#                self.sections.append((
#                    '### RNN Optimizado: Curva de Aprendizaje', fig_lc
#                ))

#                # ---- 4.2 Curva de Validación para “units” ----
#                # Rango centrado en el valor óptimo
#                #units_range = np.unique(np.linspace(
#                #    max(1, best_params['units']//2),
#                #    best_params['units']*2,
#                #    5, dtype=int
#                #))
#                if 'units' not in best_params:
#                    raise KeyError("[ERROR] El parámetro 'units' no está presente en best_params. Claves disponibles: " + str(list(best_params.keys())))

#                #units_range = np.unique(np.linspace(
#                #    max(1, best_params['units']//2),
#                #    best_params['units']*2,
#                #    5, dtype=int
#                #))
#                # AÑADIDO PARA ALIGERAR LOS CICLOS DE VALIDACION  Y APRENDIZAJE
#                units_range = np.unique(np.linspace(
#                    max(1, params['units']*0.8),
#                    params['units']*1.2,
#                    3, dtype=int
#                ))

#                #fig_vc_u, tu, vu = validation_curve(
#                tu, vu = validation_curve(
#                    rnn_ttr, X_train_sel, y_train,
#                    param_name='regressor__rnnregressor__units',
#                    param_range=units_range,
#                    cv=5,
#                    scoring='r2',
#                    n_jobs=-1
#                )
#                fig_uvc, ax_uvc = plt.subplots(figsize=(6,4))
#                ax_uvc.plot(units_range, np.mean(tu,axis=1), 'o-', label='Train R²')
#                ax_uvc.plot(units_range, np.mean(vu,axis=1), 'o-', label='CV R²')
#                ax_uvc.set_title('RNN Optimizado: Curva de Validación units')
#                ax_uvc.set_xlabel('units')
#                ax_uvc.set_ylabel('R²')
#                ax_uvc.legend()
#                self.sections.append((
#                    '### RNN Optimizado: Curva de Validación units', fig_uvc
#                ))

#                # ---- 4.3 Curva de Validación para “dropout_rate” ----
#                dr = best_params['dropout_rate']
#                #dr_range = np.linspace(max(0.0, dr-0.2), min(1.0, dr+0.2), 5)
#                dr_range = np.linspace(max(0.0, dr-0.1), min(1.0, dr+0.1), 3)   # AÑADIDO PARA ALIGERAR LOS CICLOS DE ENTRENAMIENTO CRUZADO
#                #fig_vc_d, td, vd = validation_curve(
#                td, vd = validation_curve(
#                    rnn_ttr, X_train_sel, y_train,
#                    param_name='regressor__rnnregressor__dropout_rate',
#                    param_range=dr_range,
#                    cv=5,
#                    scoring='r2',
#                    n_jobs=-1
#                )
#                fig_dvc, ax_dvc = plt.subplots(figsize=(6,4))
#                ax_dvc.plot(dr_range, np.mean(td,axis=1), 'o-', label='Train R²')
#                ax_dvc.plot(dr_range, np.mean(vd,axis=1), 'o-', label='CV R²')
#                ax_dvc.set_title('RNN Optimizado: Curva de Validación dropout_rate')
#                ax_dvc.set_xlabel('dropout_rate')
#                ax_dvc.set_ylabel('R²')
#                ax_dvc.legend()
#                self.sections.append((
#                    '### RNN Optimizado: Curva de Validación dropout_rate', fig_dvc
#                ))

#                # ---- 4.4 Análisis Generativo IA de las Curvas ----
#                prompt = (
#                    f"Para la RNN optimizada (Método={best_row['Método']}, Motor={best_row['Motor']}):\n"
#                    f"- Curva de Aprendizaje: tamaños={train_sizes.tolist()}, train R²={train_mean.tolist()}, cv R²={val_mean.tolist()}\n"
#                    f"- Validación units: rango={units_range.tolist()}, train={np.mean(tu,axis=1).tolist()}, cv={np.mean(vu,axis=1).tolist()}\n"
#                    f"- Validación dropout_rate: rango={dr_range.tolist()}, train={np.mean(td,axis=1).tolist()}, cv={np.mean(vd,axis=1).tolist()}\n\n"
#                    "1. Identifica underfitting o overfitting en cada curva.\n"
#                    "2. Señala brechas clave y su impacto en la generalización.\n"
#                    "3. Recomienda ajustes de units y dropout_rate."
#                )
#                print("[DEBUG] Llamando a OpenAI para análisis de Curvas de Aprendizaje y Validación RNN")
#                analysis = call_openai_explanation(prompt)
#                self.sections.append((
#                    '### RNN Optimizado: Interpretación IA de Curvas', analysis
#                ))

#            except Exception as e:
#                print("[DEBUG] Error en Bloque 4 Optimización RNN:", e)  # <--- NUEVO: para diagnóstico
#                self.sections.append((
#                    '### ⚠️ Error Bloque 4 Optimización RNN',
#                    f"Se produjo un error en Curvas de Aprendizaje y Validación RNN: {e}"
#                ))
            # --- Fin Bloque 4 ---

            # --- 5. Curvas de Calibración y Predicción de Intervalos para RNN Optimizado ---
            try:
                print("[DEBUG] 16.19. Iniciando Bloque 5: Curvas de Calibración y Predicción de Intervalos RNN Optimizado")

                from sklearn.calibration import calibration_curve
                import pandas as _pd
                import numpy as np
                import matplotlib.pyplot as plt

                # 5.1) Recuperar mejor modelo y scalers
                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
                df_sel = pd.DataFrame([
                    {'Método': k[1], 'Motor': k[2], 'Score': v['score'], 'Métrica': v['metric']}
                    for k,v in OPT_MODELS.items()
                    if k[0]=='rnn' and k[2] in valid_engines
                ])
                if df_sel['Métrica'].str.upper().iloc[0] == 'R2':
                    idx_best = df_sel['Score'].idxmax()
                else:
                    idx_best = df_sel['Score'].idxmin()
                best_row = df_sel.loc[idx_best]

                key     = ('rnn', best_row['Método'], best_row['Motor'])
                payload_raw = OPT_MODELS[('rnn', best_row['Método'], best_row['Motor'])]
                p           = _normalize_payload(payload_raw)

                model_rnn   = p['model']
                sx_rnn, sy_rnn = p['sx'], p['sy']
                cols_rnn    = p['cols']

                # --- Bloque 5: normalizar payload ---
                payload_raw = OPT_MODELS[('rnn', best_row['Método'], best_row['Motor'])]
                p           = _normalize_payload(payload_raw)

                model_rnn   = p['model']
                sx_rnn, sy_rnn = p['sx'], p['sy']
                cols_rnn    = p['cols']

                # 5.2) Preparar datos de test y predecir
                X_test_sel = X_test[cols].copy()
                y_true     = Y_test.values.ravel()

                # tu wrapper ya escala / reshape / inverse_transform internamente
                y_pred = model_rnn.predict(X_test_sel)

                # 5.3) Curva de calibración (regresión “reliability”)
                bins = 10
                df_cal = _pd.DataFrame({'y_pred': y_pred, 'y_true': y_true})
                try:
                    df_cal['bin'] = _pd.qcut(df_cal['y_pred'], q=bins, duplicates='drop')
                except ValueError:
                    df_cal['bin'] = _pd.cut(df_cal['y_pred'], bins=bins)
                grp = df_cal.groupby('bin', observed=True).agg({'y_pred':'mean','y_true':'mean'})
                prob_pred, prob_true = grp['y_pred'].values, grp['y_true'].values

                fig_cal, ax_cal = plt.subplots(figsize=(6,4))
                ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2, label='Calibración')
                ax_cal.plot([prob_pred.min(), prob_pred.max()],
                            [prob_pred.min(), prob_pred.max()],
                            'k--', label='Ideal')
                ax_cal.set_xlabel('Predicción promedio en bin')
                ax_cal.set_ylabel('Valor real promedio')
                ax_cal.set_title('RNN Optimizado: Curva de Calibración')
                ax_cal.legend()
                self.sections.append((
                    "### RNN Optimizado: Curva de Calibración",
                    fig_cal
                ))

                # 5.4) Intervalos de predicción ±1 STD de residuo
                residuals = y_true - y_pred
                std_res   = np.std(residuals)
                upper     = y_pred + std_res
                lower     = y_pred - std_res

                fig_int, ax_int = plt.subplots(figsize=(6,4))
                ax_int.plot(y_true,     label='Y real')
                ax_int.plot(y_pred,     label='Predicción')
                ax_int.fill_between(
                    np.arange(len(y_pred)),
                    lower, upper,
                    alpha=0.3, label='±1 STD residuo'
                )
                ax_int.set_xlabel('Índice de muestra')
                ax_int.set_ylabel('Valor')
                ax_int.set_title('RNN Optimizado: Intervalos de Predicción')
                ax_int.legend()
                self.sections.append((
                    "### RNN Optimizado: Intervalos de Predicción",
                    fig_int
                ))

                # 5.5) Análisis generativo IA de incertidumbre y calibración
                print("[DEBUG] 16.20. Llamando IA para análisis de incertidumbre y calibración RNN optimizado")
                prompt_ci_rnn = (
                    f"Para la RNN optimizada (Método={best_row['Método']}, Motor={best_row['Motor']}):\n"
                    f"- Calibración (bins={bins}): predicciones promedio={prob_pred.tolist()}, valores reales promedio={prob_true.tolist()}\n"
                    f"- Residuo estándar={std_res:.4f}\n\n"
                    "1. Evalúa la fiabilidad de la curva de calibración: donde el modelo está sub- o sobre-calibrado.\n"
                    "2. Comenta sobre la amplitud de los intervalos de predicción y su adecuación.\n"
                    "3. Sugiere mejoras para la calibración y estimación de la incertidumbre en la RNN."
                )
                analysis_ci_rnn = call_openai_explanation(prompt_ci_rnn)
                self.sections.append((
                    "### RNN Optimizado: Análisis de Incertidumbre y Calibración",
                    analysis_ci_rnn
                ))

            except Exception as e:
                self.sections.append((
                    "### ⚠️ Error Bloque 5 Optimización RNN",
                    f"Se produjo un error en Curvas de Calibración y Predicción de Intervalos RNN: {e}"
                ))
            # --- Fin Bloque 5 ---

            # --- 6. Resumen Ejecutivo y Road-Map de Siguientes Pasos para RNN Optimizado ---
            try:
                print("[DEBUG] 16.21. Iniciando bloque de Resumen Ejecutivo y Road-Map para RNN optimizado")

                # Variables clave (ya definidas en bloques anteriores)
                sel_rnn        = best_row['Método']
                eng_rnn        = best_row['Motor']
                best_score_rnn = best_row['Score']

                # Desviación de R2 en CV (bloque 3) y estadísticas de residuos (bloque 5)
                cv_std_r2      = float(np.std(r2_scores))    # r2_scores viene de bloque 3
                res_std_rnn    = float(std_res)              # std_res viene de bloque 5
                res_kurt_rnn   = float(kurtosis(residuals))  # residuals viene de bloque 5
                q25_rnn, q50_rnn, q75_rnn = [
                    float(x) for x in np.quantile(residuals, [0.25, 0.5, 0.75])
                ]

                # Markdown resumen
                summary_md_rnn = (
                    "**Puntos Clave Optimización RNN:**\n"
                    f"- **Mejor combinación:** Método `{sel_rnn}`, motor `{eng_rnn}` ➜ **Score** = {best_score_rnn:.4f}\n"
                    f"- **Robustez del modelo:** desviación estándar CV R² = {cv_std_r2:.4f}, std residuos = {res_std_rnn:.4f}\n"
                    f"- **Curtosis de residuos:** {res_kurt_rnn:.4f}, quantiles (25%,50%,75%) = "
                    f"({q25_rnn:.4f}, {q50_rnn:.4f}, {q75_rnn:.4f})\n"
                    "- **Recomendaciones inmediatas:**\n"
                    "  1. Ajustar unidades (`units`) y tasa de dropout para controlar varianza.\n"
                    "  2. Incorporar learning-rate scheduling y early stopping.\n"
                    "  3. Aumentar el set de entrenamiento o aplicar data augmentation en series temporales.\n"
                    "  4. Experimentar con arquitecturas híbridas (LSTM bidireccional, Attention).\n"
                )
                self.sections.append((
                    "### RNN Optimizado: Resumen Ejecutivo y Road-Map",
                    summary_md_rnn
                ))

                # Llamada a IA para un “Resumen Ejecutivo IA”
                print("[DEBUG] 16.22. Llamando IA para Resumen Ejecutivo y Road-Map RNN optimizado")
                prompt_exec_rnn = (
                    "Eres un investigador de Deep Learning avanzado. Basándote en estos puntos clave:\n"
                    f"{summary_md_rnn}\n\n"
                    "1. Desarrolla un análisis detallado en párrafos separados para cada punto clave.\n"
                    "2. Propón un plan de acción priorizado de 3–5 pasos claros para stakeholders.\n"
                    "3. Finaliza con un breve resumen ejecutivo de 2–3 párrafos enfatizando impacto y próximos hitos."
                )
                analysis_exec_rnn = call_openai_explanation(prompt_exec_rnn)
                self.sections.append((
                    "### RNN Optimizado: Resumen Ejecutivo IA",
                    analysis_exec_rnn
                ))

            except Exception as e:
                self.sections.append((
                    "### ⚠️ Error Bloque 6 Optimización RNN",
                    f"Se produjo un error en Resumen Ejecutivo y Road-Map RNN: {e}"
                ))
            # --- Fin Bloque 6 ---

        except Exception as e:
            self.sections.append((
                "### ⚠️ Error Bloque 0 Optimización RNN",
                f"Se produjo un error al generar el resumen de optimización RNN: {e}"
            ))

        # =============================================================================
        # 17. Análisis e Interpretación del Modelo Óptimo
        # =============================================================================
        #try:
        #    print("[DEBUG] Iniciando sección Selección Integral de Modelo")
        try:
            print("[DEBUG] 17.1.Iniciando sección Selección Integral de Modelo")
            # DEBUG: ¿Qué claves hay en OPT_MODELS?
            print(f"[DEBUG] 17.2. OPT_MODELS tiene {len(OPT_MODELS)} entradas: {list(OPT_MODELS.keys())}")
            records = []
            print("[DEBUG] 17.3. records inicializado vacío")
            import numpy as np
            import pandas as pd
            from sklearn.model_selection      import cross_validate
            from sklearn.metrics              import mean_squared_error, mean_absolute_error, r2_score
            #from sklearn.calibration          import calibration_curve
            import scipy.stats                as st
            from tensorflow.keras.models      import load_model

            records = []

            # --- Bloque 1: Construcción y presentación de la Tabla de Puntuación de los Modelos Optimizados ---
            for (mt, method, engine), payload in OPT_MODELS.items():
                if mt not in {'svr','nn','xgb','rf','rnn'}:
                    continue
                # --- cargar datos test y scalers ---
                cols = payload.get('cols', X_test.columns.tolist())
                X_test_sel = X_test[cols].copy()
                y_true     = Y_test.values.ravel()

                sx = payload.get('sx')
                if sx is not None:
                    #X_test_scaled = sx.transform(X_test_sel.values)
                    X_test_scaled = sx.transform(pd.DataFrame(X_test_sel.values, columns=X_test_sel.columns))       # EVITA WARNING EN LA EJECUCION - NO PARA EJECUCION. SI DA PROBLEMAS ELIMINAR ESTA LINEA.

                else:
                    X_test_scaled = X_test_sel.values

                # --- predicciones y métricas test ---
                if mt == 'rnn':
                    # tu wrapper ya escala, reshape e inverse_transform
                    model = payload['model']
                    y_pred = model.predict(X_test_sel)
                else:
                    model = payload['model']
                    if mt in {'svr','xgb','rf','nn'}:
                        # scikeras o sklearn
                        y_pred_raw = model.predict(X_test_scaled)
                        sy = payload.get('sy')
                        if sy is not None:
                            y_pred = sy.inverse_transform(y_pred_raw.reshape(-1,1)).ravel()
                        else:
                            y_pred = y_pred_raw.ravel()
                    else:
                        y_pred = model.predict(X_test_scaled)

                mse_test   = mean_squared_error(y_true, y_pred)
                mae_test   = mean_absolute_error(y_true, y_pred)
                rmse_test  = np.sqrt(mse_test)
                resid      = y_true - y_pred
                res_std    = np.std(resid)
                res_kurt   = st.kurtosis(resid)

                # --- validación cruzada 5 folds ---
                # Construir X_train escalado
                cols_tr = payload.get('cols', X_train.columns.tolist())
                X_tr_sel = X_train[cols_tr].copy()
                y_tr     = Y_train.values.ravel()
                sx_tr    = payload.get('sx')
                X_tr_s   = sx_tr.transform(X_tr_sel.values) if sx_tr is not None else X_tr_sel.values

                from sklearn.model_selection import train_test_split

                # Submuestreo del conjunto de entrenamiento
                X_sub, _, y_sub, _ = train_test_split(
                    X_tr_s, y_tr,
                    train_size=0.3,  # usa solo el 30% de los datos para CV
                    random_state=42,
                    shuffle=True
                )

                # --- validación cruzada con protección para modelos no-sklean ---
                try:
                    from sklearn.model_selection import cross_validate
                    cvres = cross_validate(
                        #model, X_tr_s, y_tr,
                        model, X_sub, y_sub,        # Usamos X_sub y y_sub en la validación cruzada en lugar del conjunto completo.
                        #cv=5,
                        cv=3,         # REDUCE CV FOLDS PARA MEJORAR LA RAPPIDEZ DE EJECUCION
                        scoring={
                            'r2':      'r2',
                            'neg_mse': 'neg_mean_squared_error',
                            'neg_mae': 'neg_mean_absolute_error'
                        },
                        return_train_score=False,
                        n_jobs=-1  # ← paraleliza en todos los cores
                    )
                    r2_folds  = cvres['test_r2']
                    mse_folds = [-v for v in cvres['test_neg_mse']]
                    mae_folds = [-v for v in cvres['test_neg_mae']]
                    r2_cv_std    = float(np.std(r2_folds))
                    mse_cv_mean  = float(np.mean(mse_folds))
                    mae_cv_mean  = float(np.mean(mae_folds))
                    rmse_cv_mean = float(np.mean(np.sqrt(mse_folds)))
                except TypeError as ex:
                    # no SKL estimator (e.g. keras.Sequential), omitimos CV
                    print(f"[DEBUG] CV omitido por TypeError: {ex}")
                    r2_folds, mse_folds, mae_folds = [], [], []
                    r2_cv_std    = np.nan
                    mse_cv_mean  = np.nan
                    mae_cv_mean  = np.nan
                    rmse_cv_mean = np.nan

                # --- calibración manual para regresión ---
                import pandas as pd
                # un DataFrame para agrupar por deciles de y_pred
                df_cal = pd.DataFrame({'y_pred': y_pred, 'y_true': y_true})
                # cortamos en 10 bins por cuantiles (evita duplicados)
                try:
                    #df_cal['bin'] = pd.qcut(df_cal['y_pred'], q=10, duplicates='drop')
                    df_cal['bin'] = pd.qcut(df_cal['y_pred'], q=5, duplicates='drop')   # o q=4 si quieres aún más velocidad
                except ValueError:
                    #df_cal['bin'] = pd.cut(df_cal['y_pred'], bins=10)
                    df_cal['bin'] = pd.cut(df_cal['y_pred'], bins=5)                    # o q=4 si quieres aún más velocidad
                # agrupamos: media predicha vs media real
                grp = df_cal.groupby('bin', observed=True).agg({'y_pred':'mean','y_true':'mean'})
                prob_pred = grp['y_pred'].values
                prob_true = grp['y_true'].values
                # error medio de calibración
                cal_err = float((np.abs(prob_pred - prob_true)).mean())

                # --- intervalos de predicción ±1 STD residuo ---
                intervals_std = res_std

                # --- métrica principal (score) ---
                score = payload.get('score', r2_score(y_true, y_pred))

                # --- hiperparámetros optimizados ---
                best_params = payload.get('best_params') or payload.get('params') or {}
                hp_flat = { f"hp_{k}": v for k, v in best_params.items() }

                # --- armar registro ---
                rec = {
                    'modelo':        f"{mt}-{method}-{engine}",
                    'score':         score,
                    'r2_cv_std':     r2_cv_std,
                    'mse_cv':        mse_cv_mean,
                    'mae_cv':        mae_cv_mean,
                    'rmse_cv':       rmse_cv_mean,
                    'mse_test':      mse_test,
                    'mae_test':      mae_test,
                    'rmse_test':     rmse_test,
                    'res_std':       res_std,
                    'res_kurt':      res_kurt,
                    'intervals_std': intervals_std,
                    'cal_err':       cal_err,
                    **hp_flat
                }
                records.append(rec)

            #df = pd.DataFrame(records)

            print(f"[DEBUG] 17.4. records tendrá {len(records)} elementos")
            if records:
                print(f"[DEBUG] 17.5. ejemplar de record[0]: {records[0]}")
            df = pd.DataFrame(records)
            print(f"[DEBUG] 17.6. DataFrame creado con shape={df.shape}")

            # 0) Extraer tipo, método y motor de la columna 'modelo'
            df[['tipo','metodo','motor']] = df['modelo'].str.split('-', n=2, expand=True)

            # 1) Clonar df y reiniciar índice
            df_results = df.copy()
            df_results.reset_index(drop=True, inplace=True)
            # Definimos aquí la puntuación global bruta
            df_results['puntuacion_global'] = df_results['score']

            # Bloque de normalización absoluta lineal y cálculo de puntuación
            import pandas as pd
            import numpy as np

            # Definir funciones de normalización
            def normalize_high(df, col):
                lo, hi = df[col].min(), df[col].max()
                if hi == lo:
                    return pd.Series(10.0, index=df.index)
                return ((df[col] - lo) / (hi - lo) * 10).clip(0, 10)

            def normalize_low(df, col):
                lo, hi = df[col].min(), df[col].max()
                if hi == lo:
                    return pd.Series(10.0, index=df.index)
                return ((hi - df[col]) / (hi - lo) * 10).clip(0, 10)

            # Supongamos que ya tienes df_results con la columna 'puntuacion_global'
            # y las métricas crudas: r2_cv_std, mse_cv, mae_cv, rmse_cv, mse_test, mae_test,
            # rmse_test, res_std, res_kurt, intervals_std, cal_err

            # Columnas “mayor = mejor”
            cols_high = ['puntuacion_global']

            # Columnas “menor = mejor”
            cols_low = [
                'r2_cv_std', 'mse_cv', 'mae_cv', 'rmse_cv',
                'mse_test', 'mae_test', 'rmse_test',
                'res_std', 'res_kurt', 'intervals_std', 'cal_err'
            ]

            # 1) Normalizar cada métrica a escala 0–10
            for c in cols_high:
                df_results[f'v_{c}'] = normalize_high(df_results, c)

            for c in cols_low:
                df_results[f'v_{c}'] = normalize_low(df_results, c)

            # 2) Definir pesos (ajusta según IA o tu criterio)
            pesos = {
                'v_puntuacion_global': 0.2273,
                'v_r2_cv_std':         0.0909,
                'v_mse_cv':            0.0909,
                'v_mae_cv':            0.0455,
                'v_rmse_cv':           0.0455,
                'v_mse_test':          0.0909,
                'v_mae_test':          0.0909,
                'v_rmse_test':         0.0455,
                'v_res_std':           0.0909,
                'v_res_kurt':          0.0455,
                'v_intervals_std':     0.0455,
                'v_cal_err':           0.0909,
            }

            # 3) Calcular la puntuación global final
            df_results['puntuacion_global_final'] = 0.0
            for vcol, w in pesos.items():
                df_results['puntuacion_global_final'] += df_results[vcol] * w

            # 4) Reordenar columnas para presentación
            #cols_order = [
            #    'modelo', 'tipo', 'metodo', 'motor', 'puntuacion_global'
            #] + list(pesos.keys()) + ['puntuacion_global_final']

            # 4) Reordenar columnas para presentación
            cols_order = [
                'modelo', 'tipo', 'metodo', 'motor', 'puntuacion_global',
                # métricas crudas
                'r2_cv_std','mse_cv','mae_cv','rmse_cv',
                'mse_test','mae_test','rmse_test',
                'res_std','res_kurt','intervals_std','cal_err',
            ] + list(pesos.keys()) + ['puntuacion_global_final']

            df_results = df_results[cols_order]

            # 5) Añadir la sección al informe
            #self.sections.append((
            #    '### Selección Integral de Modelo: Tabla de Puntuaciones',
            #    df_results.reset_index(drop=True)
            #))
            print("[DEBUG] 17.7. Añadiendo sección de Tabla de Puntuaciones")
            self.sections.append((
                '### Selección Integral de Modelo: Tabla de Puntuaciones',
                df_results.reset_index(drop=True)
            ))
            print("[DEBUG] 17.8. Sección Tabla de Puntuaciones añadida correctamente")

            # --- Ahora identificamos el mejor y guardamos atributos ---
            best_idx = df_results['puntuacion_global_final'].idxmax()
            best     = df_results.loc[best_idx]

            # Guardamos la info del mejor modelo
            self.best_model_info = {
                'metodo': best['metodo'],
                'motor':  best['motor'],
                'score':  best['puntuacion_global_final']
            }

            # **Guardamos también las métricas que necesitarás más adelante**:
            self.r2_cv_std = float(best['r2_cv_std'])
            self.res_std   = float(best['res_std'])
            self.cal_err   = float(best['cal_err'])

            print(f"[DEBUG] 17.9. Mejor modelo: {self.best_model_info}, "
                  f"r2_cv_std={self.r2_cv_std}, res_std={self.res_std}, cal_err={self.cal_err}")
            # --- Fin Bloque 1 ---

            # --- Bloque 2 - Gráfico de puntuaciones globales y Cuadrante Mágico de Modelos Optimizados ----
            import matplotlib.pyplot as plt

            # 1) Cerramos TODO lo que haya quedado abierto de la optimización
            #plt.close('all')

            # --- Gráfico de Barras: Puntuación Global de cada modelo ---
            def plot_global_scores(df):
                """
                Gráfico de barras profesional con la puntuación global de cada modelo.
                - df debe tener columnas ['modelo', 'puntuacion_global'].
                """
                fig, ax = plt.subplots(figsize=(10, 6))
                modelos = df['modelo']
                scores = df['puntuacion_global_final']

                # Usa una paleta profesional
                palette = plt.get_cmap('tab20').colors
                ax.bar(modelos, scores, color=palette[:len(modelos)], edgecolor='black')

                # Etiquetas y estilo
                ax.set_title('Comparación de Modelos: Puntuación Global', fontsize=16, fontweight='bold')
                ax.set_xlabel('Modelo', fontsize=14)
                ax.set_ylabel('Puntuación Global', fontsize=14)
                ax.set_xticks(modelos)
                ax.set_xticklabels(modelos, rotation=45, ha='right', fontsize=12)
                ax.grid(axis='y', linestyle='--', alpha=0.7)
                plt.tight_layout()
                #plt.close(fig)
                return fig

            def plot_magic_quadrant(df):
                """
                Magic Quadrant que sitúa cada modelo en robustez vs rendimiento.
                - df debe tener columnas ['v_r2_cv_std', 'puntuacion_global_final', 'modelo'].
                """
                # Robustez: normalizamos de 0–10 a 0–1
                robustez = (df['v_r2_cv_std'] / 10).clip(0,1)

                # Rendimiento: puntuación global final (0–10) también a 0–1
                rendimiento = (df['puntuacion_global_final'] / 10).clip(0,1)

                mask       = robustez.notna() & rendimiento.notna()
                robustez   = robustez[mask]
                rendimiento = rendimiento[mask]
                labels     = df['modelo'][mask]

                fig, ax = plt.subplots(figsize=(8, 8))
                ax.scatter(robustez, rendimiento, s=150, edgecolor='k', alpha=0.8)

                for x, y, label in zip(robustez, rendimiento, labels):
                    ax.annotate(label,
                                xy=(x, y),
                                xytext=(5, 5),
                                textcoords='offset points',
                                fontsize=12)

                # Líneas medias
                ax.axvline(robustez.mean(),    color='grey', linestyle='--')
                ax.axhline(rendimiento.mean(), color='grey', linestyle='--')

                ax.set_title('Magic Quadrant de Modelos', fontsize=16, fontweight='bold')
                ax.set_xlabel('Robustez (v_r2_cv_std / 10)', fontsize=14)
                ax.set_ylabel('Rendimiento (puntuación global / 10)', fontsize=14)
                ax.grid(True, linestyle='--', alpha=0.5)

                # Límites de 0 a 1
                ax.set_xlim(0, 1.05)
                ax.set_ylim(0, 1.05)

                plt.tight_layout()
                return fig


            fig1 = plot_global_scores(df_results)
            fig2 = plot_magic_quadrant(df_results)

            self.sections.append(('### Comparación de Modelos: Puntuación Global', fig1))
            self.sections.append(('### Magic Quadrant de Modelos', fig2))
            # --- Fin Bloque 2 ---

            # --- Bloque 3: Explicación profunda por IA y detalle final del modelo seleccionado ---
            print("[DEBUG] 17.10. Iniciando Bloque 3: Explicación IA y detalle final")

            import openai
            import pandas as pd

            # 1) Serializamos la tabla de puntuaciones para inyectarla en el prompt
            table_csv = df_results.to_csv(index=False)

            print("[DEBUG] 17.11. Iniciando llamada a IA para análisis de la tabla y gráficas")

            prompt = f"""
            He aquí los resultados completos de la **Selección Integral de Modelos**:

            1) **Tabla de Puntuaciones** (CSV):
            {table_csv}

            2) **Gráfica de Barras** titulada "Comparación de Modelos: Puntuación Global".

            3) **Magic Quadrant** titulado "Magic Quadrant de Modelos".

            Por favor, realiza lo siguiente:

            A) Explica **detalladamente** la tabla de puntuaciones:
              - Cómo se ha estructurado,
              - Qué representa cada columna de valor (tanto las métricas crudas como sus escalas 0–10),
              - Cómo cada modelo se “sitúa” según esos valores,
              - Comparativa explícita entre todos los modelos.

            B) Comenta la **gráfica de barras**:
              - Qué nos dice del rendimiento absoluto de cada modelo,
              - Destaca los valores máximo y mínimo.

            C) Interpreta el **Magic Quadrant**:
              - Define en qué ejes está midiendo robustez y rendimiento,
              - Señala qué cuadrante (alto–alto, alto–bajo, bajo–alto, bajo–bajo) es deseable,
              - Identifica modelos “líderes” y “rezagados”.

            D) Con todo lo anterior, **elige el mejor modelo optimizado**.
              - Explica por qué (qué métricas y pesos lo han elevado al primer puesto),
              - Enumera sus virtudes y posibles puntos débiles.

            E) Tras esa elección, **construye una tabla** con todos los detalles del modelo seleccionado:
              1. `modelo` (p.ej. “rf-pearson-randomsearch”)
              2. `tipo` (RF, SVR, …)
              3. `método` (Pearson, Boruta, …)
              4. `motor` de optimización (RandomSearch, Optuna, …)
              5. **Todos** sus hiperparámetros óptimos
              6. **Listado** de variables X usadas
              7. Resumen de sus **métricas crudas** y su `puntuacion_global_final`
            """

            # 2) Llamada a OpenAI
            resp = _client.chat.completions.create(
                model="gpt-4",
                messages=[{"role":"user", "content": prompt}],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS,
            )
            analysis_text = resp.choices[0].message.content

            # 3) Insertamos el análisis como sección
            self.sections.append((
                "### 📝 Explicación IA de la Selección Final",
                analysis_text
            ))

            # 4) Identificamos el mejor modelo en df_results
            best_idx = df_results['puntuacion_global_final'].idxmax()
            best     = df_results.loc[best_idx]
            mt, method, engine = best['tipo'], best['metodo'], best['motor']

            # Guardamos la info del mejor modelo para bloques posteriores
            self.best_model_info = {
                'metodo': best['metodo'],
                'motor':  best['motor'],
                'score':  best['puntuacion_global_final']
            }

            # 5) Recuperamos payload y detalles
            payload  = OPT_MODELS[(mt, method, engine)]
            hp       = payload.get('best_params', {}) or payload.get('params', {})
            features = payload.get('cols', X_train.columns.tolist())

            # 6) Preparamos el detalle en un DataFrame
            metrics_keys = [
                'r2_cv_std','mse_cv','mae_cv','rmse_cv',
                'mse_test','mae_test','rmse_test',
                'res_std','res_kurt','intervals_std','cal_err',
                'puntuacion_global','puntuacion_global_final'
            ]

            detail_dict = {
                'modelo':               best['modelo'],
                'tipo':                 mt,
                'metodo':               method,
                'motor':                engine,
                'variables_usadas':     ", ".join(features),
                'puntuacion_final':  best['puntuacion_global_final'],
            }
            # añadimos hiperparámetros
            for k, v in hp.items():
                detail_dict[f"hp_{k}"] = v
            # añadimos métricas
            for k in metrics_keys:
                detail_dict[k] = best[k]

            detail_df = pd.DataFrame([detail_dict])

            # 7) Insertamos la tabla de detalle
            self.sections.append((
                "### Detalle del Modelo Seleccionado",
                detail_df.reset_index(drop=True)
            ))
            # --- Fin Bloque 3 ---

            # --- Bloque 4: Interpretación xIA del Mejor Modelo Optimizado ---
            try:
                print("[DEBUG] 17.12. Iniciando Bloque 4: Interpretación xIA")

                import numpy as np
                import pandas as pd
                import shap
                import matplotlib.pyplot as plt
                import json
                import warnings
                from scipy.optimize import minimize
                from sklearn.inspection import partial_dependence
                from sklearn.inspection import (
                    permutation_importance,
                    PartialDependenceDisplay
                )

                # --- FUNCIÓN ROBUSTA PARA EXTRAER grid/curves DE partial_dependence ---
                def extract_grid_and_curves(pd_res, kind="average"):
                    # 1. Si es Bunch (scikit-learn >= 0.24)
                    if hasattr(pd_res, "keys"):
                        keys = list(pd_res.keys())
                        # PDP
                        if kind == "average":
                            # Puede que solo exista average/grid_values
                            if "average" in keys and "grid_values" in keys:
                                grid = pd_res["grid_values"][0]
                                avg = pd_res["average"][0]
                                return grid, avg
                            else:
                                raise RuntimeError(f"PDP: No se encuentran 'average' o 'grid_values' en Bunch: {keys}")
                        # ICE
                        elif kind == "individual":
                            if "individual" in keys and "grid_values" in keys:
                                grid = pd_res["grid_values"][0]
                                curves = pd_res["individual"][0]
                                return grid, curves
                            else:
                                raise RuntimeError(f"ICE: No se encuentran 'individual' o 'grid_values' en Bunch: {keys}")
                        else:
                            raise ValueError(f"Tipo desconocido: {kind}")

                    # 2. Si es tuple o list (formato antiguo)
                    elif isinstance(pd_res, (tuple, list)):
                        if kind == "average":
                            avg = pd_res[0]
                            grid = pd_res[1][0]
                            return grid, avg
                        elif kind == "individual":
                            curves = pd_res[0]
                            grid = pd_res[1][0]
                            return grid, curves
                        else:
                            raise ValueError(f"Tipo desconocido: {kind}")

                    # 3. Si es ndarray (muy raro)
                    elif isinstance(pd_res, np.ndarray):
                        return np.arange(pd_res.shape[-1]), pd_res

                    # 4. Si es dict (algunos edge-cases custom)
                    elif isinstance(pd_res, dict):
                        # Para ICE y PDP, usa las claves
                        if kind == "average" and "average" in pd_res and "grid_values" in pd_res:
                            grid = pd_res["grid_values"][0]
                            avg = pd_res["average"][0]
                            return grid, avg
                        elif kind == "individual" and "individual" in pd_res and "grid_values" in pd_res:
                            grid = pd_res["grid_values"][0]
                            curves = pd_res["individual"][0]
                            return grid, curves
                        else:
                            raise RuntimeError(f"Objeto dict sin claves esperadas: {pd_res.keys()}")

                    else:
                        raise RuntimeError(f"No se reconoce el objeto retornado por partial_dependence: {type(pd_res)}, contenido: {pd_res}")


                # 1) Identificar el mejor modelo
                best_idx = df_results['puntuacion_global_final'].idxmax()
                best     = df_results.loc[best_idx]
                mt, method, engine = best['tipo'], best['metodo'], best['motor']
                payload  = OPT_MODELS[(mt, method, engine)]
                model    = payload['model']
                features = payload.get('cols', X_train.columns.tolist())

                # 2) Preparar datos (escalado si procede)
                sx     = payload.get('sx')
                X_tr   = X_train[features].copy()
                X_te   = X_test[features].copy()
                X_tr_s = sx.transform(X_tr.values) if sx else X_tr.values
                X_te_s = sx.transform(X_te.values) if sx else X_te.values
                y_te   = Y_test.values.ravel()

                # ————————————————————————————————
                # 3) SHAP
                # ————————————————————————————————
                print("[DEBUG] 17.13. Iniciando Interpretación xIA con SHAP")
                # Silenciar warning de “feature names”
                warnings.filterwarnings("ignore", message="X does not have valid feature names")
                if mt in ('xgb','rf'):
                    explainer = shap.TreeExplainer(model)
                else:
                    # Uso DeepExplainer para redes y KernelExplainer solo si no hay Deep support
                    try:
                        background = shap.kmeans(X_tr_s, 100)            # solo 100 puntos de background
                        explainer = shap.DeepExplainer(model, background)
                    except Exception:
                        # fallback a KernelExplainer con pocos nsamples
                        explainer = shap.KernelExplainer(model.predict, shap.sample(X_tr_s, 100))
                # Reducir test a las primeras 100 filas para acelerar
                X_sample = X_te_s[:100]
                shap_vals = explainer.shap_values(X_sample)

#                    explainer = shap.KernelExplainer(model.predict, shap.sample(X_tr_s, 100))
#                shap_vals = explainer.shap_values(X_te_s)

                fig_shap, ax_shap = plt.subplots(figsize=(8,6))
                #shap.summary_plot(shap_vals, X_te_s, feature_names=features, show=False)
                shap.summary_plot(shap_vals, X_sample, feature_names=features, show=False)

                plt.tight_layout()
                #plt.close(fig_shap)
                self.sections.append(("### xIA: SHAP Summary", fig_shap))

                # ————————————————————————————————
                # 4) Permutation Feature Importance
                # ————————————————————————————————
                print("[DEBUG] 17.14. Iniciando Interpretación xIA con Permutation Feature Importance")
                perm = permutation_importance(model, X_te_s, y_te,
                                              n_repeats=10, random_state=0, n_jobs=-1)
                idx_imp   = np.argsort(perm.importances_mean)[::-1]
                top_feats = [features[i] for i in idx_imp[:5]]

                fig_perm, ax_perm = plt.subplots(figsize=(8,6))
                ax_perm.barh(np.arange(len(top_feats)),
                            perm.importances_mean[idx_imp[:5]],
                            xerr=perm.importances_std[idx_imp[:5]],
                            align='center')
                ax_perm.set_yticks(np.arange(len(top_feats)))
                ax_perm.set_yticklabels(top_feats)
                ax_perm.invert_yaxis()
                ax_perm.set_title("xIA: Permutation Importance")
                ax_perm.set_xlabel("Mean decrease in score")
                plt.tight_layout()
                #plt.close(fig_perm)
                self.sections.append(("### xIA: Permutation Importance", fig_perm))

                # ————————————————————————————————
                # 5) PDP + ICE (scikit-learn)
                # ————————————————————————————————
                print("[DEBUG] 17.15. Iniciando Interpretación xIA con PDP e ICE")

                pdp_records = []
                ice_records = []

                for feat in top_feats:
                    # PDP
                    pdp_res = partial_dependence(
                        model, X_tr, features=[feat], kind="average", grid_resolution=20
                    )
                    #grid, avg = extract_grid_and_curves(pdp_res, kind='average')

                    try:
                        grid, avg = extract_grid_and_curves(pdp_res, kind='average')
                    except Exception as e:
                        print(f"[DEBUG] PDP Extraction error: {e}, objeto: {type(pdp_res)}, contenido: {pdp_res}")
                        raise

                    for x, y in zip(grid, avg):
                        pdp_records.append({"feature": feat, "grid": float(x), "pdp": float(y)})

                    # gráfico PDP
                    fig_pdp, ax_pdp = plt.subplots(figsize=(6,4))
                    ax_pdp.plot(grid, avg, marker='o')
                    ax_pdp.set_title(f"PDP de {feat}")
                    plt.tight_layout()
                    #plt.close(fig_pdp)
                    self.sections.append((f"### xIA: PDP {feat}", fig_pdp))

                    # ICE
                    ice_res = partial_dependence(
                        model, X_tr, features=[feat], kind="individual", grid_resolution=20
                    )
                    #grid, curves = extract_grid_and_curves(ice_res, kind='individual')

                    try:
                        grid, curves = extract_grid_and_curves(ice_res, kind='individual')
                    except Exception as e:
                        print(f"[DEBUG] ICE Extraction error: {e}, objeto: {type(ice_res)}, contenido: {ice_res}")
                        raise

                    for obs_idx, curve in enumerate(curves):
                        for x, y in zip(grid, curve):
                            ice_records.append({
                                "feature":     feat,
                                "grid":        float(x),
                                "ice":         float(y),
                                "observation": int(obs_idx)
                            })
                    # gráfico ICE
                    fig_ice, ax_ice = plt.subplots(figsize=(6,4))
                    for curve in curves:
                        ax_ice.plot(grid, curve, alpha=0.3)
                    ax_ice.set_title(f"ICE de {feat}")
                    plt.tight_layout()
                    #plt.close(fig_ice)
                    self.sections.append((f"### xIA: ICE {feat}", fig_ice))

                # convertir a DataFrame
                pdp_results = pd.DataFrame(pdp_records)
                ice_results = pd.DataFrame(ice_records)

                # ————————————————————————————————
                # 6) ALE “a mano”
                # ————————————————————————————————
                print("[DEBUG] 17.16. Iniciando Interpretación xIA con ALE")
                def compute_ale(model, X, feat, grid_points=20):
                    Xdf = X.copy()
                    vals = np.linspace(Xdf[feat].min(),
                                      Xdf[feat].max(),
                                      grid_points+1)
                    centers = (vals[:-1] + vals[1:]) / 2
                    diffs = []
                    for low, high in zip(vals[:-1], vals[1:]):
                        X_low  = Xdf.copy(); X_high = Xdf.copy()
                        X_low.loc[Xdf[feat]  > high, feat] = low
                        X_high.loc[Xdf[feat] <= low,  feat] = high
                        arr_low  = sx.transform(X_low.values)  if sx else X_low.values
                        arr_high = sx.transform(X_high.values) if sx else X_high.values
                        pred_low  = model.predict(arr_low)
                        pred_high = model.predict(arr_high)
                        diffs.append(np.mean(pred_high - pred_low))
                    cum = np.cumsum(diffs)
                    cum -= cum.mean()
                    return centers, cum

                ale_records = []
                for feat in top_feats:
                    centers, ale_curve = compute_ale(model, X_tr, feat)
                    fig_ale, ax_ale = plt.subplots(figsize=(6,4))
                    ax_ale.plot(centers, ale_curve, marker='o')
                    ax_ale.set_title(f"ALE de {feat}")
                    plt.tight_layout()
                    #plt.close(fig_ale)
                    self.sections.append((f"### xIA: ALE {feat}", fig_ale))
                    for c, a in zip(centers, ale_curve):
                        ale_records.append({
                            "feature": feat,
                            "grid":    float(c),
                            "ale":     float(a)
                        })
                ale_results = pd.DataFrame(ale_records)

                # ————————————————————————————————
                # 7) Counterfactuals “ligeros”
                # ————————————————————————————————
                print("[DEBUG] 17.17. Iniciando Interpretación xIA con Counterfactuals")
                def generate_counterfactual(x0, delta=1.0):
                    x0_arr = x0.values if hasattr(x0, "values") else x0
                    x0_s   = sx.transform([x0_arr])[0] if sx else x0_arr
                    y0     = model.predict([x0_s])[0]
                    def obj(x): return np.sum((x - x0_s)**2)
                    cons = {
                        'type': 'ineq',
                        'fun':  lambda x: model.predict([x])[0] - y0 - delta
                    }
                    res = minimize(obj, x0_s, constraints=cons)
                    if res.success:
                        xcf_s = res.x
                        xcf   = sx.inverse_transform([xcf_s])[0] if sx else xcf_s
                        ycf   = model.predict([xcf_s])[0]
                        return xcf, ycf
                    else:
                        return None, None

                cf_explanations = []
                for i in range(min(3, len(X_te))):
                    x0 = X_te.iloc[i]
                    xcf, ycf = generate_counterfactual(x0, delta=1.0)
                    if xcf is not None:
                        delta_feats = xcf - x0.values
                        fig_cf, ax_cf = plt.subplots(figsize=(6,4))
                        ax_cf.bar(X_te.columns, delta_feats, edgecolor='k')
                        ax_cf.set_title(f"Counterfactual #{i} (Δ para +1 unidad de y)")
                        ax_cf.set_xticklabels(X_te.columns, rotation=45, ha='right')
                        plt.tight_layout()
                        #plt.close(fig_cf)
                        self.sections.append((f"### xIA: Counterfactual {i}", fig_cf))
                        cf_explanations.append({
                            "observation":     i,
                            "x0":              x0.to_dict(),
                            "counterfactual":  {features[j]: float(xcf[j]) for j in range(len(features))},
                            "y_pred_original": float(model.predict([sx.transform([x0.values])[0]]) if sx else model.predict([x0.values])[0]),
                            "y_pred_cf":       float(ycf)
                        })

                # —————————————————————————————————————————
                # 8) RESUMIR LOS RESULTADOS PARA ENVIAR A LA IA
                # —————————————————————————————————————————
                print("[DEBUG] 17.18. Resumiendo resultados XAI para envío a la IA")

                def resumir_xai_json(
                    shap_vals, features, perm, idx_imp, top_feats,
                    pdp_results, ice_results, ale_results, cf_explanations,
                    n_feats=2, n_vals=8
                ):
                    # Selecciona las top n_feats
                    features_lite = [features[i] for i in idx_imp[:n_feats]]

                    # 1. SHAP: solo valores medios globales para top features
                    shap_summary = {
                        "features": features_lite,
                        "shap_mean_abs": [float(np.mean(np.abs(shap_vals[:, features.index(f)]))) for f in features_lite]
                    }

                    # 2. Permutation: solo top features
                    perm_summary = {
                        "features": features_lite,
                        "importances_mean": [float(perm.importances_mean[features.index(f)]) for f in features_lite],
                        "importances_std": [float(perm.importances_std[features.index(f)]) for f in features_lite],
                    }

                    # 3. PDP: solo top features y primeros n_vals puntos
                    pdp_summary = {
                        feat: {
                            "grid": pdp_results.loc[pdp_results.feature == feat, "grid"].astype(float).values[:n_vals].tolist(),
                            "pdp": pdp_results.loc[pdp_results.feature == feat, "pdp"].astype(float).values[:n_vals].tolist()
                        }
                        for feat in features_lite
                    }

                    # 4. ICE: solo top features, primeros n_vals, y primeras 2 observaciones
                    ice_summary = {}
                    for feat in features_lite:
                        obs_ids = ice_results[ice_results.feature == feat]["observation"].unique()[:2]
                        ice_summary[feat] = {
                            int(obs): {
                                "grid": ice_results[(ice_results.feature == feat) & (ice_results.observation == obs)]["grid"].astype(float).values[:n_vals].tolist(),
                                "ice": ice_results[(ice_results.feature == feat) & (ice_results.observation == obs)]["ice"].astype(float).values[:n_vals].tolist()
                            }
                            for obs in obs_ids
                        }

                    # 5. ALE: igual que PDP
                    ale_summary = {
                        feat: {
                            "grid": ale_results.loc[ale_results.feature == feat, "grid"].astype(float).values[:n_vals].tolist(),
                            "ale": ale_results.loc[ale_results.feature == feat, "ale"].astype(float).values[:n_vals].tolist()
                        }
                        for feat in features_lite
                    }

                    # 6. Counterfactuals: solo 1 o 2 ejemplos, y solo diferencias principales
                    cf_summary = []
                    for c in cf_explanations[:2]:
                        d = {k: c[k] for k in ["observation", "y_pred_original", "y_pred_cf"]}
                        d["counterfactual"] = {k: v for k, v in list(c["counterfactual"].items())[:n_feats]}
                        cf_summary.append(d)

                    return {
                        "shap": shap_summary,
                        "perm": perm_summary,
                        "pdp": pdp_summary,
                        "ice": ice_summary,
                        "ale": ale_summary,
                        "cf": cf_summary
                    }

                # — Serialización resumida —
                xai_resumido = resumir_xai_json(
                    shap_vals, features, perm, idx_imp, top_feats,
                    pdp_results, ice_results, ale_results, cf_explanations,
                    n_feats=2, n_vals=8
                )

                shap_json_lite = json.dumps(xai_resumido["shap"], indent=2, ensure_ascii=False)
                perm_json_lite = json.dumps(xai_resumido["perm"], indent=2, ensure_ascii=False)
                pdp_json_lite  = json.dumps(xai_resumido["pdp"], indent=2, ensure_ascii=False)
                ice_json_lite  = json.dumps(xai_resumido["ice"], indent=2, ensure_ascii=False)
                ale_json_lite  = json.dumps(xai_resumido["ale"], indent=2, ensure_ascii=False)
                cf_json_lite   = json.dumps(xai_resumido["cf"], indent=2, ensure_ascii=False)

                # Guardar los JSON para el siguiente bloque
                self.shap_json_lite = shap_json_lite
                self.perm_json_lite = perm_json_lite
                self.pdp_json_lite  = pdp_json_lite
                self.ice_json_lite  = ice_json_lite
                self.ale_json_lite  = ale_json_lite
                self.cf_json_lite   = cf_json_lite

            except Exception as e:
                import traceback
                print("[DEBUG] Se ha producido una excepción en Interpretación xIA:")
                print(f"[DEBUG] Tipo de excepción: {type(e).__name__}")
                print(f"[DEBUG] Mensaje: {e}")
                print("[DEBUG] Traza completa:")
                traceback.print_exc()
                self.sections.append((
                    "### ⚠️ Error en interpretación xIA del modelo",
                    f"{type(e).__name__}: {e}"
                ))

            # --- Fin Bloque 4 ---

            # --- Bloque 5: Interpretación Física-Química del Mejor Modelo Optimizado mediante IA ---
            print("[DEBUG] 17.19. Iniciando Interpretación Físico - Químicamediante IA  del Mejor Modelo Optimizado")
            try:
                import os
                import json
                #import pandas as pd
                #from PyPDF2 import PdfReader
                import openai

                # 1) Cargar y extraer texto de contexto de varios PDFs
                from PyPDF2 import PdfReader
                import pandas as pd

                # --- Gestión de subida y carga de contexto desde memoria en Colab ---
                import io
                import pandas as pd
                from PyPDF2 import PdfReader
                from google.colab import files
                import io

                # 2.1) Abrimos selector de archivos y leemos el .xlsx subido
                uploaded = files.upload()
                excel_file = next(f for f in uploaded.keys() if f.lower().endswith('.xlsx'))
                book_bytes = io.BytesIO(uploaded[excel_file])

                # 2.2) Cargamos **todas** las hojas; cada DataFrame toma su primera fila como cabecera
                import pandas as _pd
                sheets_dict = _pd.read_excel(book_bytes, sheet_name=None)

                print("Hojas encontradas en el Excel:", list(sheets_dict.keys()))

                # 2.3) Convertimos cada hoja en lista de dicts (records) sin predefinir columnas
                mapa_variables = {
                    name: (
                        df
                        .astype(str)            # convertimos todo a string para evitar Timestamp u otros tipos
                        .dropna(how='all')      # eliminamos filas completamente vacías
                        .to_dict(orient="records")
                    )
                    for name, df in sheets_dict.items()
                }
                # 2.4) Añadimos al contexto global
                #contexto["mapa_variables"] = mapa_variables

                # 3) Cargar y extraer texto de TODOS los PDFs subidos
                pdf_texts = {}
                for fn, content in uploaded.items():
                    if fn.lower().endswith(".pdf"):
                        reader = PdfReader(io.BytesIO(content))
                        full = "\n".join(page.extract_text() or "" for page in reader.pages)
                        pdf_texts[fn] = full

                # 4) Del PDF de proceso aislamos la sección relevante (si existe)
                proceso_pdf = next((k for k in pdf_texts if "Procesado_Datos_Linares" in k), None)
                if proceso_pdf:
                    texto = pdf_texts[proceso_pdf]
                    start_marker = "VARIABLES Y PARTICULARIDADES DEL PROCESO"
                    end_marker   = "Etapas del proceso"
                    i0 = texto.find(start_marker)
                    i1 = texto.find(end_marker, i0 + len(start_marker))
                    if i0 != -1 and i1 != -1:
                        proceso_texto = texto[i0:i1].strip()
                    else:
                        proceso_texto = texto
                else:
                    proceso_texto = ""

                # 5) Texto de la memoria TFM (si existe)
                memoria_pdf = next((k for k in pdf_texts if "Memoria Final TFM" in k), None)
                memoria_texto = pdf_texts.get(memoria_pdf, "")

                # 6) Construir el contexto completo
                contexto = {
                    "proceso_texto":   proceso_texto,
                    "memoria_texto":   memoria_texto,
                    "mapa_variables":  mapa_variables,
                    "dominio": (
                        "Este modelo optimiza la predicción de la variable objetivo en la planta de "
                        "aglomerados de Linares. Se considera la interacción físico-química entre resinas, "
                        "temperaturas de secado y niveles de humedad, así como parámetros de prensa y fases de corte."
                    )
                }

                # Ya puedes usar `contexto` y `contexto_variables` en tu prompt de OpenAI.
                print("[DEBUG] 17.20. Iniciando llamada a IA para análisis Físico - Químico del proceso")

                # 1. Prompt SHAP + Permutation
                prompt_shap_perm = f"""
            Dominio industrial:
            {contexto['dominio']}

            Resultados SHAP (importancia global resumida):
            {self.shap_json_lite}

            Permutation Importance (top features):
            {self.perm_json_lite}

            Explica cómo afectan estas variables al proceso y su impacto físico-químico.
            """

                # 2. Prompt PDP + ALE
                prompt_pdp_ale = f"""
            Dominio industrial:
            {contexto['dominio']}

            PDP (efecto parcial) para principales variables:
            {self.pdp_json_lite}

            ALE (efecto acumulado local) para principales variables:
            {self.ale_json_lite}

            Relaciona las tendencias observadas en los gráficos PDP y ALE con los fenómenos físicos-químicos reales.
            """

                # 3. Prompt ICE
                prompt_ice = f"""
            Dominio industrial:
            {contexto['dominio']}

            ICE (efectos individuales):
            {self.ice_json_lite}

            Describe la variabilidad operativa observada en ICE y su impacto en condiciones reales de planta.
            """

                # 4. Prompt Counterfactuals
                prompt_cf = f"""
            Dominio industrial:
            {contexto['dominio']}

            Counterfactuals (sólo ejemplos principales):
            {self.cf_json_lite}

            Proporciona recomendaciones sobre ajustes operativos para mejorar el KPI.
            """

                prompts = [
                    ("### Interpretación SHAP + Permutation", prompt_shap_perm),
                    ("### Interpretación PDP + ALE", prompt_pdp_ale),
                    ("### Interpretación ICE", prompt_ice),
                    ("### Interpretación Counterfactuals", prompt_cf)
                ]

                for titulo, prompt in prompts:
                    print(f"[DEBUG] 17.21. Llamando a IA para {titulo}")
                    resp = _client.chat.completions.create(
                        model="gpt-4",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    explicacion = resp.choices[0].message.content
                    self.sections.append((titulo, explicacion))

            except Exception as e:
                self.sections.append((
                    "### ⚠️ Error en Interpretación Física-Química",
                    f"{e}"
                ))

        except Exception as e:
            #self.sections.append((
            #    "### ⚠️ Error en selección integral de modelo",
            #    f"Se produjo un error al generar la sección de selección integral: {e}"
            #))
            # DEBUG: imprimo excepción completa para rastrear el fallo
            import traceback
            print(f"[DEBUG] ERROR: {type(e).__name__}: {e}")
            traceback.print_exc()
            self.sections.append((
                "### ⚠️ Error en selección integral de modelo",
                f"Se produjo un error al generar la sección de selección integral: {type(e).__name__}: {e}"
            ))
        # --- Fin Bloque 5 - Sección Integral del Modelo ---

        # --- Bloque 6: Curvas Y real vs. Y predicha por variable X (modelo óptimo) ---
        try:
            print("[DEBUG] 17.22. Iniciando bloque de curvas Y real vs predicho por variable X")

            import numpy as np
            from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
            import matplotlib.pyplot as plt
            import pandas as pd

            # DEBUG: listar todas las secciones añadidas hasta ahora
            print("[DEBUG] 17.23. Secciones en self.sections:")
            for idx, (title, content) in enumerate(self.sections):
                tipo = type(content).__name__
                cols = content.columns.tolist() if hasattr(content, "columns") else None
                print(f"   {idx:02d}: '{title}' → {tipo}" + (f", cols={cols}" if cols else ""))
            print("[DEBUG] 17.24. Ahora buscamos la tabla con 'puntuacion_global_final'…")

            # 1) Recuperar el DataFrame de resultados globales con 'puntuacion_global_final'
            df_results = None
            for title, content in self.sections:
                if isinstance(content, pd.DataFrame) and 'puntuacion_global_final' in content.columns:
                    df_results = content
                    break
            if df_results is None:
                raise RuntimeError("No se encontró la tabla de puntuaciones globales (df_results)")

            # 2) Identificar el mejor modelo
            best_idx = df_results['puntuacion_global_final'].idxmax()
            best_row = df_results.loc[best_idx]
            tipo, metodo, motor = best_row['tipo'], best_row['metodo'], best_row['motor']
            print(f"[DEBUG] 17.25. Modelo óptimo identificado: {tipo}-{metodo}-{motor}")

            # 3) Recuperar payload, modelo, scalers y lista de variables
            payload = OPT_MODELS[(tipo, metodo, motor)]
            model   = payload['model']
            features = payload.get('cols', self.g['X_test'].columns.tolist())
            sx      = payload.get('sx')   # scaler de X, si existe
            sy      = payload.get('sy')   # scaler de Y, si existe

            # 4) Preparar datos de test y predicciones
            X_test_sel = self.g['X_test'][features].copy()
            y_true     = self.g['Y_test'].values.ravel()
            # Escalado y predict
            X_scaled = sx.transform(X_test_sel.values) if sx else X_test_sel.values
            y_pred_raw = model.predict(X_scaled)
            y_pred = (sy.inverse_transform(y_pred_raw.reshape(-1,1)).ravel()
                      if sy else y_pred_raw.ravel())

            # 5) Calcular métricas globales de ajuste (idénticas para todos los subplots)
            r2  = r2_score(y_true, y_pred)
            mae = mean_absolute_error(y_true, y_pred)
            mse = mean_squared_error(y_true, y_pred)
            print(f"[DEBUG] 17.26. Métricas globales del modelo óptimo: R2={r2:.3f}, MAE={mae:.3f}, MSE={mse:.3f}")

            # 6) Crear figura de small multiples
            n_vars = len(features)
            ncols  = min(4, n_vars)
            nrows  = int(np.ceil(n_vars / ncols))

            fig, axes = plt.subplots(
                nrows, ncols,
                figsize=(ncols * 3, nrows * 2.5),
                squeeze=False
            )

            for ax, feat in zip(axes.flatten(), features):
                # Ordenar por valor de X para trazar líneas ordenadas
                x = X_test_sel[feat].values
                idx_sort = np.argsort(x)
                x_s = x[idx_sort]
                ax.plot(x_s, y_true[idx_sort],   label='Real',    linewidth=1)
                ax.plot(x_s, y_pred[idx_sort],   label='Predicho',linewidth=1)
                ax.set_title(
                    f"{feat}\n"
                    f"R²={r2:.2f}  MAE={mae:.2f}  MSE={mse:.2f}",
                    fontsize=8
                )
                ax.tick_params(labelsize=6)
                ax.legend(fontsize=6)

            # Desactivar ejes sobrantes
            for ax in axes.flatten()[n_vars:]:
                ax.set_visible(False)

            fig.tight_layout()
            print("[DEBUG] 17.27. Bloque de curvas completado, añadiendo sección al informe")

            # 7) Añadir al informe
            self.sections.append((
                "### Curvas Y real vs Y predicha por variable X (modelo óptimo)",
                fig
            ))

        except Exception as e:
            # En caso de fallo, no romperá todo el build_sections
            print(f"[ERROR] en bloque de curvas Y vs X: {e}")
            self.sections.append((
                "### ⚠️ Error en Curvas Y vs X",
                f"Se produjo un error generando las curvas: {e}"
            ))
        # --- Fin Bloque 6: Curvas Y real vs. Y predicha por variable X (modelo óptimo) ---

        # --- Bloque 7: Análisis IA de Curvas Y real vs Y predicho por Variable X ---
        try:
            print("[DEBUG] 17.28. Enriqueciendo contexto antes de llamar a OpenAI")

            from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
            from scipy.stats import skew, kurtosis, pearsonr
            import pandas as pd

            # Recuperar la configuración del mejor modelo
            # (asegúrate de haber definido antes mt, method, engine)
            key_best     = (mt, method, engine)
            payload_best = OPT_MODELS[key_best]
            features     = payload_best['cols']
            model_best   = payload_best['model']

            # Extraer datos de test y predicciones
            X_te = X_test[features].copy()
            y_true = Y_test.values.ravel()
            sx = payload_best.get('sx', None)
            X_te_s = sx.transform(X_te.values) if sx else X_te.values
            # Si el wrapper ya invierte la escala internamente:
            y_pred = model_best.predict(X_te_s) if not hasattr(model_best, 'sy') else model_best.predict(X_te)

            # 1) Estadísticas de distribución de cada X
            dist_stats = {}
            for feat in features:
                arr = X_te[feat].values
                dist_stats[feat] = {
                    'min': float(arr.min()),
                    'max': float(arr.max()),
                    'mean': float(arr.mean()),
                    'std': float(arr.std()),
                    'skew': float(skew(arr)),
                    'kurtosis': float(kurtosis(arr)),
                }

            # 2) Correlación residual vs X (heterocedasticidad)
            residuals = y_true - y_pred
            corr_stats = {}
            for feat in features:
                r, p = pearsonr(X_te[feat].values, residuals)
                corr_stats[feat] = {'pearson_r': float(r), 'p_value': float(p)}

            # 3) Residuales por cuartiles de X
            quartile_stats = {}
            for feat in features:
                df_q = pd.DataFrame({
                    'x': X_te[feat],
                    'res': residuals
                })
                df_q['qcut'] = pd.qcut(df_q['x'], 4, labels=False, duplicates='drop')
                qs = df_q.groupby('qcut')['res'].agg(['mean','std']).to_dict(orient='index')
                quartile_stats[feat] = {
                    int(k): {'mean_res': float(v['mean']), 'std_res': float(v['std'])}
                    for k, v in qs.items()
                }

            # 4) Ejemplos de pares (X, y_real, y_pred) en cuartiles extremos
            samples = {}
            for feat in features:
                # Seleccionar solo cuartiles 0 y 3
                cuts = pd.qcut(X_te[feat], 4, labels=False, duplicates='drop')
                sel = cuts.isin([0, 3])
                df_s = pd.DataFrame({
                    'x':   X_te[feat][sel],
                    'y_r': y_true[sel],
                    'y_p': y_pred[sel]
                }).head(3)  # 3 muestras por variable
                samples[feat] = df_s.to_dict(orient='records')

            # 5) Métricas globales del modelo óptimo
            global_stats = {
                'R2':  float(r2_score(y_true, y_pred)),
                'MAE': float(mean_absolute_error(y_true, y_pred)),
                'MSE': float(mean_squared_error(y_true, y_pred))
            }

            print("[DEBUG] 17.29. Dist stats, corr stats, quartile stats y samples construidos")

            # 6) Construcción del prompt enriquecido
            prompt = [
                "A continuación tienes un informe detallado de cada variable X:\n",
                "**1) Distribución de cada X:**",
                f"{dist_stats}\n",
                "**2) Correlación Residual vs X (Pearson):**",
                f"{corr_stats}\n",
                "**3) Residuales por cuartiles de X:**",
                f"{quartile_stats}\n",
                "**4) Ejemplos de pares (X, y_real, y_predicho) en cuartiles extremos:**",
                f"{samples}\n",
                "**5) Métricas globales del modelo óptimo:**",
                f"{global_stats}\n",
                "### Instrucciones al experto IA:\n"
                "1. Analiza para cada variable X cómo la distribución y la heterocedasticidad "
                "(Pearson r, residuales por cuartiles) pueden estar afectando el ajuste.\n"
                "2. Discute zonas problemáticas (picos, colas extensas) y su impacto en la predicción.\n"
                "3. Comenta sobre las muestras de ejemplo: ¿qué patrones ves en X extremos?\n"
                "4. Integra el conocimiento físico-químico del proceso para explicar estos fenómenos.\n"
                "5. Propón recomendaciones tanto de modelado (transformaciones, nuevas features) "
                "como de operación del proceso (rangos óptimos, variables críticas).\n"
            ]
            full_prompt = "\n".join(prompt)

            print("[DEBUG] 17.30. Llamando a OpenAI directamente con _client.chat.completions.create para Curvas…")
            response = _client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "Eres un experto en análisis de series temporales y ML para procesos físico-químicos."},
                    {"role": "user",   "content": full_prompt}
                ],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS
            )
            analysis_curvas = response.choices[0].message.content.strip()
            print(f"[DEBUG] 17.31. Longitud del análisis de curvas: {len(analysis_curvas)} caracteres")

            # 7) Añadimos la sección final al reporte
            self.sections.append((
                "### Análisis IA Profundo de Y real vs Y predicho por Variable X",
                analysis_curvas
            ))
            print("[DEBUG] 17.32. Sección Análisis IA enriquecido añadida")

        except Exception as e:
            err = f"Error en Bloque IA Profundo curvas X vs Y: {e}"
            self.sections.append((
                "### ⚠️ Error Bloque IA Profundo curvas X vs Y",
                err
            ))
            print(f"[DEBUG] {err}")

        # --- Fin Bloque 7: Análisis IA de Curvas Y real vs Y predicho por Variable X ---

        # --- Bloque 8: Robustez What-If y Gráficas Extremos ---
        try:
            print("[DEBUG] 17.33. Iniciando Bloque Robustez What-If y Gráficas Extremos")

            import itertools
            import numpy as np
            import pandas as pd
            import matplotlib.pyplot as plt
            import seaborn as sns

            # <<< NUEVO: Obtener escaladores desde payload (como se hace en xIA) >>>
            sx = payload.get('sx')
            sy = payload.get('sy')

            # Ajustes globales de estilo
            sns.set(style="whitegrid", palette="deep", font_scale=1.2)
            plt.rcParams.update({
                "figure.facecolor": "white",
                "axes.facecolor": "white",
                "axes.edgecolor": "#333333",
                "axes.labelcolor": "#333333",
                "xtick.color": "#333333",
                "ytick.color": "#333333",
                "text.color": "#333333",
                "legend.frameon": True,
                "legend.framealpha": 0.9,
            })

            # 1) Variables para robustez
            vars_robust = top_feats[:2]
            print(f"[DEBUG] 17.34. Variables robustez seleccionadas: {vars_robust}")

            # 2) Medianas y extremos
            medians   = X_train[features].median()
            low_vals  = X_train[features].quantile(0.05)
            high_vals = X_train[features].quantile(0.95)
            print("[DEBUG] 17.35. Valores medianos y percentiles obtenidos")

            # 3) Generar escenarios what-if
            scenarios = []
            for combo in itertools.product(['low','high'], repeat=len(vars_robust)):
                sc = medians.copy()
                labels = []
                for var, lvl in zip(vars_robust, combo):
                    sc[var] = low_vals[var] if lvl=='low' else high_vals[var]
                    labels.append(f"{var}_{lvl}")
                sc['__label__'] = " & ".join(labels)
                scenarios.append(sc)
            df_scen = pd.DataFrame(scenarios).reset_index(drop=True)
            print(f"[DEBUG] 17.36. {len(df_scen)} escenarios generados: {df_scen['__label__'].tolist()}")

            # <<< CAMBIO: Aplicar escalado SOLO si existe sx >>>
            X_scen = sx.transform(df_scen[features].values) if sx else df_scen[features].values
            if mt == 'rnn':
                X_in = X_scen.reshape((X_scen.shape[0], 1, X_scen.shape[1]))
            else:
                X_in = X_scen

            # 5) Predecir y calcular errores
            y_pred = model.predict(X_in)
            if mt != 'rnn':
                #y_pred = sy.inverse_transform(y_pred.reshape(-1,1)).ravel()
                y_pred = sy.inverse_transform(y_pred.reshape(-1,1)).ravel() if sy else y_pred.ravel()
            df_scen['y_pred'] = y_pred

            # <<< CAMBIO: Mismo tratamiento para y_base >>>
            yb = model.predict(
                X_in[:1].reshape((1,1,X_scen.shape[1])) if mt=='rnn' else X_in[:1]
            )
            if mt != 'rnn':
                yb = sy.inverse_transform(yb.reshape(-1,1)).ravel()[0] if sy else yb.ravel()[0]

            df_scen['y_base'] = yb
            df_scen['error_abs'] = np.abs(df_scen['y_pred'] - df_scen['y_base'])
            print("[DEBUG] 17.37. Predicciones y errores calculados")

            # 6) Boxplot de Error Absoluto
            fig1, ax1 = plt.subplots(figsize=(8, 5))
            sns.boxplot(
                y=df_scen['error_abs'],
                ax=ax1,
                width=0.4,
                boxprops=dict(facecolor="#4F81BD", edgecolor="#333333"),
                medianprops=dict(color="#E74C3C", linewidth=2),
                whiskerprops=dict(color="#333333", linewidth=1.5),
                capprops=dict(color="#333333", linewidth=1.5)
            )
            ax1.set_title("What-If: Boxplot de Error Absoluto", fontsize=16, fontweight='bold')
            ax1.set_ylabel("Error absoluto", fontsize=14)
            ax1.set_xticks([])
            ax1.grid(axis='y', linestyle='--', alpha=0.7)
            plt.tight_layout()
            self.sections.append((
                "### Robustez What-If: Boxplot de Error Absoluto",
                fig1
            ))
            print("[DEBUG] 17.38. Sección Boxplot de error añadido")

            # 7) Scatter Y_pred vs Baseline por escenario
            fig2, ax2 = plt.subplots(figsize=(10, 6))
            idx = np.arange(len(df_scen))
            ax2.plot(idx, df_scen['y_base'], marker='o', linestyle='-', label='Baseline', linewidth=2)
            ax2.plot(idx, df_scen['y_pred'], marker='X', linestyle='--', label='What-If Predicho', linewidth=2)
            for i, lbl in enumerate(df_scen['__label__']):
                ax2.annotate(
                    lbl,
                    (idx[i], df_scen['y_pred'].iloc[i]),
                    textcoords="offset points",
                    xytext=(0,8),
                    ha='center',
                    fontsize=10,
                    color="#333333"
                )
            ax2.set_xticks(idx)
            ax2.set_xticklabels(df_scen['__label__'], rotation=45, ha='right', fontsize=10)
            ax2.set_title("What-If: Y Predicho vs Baseline por Escenario", fontsize=16, fontweight='bold')
            ax2.set_xlabel("Escenario", fontsize=14)
            ax2.set_ylabel("Y", fontsize=14)
            ax2.legend(frameon=True, fontsize=12)
            ax2.grid(True, linestyle='--', alpha=0.5)
            plt.tight_layout()
            self.sections.append((
                "### Robustez What-If: Y Predicho vs Baseline",
                fig2
            ))
            print("[DEBUG] 17.39. Sección Scatter plot de escenarios añadido")

        except Exception as e:
            import traceback
            print("[DEBUG] Se ha producido una excepción en el Bloque Robustez What-If:")
            print("[DEBUG] Tipo de excepción:", type(e).__name__)
            print("[DEBUG] Mensaje:", e)
            print("[DEBUG] Traza completa:")
            traceback.print_exc()
            self.sections.append((
                "### ⚠️ Error en Bloque Robustez What-If",
                f"{type(e).__name__}: {e}"
            ))
            print(f"[DEBUG] Error en Bloque Robustez What-If: {e}")
        # --- Fin Bloque 8: Robustez What-If y Gráficas Extremos ---

        # --- Bloque 9: Análisis e Interpretación IA de Robustez What-If ---
        try:
            print("[DEBUG] 17.40. Iniciando Bloque IA de Robustez What-If e Interpretación")

            # 👇 Extraemos del atributo best_model_info
            metodo = self.best_model_info['metodo']
            motor  = self.best_model_info['motor']
            score  = self.best_model_info['score']

            # 👇 Y las métricas guardadas como atributos
            r2_cv_std = self.r2_cv_std
            res_std   = self.res_std
            cal_err   = self.cal_err

            # DEBUG: comprobación de valores
            print(f"[DEBUG] 17.41. Mejor modelo → método={metodo}, motor={motor}, score={score:.4f}")
            print(f"[DEBUG] 17.42. Métricas desde atributos → r2_cv_std={r2_cv_std:.4f}, res_std={res_std:.4f}, cal_err={cal_err:.4f}")

            # 1) Resumen numérico de escenarios what-if
            stats = {
                'mean_error': float(df_scen['error_abs'].mean()),
                'std_error':  float(df_scen['error_abs'].std()),
                'max_error':  float(df_scen['error_abs'].max()),
                'min_error':  float(df_scen['error_abs'].min()),
                'percentiles_error': {
                    '25%': float(df_scen['error_abs'].quantile(0.25)),
                    '50%': float(df_scen['error_abs'].quantile(0.50)),
                    '75%': float(df_scen['error_abs'].quantile(0.75))
                }
            }
            print(f"[DEBUG] 17.43. Estadísticos de error abs: {stats}")

            # 2) Preparar tabla de escenarios en formato dict para el prompt
            table_dict = df_scen[['__label__','y_base','y_pred','error_abs']].to_dict(orient='list')
            print("[DEBUG] 17.44. Tabla de escenarios convertida a dict para prompt")

            # 3) Montar prompt rico en contexto
            prompt_robustez = f"""
        Eres un experto en evaluación de robustez de modelos y procesos físico-químicos.

        A continuación tienes los resultados del análisis What-If para el modelo óptimo (método={metodo}, motor={motor}):

        • Estadísticos globales del error absoluto:
          - Media: {stats['mean_error']:.4f}
          - Desviación estándar: {stats['std_error']:.4f}
          - Mínimo: {stats['min_error']:.4f}
          - Máximo: {stats['max_error']:.4f}
          - Percentiles: 25%={stats['percentiles_error']['25%']:.4f}, 50%={stats['percentiles_error']['50%']:.4f}, 75%={stats['percentiles_error']['75%']:.4f}

        • Detalle por escenario:
          { { 'Escenarios': table_dict } }

        Instrucciones para el análisis:
        1. Describe para cada escenario (etiqueta) cómo varía la predicción frente al baseline y qué significa en términos del proceso físico-químico.
        2. Identifica qué variables generan mayor sensibilidad en el modelo y por qué.
        3. Resume los hallazgos generales de robustez y menciona si existen condiciones extremas donde el modelo falla o se vuelve inestable.
        4. Propón recomendaciones para mejorar la robustez del modelo (por ejemplo, ajustes de hiperparámetros, transformaciones, data augmentation de escenarios extremos).
        5. Sugiere acciones operativas concretas en planta (rangos de temperatura, concentraciones, etc.) basándote en los resultados What-If.
        """

            print("[DEBUG] 17.45. Llamando a OpenAI directamente con _client.chat.completions.create…")
            response = _client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "Eres un experto en Machine Learning aplicado a procesos físico-químicos."},
                    {"role": "user",   "content": prompt_robustez}
                ],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS
            )
            analysis_robustez = response.choices[0].message.content.strip()
            print(f"[DEBUG] 17.46. Longitud del análisis de robustez: {len(analysis_robustez)} caracteres")

            # 4) Añadir sección al informe
            self.sections.append((
                "### Robustez What-If: Análisis e Interpretación IA",
                analysis_robustez
            ))
            print("[DEBUG] 17.47. Sección IA Robustez What-If añadida")

        except Exception as e:
            error_msg = f"{type(e).__name__}: {e}"
            print(f"[DEBUG] Error en Bloque IA Robustez What-If: {error_msg}")
            self.sections.append((
                "### ⚠️ Error en Bloque IA Robustez What-If",
                error_msg
            ))
        # --- Fin Bloque 9: Análisis e Interpretación IA de Robustez What-If ---

        # =============================================================================
        #  Bloque 18: Conclusiones y Recomendaciones Generales
        # =============================================================================
        try:
            print("[DEBUG] 18.1. Iniciando Bloque Final de Conclusiones y Recomendaciones")

            # 1) Extraer info clave del mejor modelo (asegúrate de haberla guardado antes)
            best = getattr(self, 'best_model_info', {})
            metodo = best.get('metodo', 'N/A')
            motor  = best.get('motor', 'N/A')
            score  = best.get('score', None)

            # 2) Extraer métricas adicionales si las guardaste como atributos
            r2_cv_std = getattr(self, 'r2_cv_std', None)
            res_std   = getattr(self, 'res_std', None)
            cal_err   = getattr(self, 'cal_err', None)

            # 3) Formatear con control de None
            score_txt   = f"{score:.4f}"    if score    is not None else "N/A"
            r2_cv_txt   = f"{r2_cv_std:.4f}" if r2_cv_std is not None else "N/A"
            res_std_txt = f"{res_std:.4f}"   if res_std   is not None else "N/A"
            cal_err_txt = f"{cal_err:.4f}"   if cal_err   is not None else "N/A"

            perf_txt = (
                f"- **Mejor modelo**: {metodo}  \n"
                f"- **Motor de optimización**: {motor}  \n"
                f"- **Score final (R² o indicador principal)**: {score_txt}  \n"
                f"- **Std R² en CV**: {r2_cv_txt}  \n"
                f"- **Std residuos**: {res_std_txt}  \n"
                f"- **Error medio de calibración**: {cal_err_txt}  \n"
            )
            print(f"[DEBUG] 18.2. perf_txt:\n{perf_txt}")

            # 4) Resumir metodología (títulos de secciones ya generados)
            pasos = [
                "1. Carga y preprocesado de datos",
                "2. Exploración estadística y visualización",
                "3. Selección de variables independientes",
                "4. Entrenamiento de modelos (SVR, NN, XGB, RF, RNN)",
                "5. Optimización de hiperparámetros",
                "6. Interpretabilidad (SHAP, PDP, ICE, ALE, counterfactuals)",
                "7. Análisis de robustez What-If y escenarios extremos"
            ]
            metod_txt = "\n".join(f"- {p}" for p in pasos)
            print(f"[DEBUG] 18.3. metod_txt:\n{metod_txt}")

            # 5) Inyectar snippets de texto IA previos (si los tienes)
            snippets = []
            for title, content in self.sections:
                if title.startswith("### 📝 Explicación IA"):
                    # tomamos los primeros 200 caracteres de cada análisis
                    text = str(content)[:200].replace("\n", " ")                                # <------ AJUSTAR AQUI (INCREMENTAR ) PARA MEJORAR LA CALIDAD DEL ANÁLISIS DE LA IA
                    snippets.append(f"{title.lstrip('# ')}: «{text}...»")
            snippets_txt = "\n".join(f"- {s}" for s in snippets)
            print(f"[DEBUG] 18.4. snippets_txt:\n{snippets_txt}")

            # 6) Construir prompt final
            prompt = (
                "Eres un investigador de Deep Learning y un experto en procesos físico-químicos industriales.\n"
                "Tienes la siguiente información:\n\n"
                "**A) Rendimiento del mejor modelo**:\n"
                f"{perf_txt}\n"
                "**B) Metodología seguida**:\n"
                f"{metod_txt}\n\n"
                "**C) Resúmenes de análisis previos**:\n"
                f"{snippets_txt}\n\n"
                "Con toda esta información, por favor:\n"
                "1. Resume cada paso de la metodología en 1–2 frases, enfatizando aprendizajes clave.\n"
                "2. Sintetiza los hallazgos principales (tendencias, variables críticas, puntos fuertes/débiles del modelo).\n"
                "3. Conecta estos hallazgos con el proceso físico-químico: ¿qué parámetros de planta son más determinantes?\n"
                "4. Propón **3–5 acciones inmediatas** (p. ej. ajustes de operación, reentrenamiento, ampliación de datos).\n"
                "5. Diseña un roadmap de validación y despliegue (pruebas A/B, monitorización de drift, retrain schedule).\n"
                "6. Finaliza con un breve párrafo de cierre brillante que refuerce la confianza en el informe.\n"
                "7. Incluye **2–3 referencias bibliográficas** (APA) que respalden tus recomendaciones.\n"
            )
            print(f"[DEBUG] 18.5. Prompt final construido (longitud {len(prompt)} caracteres)")

            # 7) Llamada a OpenAI
            response = _client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "Eres un investigador académico y consultor industrial senior."},
                    {"role": "user",   "content": prompt}
                ],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS
            )
            concl_text = response.choices[0].message.content.strip()
            print("[DEBUG] 18.6. Respuesta IA recibida con longitud:", len(concl_text))

            # 8) Añadir sección final
            self.sections.append((
                "### Conclusiones y Recomendaciones Finales",
                concl_text
            ))
            print("[DEBUG] 18.7. Sección de conclusiones añadida exitosamente")

        except Exception as e:
            print(f"[ERROR] al generar Bloque Final de Conclusiones: {e}")
            self.sections.append((
                "### ⚠️ Error en Bloque de Conclusiones",
                str(e)
            ))
        # =============================================================================
        #  Fin Bloque 18 Conclusiones
        # =============================================================================

        # ============================================================================
        # --- Bloque 19: Descripción de PMS y Road-Map de Evolución Tecnológica ---
        # ============================================================================
        try:
            print("[DEBUG] 19.1. Iniciando Bloque Descripción y roadmap de PMS")

            import os, glob, ast, inspect, json

            base_dir = os.getcwd()

            # 1) Archivos .py
            py_files = glob.glob(os.path.join(base_dir, "*.py"))
            loc_summary_py = {}
            deps = set()
            for fn in py_files:
                try:
                    with open(fn, "r", encoding="utf-8") as f:
                        src = f.read()
                    lines = src.splitlines()
                    loc_summary_py[os.path.basename(fn)] = len(lines)
                    tree = ast.parse(src)
                    for node in ast.walk(tree):
                        if isinstance(node, ast.Import):
                            for n in node.names:
                                deps.add(n.name.split(".")[0])
                        elif isinstance(node, ast.ImportFrom):
                            if node.module:
                                deps.add(node.module.split(".")[0])
                except Exception as ex:
                    print(f"[DEBUG] No pude procesar {fn}: {ex}")

            # 2) Notebooks .ipynb
            ipynb_files = glob.glob(os.path.join(base_dir, "*.ipynb"))
            nb_summary = {}
            for fn in ipynb_files:
                try:
                    with open(fn, "r", encoding="utf-8") as f:
                        nb = json.load(f)
                    code_cells = sum(1 for c in nb.get("cells", []) if c.get("cell_type")=="code")
                    nb_summary[os.path.basename(fn)] = code_cells
                except Exception as ex:
                    print(f"[DEBUG] No pude procesar {fn}: {ex}")

            # 3) Inspeccionar ReportBuilder
            members = inspect.getmembers(ReportBuilder)
            methods = [name for name,obj in members if inspect.isfunction(obj)]
            classes = [name for name,obj in members if inspect.isclass(obj)]

            # 4) Secciones ya generadas
            num_sections = len(self.sections)
            titles = [t for t,_ in self.sections]

            # 5) Formatear resumen
            summary_lines = []
            summary_lines.append(f"• Archivos .py escaneados ({len(py_files)}):")
            for fn,loc in loc_summary_py.items():
                summary_lines.append(f"    – {fn}: {loc} líneas")
            if ipynb_files:
                summary_lines.append(f"• Notebooks .ipynb escaneados ({len(ipynb_files)}):")
                for fn,cells in nb_summary.items():
                    summary_lines.append(f"    – {fn}: {cells} celdas de código")
            summary_lines.append(f"• Dependencias detectadas: {', '.join(sorted(deps))}")
            summary_lines.append(f"• Métodos en ReportBuilder: {', '.join(methods)}")
            summary_lines.append(f"• Clases definidas en ReportBuilder: {', '.join(classes)}")
            summary_lines.append(f"• Secciones del informe generadas ({num_sections}):")
            for t in titles:
                summary_lines.append(f"    – {t}")

            summary_txt = "\n".join(summary_lines)

            # 6) Construir prompt
            prompt_pms = f"""
        Eres un arquitecto de software y consultor de procesos industriales.
        A continuación tienes un **resumen de la herramienta PMS** y su código fuente:

        {summary_txt}

        En base a ello, por favor:
        1. Describe **detalladamente la arquitectura** de la aplicación:
          - Flujo de ejecución
          - Principales módulos y clases
          - Patrones de diseño o buenas prácticas observadas.

        2. Señala **puntos fuertes** y **oportunidades de mejora**:
          - Modularidad, legibilidad, rendimiento, uso de librerías.
          - Aspectos que podrían complicar el mantenimiento o la escalabilidad.

        3. Proporciona un **road-map de evolución tecnológica**:
          - Refactorizaciones y modularización adicional.
          - Incorporación de tests automatizados y pipeline de CI/CD.
          - Contenerización / despliegue (Docker, Kubernetes, microservicios).
          - Nuevas funcionalidades (AutoML, flujos batch/pipeline, APIs).

        4. Recomienda **modelos, motores o métodos futuros**:
          - E.g. Transformers para series temporales, AutoML para selección de modelos.
          - Explica el **impacto** esperado en la calidad de la predicción y en la mantenibilidad.

        5. Concluye con un **resumen ejecutivo** de 2–3 párrafos enfatizando el valor de estas mejoras.
        """

            print("[DEBUG] 19.2. Llamando a OpenAI para Bloque 10 de PMS…")
            resp = _client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role":"system", "content":"Eres investigador académico, arquitecto de software y consultor industrial."},
                    {"role":"user",   "content":prompt_pms}
                ],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS,
            )
            analysis_pms = resp.choices[0].message.content.strip()

            # 7) Añadir sección al informe
            self.sections.append((
                "### Descripción de PMS y Road-Map de Evolución Tecnológica",
                analysis_pms
            ))
            print("[DEBUG] 19.3. Bloque completado y añadido al informe")

        except Exception as e:
            print(f"[DEBUG] Error en Bloque 10: {e}")
            self.sections.append((
                "### ⚠️ Error en Descripción y Road-Map de PMS",
                str(e)
            ))
        # --- Fin Bloque 11 ---


        print("[DEBUG] 20. ReportBuilder.build_sections end")
    # =============================================================
    #  Renderizado de la salida del Informe
    # =============================================================
    def render(self):
        from IPython.display import Markdown, display, HTML
        import pandas as pd
        import matplotlib.pyplot as plt

        print("[DEBUG] ReportBuilder.render start")
        for idx, (title, content) in enumerate(self.sections):
            print(f"[DEBUG] render sección #{idx}: {title}")
            # Mostrar título
            display(Markdown(title))

            # Si es DataFrame, aplicamos el estilo como antes
            if isinstance(content, pd.DataFrame):
                df = content
                try:
                    styled = (
                        df.style
                        .set_table_styles([
                            {'selector': 'th',
                            'props': [
                                ('background-color', '#4F81BD'),
                                ('color', 'white'),
                                ('font-weight', 'bold'),
                                ('padding', '8px'),
                                ('text-align', 'center')
                            ]},
                            {'selector': 'td',
                            'props': [
                                ('padding', '8px'),
                                ('text-align', 'center')
                            ]}
                        ])
                        .apply(lambda row: ['background-color: #f2f2f2' if i%2 else '' for i in range(len(row))],
                                axis=1)
                        .set_caption(f"Mostrando {df.shape[0]} filas y {df.shape[1]} columnas")
                    )
                    html = styled.to_html()
                    display(HTML(html))
                    print(f"[DEBUG] render sección #{idx}: DataFrame mostrado")
                except Exception as e:
                    print(f"[ERROR] al mostrar DataFrame en sección #{idx}: {e}")
            # Si es figura matplotlib
            elif hasattr(content, 'savefig') or hasattr(content, 'dpi'):  # aproximación para Figure
                try:
                    display(content)  # IPython detecta Figure y la muestra
                except Exception:
                    plt.show(content)
            else:
                # Texto IA: como ya limitamos con max_tokens, lo mostramos directamente completo.
                text = str(content or "")
                # Imprimimos longitud para debug
                length = len(text)
                print(f"[DEBUG] Longitud del contenido IA: {length} caracteres")
                # Mostrar todo el texto como Markdown
                display(Markdown(text))
                print(f"[DEBUG] render sección #{idx}: texto IA mostrado completo")
        print("[DEBUG] ReportBuilder.render end")

# Artifact: function mostrar_informe
def mostrar_informe():
    import ipywidgets as widgets
    from IPython.display import clear_output, display
    """
    Construye TODO el informe, presenta un listado de checkboxes con los títulos
    reales de sección, permite al usuario marcarlos (todos DESMARCADOS por defecto)
    y al pulsar 'Generar Informe' limpia la pantalla y muestra solo las secciones elegidas.
    """

    # === Módulo de Exportaciones: Word, PDF y HTML ===
    import io, base64, os
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import display, HTML
    from docx import Document
    from docx.shared import Inches
    from fpdf import FPDF
    import ipywidgets as widgets
    import unicodedata

    def limpiar_texto(texto):
        return ''.join(
            c for c in unicodedata.normalize('NFKD', str(texto))
            if ord(c) < 256
        )

    def exportar_informe(builder):
        # === Botones de Exportación ===
        btn_export_word_via_html = widgets.Button(
            description="Exportar a Word", button_style="info",
            layout=widgets.Layout(margin="10px 10px 10px 0")
        )
#        btn_export_word = widgets.Button(
#            description="Exportar a Word", button_style="info",
#            layout=widgets.Layout(margin="10px 10px 10px 0")
#        )
        btn_export_pdf = widgets.Button(
            description="Exportar a PDF", button_style="warning",
            layout=widgets.Layout(margin="10px 10px 10px 0")
        )
        btn_export_html = widgets.Button(
            description="Exportar a HTML", button_style="primary",
            layout=widgets.Layout(margin="10px 10px 10px 0")
        )

        def export_to_word_via_html(builder):
            import io
            import base64
            import os
            import pypandoc
            import pandas as pd
            import matplotlib.pyplot as plt
            from IPython.display import display, HTML

            html_parts = ["<html><head><meta charset='utf-8'><title>Informe</title></head><body>"]
            html_parts.append("<h1>Informe Generado</h1>")

            for title, content in builder.sections:
                clean_title = title.lstrip('# ').strip()
                html_parts.append(f"<h2>{clean_title}</h2>")

                try:
                    if isinstance(content, pd.DataFrame):
                        html_parts.append(content.head(20).to_html(index=False))
                        if len(content) > 20:
                            html_parts.append(f"<p><em>⚠️ Tabla truncada: solo primeras 20 filas de {len(content)}.</em></p>")

                    elif hasattr(content, "savefig"):
                        img_buf = io.BytesIO()
                        content.savefig(img_buf, format='png', bbox_inches='tight')
                        img_buf.seek(0)
                        img_b64 = base64.b64encode(img_buf.read()).decode()
                        html_parts.append(f"<img src='data:image/png;base64,{img_b64}' style='max-width:100%;'><br>")

                    else:
                        texto = str(content)
                        lineas = texto.splitlines()
                        if len(lineas) > 100:
                            texto = "\n".join(lineas[:100]) + "\n... (contenido truncado)"
                        html_parts.append(f"<pre>{texto}</pre>")

                except Exception as e:
                    html_parts.append(f"<p><strong>⚠️ Error al procesar la sección:</strong> {e}</p>")

            html_parts.append("</body></html>")

            # Guardar HTML temporal
            html_filename = "informe_temporal.html"
            with open(html_filename, "w", encoding="utf-8") as f:
                f.write("\n".join(html_parts))

            # Convertir HTML → DOCX usando pypandoc
            docx_filename = "informe_generado.docx"
            try:
                pypandoc.convert_file(html_filename, 'docx', outputfile=docx_filename)
                print(f"[DEBUG] Documento Word generado desde HTML: {docx_filename}")
            except Exception as e:
                print(f"[ERROR] Fallo en la conversión HTML → Word: {e}")
                return

            # Mostrar enlace de descarga
            with open(docx_filename, "rb") as f:
                b64 = base64.b64encode(f.read()).decode()
            href = (
                f'<a download="{docx_filename}" '
                f'href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}">'
                "⬇️ Descargar informe Word</a>"
            )
            display(HTML(href))


#            def export_to_word(b):
#                print("[DEBUG] Iniciando exportación a Word…")
#                doc = Document()
#                doc.add_heading('Informe Generado', level=0)

#                for title, content in builder.sections:
#                    clean_title = title.lstrip('# ').strip()
#                    doc.add_heading(clean_title, level=1)

#                    if isinstance(content, pd.DataFrame):
#                        table = doc.add_table(rows=1, cols=len(content.columns))
#                        hdr = table.rows[0].cells
#                        for i, col in enumerate(content.columns):
#                            hdr[i].text = str(col)
#                        for row in content.itertuples(index=False):
#                            cells = table.add_row().cells
#                            for i, val in enumerate(row):
#                                cells[i].text = str(val)

#                    elif hasattr(content, "savefig"):
#                        img_stream = io.BytesIO()
#                        content.savefig(img_stream, format='png', bbox_inches='tight')
#                        img_stream.seek(0)
#                        doc.add_picture(img_stream, width=Inches(6))

#                    else:
#                        for line in str(content).splitlines():
#                            doc.add_paragraph(line)

#                    doc.add_page_break()

#                if len(doc.paragraphs) == 0:
#                    doc.add_paragraph("⚠️ El informe no contiene contenido válido para exportar.")

#                output_path = "informe_generado.docx"
#                doc.save(output_path)
#                print(f"[DEBUG] Documento guardado en {output_path}")

#                with open(output_path, "rb") as f:
#                    b64 = base64.b64encode(f.read()).decode()

#                href = (
#                    f'<a download="{output_path}" '
#                    f'href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}">'
#                    "⬇️ Descargar informe Word</a>"
#                )
#                display(HTML(href))

        def export_to_pdf(b):
            print("[DEBUG] Iniciando exportación a PDF…")
            pdf = FPDF(orientation='L', unit='mm', format='A4')  # Apaisado
            pdf.set_auto_page_break(auto=True, margin=15)
            pdf.add_page()
            pdf.set_font("Arial", 'B', 14)
            pdf.cell(0, 10, limpiar_texto('Informe Generado'), ln=True)
            #pdf = FPDF()
            #pdf.cell(0, 10, 'Informe Generado', ln=True)

            for title, content in builder.sections:
                pdf.add_page()
                pdf.set_font("Arial", 'B', 12)
                #pdf.multi_cell(0, 10, title.lstrip('# ').strip())
                pdf.multi_cell(0, 10, limpiar_texto(title.lstrip('# ').strip()))


                if isinstance(content, pd.DataFrame):
                    pdf.set_font("Arial", '', 8)      # Reducimos tamaño de letra de 10 a 8 para hacer más compacto el informe
                    col_width = 270 / len(content.columns)  # Distribución proporcional
                    for col in content.columns:
                        #pdf.cell(40, 10, str(col), border=1)
                        pdf.cell(col_width, 10, limpiar_texto(col), border=1)
                    pdf.ln()
                    for row in content.itertuples(index=False):
                        for val in row:
                            #pdf.cell(40, 10, str(val), border=1)
                            pdf.cell(col_width, 10, limpiar_texto(val), border=1)
                        pdf.ln()

                elif hasattr(content, "savefig"):
                    img_buf = io.BytesIO()
                    content.savefig(img_buf, format='png', bbox_inches='tight')
                    img_buf.seek(0)
                    with open("temp_fig.png", "wb") as f:
                        f.write(img_buf.read())
                    #df.image("temp_fig.png", x=10, w=180)
                    pdf.image("temp_fig.png", x=10, w=270)  # Ancho máximo para A4 apaisado
                    os.remove("temp_fig.png")

                elif isinstance(content, str):
                    pdf.set_font("Arial", '', 10)        # Reducimos tamaño de letra de 12 a 10 para hacer más compacto el informe
                    #pdf.multi_cell(0, 10, content)
                    pdf.multi_cell(0, 10, limpiar_texto(content))


            filename = "informe_generado.pdf"
            pdf.output(filename)
            print(f"[DEBUG] Informe PDF generado correctamente: {filename}")

            with open(filename, "rb") as f:
                b64 = base64.b64encode(f.read()).decode()

            href = (
                f'<a download="{filename}" '
                f'href="data:application/pdf;base64,{b64}">'
                "⬇️ Descargar informe PDF</a>"
            )
            display(HTML(href))

        def export_to_html(b):
            print("[DEBUG] Iniciando exportación a HTML…")
            html_content = ["<html><head><meta charset='utf-8'><title>Informe</title></head><body>"]
            html_content.append("<h1>Informe Generado</h1>")

            for title, content in builder.sections:
                html_content.append(f"<h2>{title.lstrip('# ').strip()}</h2>")

                if isinstance(content, pd.DataFrame):
                    html_content.append(content.to_html(index=False))
                elif hasattr(content, "savefig"):
                    img_buf = io.BytesIO()
                    content.savefig(img_buf, format='png', bbox_inches='tight')
                    img_buf.seek(0)
                    encoded = base64.b64encode(img_buf.read()).decode()
                    html_content.append(f"<img src='data:image/png;base64,{encoded}' style='max-width:100%'>")
                else:
                    html_content.append(f"<pre>{str(content)}</pre>")

            html_content.append("</body></html>")

            filename = "informe_generado.html"
            with open(filename, "w", encoding="utf-8") as f:
                f.write("\n".join(html_content))

            with open(filename, "rb") as f:
                b64 = base64.b64encode(f.read()).decode()

            href = (
                f'<a download="{filename}" '
                f'href="data:text/html;base64,{b64}">'
                "⬇️ Descargar informe HTML</a>"
            )
            display(HTML(href))

        btn_export_word_via_html.on_click(export_to_word_via_html)
        btn_export_pdf.on_click(export_to_pdf)
        btn_export_html.on_click(export_to_html)

        display(widgets.HBox([btn_export_word_via_html, btn_export_pdf, btn_export_html]))

    # === Módulo de Generación y Presentación del Informe ===
    # 1) Generamos todas las secciones internamente (sin render aún)
    builder = ReportBuilder(globals())
    builder.build_sections()

    # 2) Creamos una lista de 'títulos limpios' para los checkboxes
    #    Eliminamos el prefijo '### ' y espacios sobrantes
    clean_titles = [title.lstrip("# ").strip() for title, _ in builder.sections]

#    # 3) Checkbox dinámico (todos DESMARCADOS)
#    checkboxes = [
#        widgets.Checkbox(value=False, description=clean_title, indent=False)
#        for clean_title in clean_titles
#    ]
    # 3) Checkbox dinámico (todos MARCADOS por defecto)
    checkboxes = [
        widgets.Checkbox(value=True, description=clean_title, indent=False)
        for clean_title in clean_titles
    ]

    # 4) Checkbox global para marcar/desmarcar todos
    toggle_all = widgets.Checkbox(
        value=True,
        description="(Des)marcar todas las secciones",
        indent=False,
        style={'description_width': 'initial'}
    )

    # 5) Contador dinámico de secciones seleccionadas
    counter_label = widgets.Label()
    def actualizar_contador(_=None):
        n_sel = sum(cb.value for cb in checkboxes)
        counter_label.value = f"Secciones seleccionadas: {n_sel} de {len(checkboxes)}"
    actualizar_contador()  # Inicializa

    # 6) Callback del checkbox global
    def _on_toggle_all(change):
        for cb in checkboxes:
            cb.value = toggle_all.value
        actualizar_contador()

    toggle_all.observe(_on_toggle_all, names='value')

    # 7) Callback individual para cada checkbox (actualiza contador)
    for cb in checkboxes:
        cb.observe(actualizar_contador, names='value')

    # 8) Botón de ejecución
    btn_generate = widgets.Button(
        description="Generar Informe",
        button_style="success",
        layout=widgets.Layout(margin="10px 0 0 0")
    )

    # 9) Montamos el UI
    ui = widgets.VBox([
        widgets.HTML("<h3>Selecciona las secciones a incluir en el informe:</h3>"),
        toggle_all,  # ⬅️ Añadimos el checkbox global
        counter_label,
        widgets.VBox(checkboxes),
        btn_generate
    ])
    display(ui)

    # 10) Callback: al pulsar el botón, filtramos y renderizamos
    def _on_generate_clicked(_):
        from IPython.display import clear_output, display
        clear_output(wait=True)
        # a) Recogemos sólo los títulos marcados
        seleccion = {
            cb.description
            for cb in checkboxes
            if cb.value
        }
        # b) Filtramos builder.sections por coincidencia exacta del título limpio
        filtered = []
        for (orig_title, content), clean_title in zip(builder.sections, clean_titles):
            if clean_title in seleccion:
                filtered.append((orig_title, content))

        # c) Reemplazamos y renderizamos
        builder.sections = filtered
        builder.render()

        # ✅ d) Llamada a exportar_informe (Word, PDF, HTML)
        exportar_informe(builder)

    # 10) Asignar callback
    btn_generate.on_click(_on_generate_clicked)

# Artifact: exec exec_314
from ipywidgets import Dropdown, Button, VBox, HBox, Output

# Artifact: exec exec_315
from IPython.display import HTML as dHTML, clear_output

# Artifact: assign menu_funcs
menu_funcs = {
    # Bienvenida + Ayuda
    "1. Bienvenida":            mostrar_bienvenida,
    "2. Ayuda Global":          mostrar_ayuda_completa,

    # Bloque 1
    "B1.1.1 Carga de Datos":       mostrar_carga,
    "B1.1.2 Segmentación Datos":   mostrar_split,
    "B1.2.1 Selección variables X": mostrar_seleccion_variables,

    # Bloque 2 – Entrenamiento
    "B2.1.1 Entrenamiento SVR":            mostrar_svr,
    "B2.1.2 Entrenamiento NN":             mostrar_nn,
    "B2.1.3 Entrenamiento XGBoost":        mostrar_xgb,
    "B2.1.4 Entrenamiento Random Forest":  mostrar_rf,
    "B2.1.5 Entrenamiento RNN":            mostrar_rnn,
    "B2.1.6 Comparador Modelos":           mostrar_comparador_modelos,

    # Bloque 2 – Predicción
    "B2.2.1 Predicción SVR":               mostrar_prediccion_svr,
    "B2.2.2 Predicción NN":                mostrar_prediccion_nn,
    "B2.2.3 Predicción XGBoost":           mostrar_prediccion_xgboost,
    "B2.2.4 Predicción Random Forest":     mostrar_prediccion_rf,
    "B2.2.5 Predicción RNN":               mostrar_prediccion_rnn,
    "B2.2.6 Visualización resultados":     mostrar_grafico_y_vs_x,

    # Bloque 3 – Optimización
    "B3.1.1 Optimización SVR":             mostrar_optimizacion_svr,
    "B3.1.2 Optimización NN":              mostrar_optimizacion_nn,
    "B3.1.3 Optimización XGBoost":         mostrar_optimizacion_xgb,
    "B3.1.4 Optimización Random Forest":   mostrar_optimizacion_rf,
    "B3.1.5 Optimización RNN":             mostrar_optimizacion_rnn,

    # Bloque 4 – xIA
    "B4.1 Interpretación xIA":            mostrar_xai,

    # Informe Final
    "Generar Informe Final":              mostrar_informe,
}

# Artifact: assign menu_tree
menu_tree = {
    "Bienvenida": {
        "1. Bienvenida": None
    },
    "Ayuda General": {
        "2. Ayuda Global": None
    },
    "Bloque 1 – Carga y segmentación de datos y Selección Variables": {
        "B1.1 Carga y Segmentación de Datos": {
            "B1.1.1 Carga de Datos": None,
            "B1.1.2 Segmentación Datos": None,
        },
        "B1.2 Selección variables X": {
            "B1.2.1 Selección variables X": None,
        },
    },
    "Bloque 2 – Entrenamiento de modelos IA y Predicción de Salidas": {
        "B2.1 Entrenamiento Modelos IA": {
            "B2.1.1 Entrenamiento SVR": None,
            "B2.1.2 Entrenamiento NN": None,
            "B2.1.3 Entrenamiento XGBoost": None,
            "B2.1.4 Entrenamiento Random Forest": None,
            "B2.1.5 Entrenamiento RNN": None,
            "B2.1.6 Comparador Modelos": None,
        },
        "B2.2 Predicción y visualización de datos de salida": {
            "B2.2.1 Predicción SVR": None,
            "B2.2.2 Predicción NN": None,
            "B2.2.3 Predicción XGBoost": None,
            "B2.2.4 Predicción Random Forest": None,
            "B2.2.5 Predicción RNN": None,
            "B2.2.6 Visualización resultados": None,
        },
    },
    "Bloque 3 – Optimización de Modelos IA": {
        "B3.1 Optimización de modelos IA": {
            "B3.1.1 Optimización SVR": None,
            "B3.1.2 Optimización NN": None,
            "B3.1.3 Optimización XGBoost": None,
            "B3.1.4 Optimización Random Forest": None,
            "B3.1.5 Optimización RNN": None,
        },
    },
    "Bloque 4 – Inteligencia Artificial Explicativa xIA": {
         "B4.1 Interpretación xIA": None,
#        "B4.1 Interpretación xIA": {
#            "B4.1.1 Interpretación xIA": None,
#        },
    },
    "Generar Informe Final": {
         "Generar Informe Final": None,
#        "Generar Informe Final": {
#            "Generar Informe Final": None,
#        },
    },
}

# Artifact: function _crear_dropdown
def _crear_dropdown(options, nivel):
    return widgets.Dropdown(
        options=options,
        description=f"Nivel-{nivel}:",
        layout={
            'width': '100%'          # ⬅️  ancho fluido
            # o '1100px', '80%', etc.
        },
        style={
            'description_width': '200px'  # ajusta si hiciera falta
        }
    )

# Artifact: function _subtree_for
def _subtree_for(path):
    node = menu_tree
    for key in path:
        node = node[key]
    return node

# Artifact: assign levels_box
levels_box = VBox(layout={'width': 'auto'})

# Artifact: assign btn_next
btn_next = Button(
    description="Seleccionar Siguiente",
    button_style="info",
    layout={'width': '190px'}
)

# Artifact: assign btn_run
btn_run = Button(
    description="Ejecutar",
    button_style="success",
    layout={'width': '140px'}
)

# Artifact: assign out_panel
out_panel = widgets.Output(
    layout={
        'border': '1px solid #ccc',
        'padding': '12px',
        'width': '100%',
        'max_height': '600px',
        'overflow_y': 'auto',
        'overflow_x': 'hidden',      # ← evita scroll horizontal
        'margin_top': '12px'
    }
)

# Artifact: function _crear_dropdown
def _crear_dropdown(options, nivel):
    return Dropdown(
        options=options,
        description=f"Nivel-{nivel}:",
        layout={
            'width': 'auto',               # ← ancho solo según texto
            'min_width': '400px',          # ← margen mínimo visual aceptable
            'max_width': '700px'
        },
        style={'description_width': '160px'}
    )

# Artifact: function _update_buttons
def _update_buttons():
    path = [d.value for d in levels_box.children]
    leaf = (_subtree_for(path) is None)
    btn_next.disabled = leaf
    btn_run.disabled = not leaf

# Artifact: function _on_change
def _on_change(ch):
    dd_list = list(levels_box.children)
    idx = dd_list.index(ch['owner'])
    levels_box.children = tuple(dd_list[:idx+1])
    _update_buttons()

# Artifact: function _reset
def _reset():
    dd0 = _crear_dropdown(list(menu_tree.keys()), 1)
    dd0.observe(_on_change, names='value')
    levels_box.children = (dd0,)
    _update_buttons()

# Artifact: function _next
def _next(_):
    path = [d.value for d in levels_box.children]
    branch = _subtree_for(path)
    if branch:
        nivel = len(levels_box.children) + 1
        new_dd = _crear_dropdown(list(branch.keys()), nivel)
        new_dd.observe(_on_change, names='value')
        levels_box.children = (*levels_box.children, new_dd)
    _update_buttons()

# Artifact: function _run
def _run(_):
    nodo = levels_box.children[-1].value
    func = menu_funcs.get(nodo)
    out_panel.clear_output()
    with out_panel:
        if func is None:
            print(f"⚠️  No se ha implementado «{nodo}».")
        else:
            clear_output(wait=True)
            func()

# Artifact: exec exec_330
btn_next.on_click(_next)

# Artifact: exec exec_331
btn_run.on_click(_run)

# Artifact: exec exec_332
_reset()

# Artifact: exec exec_333
display(
    VBox([
        widgets.HTML("<h3 style='font-size:1.3rem;margin-bottom:5px;'>📋 Menú Principal</h3>"),
        levels_box,
        HBox([btn_next, btn_run], layout={'gap': '30px', 'margin_top': '5px'}),
        out_panel
    ])
)

# Artifact: exec exec_334
from ipywidgets import Button

# Artifact: exec exec_335
from IPython.display import display

# Artifact: assign btn_limpiar
btn_limpiar = Button(
    description="🧹 Limpiar pantalla",
    button_style="warning",
    layout={'width': '150px'}
)

# Artifact: function _on_limpiar
def _on_limpiar(_):
    # Borra solo el contenido del panel de resultados
    out_panel.clear_output()

# Artifact: exec exec_338
btn_limpiar.on_click(_on_limpiar)

# Artifact: exec exec_339
display(btn_limpiar)

