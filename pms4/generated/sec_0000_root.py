# Auto-generated from PMS 3.6.0 by PMS 4.0.0
# Section 0: root

# Artifact: exec exec_0
import pandas as pd

# Artifact: exec exec_1
import numpy as np

# Artifact: exec exec_2
import matplotlib.pyplot as plt

# Artifact: exec exec_3
import pickle, os

# Artifact: exec exec_4
from io import StringIO

# Artifact: exec exec_5
import ipywidgets as widgets

# Artifact: exec exec_6
from IPython.display import display, clear_output

# Artifact: exec exec_7
import shap

# Artifact: exec exec_8
import lime

# Artifact: exec exec_9
import lime.lime_tabular

# Artifact: exec exec_10
from keras_tuner import BayesianOptimization

# Artifact: exec exec_11
from sklearn.model_selection import KFold

# Artifact: exec exec_12
import shutil

# Artifact: exec exec_13
import time

# Artifact: exec exec_14
import threading

# Artifact: exec exec_15
from tensorflow.keras.callbacks import EarlyStopping

# Artifact: exec exec_16
from sklearn.svm import SVR

# Artifact: exec exec_17
from sklearn.preprocessing import StandardScaler

# Artifact: exec exec_18
from sklearn.metrics import mean_squared_error, r2_score

# Artifact: exec exec_19
from sklearn.model_selection import cross_val_score, KFold

# Artifact: exec exec_20
from sklearn.model_selection import train_test_split, KFold

# Artifact: exec exec_21
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Artifact: exec exec_22
import keras_tuner as kt

# Artifact: exec exec_23
import pickle

# Artifact: exec exec_24
import os

# Artifact: exec exec_25
import tensorflow as tf

# Artifact: exec exec_26
from tensorflow.keras.models import Sequential, load_model

# Artifact: exec exec_27
from tensorflow.keras.layers import Dense

# Artifact: exec exec_28
from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam, Ftrl

# Artifact: exec exec_29
from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback

# Artifact: exec exec_30
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Artifact: exec exec_31
import random

# Artifact: exec exec_32
from xgboost import XGBRegressor

# Artifact: exec exec_33
from xgboost.callback import EarlyStopping as XgbEarlyStopping

# Artifact: exec exec_34
import pkgutil

# Artifact: exec exec_35
import seaborn as sns

# Artifact: exec exec_36
from sklearn.ensemble import RandomForestRegressor

# Artifact: exec exec_37
from sklearn.feature_selection import mutual_info_regression

# Artifact: exec exec_38
import threading, time, pickle, os

# Artifact: exec exec_39
from ipywidgets import Output

# Artifact: exec exec_40
import io

# Artifact: exec exec_41
from google.colab import output

# Artifact: exec exec_42
from IPython.display import display, HTML, clear_output

# Artifact: exec exec_43
import re

# Artifact: function sanitize_name
def sanitize_name(s):
    """
    Unifica la sanitizaci√≥n de cualquier string de columna:
    Reemplaza espacios, puntos, comas, punto y coma, dos puntos,
    barras (/ \\), par√©ntesis (), corchetes [], llaves {},
    signo %, +, -, *, &, ^, $, #, @, !, ?, =, <, >, |, `, ~
    por gui√≥n bajo y colapsa m√∫ltiples guiones bajos.
    """
    # Reemplaza todo car√°cter no alfanum√©rico o gui√≥n bajo por '_'
    t = re.sub(r"[^\w]", "_", str(s))
    # Colapsa m√∫ltiples guiones bajos consecutivos
    t = re.sub(r"_+", "_", t)
    return t.strip("_")

# Artifact: assign out_carga
out_carga = widgets.Output()

# Artifact: assign out_svr
out_svr = widgets.Output()

# Artifact: assign out_nn
out_nn = widgets.Output()

# Artifact: assign out_xgb
out_xgb = widgets.Output()

# Artifact: assign out_pred
out_pred = widgets.Output()

# Artifact: assign out_graf
out_graf = widgets.Output()

# Artifact: assign out_xai
out_xai = widgets.Output()

# Artifact: assign out_bienvenida
out_bienvenida = widgets.Output()

# Artifact: assign out_ayuda
out_ayuda = widgets.Output()

# Artifact: assign out_nn_opt
out_nn_opt = widgets.Output()

# Artifact: assign stop_flag
stop_flag = threading.Event()

# Artifact: assign stop_flag_nn
stop_flag_nn = threading.Event()

# Artifact: assign out_svr_opt
out_svr_opt = widgets.Output()

# Artifact: assign stop_flag_svr
stop_flag_svr = threading.Event()

# Artifact: assign out_xgb_opt
out_xgb_opt = widgets.Output()

# Artifact: assign stop_flag_xgb
stop_flag_xgb = threading.Event()

# Artifact: assign out_rf
out_rf = widgets.Output()

# Artifact: assign rf_timer_stop_event
rf_timer_stop_event = threading.Event()

# Artifact: exec exec_63
if 'out_rnn' not in globals():
    out_rnn = widgets.Output()

# Artifact: assign ayuda_visible
ayuda_visible = [False]

# Artifact: exec exec_65
output.enable_custom_widget_manager()

# Artifact: function mostrar_ayuda_completa
def mostrar_ayuda_completa() -> None:
    """
    Despliega la ayuda global, dividida en 4 bloques:

    Bloque 1 ‚Üí Carga, Segmentaci√≥n y Selecci√≥n de Variables
    Bloque 2 ‚Üí Entrenamiento y Visualizaci√≥n de Modelos
    Bloque 3 ‚Üí Optimizaci√≥n Multicapa (SVR, NN, XGB, RF, RNN)
    Bloque 4 ‚Üí Interpretabilidad xIA, Navegaci√≥n y Men√∫ Principal

    Cada bloque se explica en profundidad con texto, tablas e
    im√°genes incrustadas (generadas al vuelo).  El usuario puede
    cambiar de bloque pulsando los botones de navegaci√≥n.
    """

    # -----------------------------------------------
    #  util_img_blocks.py  ¬∑  4 generadores de imagen
    # -----------------------------------------------
    import matplotlib.pyplot as plt
    from matplotlib.patches import FancyArrowPatch, Rectangle
    import numpy as np, io, base64, textwrap, itertools, random
    from IPython.display import display, HTML, clear_output

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def _fig_to_b64(fig) -> str:
        "Convierte una figura matplotlib en cadena base64"
        buf = io.BytesIO()
        fig.savefig(buf, format="png", bbox_inches="tight", dpi=140)
        plt.close(fig); buf.seek(0)
        return base64.b64encode(buf.read()).decode()

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # BLOQUE 1  ¬∑  Tubo de carga ‚Üí split ‚Üí selecci√≥n
    def _img_block1() -> str:
        fig, ax = plt.subplots(figsize=(6, 2))
        ax.axis("off")

        # 1) CSV/Excel
        ax.add_patch(Rectangle((0.05, .25), .18, .5, fc="#f0f8ff", ec="#4682b4", lw=1.5))
        ax.text(.14, .5, "Excel/CSV", ha="center", va="center", weight="bold")

        # 2) DataFrame
        ax.add_patch(Rectangle((.30, .25), .18, .5, fc="#e6ffe6", ec="#2e8b57", lw=1.5))
        ax.text(.39, .5, "DataFrame\n(pandas)", ha="center", va="center")

        # 3) Train/Test
        ax.add_patch(Rectangle((.55, .45), .18, .3, fc="#fff4e6", ec="#ff8c00", lw=1.5))
        ax.text(.64, .60, "Train", ha="center", va="center", size=8)
        ax.add_patch(Rectangle((.55, .25), .18, .15, fc="#ffe6e6", ec="#d80027", lw=1.5))
        ax.text(.64, .325, "Test", ha="center", va="center", size=8)

        # 4) Selecci√≥n de variables (nodos peque√±os)
        methods = ["Pearson", "Mutual\nInfo", "Boruta", "UMAP"]
        for i, m in enumerate(methods):
            x = .82; y = .6 - i*0.15
            ax.add_patch(Rectangle((x, y), .13, .1, fc="#fafafa", ec="#555", lw=1))
            ax.text(x+.065, y+.05, m, ha="center", va="center", size=7)

        # Flechas
        def arrow(xy1, xy2):
            ax.add_patch(FancyArrowPatch(xy1, xy2, arrowstyle="->", lw=1, color="#444"))
        arrow((.23, .5), (.30, .5))
        arrow((.48, .5), (.55, .5))
        arrow((.73, .5), (.82, .55))
        arrow((.73, .5), (.82, .4))
        arrow((.73, .5), (.82, .25))
        fig.suptitle("Pipeline Bloque 1", fontweight="bold")
        return _fig_to_b64(fig)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # BLOQUE 2  ¬∑  Comparativa de desempe√±o de modelos
    def _img_block2() -> str:
        models = ["SVR", "NN", "XGB", "RF", "RNN"]
        scores = [0.82, 0.88, 0.91, 0.86, 0.84]  # ejemplo R¬≤
        fig, ax = plt.subplots(figsize=(5, 3))
        bars = ax.bar(models, scores, color="#4c9be8")
        ax.set_ylim(0, 1.0)
        ax.set_ylabel("R¬≤ en Test")
        ax.set_title("Rendimiento modelos (ejemplo)")
        for b, s in zip(bars, scores):
            ax.text(b.get_x() + b.get_width()/2, s+0.02, f"{s:.2f}", ha="center", va="bottom", size=8)
        return _fig_to_b64(fig)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # BLOQUE 3  ¬∑  Convergencia de b√∫squeda HPO
    def _img_block3() -> str:
        fig, ax = plt.subplots(figsize=(5.5, 3))
        n_iter = 30
        # curva ‚Äúscore‚Äù ficticia para 3 t√©cnicas
        rng = np.random.RandomState(0)
        for label, c in zip(("GridSearch", "BayesSearch", "Optuna"), ("#999", "#2e8b57", "#d62728")):
            best_so_far = np.maximum.accumulate(rng.uniform(.5, .9, n_iter))
            ax.plot(range(1, n_iter+1), best_so_far, label=label, lw=1.8, color=c)
        ax.set_xlabel("Iteraci√≥n")
        ax.set_ylabel("Score acumulado (R¬≤)")
        ax.set_title("Evoluci√≥n b√∫squeda de hiperpar√°metros")
        ax.legend(frameon=False, fontsize=8)
        return _fig_to_b64(fig)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # BLOQUE 4  ¬∑  Mini-summary de interpretabilidad (SHAP simulado)
    def _img_block4() -> str:
        feats = ["X1", "X2", "X3", "X4", "X5"]
        shap_vals = np.array([0.4, -0.35, 0.25, -0.15, 0.05])
        colors = ['#d62728' if v<0 else '#2ca02c' for v in shap_vals]
        fig, ax = plt.subplots(figsize=(4.5, 3))
        ax.barh(feats, shap_vals, color=colors)
        ax.axvline(0, color="#444", lw=0.8)
        ax.set_xlabel("Valor SHAP (impacto en la predicci√≥n)")
        ax.set_title("Contribuci√≥n de variables (ejemplo)")
        plt.tight_layout()
        return _fig_to_b64(fig)

    # ----------------------------------------------------------
    # 1Ô∏è‚É£  TEXTOS DE AYUDA  (puedes ampliarlos todo lo que quieras)
    #     ‚Äî Cada bloque es un gran HTML con t√≠tulos, listas,
    #       tablas <table>, im√°genes <img>‚Ä¶
    # ----------------------------------------------------------
    bloque1_html = HTML(f"""
    <h3 style='color:#2E8B57;'>üü¢ Bloque 1 ‚Äì Carga, segmentaci√≥n y selecci√≥n de variables</h3>
    <p><b>Objetivo:</b> transformar hojas Excel o .csv en matrices <code>X</code> (predictoras) y
    <code>Y</code> (objetivo).</p>

    <h4>üì• Carga de datos</h4>
    <ul>
      <li>Importaci√≥n directa desde √°rea de transferencia (<i>copy‚Äìpaste</i> de Excel) o desde fichero.</li>
      <li>Validaci√≥n de encabezados, tipos y <code>NaN</code>.</li>
      <li>Ejemplo r√°pido:<br>
      <code>X, Y = cargar_desde_clipboard(sep='\\t')</code></li>
    </ul>

    <h4>üß© Segmentaci√≥n Train/Test</h4>
    <ul>
      <li>Divisi√≥n estratificada opcional (<i>stratify=Y</i> cuando <code>Y</code> es discreta).</li>
      <li>Seed reproducible (<code>random_state=42</code>).</li>
      <li>Visualizaci√≥n: tabla de tama√±os y gr√°fico ‚Äúbarra apilada‚Äù para comparar distribuci√≥n de
          objetivos.</li>
    </ul>

    <h4>üîç Selecci√≥n de variables <i>X</i></h4>
    <table>
    <thead><tr><th>M√©todo</th><th>Descripci√≥n resumida</th><th>M√©trica interna</th></tr></thead>
    <tbody>
    <tr><td>Pearson / Spearman</td><td>Descarta colinealidad lineal / mon√≥tona</td><td>|œÅ| &gt; œÑ</td></tr>
    <tr><td>Mutual Info</td><td>Informaci√≥n mutua no-lineal</td><td>MI &gt; œÑ</td></tr>
    <tr><td>Boruta</td><td>Selecci√≥n envolvente basada en RF</td><td>Importancia &gt; shadow</td></tr>
    <tr><td>UMAP</td><td>Reducci√≥n de dimensi√≥n no lineal (embedding)</td><td>Varianza retenida</td></tr>
    </tbody></table>

    <p><i>Resultado:</i> diccionario <code>RESUMEN_METODOS</code> con el subconjunto de columnas
    aprobado por cada t√©cnica.</p>
    <<img src="data:image/png;base64,{_img_block1()}"  ></td></tr>>
    """)

    bloque2_html = HTML(f"""
    <h3 style='color:#1E90FF;'>üîµ Bloque 2 ‚Äì Entrenamiento y visualizaci√≥n de modelos</h3>
    <p>Incluye:</p>
    <ul>
      <li><b>SVR</b> (kernels lineal / RBF)</li>
      <li><b>Red Neuronal densa</b> (Keras/TensorFlow)</li>
      <li><b>XGBoost</b> (regresi√≥n)</li>
      <li><b>Random Forest</b> (sklearn)</li>
      <li><b>RNN</b> / LSTM para series temporales</li>
    </ul>

    <h4>Flujo de trabajo general</h4>
    <ol>
      <li>Escalado (<code>StandardScaler</code>) de <code>X</code> y <code>Y</code>.</li>
      <li>Entrenamiento con <code>X_train</code>, evaluaci√≥n con <code>X_test</code>.</li>
      <li>M√©tricas trazadas: R¬≤, MSE, RMSE, MAE, MedAE.</li>
      <li>Gr√°ficos:
        <ul>
            <li>Y real vs Y predicho (scatter y l√≠nea)</li>
            <li>Residuos: histograma + Q‚ÄìQ + <i>residual vs fitted</i></li>
        </ul>
      </li>
    </ol>

    <h4>Ejemplo m√≠nimo ‚Äì SVR RBF</h4>
    <pre>
    svr = SVR(kernel='rbf', C=10, epsilon=0.1, gamma='scale')
    svr.fit(X_train_scaled, y_train_scaled)
    pred = scaler_y.inverse_transform(svr.predict(X_test_scaled).reshape(-1,1))
    </pre>
    <img src="data:image/png;base64,{_img_block2()}"  ></td></tr>
    """)

    bloque3_html = HTML(f"""
    <h3 style='color:#FFA500;'>üü† Bloque 3 ‚Äì Optimizaci√≥n multicapa (HPO)</h3>
    <p>Se soportan cinco motores por tipo de modelo:</p>
    <ul>
      <li><b>GridSearchCV</b></li>
      <li><b>RandomizedSearchCV</b></li>
      <li><b>BayesSearchCV</b> (scikit-optimize)</li>
      <li><b>Optuna</b></li>
      <li><b>Hyperband / HalvingSearchCV</b></li>
    </ul>

    <table>
    <thead><tr><th>Modelo</th><th>Espacio de b√∫squeda ‚äÇ ‚Ñù‚Åø</th><th>Trials por defecto</th></tr></thead>
    <tbody>
    <tr><td>SVR</td><td>C, Œµ, kernel</td><td>30</td></tr>
    <tr><td>Neural Net</td><td>#capas, neuronas, LR, dropout, ‚Ñì‚ÇÇ</td><td>50</td></tr>
    <tr><td>XGBoost</td><td>depth, lr, n_estim, Œ≥, subsample‚Ä¶</td><td>100</td></tr>
    <tr><td>Random Forest</td><td>n_estim, depth, mtry, bootstrap‚Ä¶</td><td>70</td></tr>
    <tr><td>RNN</td><td>units, batch, epochs, LR</td><td>50</td></tr>
    </tbody></table>

    <p>Cada ejecuci√≥n devuelve:</p>
    <ul>
      <li>TOP-5 configuraciones (tabla ordenada)</li>
      <li>Mejor curva de predicci√≥n y residuos</li>
      <li>Heat-map de m√©tricas normalizadas + Radar chart</li>
    </ul>
    <img src="data:image/png;base64,{_img_block3()}"  ></td></tr>
    """)

    bloque4_html = HTML(f"""
    <h3 style='color:#8A2BE2;'>üü£ Bloque 4 ‚Äì Interpretabilidad xIA &amp; Navegaci√≥n</h3>
    <p>El m√≥dulo integra <b>14</b> t√©cnicas:</p>
    <ol>
      <li>SHAP (Tree / Kernel / Deep)</li>
      <li>LIME (tabular)</li>
      <li>KernelExplainer (SHAP caja negra)</li>
      <li>Integrated Gradients</li>
      <li>DeepLIFT / LRP</li>
      <li>Permutation Feature Importance</li>
      <li>Partial Dependence Plots (PDP)</li>
      <li>Accumulated Local Effects (ALE)</li>
      <li>ICE plots</li>
      <li>Counterfactual Explainer</li>
      <li>Anchors (√°rboles locales)</li>
      <li>Modelos sustitutos (√°rbol global + l√≠neas locales)</li>
      <li>Explainable Boosting Machine (EBM)</li>
      <li>Optuna Hyper-parameter Importance</li>
    </ol>

    <p>Para cada t√©cnica se generan:</p>
    <ul>
      <li>Gr√°fico principal (summary, barras, scatter‚Ä¶)</li>
      <li>Tabla local (primeras 10 muestras)</li>
      <li>Tabla de importancia global</li>
      <li>Bloque de interpretaci√≥n con <i>tips</i> y lectura guiada</li>
    </ul>
    <img src="data:image/png;base64,{_img_block4()}"  ></td></tr>
    <p><i>Consejo:</i> combina SHAP + PDP + Permutation para tener una visi√≥n 360¬∞: explicaciones locales,
    efecto medio y robustez de cada variable.</p>
    """)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Botones + enlace a callback
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    # ----------------------------------------------------------
    # 2Ô∏è‚É£  √ÅREA DE SALIDA (visible a todas las funciones)
    # ----------------------------------------------------------
    _help_output = widgets.Output()

    # ----------------------------------------------------------
    # 3Ô∏è‚É£  RENDER FUNCTIONS (deben existir ANTES de .on_click)
    # ----------------------------------------------------------
    def _render_bloque_1(*_):
        _help_output.clear_output()
        with _help_output:
            display(bloque1_html)

    def _render_bloque_2(*_):
        _help_output.clear_output()
        with _help_output:
            display(bloque2_html)

    def _render_bloque_3(*_):
        _help_output.clear_output()
        with _help_output:
            display(bloque3_html)

    def _render_bloque_4(*_):
        _help_output.clear_output()
        with _help_output:
            display(bloque4_html)

    # ----------------------------------------------------------
    # 4Ô∏è‚É£  BOTONES  (creados DESPU√âS de las funciones)
    # ----------------------------------------------------------
    btn_b1 = widgets.Button(description="‚ÑπÔ∏è Bloque 1 ‚Äì DATOS",           button_style='info')
    btn_b2 = widgets.Button(description="‚ÑπÔ∏è Bloque 2 ‚Äì ENTRENAMIENTO",   button_style='info')
    btn_b3 = widgets.Button(description="‚ÑπÔ∏è Bloque 3 ‚Äì OPTIMIZACI√ìN",    button_style='info')
    btn_b4 = widgets.Button(description="‚ÑπÔ∏è Bloque 4 ‚Äì INTERPRETABILIDAD", button_style='info')

    # Enlazar callbacks  (ya no produce NameError)
    btn_b1.on_click(_render_bloque_1)
    btn_b2.on_click(_render_bloque_2)
    btn_b3.on_click(_render_bloque_3)
    btn_b4.on_click(_render_bloque_4)

    # ----------------------------------------------------------
    # 5Ô∏è‚É£  INTERFAZ ‚Äì se muestra la cabecera + botones + √°rea
    # ----------------------------------------------------------
    display(
        widgets.VBox([
            widgets.HTML("<h2 style='color:#1E90FF;'>üìò AYUDA GLOBAL ‚Äî Gu√≠a Completa de la Aplicaci√≥n</h2>"),
            widgets.HTML("<p>Selecciona el bloque sobre el que necesitas informaci√≥n detallada.</p>"),
            widgets.HBox([btn_b1, btn_b2, btn_b3, btn_b4]),
            _help_output
        ])
    )

# Artifact: exec exec_67
import io, base64, numpy as np, matplotlib.pyplot as plt

# Artifact: function _fig_to_b64
def _fig_to_b64(fig):
    """Devuelve la figura matplotlib codificada en base-64 (PNG)."""
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight", dpi=130)
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode()

# Artifact: function _block2_img_training_prediction
def _block2_img_training_prediction():
    fig, ax = plt.subplots(figsize=(6.2, 1.0))
    ax.axis("off")
    boxes = [
        ("ENTRENAMIENTO", "#e6ffe6", "#2e8b57"),
        ("VALIDACI√ìN",    "#fffbd5", "#ff8c00"),
        ("PREDICCI√ìN",    "#d6e0ff", "#4169e1")
    ]
    xs = [.02, .36, .70]
    for x, (txt, fc, ec) in zip(xs, boxes):
        ax.annotate(
            txt, (x, .5), ha="left", va="center",
            bbox=dict(fc=fc, ec=ec, lw=1.4, boxstyle="round,pad=0.28"))
    for x in [.28, .62]:
        ax.annotate(
            "", xy=(x+.03, .5), xytext=(x-.03,.5),
            arrowprops=dict(arrowstyle="->", lw=1.5))
    ax.set_xlim(0, 1); ax.set_ylim(0, 1)
    return _fig_to_b64(fig)

# Artifact: function _img_flow_trainpred
def _img_flow_trainpred():
    fig, ax = plt.subplots(figsize=(4.5, .9)); ax.axis("off")
    ax.annotate("Bloque 1\nCarga, \nSegmentacion y \nSelecci√≥n", (.05,.5), va="center",
                bbox=dict(fc="#f0f8ff", ec="#4682b4"))
    ax.annotate("Bloque 2\nEntrenamiento, \nPredicci√≥n y \nComparaci√≥n IA", (.55,.5), va="center",
                bbox=dict(fc="#e6ffe6", ec="#2e8b57"))
    ax.annotate("", xy=(.43,.5), xytext=(.33,.5),
                arrowprops=dict(arrowstyle="->", lw=1.6))
    ax.set_xlim(0,1); ax.set_ylim(0,1)
    return _fig_to_b64(fig)

# Artifact: function _img_flow_opt
def _img_flow_opt():
    fig, ax = plt.subplots(figsize=(5.2, .9)); ax.axis("off")
    ax.annotate("Bloque 1\nCarga, \nSegmentacion y \nSelecci√≥n", (.05,.5), va="center",
                bbox=dict(fc="#f0f8ff", ec="#4682b4"))
    ax.annotate("Bloque 3\nOptimizaci√≥n \nModelos \nde IA", (.55,.5), va="center",
                bbox=dict(fc="#fff4e6", ec="#ff8c00"))
    ax.annotate("", xy=(.43,.5), xytext=(.33,.5),
                arrowprops=dict(arrowstyle="->", lw=1.6))
    ax.set_xlim(0,1); ax.set_ylim(0,1)
    return _fig_to_b64(fig)

# Artifact: function _img_flow_xai
def _img_flow_xai():
    fig, ax = plt.subplots(figsize=(6.8, .9)); ax.axis("off")
    xs = [.03,.29,.55,.80]
    labels  = ["Bloque 1\nCarga, \nSegmentacion y \nSelecci√≥n","Bloque 2\nEntrenamiento, \nPredicci√≥n y \nComparaci√≥n IA","Bloque 3\nOptimizaci√≥n \nModelos \nde IA","Bloque 4\nExplicaci√≥n \nModelos \nde IA"]
    fcs     = ["#f0f8ff","#e6ffe6","#fff4e6","#fde2ff"]
    frames  = ["#4682b4","#2e8b57","#ff8c00","#ba55d3"]
    for x,l,fc,ec in zip(xs, labels, fcs, frames):
        ax.annotate(l, (x,.5), va="center",
                    bbox=dict(fc=fc, ec=ec))
    for x in [.21,.47,.72]:
        ax.annotate("", xy=(x+.05,.5), xytext=(x-.05,.5),
                    arrowprops=dict(arrowstyle="->", lw=1.6))
    ax.set_xlim(0,1); ax.set_ylim(0,1)
    return _fig_to_b64(fig)

# Artifact: function mostrar_bienvenida
def mostrar_bienvenida():
    """Pantalla de bienvenida profesional con itinerarios y accesos r√°pidos."""
    clear_output(wait=True)

    html_intro = HTML(f"""
    <style>
      .pms h1   {{font-family:'Segoe UI',Roboto,sans-serif;font-size:1.95rem;margin:.2em 0}}
      .pms h2   {{font-size:1.15rem;color:#2E8B57;margin:.8em 0 .3em}}
      .pms h3   {{font-size:1.05rem;margin:1.0em 0 .5em}}
      .pms p, .pms li {{font-size:.95rem;line-height:1.55em}}
      .pms .flow img {{border:1px solid #d0d0d0;border-radius:6px}}
      .pms ul   {{margin-top:.2em;margin-bottom:1em}}
    </style>

    <div class='pms'>

      <h1>üöÄ Pipeline Modeling Suite (PMS)</h1>
      <p><em>Entorno interactivo ¬´pasta-y-ejecuta¬ª para ciencia de datos end-to-end:
         desde la preparaci√≥n de datos hasta la explicaci√≥n xAI.</em></p>

      <!-- ‚ñ∏‚ñ∏ ITINERARIO 1: ENTRENAR + PREDICCIONES -->
      <h2>Itinerarios sugeridos de uso</h2>

      <h3>üß™ Entrenar <b>y predecir</b> &nbsp;(<i>Bloques 1 ‚Üí 2</i>)</h3>
      <div class='flow'><img src="data:image/png;base64,{_img_flow_trainpred()}" /></div>
      <ul>
        <li><b>Funcionalidades Bloque 1 - Carga, segmentaci√≥n y selecci√≥n:</b></li>
        <li><b>üì• Cargar Datos:</b> pegar o cargar X&nbsp;/ Y desde Excel/CSV.</li>
        <li><b>üîÄ Segmentar:</b> Train / Test (<code>stratify</code> opcional).</li>
        <li><b>üîç Seleccionar Variables:</b> Pearson, Spearman, Mutual Info, Boruta, UMAP.</li>
      </ul>
        <li><b>Funcionalidades Bloque 2 - Entrenamiento, predicci√≥n y comparaci√≥n de modelos de IA:</b></li>
        <li><b>ü§ñ Entrenar SVR:</b> SVR (Support Vector Regression) es un algoritmo de aprendizaje supervisado que busca predecir valores continuos ajustando una funci√≥n que mantenga los errores dentro de un margen tolerable (√©psilon) y maximizando la generalizaci√≥n del modelo.</li>
        <li><b>üß† Entrenar NN:</b> Una red neuronal (NN) es un modelo de aprendizaje autom√°tico inspirado en el cerebro humano, compuesto por capas de nodos interconectados que procesan datos para reconocer patrones y hacer predicciones.</li>
        <li><b>üå≤ Entrenar XGBoost:</b> Algoritmo de aprendizaje autom√°tico basado en √°rboles de decisi√≥n que utiliza t√©cnicas de gradiente boosting para lograr alta precisi√≥n y eficiencia en tareas de clasificaci√≥n y regresi√≥n. </li>
        <li><b>üå≥ Entrenar Random Forest.</b> Algoritmo de aprendizaje autom√°tico basado en conjuntos que construye m√∫ltiples √°rboles de decisi√≥n y combina sus predicciones para mejorar la precisi√≥n y reducir el sobreajuste. </li>
        <li><b>üîÅ Entrenar RNN:</b> La Red Neuronal Recurrente (RNN)) es un tipo de red neuronal dise√±ada para procesar secuencias de datos, donde cada salida depende no solo de la entrada actual sino tambi√©n del estado anterior, lo que la hace ideal para tareas como series temporales, texto o audio</li>
        <li><b>üìà Predicci√≥n con modelos SVR, NN, XGBoostm RandomForest y RNN:</b> compara Y-real vs Y-predicho, residuos y curvas.</li>
        <li><b>üìä Comparador:</b> ranking m√©trico y visual entre modelos.</li>
      </ul>
      <div style="margin-bottom:1em;text-align:center">
        <img src="data:image/png;base64,{_block2_img_training_prediction()}" />
        <div style="font-size:.86rem;margin-top:.3em;color:#555">
          Flujo interno de Bloque 2: entrenamiento ‚Üí validaci√≥n ‚Üí <b>predicci√≥n</b>
        </div>
      </div>

      <!-- ‚ñ∏‚ñ∏ ITINERARIO 2: OPTIMIZAR -->
      <h3>‚öôÔ∏è Optimizar modelos &nbsp;(<i>Bloques 1 ‚Üí 3</i>)</h3>
      <div class='flow'><img src="data:image/png;base64,{_img_flow_opt()}" /></div>
      <ul>
        <li><b>Funcionalidades Bloque 3 - Optimizaci√≥n de Modelos de Inteligencia Artificial:</b></li>
        <li><b>üîß Optimizar SVR:</b> Grid, Random, Optuna, BayesSearch.</li>
        <li><b>‚öôÔ∏è Optimizar NN:</b> RandomSearch, Bayesian, Hyperband, Optuna.</li>
        <li><b>üî© Optimizar XGB:</b> RandomSearch, Bayesian, Hyperband, Optuna.</li>
        <li><b>üå≥‚öôÔ∏è Optimizar RF:</b> RandomSearch, Bayesian, Hyperband, Optuna.</li>
        <li><b>üîÅ Optimizar RNN:</b> RandomSearch, Bayesian, Hyperband, Optuna.</li>
      </ul>

      <!-- ‚ñ∏‚ñ∏ ITINERARIO 3: EXPLICAR -->
      <h3>üß† Explicar modelos &nbsp;(<i>Bloques 1 ‚Üí 2 ‚Üí 3 ‚Üí 4</i>)</h3>
      <div class='flow'><img src="data:image/png;base64,{_img_flow_xai()}" /></div>
      <ul>
        <li><b>Funcionalidades Bloque 4 - Inteligencia Artificial Explicativa xIA:</b></li>
        <li><b>üìù SHAP, LIME, KernelExplainer.</b></li>
        <li><b>üìà PDP, ALE, ICE.</b></li>
        <li><b>üß≠ Surrogate Models &amp; Anchors.</b></li>
        <li><b>üí† EBM, Contrafactuales.</b></li>
      </ul>
    """)

    # Muestra el HTML + botones
    display(html_intro)

# Artifact: exec exec_74
from IPython.display import display, clear_output, HTML

# Artifact: assign X_data,Y_data,FECHAS,y_variable_name
X_data, Y_data, FECHAS, y_variable_name = None, None, None, None

# Artifact: function mostrar_carga
def mostrar_carga(b=None):
    out_carga.clear_output()

    text_X = widgets.Textarea(
        placeholder='Pega aqu√≠ la matriz X desde Excel (sin √≠ndice).',
        layout=widgets.Layout(width='100%', height='150px')
    )
    text_Y = widgets.Textarea(
        placeholder='Pega aqu√≠ la matriz Y (una o m√°s columnas).',
        layout=widgets.Layout(width='100%', height='100px')
    )
    text_F = widgets.Textarea(
        placeholder='Pega aqu√≠ la columna de fechas (una sola columna con encabezado).',
        layout=widgets.Layout(width='100%', height='100px')
    )

    boton_importar = widgets.Button(description="üì• Importar Datos", button_style='success')
    salida = widgets.Output()

    def importar_datos(_):
        salida.clear_output()
        global X_data, Y_data, FECHAS, y_variable_name

        try:
            # ------------------ Matriz X ------------------
            X = pd.read_csv(io.StringIO(text_X.value.strip()), sep='\t', header=0)
            X = X.apply(lambda col: col.str.replace(',', '.', regex=False) if col.dtype == 'object' else col)
            X = X.apply(pd.to_numeric, errors='raise')

            # ------------------ Matriz Y ------------------
            Y = pd.read_csv(io.StringIO(text_Y.value.strip()), sep='\t', header=0)
            Y = Y.apply(lambda col: col.str.replace(',', '.', regex=False) if col.dtype == 'object' else col)
            Y = Y.apply(pd.to_numeric, errors='raise')
            y_variable_name = ', '.join(Y.columns) if Y.shape[1] > 1 else Y.columns[0]

            # ------------------ Columna de Fechas ------------------
            raw_text = text_F.value.strip()
            F = pd.read_csv(io.StringIO(raw_text), sep='\t', header=0)
            if F.shape[1] != 1:
                raise ValueError("‚ùå La columna de fechas debe tener solo una columna.")

            fecha_raw = F.iloc[:, 0].astype(str).str.strip()
            FECHAS = pd.to_datetime(fecha_raw, errors='coerce', format="%Y-%m-%d %H:%M")

            if FECHAS.isna().sum() > 0:
                display(HTML("<b style='color:red;'>‚ùå Estas son las fechas no reconocidas:</b>"))
                display(pd.DataFrame({"Fecha original": fecha_raw[FECHAS.isna()]}))
                raise ValueError("‚ùå Algunas fechas no se pudieron interpretar. Revisa el formato o caracteres ocultos.")

            # ------------------ Validar dimensiones ------------------
            if not (len(X) == len(Y) == len(FECHAS)):
                raise ValueError(f"‚ùå Dimensiones incompatibles: X({len(X)}), Y({len(Y)}), Fechas({len(FECHAS)})")

            # ------------------ Guardar ------------------
            X_data = X.copy()
            Y_data = Y.copy()
            mostrar_estadisticas_datos()  # ‚Üê A√±adir esta l√≠nea al final

            display(HTML("<b style='color:green;'>‚úÖ Datos cargados correctamente.</b>"))
            mostrar_estadisticas_datos()

        except Exception as e:
            display(HTML(f"<span style='color:red;'>‚ùå Error al importar: {str(e)}</span>"))

    boton_importar.on_click(importar_datos)

    with out_carga:
        display(HTML("<h3>üì• Carga de Datos</h3>"))
        display(widgets.VBox([
            widgets.Label("üî∑ Matriz X (variables predictoras):"), text_X,
            widgets.Label("üî∂ Matriz Y (variable/s a predecir):"), text_Y,
            widgets.Label("üïí Columna de Fechas (una sola columna):"), text_F,
            boton_importar, salida
        ]))

    # ‚úÖ Mostrar el output
    display(out_carga)

# Artifact: function mostrar_estadisticas_datos
def mostrar_estadisticas_datos():
    with out_carga:
        try:
            display(HTML("<h3>üìä Estad√≠sticas de los Datos Cargados</h3>"))

            # Estad√≠sticas de X
            if X_data is not None:
                display(HTML("<h4>üìà Estad√≠sticas de X (Variables Independientes):</h4>"))
                display(X_data.describe(include='all').T.style.set_caption("Resumen Estad√≠stico de X").format(precision=3))

            # Estad√≠sticas de Y
            if Y_data is not None:
                display(HTML("<h4>üéØ Estad√≠sticas de Y (Variable Objetivo):</h4>"))
                display(Y_data.describe(include='all').T.style.set_caption("Resumen Estad√≠stico de Y").format(precision=3))

            # Estad√≠sticas de Fechas
            if FECHAS is not None and not FECHAS.isna().all():
                display(HTML("<h4>üìÖ Estad√≠sticas de Fechas:</h4>"))
                display(pd.DataFrame({
                    'Primera fecha': [FECHAS.min()],
                    '√öltima fecha': [FECHAS.max()],
                    'Total registros': [len(FECHAS)],
                    'Frecuencia media (d√≠as)': [FECHAS.diff().dt.total_seconds().dropna().mean() / 86400]
                }).T.rename(columns={0: 'Valor'}))

        except Exception as e:
            display(HTML(f"<span style='color:red;'>‚ùå Error al mostrar estad√≠sticas: {str(e)}</span>"))

# Artifact: exec exec_78
from IPython.display import display, HTML, Javascript, clear_output

# Artifact: exec exec_79
from sklearn.model_selection import train_test_split

# Artifact: assign out_split
out_split = widgets.Output()

# Artifact: function mostrar_split
def mostrar_split(event=None):
    clear_output(wait=True)           # üîÅ Borra todo lo visible antes de pintar de nuevo
#    out_split.clear_output()          # üîÅ Borra lo que hab√≠a dentro del widget
    with out_split:
        #out_split.clear_output()
        # Validar que los datos est√©n cargados
        if 'X_data' not in globals() or 'Y_data' not in globals():
            print("‚ùå Debes cargar primero los datos (X_data, Y_data)")
            return
        X = X_data.copy()
        Y = Y_data.copy()

        # T√≠tulo e instrucciones
        display(HTML("<h3 style='color:#2E8B57;'>üîÄ Filtrado de Datos para Train/Test</h3>"))
        print("Configura el split de tu dataset (recomendado test_size=0.2, random_state=42)")

        # Controles de usuario
        test_size = widgets.FloatSlider(
            value=0.2, min=0.05, max=0.5, step=0.05,
            description='test_size:', tooltip='reserva el % de filas para test'
        )
        random_state = widgets.BoundedIntText(
            value=42, min=0, description='random_state:'
        )
        stratify_chk = widgets.Checkbox(
            value=False, description='Estratificar seg√∫n Y'
        )
        bin_method = widgets.Dropdown(
            options=['qcut','cut'], value='qcut', description='M√©todo bins:'
        )
        q_bins = widgets.BoundedIntText(
            value=5, min=2, max=20, description='q (bins):'
        )
        btn_split = widgets.Button(
            description='Aplicar Split', button_style='success'
        )

        display(widgets.VBox([test_size, random_state,
                              stratify_chk, bin_method, q_bins, btn_split]))

        def run_split(b):
            out_split.clear_output()      # <-- CAMBIO: borra cualquier contenido previo en out_split cuando se pulsa de nuevo
            global X_train, X_test, Y_train, Y_test, FECHAS_train, FECHAS_test
            # Preparar stratify
            stratify = None
            if stratify_chk.value:
                try:
                    # Asegurar que usamos una sola columna para la estratificaci√≥n
                    if isinstance(Y, pd.DataFrame):
                        Y_strat = Y.iloc[:, 0]
                    else:
                        Y_strat = pd.Series(Y)

                    if bin_method.value == 'qcut':
                        bins = pd.qcut(Y_strat, q=q_bins.value, duplicates='drop')
                    else:
                        bins = pd.cut(Y_strat, bins=q_bins.value)
                    stratify = bins
                except Exception as e:
                    print(f"‚ùå Error al crear bins: {e}")
                    return

            # Realizar split
            try:
                X_train, X_test, Y_train, Y_test, FECHAS_train, FECHAS_test = train_test_split(
                    X, Y, FECHAS,
                    test_size=test_size.value,
                    random_state=random_state.value,
                    stratify=stratify if stratify_chk.value else None
                )
                # justo aqu√≠, guardo los par√°metros en globals
                global SPLIT_PARAMS                           # Nuevo desde aqui: Creado para poder generar el informe final
                SPLIT_PARAMS = {
                    "test_size": test_size.value,
                    "random_state": random_state.value,
                    "stratify": stratify_chk.value,
                    "bin_method": bin_method.value,
                    "q_bins": q_bins.value
                }                                             # Nuevo hasta aqui
            except Exception as e:
                print(f"‚ùå Error en train_test_split: {e}")
                return

            y_col = Y.columns[0]
            df_train = X_train.copy()
            df_train[y_col] = Y_train.values
            df_train['fecha'] = FECHAS_train.values
            df_train['set'] = 'train'

            df_test = X_test.copy()
            df_test[y_col] = Y_test.values
            df_test['fecha'] = FECHAS_test.values
            df_test['set'] = 'test'

            df_out = pd.concat([df_train, df_test], axis=0)

            # Mostrar resumen de partici√≥n
            print(f"üîπ Total registros: {len(X)}")
            print(f"üîπ Registros en Train: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)")
            print(f"üîπ Registros en Test: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)")

            # Mostrar DataFrame final
            print("üìä Resultado del split (train/test) para copiar y pegar:")
            display(df_out)

            # Botones de copia X e Y
            # Entrenamiento Y
            btn_copy_y_train = widgets.Button(
                description='üìã Copiar Y Train', icon='clipboard', button_style='info'
            )
            # Entrenamiento X
            btn_copy_x_train = widgets.Button(
                description='üìã Copiar X Train', icon='clipboard', button_style='info'
            )
            # Entrenamiento Fechas
            btn_copy_f_train = widgets.Button(
                description='üìã Copiar Fechas Train', icon='calendar', button_style='info'
            )
            # Test Y
            btn_copy_y_test = widgets.Button(
                description='üìã Copiar Y Test', icon='clipboard', button_style='info'
            )
            # Test X
            btn_copy_x_test = widgets.Button(
                description='üìã Copiar X Test', icon='clipboard', button_style='info'
            )
            # Test Fechas
            btn_copy_f_test = widgets.Button(
                description='üìã Copiar Fechas Test', icon='calendar', button_style='info'
            )
            msg_train_y = widgets.Output()
            msg_train_x = widgets.Output()
            msg_test_y = widgets.Output()
            msg_test_x = widgets.Output()
            msg_f_train = widgets.Output()
            msg_f_test = widgets.Output()

            def copy_y_train(_):
                try:
                    Y_train.to_frame() .to_clipboard(index=False)
                    with msg_train_y:
                        display(HTML("<span style='color:green;'>‚úÖ Y Train copiada</span>"))
                except Exception:
                    csv = Y_train.to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_train_y:
                        display(HTML("<span style='color:green;'>‚úÖ Y Train copiada via JS</span>"))
            def copy_x_train(_):
                try:
                    df_train.drop(columns=[Y.name,'set']).to_clipboard(index=False)
                    with msg_train_x:
                        display(HTML("<span style='color:green;'>‚úÖ X Train copiada</span>"))
                except Exception:
                    csv = df_train.drop(columns=[Y.name,'set']).to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_train_x:
                        display(HTML("<span style='color:green;'>‚úÖ X Train copiada via JS</span>"))
            def copy_f_train(_):
                try:
                    FECHAS.iloc[X_train.index].to_frame().to_clipboard(index=False)
                    with msg_f_train:
                        msg_f_train.clear_output()
                        display(HTML("<span style='color:green;'>‚úÖ Fechas Train copiadas</span>"))
                except Exception:
                    csv = FECHAS.iloc[X_train.index].to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_f_train:
                        msg_f_train.clear_output()
                        display(HTML("<span style='color:green;'>‚úÖ Fechas Train copiadas v√≠a JS</span>"))

            def copy_y_test(_):
                try:
                    Y_test.to_frame().to_clipboard(index=False)
                    with msg_test_y:
                        display(HTML("<span style='color:green;'>‚úÖ Y Test copiada</span>"))
                except Exception:
                    csv = Y_test.to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_test_y:
                        display(HTML("<span style='color:green;'>‚úÖ Y Test copiada via JS</span>"))
            def copy_x_test(_):
                try:
                    df_test.drop(columns=[Y.name,'set']).to_clipboard(index=False)
                    with msg_test_x:
                        display(HTML("<span style='color:green;'>‚úÖ X Test copiada</span>"))
                except Exception:
                    csv = df_test.drop(columns=[Y.name,'set']).to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_test_x:
                        display(HTML("<span style='color:green;'>‚úÖ X Test copiada via JS</span>"))
            def copy_f_test(_):
                try:
                    FECHAS.iloc[X_test.index].to_frame().to_clipboard(index=False)
                    with msg_f_test:
                        msg_f_test.clear_output()
                        display(HTML("<span style='color:green;'>‚úÖ Fechas Test copiadas</span>"))
                except Exception:
                    csv = FECHAS.iloc[X_test.index].to_csv(index=False)
                    display(Javascript(f"navigator.clipboard.writeText(`{csv}`)"))
                    with msg_f_test:
                        msg_f_test.clear_output()
                        display(HTML("<span style='color:green;'>‚úÖ Fechas Test copiadas v√≠a JS</span>"))

            btn_copy_y_train.on_click(copy_y_train)
            btn_copy_x_train.on_click(copy_x_train)
            btn_copy_f_train.on_click(copy_f_train)
            btn_copy_y_test.on_click(copy_y_test)
            btn_copy_x_test.on_click(copy_x_test)
            btn_copy_f_test.on_click(copy_f_test)

            #display(widgets.HBox([btn_copy_y_train, btn_copy_x_train, btn_copy_y_test, btn_copy_x_test]))
            display(widgets.HBox([
                btn_copy_y_train, btn_copy_x_train, btn_copy_y_test, btn_copy_x_test,
                btn_copy_f_train, btn_copy_f_test
            ]))
            #display(widgets.HBox([msg_train_y, msg_train_x, msg_test_y, msg_test_x]))
            display(widgets.HBox([
                msg_train_y, msg_train_x, msg_test_y, msg_test_x, msg_f_train, msg_f_test
            ]))

        btn_split.on_click(run_split)

    display(out_split)

# Artifact: assign BORUTA_AVAILABLE
BORUTA_AVAILABLE = pkgutil.find_loader('boruta') is not None

# Artifact: assign UMAP_AVAILABLE
UMAP_AVAILABLE   = pkgutil.find_loader('umap')   is not None

# Artifact: exec exec_84
if BORUTA_AVAILABLE:
    from boruta import BorutaPy

# Artifact: exec exec_85
if UMAP_AVAILABLE:
    import umap

# Artifact: assign _timer_stop_event
_timer_stop_event = threading.Event()

# Artifact: function _update_timer
def _update_timer(event, widget):
    start = time.time()
    while not event.is_set():
        widget.value = f"‚è±Ô∏è {time.time() - start:.1f}s"
        time.sleep(0.5)

# Artifact: assign dlg_out
dlg_out = widgets.Output()

# Artifact: assign res_out
res_out = widgets.Output()

# Artifact: assign ayuda_out
ayuda_out = widgets.Output()

# Artifact: assign VARIABLES_SELECCIONADAS
VARIABLES_SELECCIONADAS = {}

# Artifact: assign METODO_SELECCION
METODO_SELECCION = ""

# Artifact: assign VALORES_CORRELACION
VALORES_CORRELACION = pd.Series(dtype=float)

# Artifact: assign RESUMEN_METODOS
RESUMEN_METODOS = {}

# Artifact: function mostrar_seleccion_variables
def mostrar_seleccion_variables(event=None):
    global X_train, Y_train
    dlg_out.clear_output()
    res_out.clear_output()
    display(dlg_out, res_out)

    with dlg_out:
        clear_output()
        if 'X_train' not in globals() or 'Y_train' not in globals():
            print("‚ùå Debes segmentar antes los datos (X_train, Y_train).")
            return

        X = X_train.copy()
        Y = Y_train.copy()
        if isinstance(Y, pd.DataFrame):
            Y_corr = Y.iloc[:, 0]
        else:
            Y_corr = pd.Series(Y)

        print(f"üîç Variables disponibles: {X.shape[1]}")
        print(f"üîç Observaciones en entrenamiento: {X.shape[0]}")

        display(HTML("<h3 style='color:#2E8B57;'>üîé Selecci√≥n de Variables</h3>"))

        ayuda_pearson = widgets.HTML("""
        <ul>
            <li><b>Umbral X‚ÄìY:</b> Selecciona las variables cuya correlaci√≥n absoluta con Y supera un valor determinado.</li>
            <li><b>Valores recomendados:</b> entre 0.3 y 0.6 para evitar colinealidad excesiva.</li>
            <li><i>Pearson mide relaciones lineales.</i></li>
        </ul>
        """)
        ayuda_spearman = widgets.HTML("""
        <ul>
            <li><b>Umbral X‚ÄìY:</b> Selecciona variables con alta correlaci√≥n de rangos con Y.</li>
            <li><b>Recomendado:</b> igual a Pearson (0.3 ‚Äì 0.6).</li>
            <li><i>Spearman es √∫til para relaciones no lineales mon√≥tonas.</i></li>
        </ul>
        """)
        ayuda_mi = widgets.HTML("""
        <ul>
            <li><b>Top k MI:</b> N√∫mero de variables con mayor informaci√≥n mutua respecto a Y.</li>
            <li><b>Valores recomendados:</b> entre 5 y 10 para datasets medianos.</li>
            <li><i>Captura relaciones no lineales.</i></li>
        </ul>
        """)
        ayuda_boruta = widgets.HTML("""
        <ul>
            <li><b>RF est:</b> N√∫mero de √°rboles del bosque aleatorio. (Recomendado: ‚â• 100).</li>
            <li><b>Iter BOR:</b> Iteraciones del algoritmo Boruta. (Recomendado: 50‚Äì100).</li>
            <li><b>Alpha:</b> Nivel de significancia estad√≠stica. (Recomendado: 0.01 ‚Äì 0.1).</li>
            <li><i>Selecciona solo variables relevantes con base en importancia del modelo.</i></li>
        </ul>
        """)
        ayuda_umap = widgets.HTML("""
        <ul>
            <li><b>Dims UMAP:</b> Dimensiones latentes en la proyecci√≥n (t√≠picamente 2‚Äì5).</li>
            <li><b>Top k UMAP:</b> Variables con mayor correlaci√≥n a las dimensiones proyectadas.</li>
            <li><i>UMAP revela estructuras no lineales complejas en los datos.</i></li>
        </ul>
        """)

        metodo = widgets.Dropdown(
            options=["Pearson", "Spearman", "MutualInfo"]
                    + (["Boruta"] if BORUTA_AVAILABLE else [])
                    + (["UMAP"] if UMAP_AVAILABLE else []),
            description='M√©todo:'
        )
        th_xy = widgets.FloatSlider(
            value=0.1, min=0.0, max=1.0, step=0.01, description='Umbral X‚ÄìY:', readout=False
        )
        th_xy_lbl = widgets.Label(value=f"{th_xy.value:.2f}")
        def actualizar_umbral(change):
            th_xy_lbl.value = f"{change['new']:.2f}"
        th_xy.observe(actualizar_umbral, names='value')
        fila_th_xy = widgets.HBox([th_xy, th_xy_lbl])

        mi_k     = widgets.BoundedIntText(value=5, min=1, max=X.shape[1], description='Top k MI:')
        bor_n    = widgets.BoundedIntText(value=100, min=1, max=1000, description='RF est:')
        bor_iter = widgets.BoundedIntText(value=50, min=1, max=500, description='Iter BOR:')
        bor_a    = widgets.BoundedFloatText(value=0.05, min=0.0, max=1.0, description='Alpha:')
        umap_d   = widgets.BoundedIntText(value=2, min=1, max=min(10, X.shape[1]), description='Dims UMAP:')
        umap_k   = widgets.BoundedIntText(value=5, min=1, max=X.shape[1], description='Top k UMAP:')
        btn_run  = widgets.Button(description='Ejecutar', button_style='success')
        btn_resumen = widgets.Button(description='üìã Ver Resumen', button_style='info')
        timer_lbl= widgets.Label('‚è±Ô∏è 0.0s')

        ayudas = {
            'Pearson': ayuda_pearson,
            'Spearman': ayuda_spearman,
            'MutualInfo': ayuda_mi,
            'Boruta': ayuda_boruta,
            'UMAP': ayuda_umap
        }

        fila_th_xy.layout.display = 'none'
        mi_k.layout.display = 'none'
        bor_n.layout.display = 'none'
        bor_iter.layout.display = 'none'
        bor_a.layout.display = 'none'
        umap_d.layout.display = 'none'
        umap_k.layout.display = 'none'

        def toggle_params(_=None):
            m = metodo.value
            corr_visible = m in ['Pearson', 'Spearman']
            fila_th_xy.layout.display = 'flex' if corr_visible else 'none'
            mi_k.layout.display     = 'block' if m == 'MutualInfo' else 'none'
            bor_n.layout.display    = 'block' if m == 'Boruta' else 'none'
            bor_iter.layout.display = 'block' if m == 'Boruta' else 'none'
            bor_a.layout.display    = 'block' if m == 'Boruta' else 'none'
            umap_d.layout.display   = 'block' if m == 'UMAP' else 'none'
            umap_k.layout.display   = 'block' if m == 'UMAP' else 'none'
            with ayuda_out:
                clear_output()
                if m in ayudas:
                    display(ayudas[m])

        metodo.observe(toggle_params, names='value')
        toggle_params()

        display(widgets.VBox([
            metodo, fila_th_xy, mi_k, bor_n, bor_iter, bor_a, umap_d, umap_k, ayuda_out, btn_run, btn_resumen, timer_lbl
        ]))

    def run_selection(_):
        global VARIABLES_SELECCIONADAS, METODO_SELECCION, VALORES_CORRELACION, RESUMEN_METODOS
        res_out.clear_output()
        _timer_stop_event.clear()
        threading.Thread(target=_update_timer, args=(_timer_stop_event, timer_lbl), daemon=True).start()

        with res_out:
            X = X_train.copy()
            Y = Y_train.copy()
            Y_corr = Y.iloc[:, 0] if isinstance(Y, pd.DataFrame) else pd.Series(Y)
            method = metodo.value
            selected = []
            correlaciones = pd.Series(dtype=float)

            if method in ['Pearson', 'Spearman']:
                correlaciones = X.apply(lambda col: col.corr(Y_corr, method=method.lower()))
                correlaciones_abs = correlaciones.abs()
                display(HTML(f"<h4>üìà Correlaciones X‚ÄìY (abs) usando <u>{method}</u>:</h4>"))
                display(correlaciones_abs.to_frame(name=f'|correlaci√≥n {method}|'))
                selected = correlaciones_abs[correlaciones_abs >= th_xy.value].index.tolist()
                not_selected = correlaciones_abs[~correlaciones_abs.index.isin(selected)].index.tolist()

                if selected:
                    display(HTML(f"<h4 style='color:green;'>‚úÖ Variables Seleccionadas ({method}, umbral ‚â• {th_xy.value}):</h4>"))
                    display(correlaciones[selected].to_frame(name=f'correlaci√≥n {method}').sort_values(by=f'correlaci√≥n {method}', ascending=False))
                else:
                    display(HTML(f"<h4 style='color:red;'>‚ö†Ô∏è No se seleccionaron variables con {method} ‚â• {th_xy.value}</h4>"))

                if not_selected:
                    display(HTML(f"<h4>üìå Variables No Seleccionadas ({method}):</h4>"))
                    display(correlaciones[not_selected].to_frame(name=f'correlaci√≥n {method}').sort_values(by=f'correlaci√≥n {method}', ascending=False))

            elif method == 'MutualInfo':
                mi = mutual_info_regression(X, Y_corr)
                correlaciones = pd.Series(mi, index=X.columns).sort_values(ascending=False)
                display(HTML('<b>Top MutualInfo:</b>'))
                display(correlaciones.head(mi_k.value).to_frame('MI'))
                selected = correlaciones.head(mi_k.value).index.tolist()

            elif method == 'Boruta' and BORUTA_AVAILABLE:
                #rf = RandomForestRegressor(n_estimators=bor_n.value, random_state=42)
                #bor = BorutaPy(rf, alpha=bor_a.value, max_iter=bor_iter.value, random_state=42)
                # ‚îÄ‚îÄ‚îÄ A√ëADIDO: usar todos los cores ‚îÄ‚îÄ‚îÄ
                rf = RandomForestRegressor(
                    n_estimators=bor_n.value,
                    random_state=42,
                    n_jobs=-1              # Paraleliza el entrenamiento del RF
                )
                bor = BorutaPy(
                    estimator=rf,
                    alpha=bor_a.value,
                    max_iter=bor_iter.value,
                    random_state=42,
                    verbose=2          # <‚Äì‚Äì 1 para resumen, 2 o 3 para detalle completo
                )
                bor.fit(X.values, Y_corr.values)
                support_mask = bor.support_
                correlaciones = pd.Series(bor.ranking_, index=X.columns)
                dfb = pd.DataFrame({'Feature': X.columns, 'Rank': bor.ranking_, 'Support': support_mask})
                display(HTML('<b>Ranking Boruta Top10:</b>'))
                display(dfb.sort_values('Rank').head(10))
                selected = list(X.columns[support_mask])

            elif method == 'UMAP' and UMAP_AVAILABLE:
                reducer = umap.UMAP(n_components=umap_d.value, random_state=42)
                emb = reducer.fit_transform(X)
                dfemb = pd.DataFrame(emb)
                corr = X.apply(lambda c: np.mean([abs(np.corrcoef(c, dfemb[i])[0,1]) for i in range(dfemb.shape[1])]), axis=0)
                correlaciones = corr
                display(HTML('<b>Correlaci√≥n media UMAP:</b>'))
                display(correlaciones.to_frame('mean_corr'))
                selected = correlaciones.sort_values(ascending=False).head(umap_k.value).index.tolist()

            if not selected:
                print("‚ùå No se seleccionaron variables. Ajusta el umbral o m√©todo.")
            else:
                VARIABLES_SELECCIONADAS = selected
                METODO_SELECCION = method
                VALORES_CORRELACION = correlaciones
                RESUMEN_METODOS[method] = selected

                # ‚Äî‚Äî‚Äî A√ëADIDO: sanitizar nombres para que no haya corchetes, % ni espacios raros ‚Äî‚Äî‚Äî
                #import re
                #clean = lambda c: re.sub(r'[\[\]<>%]', '_', str(c))
                #selected = [ clean(c) for c in selected ]
                # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî
                #RESUMEN_METODOS[method] = selected

                dfout = X[selected].copy()
                dfout[Y_corr.name] = Y_corr.values
                display(HTML('<b>Variables Seleccionadas:</b>'))
                display(dfout)
                txt = widgets.Textarea(value=dfout.drop(columns=[Y_corr.name]).to_csv(index=False),
                                       layout=widgets.Layout(width='100%', height='150px'))
                display(HTML('<b>CSV X:</b>'))
                display(txt)

        _timer_stop_event.set()

    def mostrar_resumen(b):
        with res_out:
            clear_output()
            if not RESUMEN_METODOS:
                display(HTML("<b>‚ö†Ô∏è No hay m√©todos ejecutados a√∫n.</b>"))
            else:
                for metodo, variables in RESUMEN_METODOS.items():
                    display(HTML(f"<h4>üìå {metodo}:</h4>"))
                    display(pd.DataFrame(variables, columns=["Variables Seleccionadas"]))

    btn_run.on_click(run_selection, remove=True)
    btn_run.on_click(run_selection)
    btn_resumen.on_click(mostrar_resumen)

# Artifact: exec exec_96
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Artifact: exec exec_97
if 'out_svr' not in globals():
    out_svr = widgets.Output()

# Artifact: function mostrar_svr
def mostrar_svr(b=None):
    if b is None:
        display(out_svr)

    with out_svr:
        clear_output()

        if 'X_train' not in globals() or 'X_test' not in globals():
            display(widgets.HTML("""<span style='color:red;'>‚ùå Primero debes segmentar los datos en train/test.</span>"""))
            return

        # Bloque para sincronizar variables individuales a partir del resumen RESUMEN_METODOS
        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        # Widgets para configuraci√≥n
        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )
        C_val = widgets.FloatLogSlider(value=1.0, base=10, min=-2, max=2, step=0.1, description='C:')
        epsilon_val = widgets.FloatLogSlider(value=0.1, base=10, min=-3, max=0, step=0.1, description='Epsilon:')
        kernel_val = widgets.Dropdown(options=['rbf', 'linear', 'poly', 'sigmoid'], value='rbf', description='Kernel:')
        gamma_val = widgets.Dropdown(options=['scale', 'auto'], description='Gamma:')

        btn_train = widgets.Button(description="üöÄ Entrenar SVR", button_style='success')
        output_area = widgets.Output()
        tiempo_lbl = widgets.Label()

        def entrenar_svr(_):
            output_area.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            with output_area:
                for i, metodo in enumerate(metodos):
                    var_key = f"selected_vars_{metodo.lower()}"
                    if var_key not in globals():
                        print(f"‚ö†Ô∏è No hay variables seleccionadas para el m√©todo: {metodo}")
                        continue
                    selected_vars = globals()[var_key]

                    Xtr, Xts = X_train[selected_vars], X_test[selected_vars]
                    ytr, yts = Y_train.values.ravel(), Y_test.values.ravel()

                    sx, sy = StandardScaler(), StandardScaler()
                    Xtr_scaled = sx.fit_transform(Xtr)
                    Xts_scaled = sx.transform(Xts)
                    ytr_scaled = sy.fit_transform(ytr.reshape(-1,1)).ravel()

                    model = SVR(C=C_val.value, epsilon=epsilon_val.value, kernel=kernel_val.value, gamma=gamma_val.value)
                    model.fit(Xtr_scaled, ytr_scaled)

                    y_pred_scaled = model.predict(Xts_scaled)
                    y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()

                    r2 = r2_score(yts, y_pred)
                    mse = mean_squared_error(yts, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(yts, y_pred)

                    resumen_modelos.append({
                        'M√©todo': metodo,
                        'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                    })

                    # Guardar modelo
                    nombre_archivo = f"modelo_svr_{metodo.lower()}.pkl"
                    with open(nombre_archivo, 'wb') as f:
                        pickle.dump({'model': model, 'sx': sx, 'sy': sy, 'cols': selected_vars, 'yname': y_variable_name}, f)

                    ax.plot(y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])
                    print(f"‚úÖ Modelo {metodo} entrenado. R¬≤: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")

                if resumen_modelos:
                    ax.plot(yts, label='Y Real', color='black', linewidth=2)
                    ax.set_title('Comparaci√≥n Y Real vs Predicciones SVR por M√©todo')
                    ax.grid(); ax.legend()
                    plt.show()

                    # Tabla resumen
                    print("\nüìä Resumen comparativo de m√©tricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('M√©todo'))

            tiempo_lbl.value = f"‚è±Ô∏è Duraci√≥n total: {time.time()-inicio:.2f} segundos"

        btn_train.on_click(entrenar_svr)

        # Ayuda extendida
        ayuda = widgets.HTML("""
        <h4>‚ÑπÔ∏è Ayuda - Par√°metros del modelo SVR</h4>
        <ul>
            <li><b>C:</b> Penalizaci√≥n al error. Valores altos = bajo sesgo, alto sobreajuste. Recomendado: 0.1 a 100</li>
            <li><b>Epsilon:</b> Margen de tolerancia para el error. Cuanto mayor, m√°s simple el modelo. Recomendado: 0.001 a 0.1</li>
            <li><b>Kernel:</b> Funci√≥n para proyectar los datos. rbf es el m√°s com√∫n. Otras: linear, poly, sigmoid</li>
            <li><b>Gamma:</b> Influencia de un punto de entrenamiento. 'scale' es recomendado.</li>
        </ul>
        """)

        display(widgets.VBox([
            widgets.HBox([metodo_sel]),
            widgets.HBox([C_val, epsilon_val]),
            widgets.HBox([kernel_val, gamma_val]),
            btn_train, tiempo_lbl,
            ayuda, output_area
        ]))

# Artifact: exec exec_99
from tensorflow.keras.models import Sequential

# Artifact: exec exec_100
from tensorflow.keras.optimizers import Adam, SGD, RMSprop

# Artifact: exec exec_101
if 'out_nn' not in globals():
    out_nn = widgets.Output()

# Artifact: function mostrar_nn
def mostrar_nn(b=None):
    if b is None:
        display(out_nn)

    with out_nn:
        clear_output()

        if 'X_train' not in globals() or 'X_test' not in globals():
            display(widgets.HTML("<span style='color:red;'>‚ùå Primero debes segmentar los datos en train/test.</span>"))
            return

        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )

        capas = widgets.BoundedIntText(value=2, min=1, max=10, description='Capas ocultas:')
        neuronas = widgets.Text(value='64,32', description='Neuronas por capa:', placeholder='Ej: 64,32')
        activacion = widgets.Dropdown(options=['relu','tanh','sigmoid'], value='relu', description='Activaci√≥n:')
        loss_fn = widgets.Dropdown(options=[('MSE','mse'),('MAE','mae'),('Huber','huber')], value='mse', description='P√©rdida:')
        tasa = widgets.FloatText(value=0.001, description='Learning Rate:')
        epocas = widgets.BoundedIntText(value=100, min=1, description='Epocas:')
        batch = widgets.BoundedIntText(value=32, min=1, description='Batch size:')
        opt = widgets.Dropdown(options=['adam','sgd','rmsprop'], value='adam', description='Optimizador:')

        btn_train = widgets.Button(description='üöÄ Entrenar NN', button_style='success')
        output_area = widgets.Output()
        tiempo_lbl = widgets.Label()

        def entrenar_nn(_):
            output_area.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            with output_area:
                for i, metodo in enumerate(metodos):
                    var_key = f"selected_vars_{metodo.lower()}"
                    if var_key not in globals():
                        print(f"‚ö†Ô∏è No hay variables seleccionadas para el m√©todo: {metodo}")
                        continue

                    selected_vars = globals()[var_key]
                    Xtr, Xts = X_train[selected_vars], X_test[selected_vars]
                    ytr, yts = Y_train.values.ravel(), Y_test.values.ravel()

                    sx, sy = StandardScaler(), StandardScaler()
                    Xtr_scaled = sx.fit_transform(Xtr)
                    Xts_scaled = sx.transform(Xts)
                    ytr_scaled = sy.fit_transform(ytr.reshape(-1,1)).ravel()

                    model = Sequential()
                    try:
                        layers = [int(n) for n in neuronas.value.split(',')]
                        if len(layers) != capas.value:
                            raise ValueError("‚ùå Especifica tantas capas como valores de neuronas.")
                        model.add(Dense(layers[0], activation=activacion.value, input_shape=(Xtr_scaled.shape[1],)))
                        for units in layers[1:]:
                            model.add(Dense(units, activation=activacion.value))
                        model.add(Dense(1))
                    except Exception as e:
                        print(f"‚ùå Error en la definici√≥n de la arquitectura: {e}")
                        return

                    opt_dict = {'adam': Adam, 'sgd': SGD, 'rmsprop': RMSprop}
                    optimizer = opt_dict[opt.value](learning_rate=tasa.value)

                    loss = {'mse':'mean_squared_error','mae':'mean_absolute_error','huber':tf.keras.losses.Huber()}[loss_fn.value]
                    model.compile(optimizer=optimizer, loss=loss, metrics=['mae'])

                    # === Aqu√≠ guardamos los hiperpar√°metros antes de entrenar ===
                    hp = {
                        'capas_ocultas': capas.value,
                        'neuronas_por_capa': neuronas.value,  # e.g. '64,32'
                        'activacion': activacion.value,
                        'loss_fn': loss_fn.value,
                        'learning_rate': tasa.value,
                        'epocas': epocas.value,
                        'batch_size': batch.value,
                        'optimizador': opt.value
                    }
                    import pickle
                    hp_fname = f"hyperparams_nn_{metodo.lower()}.pkl"
                    try:
                        with open(hp_fname, "wb") as f_hp:
                            pickle.dump(hp, f_hp)
                        print(f"‚úÖ Hiperpar√°metros guardados en {hp_fname}")
                    except Exception as e:
                        print(f"‚ùå No se pudo guardar hiperpar√°metros en {hp_fname}: {e}")

                    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
                    history = model.fit(Xtr_scaled, ytr_scaled, validation_split=0.2, epochs=epocas.value, batch_size=batch.value, verbose=0, callbacks=[es])

                    y_pred_scaled = model.predict(Xts_scaled).ravel()
                    y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()

                    r2 = r2_score(yts, y_pred)
                    mse = mean_squared_error(yts, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(yts, y_pred)

                    resumen_modelos.append({'M√©todo': metodo, 'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae})

                    nombre_archivo = f"modelo_nn_{metodo.lower()}.h5"
                    model.save(nombre_archivo)

                    with open(f"escaladores_nn_{metodo.lower()}.pkl", "wb") as f:
                        pickle.dump({
                            'scaler_X': sx,
                            'scaler_Y': sy,
                            'cols': selected_vars,
                            'yname': y_variable_name
                        }, f)

                    ax.plot(y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])
                    print(f"‚úÖ Modelo {metodo} entrenado. R¬≤: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")


                if resumen_modelos:
                    ax.plot(yts, label='Y Real', color='black', linewidth=2)
                    ax.set_title('Comparaci√≥n Y Real vs Predicciones NN por M√©todo')
                    ax.grid(); ax.legend()
                    plt.show()

                    print("\nüìä Resumen comparativo de m√©tricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('M√©todo'))

            tiempo_lbl.value = f"‚è±Ô∏è Duraci√≥n total: {time.time()-inicio:.2f} segundos"

        btn_train.on_click(entrenar_nn)

        ayuda = widgets.HTML("""
        <h4>‚ÑπÔ∏è Ayuda - Par√°metros de la Red Neuronal</h4>
        <ul>
            <li><b>Capas ocultas:</b> N√∫mero de capas intermedias. M√°s capas pueden mejorar la expresividad.</li>
            <li><b>Neuronas por capa:</b> Lista separada por comas. Cada valor representa una capa. Ej: 64,32</li>
            <li><b>Activaci√≥n:</b> Funciones como relu (recomendado), tanh, sigmoid. Afectan la no linealidad.</li>
            <li><b>Learning Rate:</b> Tama√±o del paso. Valores t√≠picos: 0.001, 0.01</li>
            <li><b>Epocas:</b> N√∫mero de iteraciones sobre el dataset. Demasiadas pueden sobreajustar.</li>
            <li><b>Batch size:</b> Tama√±o de lote en cada actualizaci√≥n de gradiente.</li>
            <li><b>Optimizador:</b> Algoritmo de ajuste. Adam es general. SGD es m√°s simple. RMSprop es bueno en secuencias.</li>
        </ul>
        """)

        display(widgets.VBox([
            widgets.HBox([metodo_sel]),
            widgets.HBox([capas, neuronas]),
            widgets.HBox([activacion, opt]),
            widgets.HBox([tasa, epocas, batch]),
            widgets.HBox([loss_fn]),
            btn_train, tiempo_lbl,
            ayuda, output_area
        ]))

# Artifact: exec exec_103
if 'out_xgb' not in globals():
    out_xgb = widgets.Output()

# Artifact: function mostrar_xgb
def mostrar_xgb(b=None):
    if b is None:
        display(out_xgb)

    with out_xgb:
        clear_output()

        if 'X_train' not in globals() or 'X_test' not in globals():
            display(widgets.HTML("""<span style='color:red;'>‚ùå Primero debes segmentar los datos en train/test.</span>"""))
            return

        # Bloque para sincronizar variables individuales a partir del resumen RESUMEN_METODOS
        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )
        n_estimators = widgets.IntSlider(value=100, min=10, max=1000, step=10, description='√Årboles:')
        learning_rate = widgets.FloatLogSlider(value=0.1, base=10, min=-3, max=0, step=0.01, description='Learning Rate:')
        max_depth = widgets.IntSlider(value=3, min=1, max=20, step=1, description='Profundidad:')
        subsample = widgets.FloatSlider(value=1.0, min=0.1, max=1.0, step=0.1, description='Subsample:')

        btn_train = widgets.Button(description="üöÄ Entrenar XGBoost", button_style='success')
        output_area = widgets.Output()
        tiempo_lbl = widgets.Label()

        def entrenar_xgb(_):
            output_area.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            with output_area:
                for i, metodo in enumerate(metodos):
                    var_key = f"selected_vars_{metodo.lower()}"
                    if var_key not in globals():
                        print(f"‚ö†Ô∏è No hay variables seleccionadas para el m√©todo: {metodo}")
                        continue
                    selected_vars = globals()[var_key]

                    Xtr, Xts = X_train[selected_vars], X_test[selected_vars]
                    ytr, yts = Y_train.values.ravel(), Y_test.values.ravel()

                    sx, sy = StandardScaler(), StandardScaler()
                    Xtr_scaled = sx.fit_transform(Xtr)
                    Xts_scaled = sx.transform(Xts)
                    ytr_scaled = sy.fit_transform(ytr.reshape(-1,1)).ravel()

                    model = XGBRegressor(
                        n_estimators=n_estimators.value,
                        learning_rate=learning_rate.value,
                        max_depth=max_depth.value,
                        subsample=subsample.value,
                        verbosity=0
                    )
                    model.fit(Xtr_scaled, ytr_scaled)

                    y_pred_scaled = model.predict(Xts_scaled)
                    y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()

                    r2 = r2_score(yts, y_pred)
                    mse = mean_squared_error(yts, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(yts, y_pred)

                    resumen_modelos.append({
                        'M√©todo': metodo,
                        'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                    })

                    # Guardar modelo
                    nombre_archivo = f"modelo_xgb_{metodo.lower()}.pkl"
                    with open(nombre_archivo, 'wb') as f:
                        pickle.dump({'model': model, 'sx': sx, 'sy': sy, 'cols': selected_vars, 'yname': y_variable_name}, f)

                    ax.plot(y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])
                    print(f"‚úÖ Modelo {metodo} entrenado. R¬≤: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")

                if resumen_modelos:
                    ax.plot(yts, label='Y Real', color='black', linewidth=2)
                    ax.set_title('Comparaci√≥n Y Real vs Predicciones XGBoost por M√©todo')
                    ax.grid(); ax.legend()
                    plt.show()

                    print("\nüìä Resumen comparativo de m√©tricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('M√©todo'))

            tiempo_lbl.value = f"‚è±Ô∏è Duraci√≥n total: {time.time()-inicio:.2f} segundos"

        btn_train.on_click(entrenar_xgb)

        ayuda = widgets.HTML("""
        <h4>‚ÑπÔ∏è Ayuda - Par√°metros del modelo XGBoost</h4>
        <ul>
            <li><b>n_estimators:</b> n√∫mero de √°rboles. Mayor n√∫mero = mayor precisi√≥n pero m√°s tiempo.</li>
            <li><b>learning_rate:</b> tasa de aprendizaje. Peque√±os valores mejoran precisi√≥n, pero requieren m√°s √°rboles.</li>
            <li><b>max_depth:</b> profundidad de √°rboles. Mayor profundidad permite m√°s complejidad, pero riesgo de sobreajuste.</li>
            <li><b>subsample:</b> fracci√≥n de muestras usadas por √°rbol. Menor valor ayuda a regularizaci√≥n.</li>
        </ul>
        """)

        display(widgets.VBox([
            widgets.HBox([metodo_sel]),
            widgets.HBox([n_estimators, learning_rate]),
            widgets.HBox([max_depth, subsample]),
            btn_train, tiempo_lbl,
            ayuda, output_area
        ]))

# Artifact: exec exec_105
if 'out_rf' not in globals():
    out_rf = widgets.Output()

# Artifact: function mostrar_rf
def mostrar_rf(b=None):
    if b is None:
        display(out_rf)

    with out_rf:
        clear_output()

        if 'X_train' not in globals() or 'X_test' not in globals():
            display(widgets.HTML("""<span style='color:red;'>‚ùå Primero debes segmentar los datos en train/test.</span>"""))
            return

        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )

        n_estimators = widgets.IntSlider(value=100, min=10, max=500, step=10, description='√Årboles:')
        max_depth = widgets.IntSlider(value=5, min=1, max=50, step=1, description='Profundidad:')
        min_samples_split = widgets.IntSlider(value=2, min=2, max=20, step=1, description='Min Split:')
        min_samples_leaf = widgets.IntSlider(value=1, min=1, max=20, step=1, description='Min Leaf:')
        max_features = widgets.Dropdown(options=['auto', 'sqrt', 'log2'], value='sqrt', description='Max Features:')
        bootstrap = widgets.Checkbox(value=True, description='Bootstrap:')

        btn_train = widgets.Button(description="üöÄ Entrenar RF", button_style='success')
        output_area = widgets.Output()
        tiempo_lbl = widgets.Label()

        def entrenar_rf(_):
            output_area.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            with output_area:
                for i, metodo in enumerate(metodos):
                    var_key = f"selected_vars_{metodo.lower()}"
                    if var_key not in globals():
                        print(f"‚ö†Ô∏è No hay variables seleccionadas para el m√©todo: {metodo}")
                        continue
                    selected_vars = globals()[var_key]

                    Xtr, Xts = X_train[selected_vars], X_test[selected_vars]
                    ytr, yts = Y_train.values.ravel(), Y_test.values.ravel()

                    sx, sy = StandardScaler(), StandardScaler()
                    Xtr_scaled = sx.fit_transform(Xtr)
                    Xts_scaled = sx.transform(Xts)
                    ytr_scaled = sy.fit_transform(ytr.reshape(-1,1)).ravel()

                    model = RandomForestRegressor(
                        n_estimators=n_estimators.value,
                        max_depth=max_depth.value,
                        min_samples_split=min_samples_split.value,
                        min_samples_leaf=min_samples_leaf.value,
                        max_features=max_features.value,
                        bootstrap=bootstrap.value,
                        random_state=42,
                        n_jobs=-1
                    )
                    model.fit(Xtr_scaled, ytr_scaled)
                    y_pred_scaled = model.predict(Xts_scaled)
                    y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()

                    r2 = r2_score(yts, y_pred)
                    mse = mean_squared_error(yts, y_pred)
                    rmse = np.sqrt(mse)
                    mae = mean_absolute_error(yts, y_pred)

                    resumen_modelos.append({
                        'M√©todo': metodo,
                        'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                    })

                    nombre_archivo = f"modelo_rf_{metodo.lower()}.pkl"
                    with open(nombre_archivo, 'wb') as f:
                        pickle.dump({'model': model, 'sx': sx, 'sy': sy, 'cols': selected_vars, 'yname': y_variable_name}, f)

                    ax.plot(y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])
                    print(f"‚úÖ Modelo {metodo} entrenado. R¬≤: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")

                if resumen_modelos:
                    ax.plot(yts, label='Y Real', color='black', linewidth=2)
                    ax.set_title('Comparaci√≥n Y Real vs Predicciones Random Forest por M√©todo')
                    ax.grid(); ax.legend()
                    plt.show()

                    print("\nüìä Resumen comparativo de m√©tricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('M√©todo'))

            tiempo_lbl.value = f"‚è±Ô∏è Duraci√≥n total: {time.time()-inicio:.2f} segundos"

        btn_train.on_click(entrenar_rf)

        ayuda = widgets.HTML("""
        <h4>‚ÑπÔ∏è Ayuda - Par√°metros del modelo Random Forest</h4>
        <ul>
            <li><b>n_estimators:</b> n√∫mero de √°rboles. Mayor n√∫mero = mejor precisi√≥n, mayor tiempo.</li>
            <li><b>max_depth:</b> profundidad m√°xima. Limita la complejidad del modelo.</li>
            <li><b>min_samples_split:</b> tama√±o m√≠nimo para dividir nodo. Mayor = menos sobreajuste.</li>
            <li><b>min_samples_leaf:</b> m√≠nimo de muestras en hoja. Controla profundidad m√≠nima.</li>
            <li><b>max_features:</b> n¬∫ de variables evaluadas por divisi√≥n. 'sqrt' es t√≠pico para regresi√≥n.</li>
            <li><b>bootstrap:</b> si se usan muestras con reemplazo. True mejora diversidad.</li>
        </ul>
        """)

        display(widgets.VBox([
            widgets.HBox([metodo_sel]),
            widgets.HBox([n_estimators, max_depth]),
            widgets.HBox([min_samples_split, min_samples_leaf]),
            widgets.HBox([max_features, bootstrap]),
            btn_train, tiempo_lbl,
            ayuda, output_area
        ]))

# Artifact: exec exec_107
import time, pickle

# Artifact: exec exec_108
from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Bidirectional, TimeDistributed, RepeatVector

# Artifact: exec exec_109
from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad

# Artifact: exec exec_110
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Artifact: exec exec_111
if 'output_area_rnn' not in globals():
    output_area_rnn = widgets.Output()

# Artifact: function mostrar_rnn
def mostrar_rnn(b=None):
    if b is None:
        display(out_rnn)

    with out_rnn:
        clear_output()

        if not all(k in globals() for k in ['X_train', 'X_test', 'Y_train', 'Y_test', 'FECHAS_train', 'FECHAS_test']):
            display(widgets.HTML("""<span style='color:red;'>‚ùå Primero debes segmentar los datos en train/test incluyendo fechas.</span>"""))
            return

        # Actualizar variables seleccionadas si existen
        if 'RESUMEN_METODOS' in globals():
            for metodo, variables in RESUMEN_METODOS.items():
                globals()[f"selected_vars_{metodo.lower()}"] = variables

        metodo_sel = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selector:'
        )
        tipo_rnn = widgets.Dropdown(
            options=['Vanilla RNN', 'LSTM', 'GRU', 'BiLSTM', 'BiGRU', 'Deep RNN', 'Encoder-Decoder'],
            description='Tipo RNN:'
        )
        window_size = widgets.IntSlider(value=10, min=5, max=100, description='Ventana:')
        units = widgets.IntSlider(value=50, min=10, max=200, step=10, description='Unidades:')
        layers = widgets.IntSlider(value=1, min=1, max=5, description='Capas:')
        batch = widgets.IntSlider(value=32, min=8, max=128, step=8, description='Batch:')
        epochs = widgets.IntSlider(value=30, min=10, max=500, step=10, description='√âpocas:')
        learning_rate = widgets.FloatLogSlider(value=0.001, base=10, min=-5, max=-1, step=0.1, description='LR:')
        optimizer = widgets.Dropdown(options=['adam', 'sgd', 'rmsprop', 'adagrad'], description='Optimizador:')
        loss_fn = widgets.Dropdown(options=['mse', 'mae', 'huber'], description='P√©rdida:')
        activation = widgets.Dropdown(options=['tanh', 'relu', 'sigmoid'], description='Activaci√≥n:')
        drop = widgets.FloatSlider(value=0.0, min=0.0, max=0.5, step=0.05, description='Dropout:')
        boton_entrenar = widgets.Button(description='üöÄ Entrenar RNN', button_style='success')
        tiempo_lbl = widgets.Label()

        def entrenar_rnn(_):
            output_area_rnn.clear_output()
            resumen_modelos = []
            inicio = time.time()

            metodos = [metodo_sel.value] if metodo_sel.value != 'Todos' else ['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']
            colores = ['red', 'blue', 'green', 'purple', 'orange']
            fig, ax = plt.subplots(figsize=(10,6))

            for i, metodo in enumerate(metodos):
                var_key = f"selected_vars_{metodo.lower()}"
                if var_key not in globals():
                    with output_area_rnn:
                        print(f"‚ö†Ô∏è No hay variables seleccionadas para el m√©todo: {metodo}")
                    continue
                selected_vars = globals()[var_key]

                df_train = X_train[selected_vars].copy()
                df_test = X_test[selected_vars].copy()
                y_train = Y_train.values.ravel()
                y_test = Y_test.values.ravel()

                sx, sy = StandardScaler(), StandardScaler()
                Xtr = sx.fit_transform(df_train)
                Xts = sx.transform(df_test)
                ytr = sy.fit_transform(y_train.reshape(-1,1)).ravel()

                def create_sequences(X, Y, window):
                    X_seq, Y_seq = [], []
                    for j in range(len(X) - window):
                        X_seq.append(X[j:j+window])
                        Y_seq.append(Y[j+window])
                    return np.array(X_seq), np.array(Y_seq)

                X_seq, Y_seq = create_sequences(Xtr, ytr, window_size.value)
                Xts_seq, Yts_seq = create_sequences(Xts, y_test, window_size.value)
                input_shape = (X_seq.shape[1], X_seq.shape[2])

                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                # Exportar las secuencias al namespace global para el motor IG
                globals()['X_seq'] = X_seq.copy()
                globals()['Y_seq'] = Y_seq.copy()
                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

                model = Sequential()
                RNNLayer = {
                    'Vanilla RNN': SimpleRNN,
                    'LSTM': LSTM,
                    'GRU': GRU
                }.get(tipo_rnn.value.split()[0], LSTM)

                if 'Bi' in tipo_rnn.value:
                    for _ in range(layers.value - 1):
                        model.add(Bidirectional(RNNLayer(units.value, activation=activation.value, return_sequences=True), input_shape=input_shape))
                    model.add(Bidirectional(RNNLayer(units.value, activation=activation.value)))
                elif 'Deep' in tipo_rnn.value:
                    for _ in range(layers.value - 1):
                        model.add(RNNLayer(units.value, activation=activation.value, return_sequences=True))
                    model.add(RNNLayer(units.value, activation=activation.value))
                elif 'Encoder' in tipo_rnn.value:
                    model.add(LSTM(units.value, activation=activation.value, input_shape=input_shape))
                    model.add(RepeatVector(1))
                    model.add(LSTM(units.value, activation=activation.value, return_sequences=True))
                    model.add(TimeDistributed(Dense(1)))
                else:
                    for _ in range(layers.value - 1):
                        model.add(RNNLayer(units.value, activation=activation.value, return_sequences=True, input_shape=input_shape))
                    model.add(RNNLayer(units.value, activation=activation.value))

                if 'Encoder' not in tipo_rnn.value:
                    model.add(Dense(1))

                opt_dict = {
                    'adam': Adam(learning_rate=learning_rate.value),
                    'sgd': SGD(learning_rate=learning_rate.value),
                    'rmsprop': RMSprop(learning_rate=learning_rate.value),
                    'adagrad': Adagrad(learning_rate=learning_rate.value)
                }

                #model.compile(loss=loss_fn.value, optimizer=opt_dict[optimizer.value])
                from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, Huber

                loss_function = {
                    'mse': MeanSquaredError(),
                    'mae': MeanAbsoluteError(),
                    'huber': Huber()
                }[loss_fn.value]

                model.compile(loss=loss_function, optimizer=opt_dict[optimizer.value])

                model.fit(X_seq, Y_seq, epochs=epochs.value, batch_size=batch.value, verbose=0)
                Y_pred_scaled = model.predict(Xts_seq).ravel()
                Y_pred = sy.inverse_transform(Y_pred_scaled.reshape(-1,1)).ravel()
                Y_real = Yts_seq

                r2 = r2_score(Y_real, Y_pred)
                mse = mean_squared_error(Y_real, Y_pred)
                rmse = np.sqrt(mse)
                mae = mean_absolute_error(Y_real, Y_pred)

                resumen_modelos.append({
                    'M√©todo': metodo,
                    'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                })

                # Dentro de la funci√≥n entrenar_rnn, despu√©s de model.fit(...) y antes de model.save(...):
                hp = {
                    'tipo_rnn': tipo_rnn.value,
                    'window_size': window_size.value,
                    'units': units.value,
                    'layers': layers.value,
                    'batch_size': batch.value,
                    'epochs': epochs.value,
                    'learning_rate': learning_rate.value,
                    'optimizer': optimizer.value,
                    'loss_fn': loss_fn.value,
                    'activation': activation.value,
                    'dropout': drop.value
                }
                # Serializar en pickle:
                import pickle
                hp_fname = f"hyperparams_rnn_{metodo.lower()}.pkl"
                with open(hp_fname, "wb") as f_hp:
                    pickle.dump(hp, f_hp)
                print(f"‚úÖ Hiperpar√°metros RNN guardados en {hp_fname}")

                nombre_archivo = f"modelo_rnn_{metodo.lower()}.h5"
                model.save(nombre_archivo)

                with open(f"escaladores_rnn_{metodo.lower()}.pkl", "wb") as f:
                    pickle.dump({
                        'scaler_X': sx,
                        'scaler_Y': sy,
                        'cols': selected_vars,
                        'yname': y_variable_name
                    }, f)

                ax.plot(Y_pred, label=f'{metodo}', alpha=0.7, linestyle='--', color=colores[i])

                with output_area_rnn:
                    print(f"‚úÖ Modelo {metodo} entrenado. R¬≤: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}")

            if resumen_modelos:
                ax.plot(Y_real, label='Y Real', color='black', linewidth=2)
                ax.set_title('Comparaci√≥n Y Real vs Predicciones RNN por M√©todo')
                ax.grid(); ax.legend()

                with output_area_rnn:
                    plt.show()
                    print("\nüìä Resumen comparativo de m√©tricas:")
                    df = pd.DataFrame(resumen_modelos)
                    display(df.set_index('M√©todo'))

            tiempo_lbl.value = f"‚è±Ô∏è Duraci√≥n total: {time.time()-inicio:.2f} segundos"

        boton_entrenar.on_click(entrenar_rnn)

        ayuda = widgets.HTML("""
        <h4>‚ÑπÔ∏è Ayuda - Par√°metros del modelo RNN</h4>
        <ul>
            <li><b>Tipo RNN:</b> Define la arquitectura de red. LSTM y GRU son recomendados para series con dependencia larga.</li>
            <li><b>Ventana:</b> N√∫mero de pasos de tiempo usados para predecir el siguiente valor.</li>
            <li><b>Capas / Unidades:</b> M√°s capas y unidades aumentan capacidad, pero tambi√©n el riesgo de sobreajuste.</li>
            <li><b>Batch, Epochs:</b> Controlan tama√±o del lote y n√∫mero de iteraciones de entrenamiento.</li>
            <li><b>LR:</b> Tasa de aprendizaje. Valores muy altos o bajos pueden afectar la convergencia.</li>
            <li><b>Dropout:</b> Regulariza y previene sobreajuste. 0.1‚Äì0.3 com√∫n.</li>
        </ul>
        """)

        display(widgets.VBox([
            metodo_sel,
            widgets.HBox([tipo_rnn, window_size]),
            widgets.HBox([units, layers, batch]),
            widgets.HBox([epochs, learning_rate, optimizer]),
            widgets.HBox([activation, drop, loss_fn]),
            boton_entrenar, tiempo_lbl,
            ayuda, output_area_rnn
        ]))

# Artifact: exec exec_113
from tensorflow.keras.models import load_model

# Artifact: assign out_model_comparator
out_model_comparator = widgets.Output()

# Artifact: assign btn_lanzar_comparador
btn_lanzar_comparador = widgets.Button(description='üìä Comparar Modelos Entrenados', button_style='success')

# Artifact: function mostrar_comparador_modelos
def mostrar_comparador_modelos(b=None):
    with out_model_comparator:
        clear_output()
        display(btn_lanzar_comparador)

# Artifact: function ejecutar_comparador
def ejecutar_comparador(b=None):
    with out_model_comparator:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>üìä Comparador de Modelos Entrenados</h3>
        <p>Este comparador analiza los modelos entrenados con distintos algoritmos y m√©todos de selecci√≥n de variables.</p>
        """))

        ruta_modelos = '.'
        modelos_validos = []

        print("üîç Buscando modelos guardados...")
        for archivo in os.listdir(ruta_modelos):
            if archivo.startswith("modelo_") and (archivo.endswith(".pkl") or archivo.endswith(".h5")):
                nombre_modelo = archivo.replace("modelo_", "").replace(".pkl", "").replace(".h5", "")
                try:
                    if archivo.endswith(".pkl"):
                        with open(os.path.join(ruta_modelos, archivo), 'rb') as f:
                            modelo_guardado = pickle.load(f)
                        modelo = modelo_guardado.get('model')
                        scaler_X = modelo_guardado.get('scaler_X', modelo_guardado.get('sx'))
                        scaler_Y = modelo_guardado.get('scaler_Y', modelo_guardado.get('sy'))
                        cols = modelo_guardado.get('cols')
                        yname = modelo_guardado.get('yname')
                        if scaler_X is None or scaler_Y is None:
                            raise KeyError("Faltan escaladores")
                    else:
                        modelo = load_model(os.path.join(ruta_modelos, archivo))
                        escalador_path = f"escaladores_{nombre_modelo}.pkl"
                        with open(escalador_path, 'rb') as f:
                            escaladores = pickle.load(f)
                        scaler_X = escaladores['scaler_X']
                        scaler_Y = escaladores['scaler_Y']
                        cols = escaladores['cols']
                        yname = escaladores['yname']

                    modelos_validos.append({
                        'nombre': nombre_modelo,
                        'modelo': modelo,
                        'scaler_X': scaler_X,
                        'scaler_Y': scaler_Y,
                        'cols': cols,
                        'yname': yname
                    })
                except Exception as e:
                    print(f"‚ùå Error al procesar {archivo}: {e}")

        if not modelos_validos:
            display(HTML("<b style='color:red;'>‚ö†Ô∏è No se encontraron modelos entrenados v√°lidos.</b>"))
            return

        resultados = []
        detalles_modelos = []

        for entry in modelos_validos:
            nombre = entry['nombre']
            model = entry['modelo']
            sx = entry['scaler_X']
            sy = entry['scaler_Y']
            cols = entry['cols']
            yname = entry['yname']

            Xtest = X_test[cols].copy()
            ytest = Y_test.values.ravel()

            # Detectar si es un modelo RNN por la forma esperada
            try:
                input_shape = model.input_shape
                is_rnn = len(input_shape) == 3
            except:
                is_rnn = False

            if is_rnn:
                window = input_shape[1]
                X_full = X_test[cols].copy()
                y_full = Y_test.values.ravel()
                X_scaled = sx.transform(X_full)
                y_scaled = sy.transform(y_full.reshape(-1, 1)).ravel()

                X_seq, y_seq = [], []
                for i in range(len(X_scaled) - window):
                    X_seq.append(X_scaled[i:i+window])
                    y_seq.append(y_full[i+window])
                X_seq = np.array(X_seq)
                y_seq = np.array(y_seq)

                pred_scaled = model.predict(X_seq).ravel()
                pred = sy.inverse_transform(pred_scaled.reshape(-1, 1)).ravel()
                ytest = y_seq  # ajustar Y real a misma longitud
            else:
                Xtest_scaled = sx.transform(Xtest)
                pred_scaled = model.predict(Xtest_scaled)
                if isinstance(pred_scaled, tuple): pred_scaled = pred_scaled[0]
                pred = sy.inverse_transform(pred_scaled.reshape(-1, 1)).ravel()
                ytest = ytest  # no cambia

            r2 = r2_score(ytest, pred)
            mse = mean_squared_error(ytest, pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(ytest, pred)

            resultados.append({
                'Modelo': nombre,
                'R2': r2,
                'MSE': mse,
                'RMSE': rmse,
                'MAE': mae,
                'Pred': pred
            })

            detalles_modelos.append({
                'Modelo': nombre,
                'Variables X': ', '.join(cols),
                'Variable Y': yname,
                'N¬∫ Variables': len(cols),
                'Tipo Modelo': nombre.split('_')[0].upper(),
                'M√©todo Selecci√≥n': nombre.split('_')[-1].capitalize()
            })

        df_resultados = pd.DataFrame(resultados)
        df_detalles = pd.DataFrame(detalles_modelos)

        display(HTML("<h4>üìã Comparativa de Resultados</h4>"))
        display(df_resultados[['Modelo', 'R2', 'RMSE', 'MAE', 'MSE']]
                .sort_values(by='R2', ascending=False)
                .style.set_caption("Ranking de Modelos por R¬≤")
                .set_properties(**{'border': '1px solid gray', 'padding': '6px'})
                .set_table_styles([
                    {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('font-weight', 'bold')]},
                ]))

        df_sorted = df_resultados.sort_values(by='R2', ascending=False)
        fig, ax = plt.subplots(figsize=(10, 6))
        colors = ['gold', 'silver', 'peru'] + ['lightblue']*(len(df_sorted)-3)
        ax.barh(df_sorted['Modelo'], df_sorted['R2'], color=colors[:len(df_sorted)])
        ax.set_title("üèÜ Ranking de Modelos por R¬≤")
        ax.invert_yaxis()
        for i, v in enumerate(df_sorted['R2']):
            ax.text(v + 0.01, i, f"{v:.3f}", va='center')
        plt.grid(axis='x')
        plt.tight_layout()
        plt.show()

        display(HTML("<h4>üîß Par√°metros de Entrenamiento de los Modelos</h4>"))
        display(df_detalles.style.set_caption("Resumen de Configuraci√≥n de Modelos")
                .set_properties(**{'border': '1px solid gray', 'padding': '6px'})
                .set_table_styles([
                    {'selector': 'th', 'props': [('background-color', '#e0f7fa'), ('font-weight', 'bold')]},
                ]))

        # Mostrar tabla con par√°metros t√©cnicos (si existen)
        tabla_parametros = []

        for entry in modelos_validos:
            nombre = entry['nombre']
            modelo = entry['modelo']

            fila = {'Modelo': nombre}
            try:
                if hasattr(modelo, 'get_params'):
                    fila.update(modelo.get_params())
                elif isinstance(modelo, tf.keras.Model):
                    config = modelo.get_config()
                    fila['Capas'] = len(config['layers'])
                    fila['Optimizador'] = config.get('optimizer_config', {}).get('class_name', 'Desconocido')
                    fila['P√©rdida'] = config.get('loss', 'Desconocida')
                else:
                    fila['Info'] = '‚ö†Ô∏è Tipo de modelo no reconocido'
            except Exception as e:
                fila['Error'] = str(e)

            tabla_parametros.append(fila)

        df_parametros = pd.DataFrame(tabla_parametros)
        display(HTML("<h4>üßæ Par√°metros de Configuraci√≥n (Detalles T√©cnicos)</h4>"))
        if not df_parametros.empty:
            display(df_parametros.style.set_caption("Par√°metros usados en cada modelo")
                    .set_properties(**{'border': '1px solid #ccc', 'padding': '4px'})
                    .set_table_styles([{'selector': 'th', 'props': [('background-color', '#f8f8f8'), ('font-weight', 'bold')]}]))
        else:
            display(HTML("<i>No se pudieron recuperar par√°metros para los modelos cargados.</i>"))

        display(HTML("<h4>üìà Gr√°ficos Comparativos Y Real vs. Predicci√≥n</h4>"))
        for res in resultados:
            nombre = res['Modelo']
            pred = res['Pred']
            fig, ax = plt.subplots(figsize=(10,4))
            ax.plot(Y_test.values, label='Y Real', color='black')
            ax.plot(pred, label=f'{nombre}', linestyle='--')
            ax.set_title(f'{nombre}: Real vs Predicho')
            ax.legend()
            ax.grid(True)
            plt.show()

        # Tabla de par√°metros completos si est√°n disponibles
        display(HTML("<h4>üßæ Par√°metros de Configuraci√≥n (Detalles T√©cnicos)</h4>"))

        tabla_parametros = []

        for entry in modelos_validos:
            modelo = entry['modelo']
            nombre = entry['nombre']
            tipo   = nombre.split('_')[0].upper()

            if hasattr(modelo, 'get_params'):
                try:
                    params = modelo.get_params()
                    tabla_parametros.append({
                        'Modelo': nombre,
                        **params
                    })
                except:
                    tabla_parametros.append({'Modelo': nombre, 'Info': '‚ö†Ô∏è No se pudieron extraer los par√°metros'})
            elif isinstance(modelo, tf.keras.Model):
                config = modelo.get_config()
                tabla_parametros.append({
                    'Modelo': nombre,
                    'Capas': len(config['layers']),
                    'Optim.': config.get('optimizer_config', {}).get('class_name', 'N/A'),
                    'Loss': config.get('loss', 'N/A') if isinstance(config.get('loss'), str) else str(config.get('loss')),
                    'Tipo': tipo
                })
            else:
                tabla_parametros.append({'Modelo': nombre, 'Info': '‚ö†Ô∏è Modelo no compatible'})

        df_params = pd.DataFrame(tabla_parametros)
        display(df_params.style.set_caption("üõ†Ô∏è Par√°metros de Ajuste de Cada Modelo")
                .set_properties(**{'border': '1px solid #999', 'padding': '5px'})
                .set_table_styles([{'selector': 'th', 'props': [('background-color', '#f9f9f9'), ('font-weight', 'bold')]}]))

# Artifact: exec exec_118
btn_lanzar_comparador.on_click(ejecutar_comparador)

# Artifact: exec exec_119
display(out_model_comparator)

# Artifact: assign out_pred_svr
out_pred_svr = widgets.Output()

# Artifact: function mostrar_prediccion_svr
def mostrar_prediccion_svr(b=None):
    with out_pred_svr:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>üîÆ Predicci√≥n con Modelo SVR</h3>
        <p>Este m√≥dulo permite realizar predicciones con modelos SVR entrenados previamente
        utilizando variables seleccionadas autom√°ticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selecci√≥n de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='N¬∫ Casos:')

        modo_datos = widgets.ToggleButtons(
            options=['Autom√°tico', 'Manual'],
            description='Modo de entrada:'
        )

        btn_generar = widgets.Button(description='‚û°Ô∏è Generar Variables X')
        btn_predecir = widgets.Button(description='üìà Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='üìã Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        datos_generados = {}
        resultados = {}

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                nombre_modelo = f"modelo_svr_{metodo.lower()}.pkl"
                if not os.path.exists(nombre_modelo):
                    continue
                with open(nombre_modelo, 'rb') as f:
                    modelo_dict = pickle.load(f)
                cols = modelo_dict['cols']

                df_x = pd.DataFrame()
                for col in cols:
                    if col not in X_data.columns or X_data[col].isnull().all():
                        continue
                    serie = X_data[col]
                    minimo, maximo = serie.min(), serie.max()
                    tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                    if modo_datos.value == 'Autom√°tico':
                        vals = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' \
                            else np.linspace(maximo, minimo, num_casos.value)
                        df_x[col] = vals
                    else:
                        df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                datos_generados[metodo] = df_x

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>üßæ Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))

                    if isinstance(df, pd.DataFrame) and modo_datos.value == 'Autom√°tico':
                        display(df)
                    elif modo_datos.value == 'Manual':
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i+1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                if metodo not in datos_generados:
                    continue
                df = datos_generados[metodo]
                nombre_modelo = f"modelo_svr_{metodo.lower()}.pkl"
                if not os.path.exists(nombre_modelo):
                    continue
                with open(nombre_modelo, 'rb') as f:
                    modelo_dict = pickle.load(f)

                sx, sy, model = modelo_dict['sx'], modelo_dict['sy'], modelo_dict['model']

                if modo_datos.value == 'Manual':
                    df_manual = pd.DataFrame()
                    for col in df.columns:
                        df_manual[col] = [w.value for w in df[col]]
                    df_to_use = df_manual
                else:
                    df_to_use = df

                x_scaled = sx.transform(df_to_use.values)
                y_pred = sy.inverse_transform(model.predict(x_scaled).reshape(-1, 1)).ravel()
                df_pred = df_to_use.copy()
                df_pred['Y_pred'] = y_pred
                resultados[metodo] = df_pred

            tabla_pred.clear_output()
            contenedor_tablas = []
            for metodo in metodos:
                if metodo in resultados:
                    df = resultados[metodo]
                    contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>üßÆ {metodo}</h4>"))
                    contenedor_tablas.append(widgets.Output())
                    with contenedor_tablas[-1]:
                        display(df)

            with tabla_pred:
                clear_output()
                display(HTML("<h3>üìã Resultados de la Predicci√≥n</h3>"))
                display(widgets.VBox(contenedor_tablas))

            with grafico_pred:
                plt.figure(figsize=(10, 4))
                for metodo in metodos:
                    if metodo in resultados:
                        y_vals = resultados[metodo]['Y_pred'].values
                        if y_vals.size > 0:
                            plt.plot(y_vals, label=str(metodo), linestyle='--')

                plt.title("üìä Predicciones Y por M√©todo")
                plt.xlabel("Caso")
                plt.ylabel("Y_predicho")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        def copiar_al_portapapeles(_):
            from IPython.display import Javascript
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("‚úÖ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_122
display(out_pred_svr)

# Artifact: assign out_pred_nn
out_pred_nn = widgets.Output()

# Artifact: function mostrar_prediccion_nn
def mostrar_prediccion_nn(b=None):
    with out_pred_nn:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>üîÆ Predicci√≥n con Red Neuronal</h3>
        <p>Este m√≥dulo permite realizar predicciones con redes neuronales previamente entrenadas
        utilizando variables seleccionadas autom√°ticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selecci√≥n de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='N¬∫ Casos:')

        modo_datos = widgets.ToggleButtons(
            options=['Autom√°tico', 'Manual'],
            description='Modo de entrada:'
        )

        btn_generar = widgets.Button(description='‚û°Ô∏è Generar Variables X')
        btn_predecir = widgets.Button(description='üìà Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='üìã Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        datos_generados = {}
        resultados = {}

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                modelo_path = f"modelo_nn_{metodo.lower()}.h5"
                scaler_path = f"escaladores_nn_{metodo.lower()}.pkl"
                if not os.path.exists(modelo_path) or not os.path.exists(scaler_path):
                    continue
                with open(scaler_path, 'rb') as f:
                    datos = pickle.load(f)
                cols = datos['cols']

                df_x = pd.DataFrame()
                for col in cols:
                    if col not in X_data.columns or X_data[col].isnull().all():
                        continue
                    serie = X_data[col]
                    minimo, maximo = serie.min(), serie.max()
                    tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                    if modo_datos.value == 'Autom√°tico':
                        vals = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' \
                            else np.linspace(maximo, minimo, num_casos.value)
                        df_x[col] = vals
                    else:
                        df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                datos_generados[metodo] = df_x

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>üßæ Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))
                    if isinstance(df, pd.DataFrame) and modo_datos.value == 'Autom√°tico':
                        display(df)
                    elif modo_datos.value == 'Manual':
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i+1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                if metodo not in datos_generados:
                    continue
                df = datos_generados[metodo]
                modelo_path = f"modelo_nn_{metodo.lower()}.h5"
                scaler_path = f"escaladores_nn_{metodo.lower()}.pkl"
                if not os.path.exists(modelo_path) or not os.path.exists(scaler_path):
                    continue

                model = load_model(modelo_path)
                with open(scaler_path, 'rb') as f:
                    datos = pickle.load(f)
                sx, sy = datos['scaler_X'], datos['scaler_Y']

                if modo_datos.value == 'Manual':
                    df_manual = pd.DataFrame()
                    for col in df.columns:
                        df_manual[col] = [w.value for w in df[col]]
                    df_to_use = df_manual
                else:
                    df_to_use = df

                x_scaled = sx.transform(df_to_use.values)
                y_pred = sy.inverse_transform(model.predict(x_scaled)).ravel()
                df_pred = df_to_use.copy()
                df_pred['Y_pred'] = y_pred
                resultados[metodo] = df_pred

            tabla_pred.clear_output()
            contenedor_tablas = []
            for metodo in metodos:
                if metodo in resultados:
                    df = resultados[metodo]
                    contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>üßÆ {metodo}</h4>"))
                    contenedor_tablas.append(widgets.Output())
                    with contenedor_tablas[-1]:
                        display(df)

            with tabla_pred:
                clear_output()
                display(HTML("<h3>üìã Resultados de la Predicci√≥n</h3>"))
                display(widgets.VBox(contenedor_tablas))

            with grafico_pred:
                plt.figure(figsize=(10, 4))
                for metodo in metodos:
                    if metodo in resultados:
                        plt.plot(resultados[metodo]['Y_pred'].values, label=metodo, linestyle='--')
                plt.title("üìä Predicciones Y por M√©todo (NN)")
                plt.xlabel("Caso")
                plt.ylabel("Y_predicho")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        def copiar_al_portapapeles(_):
            from IPython.display import Javascript
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("‚úÖ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_125
display(out_pred_nn)

# Artifact: assign out_pred_xgb
out_pred_xgb = widgets.Output()

# Artifact: function mostrar_prediccion_xgboost
def mostrar_prediccion_xgboost(b=None):
    with out_pred_xgb:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>üîÆ Predicci√≥n con XGBoost</h3>
        <p>Este m√≥dulo permite realizar predicciones con modelos XGBoost previamente entrenados
        utilizando variables seleccionadas autom√°ticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selecci√≥n de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='N¬∫ Casos:')

        modo_datos = widgets.ToggleButtons(
            options=['Autom√°tico', 'Manual'],
            description='Modo de entrada:'
        )

        btn_generar = widgets.Button(description='‚û°Ô∏è Generar Variables X')
        btn_predecir = widgets.Button(description='üìà Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='üìã Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        datos_generados = {}
        resultados = {}

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                path_model = f"modelo_xgb_{metodo.lower()}.pkl"
                if not os.path.exists(path_model):
                    continue
                with open(path_model, 'rb') as f:
                    datos = pickle.load(f)
                cols = datos['cols']

                df_x = pd.DataFrame()
                for col in cols:
                    if col not in X_data.columns or X_data[col].isnull().all():
                        continue
                    serie = X_data[col]
                    minimo, maximo = serie.min(), serie.max()
                    tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                    if modo_datos.value == 'Autom√°tico':
                        vals = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' \
                            else np.linspace(maximo, minimo, num_casos.value)
                        df_x[col] = vals
                    else:
                        df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                datos_generados[metodo] = df_x

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>üßæ Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))
                    if isinstance(df, pd.DataFrame) and modo_datos.value == 'Autom√°tico':
                        display(df)
                    elif modo_datos.value == 'Manual':
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i+1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                if metodo not in datos_generados:
                    continue
                df = datos_generados[metodo]
                path_model = f"modelo_xgb_{metodo.lower()}.pkl"
                if not os.path.exists(path_model):
                    continue

                with open(path_model, 'rb') as f:
                    datos = pickle.load(f)
                model = datos['model']
                sx, sy = datos['sx'], datos['sy']

                if modo_datos.value == 'Manual':
                    df_manual = pd.DataFrame()
                    for col in df.columns:
                        df_manual[col] = [w.value for w in df[col]]
                    df_to_use = df_manual
                else:
                    df_to_use = df

                x_scaled = sx.transform(df_to_use.values)
                y_pred = sy.inverse_transform(model.predict(x_scaled).reshape(-1, 1)).ravel()
                df_pred = df_to_use.copy()
                df_pred['Y_pred'] = y_pred
                resultados[metodo] = df_pred

            contenedor_tablas = []
            for metodo in metodos:
                if metodo in resultados:
                    df = resultados[metodo]
                    contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>üßÆ {metodo}</h4>"))
                    contenedor_tablas.append(widgets.Output())
                    with contenedor_tablas[-1]:
                        display(df)

            with tabla_pred:
                clear_output()
                display(HTML("<h3>üìã Resultados de la Predicci√≥n (XGBoost)</h3>"))
                display(widgets.VBox(contenedor_tablas))

            with grafico_pred:
                plt.figure(figsize=(10, 4))
                for metodo in metodos:
                    if metodo in resultados:
                        plt.plot(resultados[metodo]['Y_pred'].values, label=metodo, linestyle='--')
                plt.title("üìä Predicciones Y por M√©todo (XGBoost)")
                plt.xlabel("Caso")
                plt.ylabel("Y_predicho")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        def copiar_al_portapapeles(_):
            from IPython.display import Javascript
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("‚úÖ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_128
display(out_pred_xgb)

# Artifact: exec exec_129
import pickle, os, traceback, time

# Artifact: exec exec_130
from IPython.display import display, HTML, clear_output, Javascript

# Artifact: assign out_pred_rf
out_pred_rf = widgets.Output()

# Artifact: function mostrar_prediccion_rf
def mostrar_prediccion_rf(b=None):
    with out_pred_rf:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>üîÆ Predicci√≥n con Random Forest</h3>
        <p>Este m√≥dulo permite realizar predicciones con modelos Random Forest previamente entrenados
        utilizando variables seleccionadas autom√°ticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selecci√≥n de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='N¬∫ Casos:')

        modo_datos = widgets.ToggleButtons(
            options=['Autom√°tico', 'Manual'],
            description='Modo de entrada:'
        )

        btn_generar = widgets.Button(description='‚û°Ô∏è Generar Variables X')
        btn_predecir = widgets.Button(description='üìà Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='üìã Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        progreso = widgets.Label()

        datos_generados = {}
        resultados = {}

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                path_model = f"modelo_rf_{metodo.lower()}.pkl"
                if not os.path.exists(path_model):
                    continue
                try:
                    with open(path_model, 'rb') as f:
                        datos = pickle.load(f)
                    cols = datos.get('cols', [])
                    if not cols:
                        continue

                    df_x = pd.DataFrame()
                    for col in cols:
                        if col not in X_data.columns or X_data[col].isnull().all():
                            continue
                        serie = X_data[col]
                        minimo, maximo = serie.min(), serie.max()
                        tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                        if modo_datos.value == 'Autom√°tico':
                            vals = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' \
                                else np.linspace(maximo, minimo, num_casos.value)
                            df_x[col] = vals
                        else:
                            df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                    datos_generados[metodo] = df_x
                except Exception as e:
                    print(f"‚ùå Error al generar variables para {metodo}: {e}")

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>üßæ Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))
                    if isinstance(df, pd.DataFrame) and modo_datos.value == 'Autom√°tico':
                        display(df)
                    elif modo_datos.value == 'Manual':
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i+1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            progreso.value = "‚è≥ Realizando predicciones..."
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            t_ini = time.time()
            errores = []  # ‚Üê para mostrar errores al final

            for metodo in metodos:
                if metodo not in datos_generados:
                    continue
                df = datos_generados[metodo]
                path_model = f"modelo_rf_{metodo.lower()}.pkl"
                if not os.path.exists(path_model):
                    continue

                try:
                    with open(path_model, 'rb') as f:
                        datos = pickle.load(f)
                    model = datos['model']
                    #sx, sy = datos['scaler_X'], datos['scaler_Y']
                    sx = datos.get('scaler_X', None)
                    sy = datos.get('scaler_Y', None)


                    if modo_datos.value == 'Manual':
                        df_manual = pd.DataFrame()
                        for col in df.columns:
                            df_manual[col] = [w.value for w in df[col]]
                        df_to_use = df_manual
                    else:
                        df_to_use = df

                    if set(df_to_use.columns) != set(datos['cols']):
                        errores.append(f"‚ö†Ô∏è Columnas incompatibles para {metodo}. Se omite.")
                        continue
                    df_to_use = df_to_use[datos['cols']]

                    if df_to_use.empty:
                        errores.append(f"‚ö†Ô∏è DataFrame vac√≠o para {metodo}. Se omite.")
                        continue

                    print(f"[DEBUG] Prediciendo para m√©todo: {metodo}, df.shape = {df_to_use.shape}")

                    # === Predicci√≥n con o sin escalado ===
                    if sx is not None:
                        x_scaled = sx.transform(df_to_use.values)
                    else:
                        x_scaled = df_to_use.values

                    y_pred_scaled = model.predict(x_scaled).reshape(-1, 1)

                    if sy is not None:
                        y_pred = sy.inverse_transform(y_pred_scaled).ravel()
                    else:
                        y_pred = y_pred_scaled.ravel()

                    df_pred = df_to_use.copy()
                    df_pred['Y_pred'] = y_pred
                    resultados[metodo] = df_pred

                except Exception as e:
                    errores.append(f"‚ùå Error al predecir para {metodo}:\n{traceback.format_exc()}")

            progreso.value = f"‚úÖ Predicciones completadas en {time.time() - t_ini:.1f}s"

            contenedor_tablas = []
            for metodo in metodos:
                if metodo in resultados:
                    df = resultados[metodo]
                    contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>üßÆ {metodo}</h4>"))
                    contenedor_tablas.append(widgets.Output())
                    with contenedor_tablas[-1]:
                        display(df)

            with tabla_pred:
                clear_output()
                display(HTML("<h3>üìã Resultados de la Predicci√≥n (Random Forest)</h3>"))
                if contenedor_tablas:
                    display(widgets.VBox(contenedor_tablas))
                if errores:
                    display(HTML("<h4 style='color:red;'>‚ùå Errores detectados:</h4>"))
                    for err in errores:
                        display(HTML(f"<pre style='color:darkred;'>{err}</pre>"))

            with grafico_pred:
                clear_output()
                plt.figure(figsize=(10, 4))
                hay_datos = False
                for metodo in metodos:
                    if metodo in resultados:
                        plt.plot(resultados[metodo]['Y_pred'].values, label=metodo, linestyle='--')
                        hay_datos = True
                if hay_datos:
                    plt.title("üìä Predicciones Y por M√©todo (Random Forest)")
                    plt.xlabel("Caso")
                    plt.ylabel("Y_predicho")
                    plt.legend()
                    plt.grid(True)
                    plt.tight_layout()
                    plt.show()

        def copiar_al_portapapeles(_):
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("‚úÖ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            progreso,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_133
display(out_pred_rf)

# Artifact: exec exec_134
import pickle, os, traceback

# Artifact: assign out_pred_rnn
out_pred_rnn = widgets.Output()

# Artifact: assign resultados
resultados = {}

# Artifact: assign datos_generados
datos_generados = {}

# Artifact: function mostrar_prediccion_rnn
def mostrar_prediccion_rnn(b=None):
    with out_pred_rnn:
        clear_output()

        display(HTML("""
        <h3 style='color:#2E8B57;'>üîÆ Predicci√≥n con RNN</h3>
        <p>Este m√≥dulo permite realizar predicciones con modelos RNN previamente entrenados
        utilizando variables seleccionadas autom√°ticamente o introducidas manualmente.</p>
        """))

        metodo_selector = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP', 'Todos'],
            description='Selecci√≥n de Variables:'
        )

        num_casos = widgets.BoundedIntText(value=5, min=1, max=100, description='N¬∫ Casos:')
        modo_datos = widgets.ToggleButtons(options=['Autom√°tico', 'Manual'], description='Modo de entrada:')

        btn_generar = widgets.Button(description='‚û°Ô∏è Generar Variables X')
        btn_predecir = widgets.Button(description='üìà Predecir Y', button_style='success')
        btn_copiar = widgets.Button(description='üìã Copiar Tabla', button_style='info')

        tabla_x = widgets.Output()
        tabla_pred = widgets.Output()
        grafico_pred = widgets.Output()
        progreso = widgets.Label()

        def generar_valores(_):
            tabla_x.clear_output()
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            progreso.value = ""
            datos_generados.clear()
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            for metodo in metodos:
                modelo_path = f"modelo_rnn_{metodo.lower()}.h5"
                scaler_path = f"escaladores_rnn_{metodo.lower()}.pkl"
                if not os.path.exists(modelo_path) or not os.path.exists(scaler_path):
                    continue
                with open(scaler_path, 'rb') as f:
                    datos = pickle.load(f)
                cols = datos.get('cols', [])
                if not cols:
                    continue

                df_x = pd.DataFrame()
                for col in cols:
                    if col not in X_data.columns or X_data[col].isnull().all():
                        continue
                    serie = X_data[col]
                    minimo, maximo = serie.min(), serie.max()
                    tendencia = 'asc' if serie.corr(Y_data.iloc[:, 0]) > 0 else 'desc'
                    if modo_datos.value == 'Autom√°tico':
                        valores = np.linspace(minimo, maximo, num_casos.value) if tendencia == 'asc' else np.linspace(maximo, minimo, num_casos.value)
                        df_x[col] = valores
                    else:
                        df_x[col] = [widgets.FloatText(value=0.0, layout=widgets.Layout(width='80px')) for _ in range(num_casos.value)]
                datos_generados[metodo] = df_x

            with tabla_x:
                clear_output()
                display(HTML(f"<h4>üßæ Variables X Generadas ({modo_datos.value})</h4>"))
                for metodo in metodos:
                    if metodo not in datos_generados:
                        continue
                    display(HTML(f"<b style='color:#2E8B57;'>{metodo}</b>"))
                    df = datos_generados[metodo]
                    if modo_datos.value == 'Autom√°tico':
                        display(df)
                    else:
                        grid = widgets.GridspecLayout(num_casos.value + 1, len(df.columns))
                        for j, col in enumerate(df.columns):
                            grid[0, j] = widgets.Label(value=col)
                            for i in range(num_casos.value):
                                grid[i + 1, j] = df[col][i]
                        display(grid)

        def realizar_prediccion(_):
            tabla_pred.clear_output()
            grafico_pred.clear_output()
            progreso.value = "‚è≥ Realizando predicciones..."
            resultados.clear()

            metodos = [metodo_selector.value] if metodo_selector.value != 'Todos' else [
                'Pearson', 'Spearman', 'MutualInfo', 'Boruta', 'UMAP']

            errores = []

            for metodo in metodos:
                try:
                    if metodo not in datos_generados:
                        continue
                    df = datos_generados[metodo]

                    modelo_path = f"modelo_rnn_{metodo.lower()}.h5"
                    scaler_path = f"escaladores_rnn_{metodo.lower()}.pkl"
                    if not os.path.exists(modelo_path) or not os.path.exists(scaler_path):
                        errores.append(f"‚ùå Archivos no encontrados para {metodo}")
                        continue

                    with open(scaler_path, 'rb') as f:
                        datos = pickle.load(f)
                    sx, sy = datos.get('scaler_X'), datos.get('scaler_Y')
                    model = load_model(modelo_path)

                    if modo_datos.value == 'Manual':
                        df_manual = pd.DataFrame()
                        for col in df.columns:
                            df_manual[col] = [w.value for w in df[col]]
                        df_to_use = df_manual
                    else:
                        df_to_use = df

                    if set(df_to_use.columns) != set(datos['cols']):
                        errores.append(f"‚ö†Ô∏è Columnas incompatibles para {metodo}. Se omite.")
                        continue
                    df_to_use = df_to_use[datos['cols']]

                    x_scaled = sx.transform(df_to_use.values)
                    x_scaled_rnn = x_scaled.reshape((x_scaled.shape[0], 1, x_scaled.shape[1]))
                    y_pred_scaled = model.predict(x_scaled_rnn).reshape(-1, 1)
                    y_pred = sy.inverse_transform(y_pred_scaled).ravel()

                    df_pred = df_to_use.copy()
                    df_pred['Y_pred'] = y_pred
                    resultados[metodo] = df_pred

                except Exception as e:
                    errores.append(f"‚ùå Error al predecir para {metodo}:\n{traceback.format_exc()}")

            progreso.value = "‚úÖ Predicciones completadas"

            with tabla_pred:
                clear_output()
                contenedor_tablas = []
                for metodo in metodos:
                    if metodo in resultados:
                        df = resultados[metodo]
                        contenedor_tablas.append(HTML(f"<h4 style='color:#2E8B57;'>üßÆ {metodo}</h4>"))
                        contenedor_tablas.append(widgets.Output())
                        with contenedor_tablas[-1]:
                            display(df)
                if contenedor_tablas:
                    display(HTML("<h3>üìã Resultados de la Predicci√≥n (RNN)</h3>"))
                    display(widgets.VBox(contenedor_tablas))
                if errores:
                    display(HTML("<h4 style='color:red;'>‚ùå Errores detectados:</h4>"))
                    for err in errores:
                        display(HTML(f"<pre style='color:darkred;'>{err}</pre>"))

            with grafico_pred:
                clear_output()
                plt.figure(figsize=(10, 4))
                for metodo in metodos:
                    if metodo in resultados:
                        plt.plot(resultados[metodo]['Y_pred'].values, label=metodo, linestyle='--')
                plt.title("üìä Predicciones Y por M√©todo (RNN)")
                plt.xlabel("Caso")
                plt.ylabel("Y_predicho")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        def copiar_al_portapapeles(_):
            contenido = ""
            for metodo, df in resultados.items():
                contenido += f"\n### {metodo}\n" + df.to_csv(index=False)
            js_code = f"navigator.clipboard.writeText(`{contenido}`)"
            display(Javascript(js_code))
            print("‚úÖ Tabla copiada al portapapeles.")

        btn_generar.on_click(generar_valores)
        btn_predecir.on_click(realizar_prediccion)
        btn_copiar.on_click(copiar_al_portapapeles)

        display(widgets.VBox([
            metodo_selector,
            num_casos,
            modo_datos,
            btn_generar,
            tabla_x,
            btn_predecir,
            progreso,
            tabla_pred,
            grafico_pred,
            btn_copiar
        ]))

# Artifact: exec exec_139
display(out_pred_rnn)

# Artifact: exec exec_140
import glob

# Artifact: exec exec_141
from keras.models import load_model

# Artifact: assign out_graf_86
out_graf_86 = widgets.Output()

# Artifact: function listar_modelos
def listar_modelos():
    modelos = {}
    for path in glob.glob("modelo_*.pkl"):
        nombre = os.path.splitext(os.path.basename(path))[0].replace("modelo_", "").upper()
        modelos[nombre] = path

    for h5_path in glob.glob("modelo_*.h5"):
        nombre = os.path.splitext(os.path.basename(h5_path))[0].replace("modelo_", "").upper()
        pkl_path = f"escaladores_{nombre.lower()}.pkl"
        if os.path.exists(pkl_path):
            modelos[nombre] = (h5_path, pkl_path)
        else:
            modelos[nombre] = h5_path
    return modelos

# Artifact: function mostrar_grafico_y_vs_x
def mostrar_grafico_y_vs_x():
    with out_graf_86:
        clear_output()

        if 'X_data' not in globals() or 'Y_data' not in globals():
            print("‚ùå Faltan datos cargados (X_data o Y_data).")
            return

        modelos_disponibles = listar_modelos()

        selector_variable = widgets.Dropdown(
            options=X_data.columns.tolist(),
            description='Variable X:',
            layout=widgets.Layout(width='50%')
        )

        selector_dataset = widgets.ToggleButtons(
            options=['Train', 'Test'],
            description='Dataset:',
            style={'description_width': 'initial'}
        )

        selector_modelos = widgets.SelectMultiple(
            options=list(modelos_disponibles.keys()),
            description='Modelos:',
            layout=widgets.Layout(width='50%', height='150px')
        )

        boton_ver = widgets.Button(description='üìä Comparar Y', button_style='success')
        resumen_out = widgets.Output()
        tabla_out = widgets.Output()
        debug_out = widgets.Output()
        grafico_out = widgets.Output()

        def graficar(_):
            resumen_out.clear_output()
            tabla_out.clear_output()
            grafico_out.clear_output()
            debug_out.clear_output()

            var_x = selector_variable.value
            if var_x is None:
                print("‚ö†Ô∏è No se ha seleccionado variable X")
                return

            dataset = selector_dataset.value
            if dataset == 'Train':
                X_base = X_train.copy()
                Y_base = Y_train.copy()
            else:
                X_base = X_test.copy()
                Y_base = Y_test.copy()

            x_vals = X_base[var_x].values
            y_vals = Y_base.values.ravel()
            df = pd.DataFrame({"X": x_vals, "Y_real": y_vals})
            metricas = {}

            modelos_seleccionados = selector_modelos.value
            if isinstance(modelos_seleccionados, str):
                modelos_seleccionados = [modelos_seleccionados]
            elif isinstance(modelos_seleccionados, tuple):
                modelos_seleccionados = list(modelos_seleccionados)

            for modelo_key in modelos_seleccionados:
                modelo_path = modelos_disponibles.get(modelo_key)
                if not modelo_path:
                    with debug_out:
                        print(f"‚ö†Ô∏è Modelo {modelo_key} no encontrado.")
                    continue

                try:
                    if isinstance(modelo_path, tuple):
                        h5_file, pkl_file = modelo_path
                        model = load_model(h5_file)
                        with open(pkl_file, 'rb') as f:
                            datos = pickle.load(f)
                    else:
                        with open(modelo_path, 'rb') as f:
                            datos = pickle.load(f)
                        model = datos.get('model')

                    if model is None:
                        raise ValueError("‚ùå No se encontr√≥ el modelo entrenado en el archivo.")

                    sx = datos.get('scaler_X', datos.get('sx'))
                    sy = datos.get('scaler_Y', datos.get('sy'))

                    if sx is None or sy is None:
                        raise ValueError("‚ùå No se encontraron los escaladores (sx/sy o scaler_X/scaler_Y) en el modelo.")

                    cols = datos.get('cols', None)
                    if cols is None:
                        cols = list(set(X_base.columns) & set(sx.feature_names_in_))
                        if not cols:
                            raise ValueError("‚ùå No se pudo inferir columnas para aplicar scaler_X")

                    X_scaled = sx.transform(X_base[cols])

                    # Si el modelo requiere entrada 3D (ej. RNN)
                    if hasattr(model, 'input_shape') and len(model.input_shape) == 3:
                        X_scaled = np.expand_dims(X_scaled, axis=1)  # Convertir a (batch_size, 1, features)

                    y_pred_scaled = model.predict(X_scaled).reshape(-1, 1)
                    y_pred = sy.inverse_transform(y_pred_scaled).ravel()

                    df[f"Y_{modelo_key}"] = y_pred
                    metricas[modelo_key] = {
                        'R2': r2_score(y_vals, y_pred),
                        'MSE': mean_squared_error(y_vals, y_pred),
                        'MAE': mean_absolute_error(y_vals, y_pred)
                    }
                except Exception as e:
                    with debug_out:
                        print(f"‚ö†Ô∏è Error al procesar {modelo_key}: {e}")
                        print(f"üìÅ Contenido del modelo cargado: {list(datos.keys()) if 'datos' in locals() else '‚ùå No cargado'}")

            with resumen_out:
                display(HTML("<h4>üìå M√©tricas comparativas:</h4>"))
                filas = [[m, f"{v['R2']:.3f}", f"{v['MSE']:.3f}", f"{v['MAE']:.3f}"] for m, v in metricas.items()]
                display(pd.DataFrame(filas, columns=['Modelo', 'R¬≤', 'MSE', 'MAE']))

            with tabla_out:
                display(HTML("<h4>üìä Tabla X, Y real y predicho (Top 20 casos):</h4>"))
                display(df.head(20))
                try:
                    import pyperclip
                    pyperclip.copy(df.to_csv(sep=';', index=False))
                    print("üìã Copiado al portapapeles")
                except:
                    print("‚ö†Ô∏è pyperclip no disponible")

            with grafico_out:
                plt.figure(figsize=(10,6))
                plt.scatter(df['X'], df['Y_real'], label='Y Real', color='black', s=50, alpha=0.6)
                for col in df.columns:
                    if col.startswith("Y_"):
                        modelo = col[2:]
                        if modelo in metricas:
                            plt.scatter(df['X'], df[col], label=f"{modelo} (R¬≤={metricas[modelo]['R2']:.2f})", alpha=0.6)
                plt.xlabel(var_x)
                plt.ylabel('Y')
                plt.title(f"Comparaci√≥n Y real vs predicci√≥n - {var_x} ({dataset})")
                plt.legend()
                plt.grid(True)
                plt.tight_layout()
                plt.show()

        boton_ver.on_click(graficar)

        display(widgets.VBox([
            selector_variable,
            selector_dataset,
            selector_modelos,
            boton_ver,
            resumen_out,
            tabla_out,
            grafico_out,
            debug_out
        ]))

# Artifact: exec exec_145
display(out_graf_86)

# Artifact: exec exec_146
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Artifact: exec exec_147
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, median_absolute_error

# Artifact: exec exec_148
from IPython.display import display, clear_output, HTML, Javascript

# Artifact: exec exec_149
import optuna

# Artifact: exec exec_150
from skopt import BayesSearchCV

# Artifact: exec exec_151
from skopt.space import Real, Categorical

# Artifact: exec exec_152
import scipy.stats as stats

# Artifact: exec exec_153
from scipy.stats import shapiro

# Artifact: assign out_opt_svr
out_opt_svr = widgets.Output()

# Artifact: function mostrar_optimizacion_svr
def mostrar_optimizacion_svr():
    with out_opt_svr:
        clear_output()

        # 1) Verifico que ya se haya segmentado X_train/X_test
        if 'X_train' not in globals() or 'X_test' not in globals():
            print("‚ùå Ejecute primero la segmentaci√≥n para definir X_train y X_test.")
            return

        # 2) Ahora s√≠ puedo sanear columnas
        # Usar sanitize_name para limpiar columnas en el payload
        def clean_cols(col_list):
            return [sanitize_name(c) for c in col_list]
        # Ejemplo de sanitizaci√≥n de X_train antes de fit
        X_train.columns = [sanitize_name(col) for col in X_train.columns]
        X_test.columns = [sanitize_name(col) for col in X_test.columns]

        display(HTML("<h3 style='color:#2E8B57;'>üîß Optimizaci√≥n de Hiperpar√°metros - Modelo SVR</h3>"))
        display(HTML("""
            <h3 style='color:#2E8B57;'>üîß Optimizaci√≥n de Hiperpar√°metros - Modelo SVR</h3>
            <p>Este m√≥dulo permite encontrar la mejor configuraci√≥n de hiperpar√°metros del modelo SVR
            usando distintos motores de optimizaci√≥n. Cada motor aplica estrategias diferentes de b√∫squeda del √≥ptimo:</p>
            <ul>
                <li><b>GridSearchCV</b>: b√∫squeda exhaustiva sobre combinaciones definidas. Garantiza el hallazgo del mejor resultado entre todas las combinaciones, pero puede ser computacionalmente costoso.</li>
                <li><b>RandomizedSearchCV</b>: muestreo aleatorio sobre el espacio de b√∫squeda. Acelera el proceso seleccionando combinaciones al azar.</li>
                <li><b>Optuna</b>: optimizaci√≥n bayesiana con estrategia de aprendizaje secuencial. Aprende de cada iteraci√≥n para mejorar la siguiente.</li>
                <li><b>BayesSearchCV</b>: b√∫squeda bayesiana usando scikit-optimize. Muy eficaz para espacios amplios con hiperpar√°metros complejos.</li>
                <li><b>HalvingGridSearchCV</b>: b√∫squeda jer√°rquica que eval√∫a inicialmente muchas configuraciones con pocos recursos y reserva los recursos mayores solo a las mejores.</li>
            </ul>

            <h4 style="color:#1E90FF;">üìò ¬øQu√© es la Validaci√≥n Cruzada?</h4>
            <p>La validaci√≥n cruzada (CV) eval√∫a la capacidad de generalizaci√≥n de un modelo dividiendo los datos en varias particiones ("folds").
            En cada iteraci√≥n, uno de los folds se usa como conjunto de validaci√≥n mientras los restantes se usan para entrenamiento.
            El modelo se entrena y valida m√∫ltiples veces y luego se promedia la m√©trica para obtener una evaluaci√≥n m√°s robusta.</p>
            <p>Esto reduce el riesgo de sobreajuste y asegura que el modelo funciona correctamente en datos que no ha visto.</p>

            <h4 style="color:#1E90FF;">üìä ¬øQu√© son los residuos?</h4>
            <p>Los residuos son la diferencia entre los valores reales (observados) y los predichos por el modelo.
            Se calculan como:</p>
            <pre>residuo = valor_real - valor_predicho</pre>
            <p>Interpretaci√≥n:</p>
            <ul>
                <li>üîπ Residuos cercanos a cero indican buen ajuste.</li>
                <li>üîπ Una distribuci√≥n normal de los residuos es deseable: implica que los errores son aleatorios.</li>
                <li>üîπ La presencia de sesgos, asimetr√≠as o colas en los residuos puede indicar fallos estructurales del modelo.</li>
            </ul>
            <p>Adem√°s de los histogramas, se utiliza el test de Shapiro-Wilk para evaluar si los residuos siguen una distribuci√≥n normal:</p>
            <pre>p-value > 0.05 ‚ûú los residuos se consideran normales.</pre>

            <h4 style="color:#1E90FF;">üìâ Comparativa Visual entre Modelos</h4>
            <p>Una vez obtenidos los 5 mejores modelos, se genera una comparativa visual con las m√©tricas R¬≤, MSE, MAE, RMSE y MedAE
            para facilitar la selecci√≥n del modelo m√°s robusto en funci√≥n de las prioridades del usuario.</p>
            <p>Tambi√©n se generan histogramas de residuos para evaluar el comportamiento del error y gr√°ficos Q-Q para validar la normalidad de dichos residuos.</p>
            <p>Se incluir√°n gr√°ficos de barras para comparar m√©tricas entre modelos y residuos superpuestos para identificar el m√°s preciso.</p>
            <hr>
            <p style="color:gray;">Puedes lanzar la optimizaci√≥n seleccionando el m√©todo de selecci√≥n de variables (Pearson, MutualInfo, etc.) y los motores deseados.</p>
            """))

        metodos = list(RESUMEN_METODOS.keys()) if isinstance(RESUMEN_METODOS, dict) else []
        if not metodos:
            display(HTML("<span style='color:red;'>‚ö†Ô∏è No se encontraron variables seleccionadas por ning√∫n m√©todo en RESUMEN_METODOS.</span>"))
            return

        metodo_selector = widgets.Dropdown(
            options=metodos + ['Todos'],
            description='Variables X:',
            layout=widgets.Layout(width='50%')
        )

        funcion_selector = widgets.Dropdown(
            options=['R2', 'MSE', 'MAE', 'RMSE', 'MedAE'],
            value='R2',
            description='Funci√≥n objetivo:',
            layout=widgets.Layout(width='50%')
        )

        motor_selector = widgets.SelectMultiple(
            options=['GridSearchCV', 'RandomizedSearchCV', 'Optuna', 'BayesSearchCV', 'Todos'],
            value=['GridSearchCV'],
            description='Motores de Optimizaci√≥n:',
            layout=widgets.Layout(width='70%', height='100px')
        )

        btn_ejecutar = widgets.Button(description='üöÄ Ejecutar Optimizaci√≥n', button_style='success')
        progreso = widgets.HTML()
        traza = widgets.Output()
        salida_resultados = widgets.Output()

        def ejecutar_optimizacion(_):
            with salida_resultados:
                clear_output()
            with traza:
                clear_output()
                print("üü¢ Iniciando optimizaci√≥n...")

            inicio = time.time()
            metodos_a_probar = metodos if metodo_selector.value == 'Todos' else [metodo_selector.value]
            motores = ['GridSearchCV', 'RandomizedSearchCV', 'Optuna', 'BayesSearchCV'] if 'Todos' in motor_selector.value else list(motor_selector.value)

            mejores_modelos = []

            for metodo in metodos_a_probar:
                with traza:
                    print(f"\nüîç Optimizando para variables seleccionadas por: {metodo}")
                #vars_x = RESUMEN_METODOS.get(metodo, [])
                #if not vars_x:
                #    with traza:
                #        print(f"‚ö†Ô∏è No hay variables seleccionadas por {metodo}. Se omite.")
                #    continue
                # ‚Äî‚Äî‚Äî A√ëADIDO: limpiar lista de variables antes de indexar ‚Äî‚Äî‚Äî
                raw_vars = RESUMEN_METODOS.get(metodo, [])
                if not raw_vars:
                    with traza:
                        print(f"‚ö†Ô∏è No hay variables para {metodo}, omito.")
                    continue
                vars_x = clean_cols(raw_vars)
                # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî
                try:
                    X_train_sel = X_train[vars_x].copy()
                    X_test_sel = X_test[vars_x].copy()
                    y_train_sel = Y_train.values.ravel()
                    y_test_sel = Y_test.values.ravel()

                    sx = StandardScaler()
                    sy = StandardScaler()
                    X_train_scaled = sx.fit_transform(X_train_sel)
                    X_test_scaled = sx.transform(X_test_sel)
                    y_train_scaled = sy.fit_transform(y_train_sel.reshape(-1, 1)).ravel()

                    def calcular_score(y_real, y_pred):
                        if funcion_selector.value == 'R2': return r2_score(y_real, y_pred)
                        elif funcion_selector.value == 'MSE': return mean_squared_error(y_real, y_pred)
                        elif funcion_selector.value == 'MAE': return mean_absolute_error(y_real, y_pred)
                        elif funcion_selector.value == 'RMSE': return np.sqrt(mean_squared_error(y_real, y_pred))
                        elif funcion_selector.value == 'MedAE': return median_absolute_error(y_real, y_pred)

                    def objetivo_optuna(trial):
                        C = trial.suggest_float('C', 1e-2, 1e3, log=True)
                        epsilon = trial.suggest_float('epsilon', 1e-4, 0.5, log=True)
                        kernel = trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly'])
                        degree = trial.suggest_int('degree', 2, 4) if kernel == 'poly' else 3

                        #C = trial.suggest_float('C', 0.1, 100, log=True)
                        #epsilon = trial.suggest_float('epsilon', 0.01, 1.0, log=True)
                        #kernel = trial.suggest_categorical('kernel', ['rbf', 'linear'])

                        #svr = SVR(C=C, epsilon=epsilon, kernel=kernel)

                        svr = SVR(C=C, epsilon=epsilon, kernel=kernel, degree=degree)
                        svr.fit(X_train_scaled, y_train_scaled)
                        y_pred = sy.inverse_transform(svr.predict(X_test_scaled).reshape(-1, 1)).ravel()
                        score = calcular_score(y_test_sel, y_pred)
                        return score if funcion_selector.value == 'R2' else -score

                    for motor in motores:
                        with traza:
                            print(f"‚öôÔ∏è Motor: {motor} ‚Üí Variables: {len(vars_x)} ‚Üí Datos: {X_train_scaled.shape}")

                        best_model = None

                        if motor == 'GridSearchCV':
                            grid = GridSearchCV(
                                SVR(),
#                                param_grid={
#                                    'C': [0.1, 1, 10, 100],
#                                    'epsilon': [0.01, 0.1, 0.5, 1],
#                                    'kernel': ['rbf', 'linear']
#                                },
                                param_grid= {
                                    'C': [0.01, 0.1, 1, 10, 100, 1000],
                                    'epsilon': [0.001, 0.01, 0.1, 0.5],
                                    'kernel': ['rbf', 'linear', 'poly'],
                                    'degree': [2, 3]  # solo si kernel = poly
                                },
                                scoring='r2', cv=3, n_jobs=-1
                            )
                            grid.fit(X_train_scaled, y_train_scaled)
                            best_model = grid.best_estimator_

                        elif motor == 'RandomizedSearchCV':
                            rand = RandomizedSearchCV(
                                SVR(),
#                                param_distributions={
#                                    'C': np.logspace(-1, 2, 20),
#                                    'epsilon': np.logspace(-2, 0, 20),
#                                    'kernel': ['rbf', 'linear']
#                                },
                                param_distributions={
                                    'C': stats.reciprocal(1e-2, 1e3),
                                    'epsilon': stats.reciprocal(1e-4, 0.5),
                                    'kernel': ['rbf', 'linear', 'poly'],
                                    'degree': stats.randint(2, 4)
                                },
                                scoring='r2', n_iter=30, cv=3, n_jobs=-1, random_state=42
                            )
                            rand.fit(X_train_scaled, y_train_scaled)
                            best_model = rand.best_estimator_

                        elif motor == 'Optuna':
                            study = optuna.create_study(direction='maximize' if funcion_selector.value == 'R2' else 'minimize')
                            study.optimize(objetivo_optuna, n_trials=30)
                            best_model = SVR(**study.best_params)
                            best_model.fit(X_train_scaled, y_train_scaled)

                        elif motor == 'BayesSearchCV':
                            bayes = BayesSearchCV(
                                SVR(),
#                                search_spaces={
#                                    'C': Real(0.1, 100, prior='log-uniform'),
#                                    'epsilon': Real(0.01, 1.0, prior='log-uniform'),
#                                    'kernel': Categorical(['rbf', 'linear'])
#                                },
                                search_spaces={
                                    'C': Real(1e-2, 1e3, prior='log-uniform'),
                                    'epsilon': Real(1e-4, 0.5, prior='log-uniform'),
                                    'kernel': Categorical(['rbf', 'linear', 'poly']),
                                    'degree': (2, 4)
                                },
                                scoring='r2', cv=3, n_iter=30, n_jobs=-1, random_state=42
                            )
                            bayes.fit(X_train_scaled, y_train_scaled)
                            best_model = bayes.best_estimator_

                        y_pred = sy.inverse_transform(best_model.predict(X_test_scaled).reshape(-1, 1)).ravel()
                        score = calcular_score(y_test_sel, y_pred)
                        mejores_modelos.append((f"{metodo} - {motor}", best_model, score, y_test_sel, y_pred))

                        with traza:
                            print(f"‚úÖ {metodo} [{motor}] ‚Üí {funcion_selector.value}: {score:.4f}")

                        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                        # ‚¨áÔ∏è  Bloque de Grabaci√≥n de resultados - persistencia
                        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                        try:
                            from pathlib import Path
                            import pickle

                            save_dir = Path("modelos_opt")
                            save_dir.mkdir(exist_ok=True)

                            modelo_fname = (
                                save_dir / f"modelo_svr_{metodo.lower()}_opt_{motor.lower()}.pkl"
                            )
                            study_fname = (
                                save_dir / f"optuna_svr_{metodo.lower()}_opt_{motor.lower()}.pkl"
                            )

                            # Obtener nombre Y de forma robusta
                            if isinstance(Y_train, pd.Series):
                                y_name = Y_train.name or "target"
                            else:  # DataFrame (una sola columna)
                                y_name = Y_train.columns[0] if Y_train.shape[1] == 1 else "target"

                            payload = {
                                "model":  best_model,
                                "sx":     sx,
                                "sy":     sy,
                                "cols":   vars_x,
                                "yname":  y_name,
                                "score":  score,
                                "metric": funcion_selector.value,
                            }

                            with open(modelo_fname, "wb") as f:
                                pickle.dump(payload, f)

                            study_fname = "optuna_study.pkl"   # nombre que espera la celda 10
                            if motor.lower() == "optuna" and "study" in locals():
                                with open(study_fname, "wb") as f:
                                    pickle.dump(study, f)
                                with traza: print(f"üìÅ Estudio Optuna guardado en: {study_fname}")

                            with traza: print(f"üíæ Modelo guardado en: {modelo_fname}")

                            # Registrar en un diccionario global opcional
                            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
                            OPT_MODELS[("svr", metodo.lower(), motor.lower())] = payload
                            if motor.lower() == "optuna" and "study" in locals():
                                OPT_MODELS[("svr", metodo.lower(), "optuna_study")] = study

                        except Exception as e:
                            with traza: print(f"‚ö†Ô∏è No se pudo guardar el modelo o estudio: {e}")
                        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                        # ‚¨ÜÔ∏è  FIN DEL BLOQUE DE PERSISTENCIA
                        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                except Exception as e:
                    with traza:
                        print(f"‚ùå Error al optimizar {metodo}: {e}")

            with salida_resultados:
                if mejores_modelos:
                    mejores_modelos.sort(key=lambda x: x[2], reverse=(funcion_selector.value == 'R2'))
                    top5 = mejores_modelos[:5]

                    df_top5 = pd.DataFrame([{
                        'M√©todo-Motor': m[0],
                        funcion_selector.value: round(m[2], 4),
                        'C': m[1].C,
                        'Epsilon': m[1].epsilon,
                        'Kernel': m[1].kernel
                    } for m in top5])

                    display(HTML("<h4 style='color:#2E8B57;'>üìä Top 5 Modelos Optimizado...</h4>"))
                    display(df_top5.style.set_caption("Top 5 configuraciones SVR")
                            .set_properties(**{'border': '1px solid gray', 'text-align': 'center'})
                            .set_table_styles([{'selector': 'th', 'props': [('background-color', '#2E8B57'), ('color', 'white')]}]))

                    mejor = top5[0]
                    metodo_motor, model, score, y_real, y_pred = mejor

                    display(HTML(f"""
                    <h4 style='color:green;'>üéØ Mejor configuraci√≥n encontrada:</h4>
                    <b>M√©todo:</b> {metodo_motor}<br>
                    <b>{funcion_selector.value}:</b> {score:.4f}
                    <hr>
                    <h4>üìã Detalle de Hiperpar√°metros:</h4>
                    """))

                    df_hp = pd.DataFrame({
                        'Par√°metro': ['C', 'epsilon', 'kernel'],
                        'Valor √ìptimo': [model.C, model.epsilon, model.kernel],
                        'Descripci√≥n': [
                            'Penalizaci√≥n del margen. Equilibra error y generalizaci√≥n',
                            'Zona de tolerancia sin penalizaci√≥n en el error',
                            'Funci√≥n que transforma el espacio (lineal o no lineal)'
                        ],
                        'Rango T√≠pico': ['0.1 ‚Äì 100', '0.01 ‚Äì 1.0', 'rbf / linear']
                    })

                    display(df_hp.style.set_table_styles([
                        {'selector': 'th', 'props': [('background-color', '#2E8B57'), ('color', 'white')]},
                        {'selector': 'td', 'props': [('text-align', 'center')]}
                    ]).set_properties(**{'border': '1px solid gray', 'padding': '6px'}))

                    plt.figure(figsize=(8, 5))
                    plt.plot(y_real, label='Real', marker='o')
                    plt.plot(y_pred, label='Predicci√≥n', marker='x')
                    plt.title(f'Y Real vs Y Predicho (Mejor SVR - {metodo_motor})')
                    plt.legend()
                    plt.grid()
                    plt.tight_layout()
                    plt.show()

                    # ===============================================================
                    # An√°lisis de Residuos del Mejor Modelo
                    # ===============================================================
                    residuos = y_real - y_pred

                    display(HTML("<h4 style='color:#2E8B57;'>üìâ An√°lisis de Residuos del Mejor Modelo</h4>"))
                    display(HTML("""
                    <p>Los <b>residuos</b> representan la diferencia entre los valores reales (observados) y los predichos por el modelo.
                    Evaluar su comportamiento ayuda a determinar si el modelo ha capturado correctamente la estructura de los datos.</p>
                    <ul>
                    <li><b>Residuos = Valor Real ‚Äì Valor Predicho</b></li>
                    <li>Distribuci√≥n sim√©trica centrada en cero es se√±al de buen ajuste</li>
                    <li>Asimetr√≠a, colas largas o concentraciones pueden indicar sobreajuste, variables omitidas u otros problemas.</li>
                    </ul>
                    """))

                    # Estad√≠sticas b√°sicas
                    res_stats = pd.DataFrame({
                        'M√©trica': ['Media', 'Desviaci√≥n est√°ndar', 'M√≠nimo', 'M√°ximo'],
                        'Valor': [np.mean(residuos), np.std(residuos), np.min(residuos), np.max(residuos)]
                    })
                    display(res_stats.style.set_caption("üìå Estad√≠sticas de los Residuos")
                            .set_properties(**{'border': '1px solid gray', 'text-align': 'center'})
                            .set_table_styles([{'selector': 'th', 'props': [('background-color', '#2E8B57'), ('color', 'white')]}]))

                    # Histograma de residuos
                    plt.figure(figsize=(8,4))
                    plt.hist(residuos, bins=25, color='skyblue', edgecolor='black')
                    plt.title('üìä Histograma de Residuos')
                    plt.xlabel('Residuo')
                    plt.ylabel('Frecuencia')
                    plt.grid(True)
                    plt.tight_layout()
                    plt.show()

                    # Gr√°fico Q-Q
                    plt.figure(figsize=(6, 6))
                    stats.probplot(residuos, dist="norm", plot=plt)
                    plt.title('üìà Gr√°fico Q-Q de los Residuos')
                    plt.grid(True)
                    plt.tight_layout()
                    plt.show()

                    # Test de normalidad de Shapiro-Wilk
                    residuos_validos = residuos[~np.isnan(residuos) & ~np.isinf(residuos)]

                    display(HTML("<h4>üìê Test de Normalidad (Shapiro-Wilk)</h4>"))

                    print(f"N√∫mero de residuos v√°lidos: {len(residuos_validos)}")
                    print("Primeros residuos v√°lidos:", residuos_validos[:10])

                    if residuos_validos.size >= 3:
                        try:
                            stat, p = shapiro(residuos_validos)
                            interpretacion = '‚úÖ Residuos normales (p > 0.05)' if p > 0.05 else '‚ö†Ô∏è Residuos no normales (p ‚â§ 0.05)'
                            display(HTML(f"""
                                <ul>
                                    <li><b>Estad√≠stico:</b> {stat:.4f}</li>
                                    <li><b>p-valor:</b> {p:.4f}</li>
                                    <li>{interpretacion}</li>
                                </ul>
                            """))
                        except Exception as e:
                            display(HTML(f"<span style='color:red;'>‚ùå Error al ejecutar el test de Shapiro: {e}</span>"))
                    else:
                        display(HTML("<span style='color:red;'>‚ùå No hay suficientes datos v√°lidos para realizar el test de normalidad.</span>"))

                    # ==========================================================
                    # üîç ANALISIS COMPARATIVO AVANZADO
                    # ==========================================================
                    # ============================================
                    # üìä CREACI√ìN DE DATAFRAME DE M√âTRICAS PARA COMPARATIVA
                    # ============================================
                    metricas_df = pd.DataFrame([
                        {
                            'Modelo': nombre,
                            'R2': r2_score(y_real, y_pred),
                            'MSE': mean_squared_error(y_real, y_pred),
                            'MAE': mean_absolute_error(y_real, y_pred),
                            'RMSE': np.sqrt(mean_squared_error(y_real, y_pred)),
                            'MedAE': median_absolute_error(y_real, y_pred)
                        }
                        for nombre, modelo, _, y_real, y_pred in top5
                    ])

                    # ============================================
                    # üî• MAPA DE CALOR DE M√âTRICAS
                    # ============================================
                    metricas_norm = (metricas_df.drop('Modelo', axis=1) - metricas_df.drop('Modelo', axis=1).min()) / (
                        metricas_df.drop('Modelo', axis=1).max() - metricas_df.drop('Modelo', axis=1).min())
                    plt.figure(figsize=(10, 5))
                    sns.heatmap(metricas_norm.T, annot=True, cmap='YlGnBu', xticklabels=metricas_df['Modelo'], fmt=".2f")
                    plt.title("üå°Ô∏è Mapa de Calor de M√©tricas Normalizadas")
                    plt.tight_layout()
                    plt.show()

                    # ============================================
                    # üéØ RADAR CHART DE M√âTRICAS
                    # ============================================
                    #import matplotlib.pyplot as plt
                    from math import pi

                    # Preparar datos
                    categorias = list(metricas_df.columns[1:])
                    N = len(categorias)
                    angles = [n / float(N) * 2 * pi for n in range(N)]
                    angles += angles[:1]

                    plt.figure(figsize=(8, 6))
                    for i in range(len(metricas_df)):
                        valores = metricas_df.iloc[i, 1:].values.flatten().tolist()
                        valores += valores[:1]
                        plt.polar(angles, valores, label=metricas_df.iloc[i, 0], marker='o')

                    plt.xticks(angles[:-1], categorias, color='grey', size=8)
                    plt.title("üéØ Radar Chart - Comparativa Multim√©trica")
                    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
                    plt.tight_layout()
                    plt.show()

                    # ===============================================================
                    # ACopiar resultados al portapapeles
                    # ===============================================================
                    btn_copiar = widgets.Button(description='üìã Copiar Hiperpar√°metros', button_style='info')
                    def copiar(_):
                        texto = str(model.get_params())
                        js = f"navigator.clipboard.writeText(`{texto}`)"
                        display(Javascript(js))
                        print("üìã Copiados al portapapeles.")
                    btn_copiar.on_click(copiar)
                    display(btn_copiar)

                else:
                    print("‚ö†Ô∏è No se encontr√≥ ninguna configuraci√≥n √≥ptima v√°lida.")

            progreso.value = f"‚è±Ô∏è Tiempo total de optimizaci√≥n: {time.time() - inicio:.2f} segundos"

        btn_ejecutar.on_click(ejecutar_optimizacion)

        display(widgets.VBox([
            metodo_selector,
            funcion_selector,
            motor_selector,
            btn_ejecutar,
            progreso,
            traza,
            salida_resultados
        ]))

# Artifact: exec exec_156
display(out_opt_svr)

# Artifact: exec exec_157
from ipywidgets import VBox, HBox, Dropdown, IntSlider, IntText, IntProgress, FloatSlider, SelectMultiple, Button, Output, HTML, Accordion

# Artifact: exec exec_158
from tensorflow import keras

# Artifact: exec exec_159
from tensorflow.keras import layers, regularizers

# Artifact: exec exec_160
from tensorflow.keras import mixed_precision

# Artifact: exec exec_161
mixed_precision.set_global_policy('mixed_float16')

# Artifact: exec exec_162
from tensorflow.keras.callbacks import EarlyStopping, Callback

# Artifact: class TimeStopping
class TimeStopping(Callback):
    """Detiene el entrenamiento si supera un tiempo m√°ximo (en segundos)."""
    def __init__(self, max_seconds=600):
        super().__init__()
        self.max_seconds = max_seconds

    def on_train_begin(self, logs=None):
        self.start_time = time.time()

    def on_epoch_end(self, epoch, logs=None):
        if time.time() - self.start_time > self.max_seconds:
            self.model.stop_training = True

# Artifact: exec exec_164
import signal

# Artifact: class TimeoutException
class TimeoutException(Exception):
    pass

# Artifact: function _timeout_handler
def _timeout_handler(signum, frame):
    raise TimeoutException()

# Artifact: exec exec_167
signal.signal(signal.SIGALRM, _timeout_handler)

# Artifact: class R2
class R2(tf.keras.metrics.Metric):
    def __init__(self, name='r2', **kwargs):
        super().__init__(name=name, **kwargs)
        self.sse = self.add_weight(name='sse', initializer='zeros')
        self.sst = self.add_weight(name='sst', initializer='zeros')
    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.cast(y_pred, tf.float32)
        resid = tf.reduce_sum(tf.square(y_true - y_pred))
        mean_true = tf.reduce_mean(y_true)
        sst_value = tf.reduce_sum(tf.square(y_true - mean_true))
        self.sse.assign_add(resid)
        self.sst.assign_add(sst_value)
    def result(self):
        return 1.0 - (self.sse / (self.sst + tf.keras.backend.epsilon()))
    def reset_states(self):
        self.sse.assign(0.0)
        self.sst.assign(0.0)

# Artifact: exec exec_169
from keras_tuner import RandomSearch, BayesianOptimization, Hyperband, Objective

# Artifact: assign ayuda_parametros
ayuda_parametros = HTML("""
<h4>üìò Explicaci√≥n de Par√°metros</h4>
<ul>
  <li><b>M√©todos X:</b> M√©todos de selecci√≥n de variables predictoras. Usan correlaciones estad√≠sticas o algoritmos de reducci√≥n de dimensi√≥n. <br>
      <i>Pearson</i> y <i>Spearman</i>: correlaciones lineales y mon√≥tonas.<br>
      <i>MutualInfo</i>: mide dependencia informacional. <br>
      <i>Boruta</i>: selecci√≥n envolvente basada en √°rboles. <br>
      <i>UMAP</i>: reducci√≥n no lineal de dimensiones. <br>
      <b>Todos</b> ejecuta cada uno secuencialmente.</li>
  <li><b>Motores:</b> Algoritmos de optimizaci√≥n de hiperpar√°metros. <br>
      <i>RandomSearch</i>: b√∫squeda aleatoria. <br>
      <i>BayesianOptimization</i>: estima regiones √≥ptimas. <br>
      <i>Hyperband</i>: eficiente para grandes espacios de b√∫squeda. <br>
      <i>Optuna</i>: flexible y potente. <br>
      <b>Todos</b> ejecuta todos los motores.</li>
  <li><b>Funci√≥n objetivo:</b> M√©trica a maximizar o minimizar: <br>
      <i>R2</i>: se desea maximizar. <i>MAE</i> y <i>MSE</i>: se minimizan.</li>
  <li><b>Trials:</b> N√∫mero de combinaciones a evaluar en la b√∫squeda.</li>
  <li><b>√âpocas:</b> Iteraciones completas sobre el dataset de entrenamiento (100 a 2000 recomendado).</li>
  <li><b>Capas:</b> Cantidad de capas ocultas en la red (1 a 20 habitual, m√°ximo 100 para pruebas avanzadas).</li>
  <li><b>Neuronas/capa:</b> N√∫mero de neuronas por capa (32 a 512 recomendado).</li>
  <li><b>Dropout:</b> Fracci√≥n de neuronas descartadas en entrenamiento (0.1 a 0.4 recomendado).</li>
  <li><b>L2 Reg:</b> Regularizaci√≥n L2 para evitar sobreajuste (0.001 a 0.01 habitual).</li>
</ul>
""")

# Artifact: assign select_metodos
select_metodos = SelectMultiple(
    options=['Pearson', 'Spearman', 'Mutualinfo', 'Boruta', 'UMAP', 'Todos'],
    description='M√©todos Selecci√≥n Variables X:',
    layout={'width': '50%'}
)

# Artifact: assign select_motores
select_motores = SelectMultiple(
    options=['RandomSearch', 'BayesianOptimization', 'Hyperband', 'Optuna', 'Todos'],
    description='Motores:',
    layout={'width': '50%'}
)

# Artifact: assign func_objetivo
func_objetivo = Dropdown(
    options=['R2', 'MAE', 'MSE'],
    value='R2',
    description='Funci√≥n objetivo:',
    layout={'width': '40%'}
)

# Artifact: assign n_trials_slider
n_trials_slider = IntSlider(value=10, min=1, max=50, step=1, description='Trials:')

# Artifact: assign rango_epocas
rango_epocas = IntSlider(value=500, min=1, max=200, step=10, description='√âpocas:')

# Artifact: assign rango_capas
rango_capas = IntSlider(value=3, min=1, max=6, step=1, description='Capas:')

# Artifact: assign rango_neuronas
rango_neuronas = IntSlider(value=64, min=256, max=512, step=8, description='Neuronas/capa:')

# Artifact: assign dropout_rate
dropout_rate = FloatSlider(value=0.2, min=0.0, max=0.7, step=0.05, description='Dropout:')

# Artifact: assign l2_reg
l2_reg = FloatSlider(value=0.001, min=0.0, max=0.01, step=0.0005, description='L2 Reg:')

# Artifact: assign btn_ejecutar
btn_ejecutar = Button(description='üöÄ Ejecutar Optimizaci√≥n NN', button_style='success')

# Artifact: assign progreso_bar
progreso_bar = IntProgress(min=0, max=1, description='Progreso:', style={'bar_color': 'green'})

# Artifact: assign out_nn
out_nn = Output()

# Artifact: function ejecutar_optimizacion
def ejecutar_optimizacion(_):
    with out_nn:
        clear_output()

        # 2) Ahora s√≠ puedo sanear columnas
        # Usar sanitize_name para limpiar columnas en el payload
        def clean_cols(col_list):
            return [sanitize_name(c) for c in col_list]
        # Ejemplo de sanitizaci√≥n de X_train antes de fit
        X_train.columns = [sanitize_name(col) for col in X_train.columns]
        X_test.columns = [sanitize_name(col) for col in X_test.columns]

        print("‚è≥ Iniciando optimizaci√≥n...")
        start_time = time.time()
        max_total_time = 6000   # 100 minutos en total para TODO el tuning
        resultados_modelos = []

        for metodo in select_metodos.value:
            print(f"üîç M√©todo: {metodo}")
            # Simulaci√≥n de filtrado de variables seg√∫n el m√©todo seleccionado
            X_train_sel, X_test_sel = X_train.copy(), X_test.copy()
            y_train_sel, y_test_sel = Y_train.copy(), Y_test.copy()

            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # Si el usuario marca ‚ÄúTodos‚Äù, reemplazamos esa opci√≥n
            motores = list(select_motores.value)
            if "Todos" in motores:
                motores = ["RandomSearch", "BayesianOptimization", "Hyperband", "Optuna"]
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError
            #from tensorflow_addons.metrics import RSquare  # si lo tienes instalado

            #for motor in select_motores.value:
            for motor in motores:
                print(f"‚öôÔ∏è Motor: {motor}")

                # ‚Äî‚Äî‚Äî A√ëADIDO: tope global de tiempo ‚Äî‚Äî‚Äî
                # 1. Chequeo de tiempo PARA ESTE motor
                elapsed = time.time() - start_time
                if elapsed > max_total_time:
                    print(f"‚èπÔ∏è Tiempo agotado antes de {motor} en {metodo}; sigo con el siguiente m√©todo.")
                    break   # solo sale del bucle 'motor'
                # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî

                metric_name = func_objetivo.value.lower()
                direction = 'max' if metric_name == 'r2' else 'min'
                # Ahora monitorizamos la m√©trica de validaci√≥n correcta:
                tuner_metric = f"val_{metric_name}"                 # 'val_r2', 'val_mae' o 'val_mse'

                #tuner_metric = 'val_loss' if metric_name == 'r2' else metric_name
                #tuner_metric = 'val_r2'   if metric_name=='r2' else f'val_{metric_name}'

                def build_model(hp):
                    model = keras.Sequential()
                    model.add(layers.Input(shape=(X_train_sel.shape[1],)))
                    for i in range(hp.Int('layers', 1, rango_capas.max)):
                        model.add(layers.Dense(hp.Int(f'units_{i}', 8, rango_neuronas.max), activation='relu'))
                        model.add(layers.Dropout(hp.Float(f'dropout_{i}', 0.0, dropout_rate.max)))
                    model.add(layers.Dense(1))
                    #model.compile(optimizer='adam', loss='mse')
                    model.compile(
                        optimizer='adam',
                        loss='mse',
                        metrics=[R2(name='r2'),
                                tf.keras.metrics.MeanSquaredError(name='mse'),
                                tf.keras.metrics.MeanAbsoluteError(name='mae')]
                    )
                    return model

                #callbacks = [EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]
                # ‚Äî‚Äî‚Äî A√ëADIDO: EarlyStopping con min_delta + TimeStopping ‚Äî‚Äî‚Äî
                callbacks = [
                    EarlyStopping(
                        monitor=tuner_metric,      # mejorar seg√∫n la m√©trica que toque
                        mode = 'max' if metric_name == 'r2' else 'min',
                        min_delta=1e-1,            # mejora m√≠nima del 10%
                        patience=3,               # si no mejora tras 3 √©pocas, cortar
                        restore_best_weights=True
                    ),
                    TimeStopping(max_seconds=120)  # tope de 120 s (~2 min) por modelo
                ]
                # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî

                # Eliminar directorios previos si existen
                if motor == 'RandomSearch':
                    tuner_dir = f'randomsearch_dir/random_{metodo}'
                    if os.path.exists(tuner_dir):
                        shutil.rmtree(tuner_dir)
                    tuner = RandomSearch(
                        build_model,
                        objective=Objective(tuner_metric, direction=direction),
                        max_trials=n_trials_slider.value,
                        executions_per_trial=1,
                        directory='randomsearch_dir',
                        project_name=f'random_{metodo}'
                    )
                    #tuner.search(X_train_sel, y_train_sel, epochs=rango_epocas.value, validation_split=0.2, verbose=1, callbacks=callbacks)
                    # ‚Äî‚Äî‚Äî A√ëADIDO: timeout para este tuner ‚Äî‚Äî‚Äî
                    remaining = max_total_time - (time.time() - start_time)
                    # no menos de 1 segundo
                    timeout_secs = int(max(1, remaining))
                    signal.alarm(timeout_secs)
                    try:
                        tuner.search(
                          X_train_sel, y_train_sel,
                          epochs=rango_epocas.value,
                          validation_split=0.2,
                          verbose=1,
                          callbacks=callbacks
                        )
                    except TimeoutException:
                        print(f"‚èπÔ∏è RandomSearch ({metodo}) interrumpido tras {timeout_secs}s")
                    finally:
                        signal.alarm(0)
                  # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî
                    best_hps = tuner.get_best_hyperparameters(1)[0]

                elif motor == 'BayesianOptimization':
                    tuner_dir = f'bo_dir/bo_{metodo}'
                    if os.path.exists(tuner_dir):
                        shutil.rmtree(tuner_dir)
                    tuner = BayesianOptimization(
                        build_model,
                        objective=Objective(tuner_metric, direction=direction),
                        max_trials=n_trials_slider.value,
                        directory='bo_dir',
                        project_name=f'bo_{metodo}'
                    )
                    #tuner.search(X_train_sel, y_train_sel, epochs=rango_epocas.value, validation_split=0.2, verbose=1, callbacks=callbacks)
                    # ‚Äî‚Äî‚Äî A√ëADIDO: timeout para este tuner ‚Äî‚Äî‚Äî
                    remaining = max_total_time - (time.time() - start_time)
                    # no menos de 1 segundo
                    timeout_secs = int(max(1, remaining))
                    signal.alarm(timeout_secs)
                    try:
                        tuner.search(
                           X_train_sel, y_train_sel,
                           epochs=rango_epocas.value,
                           validation_split=0.2,
                           verbose=1,
                           callbacks=callbacks
                        )
                    except TimeoutException:
                        print(f"‚èπÔ∏è RandomSearch ({metodo}) interrumpido tras {timeout_secs}s")
                    finally:
                        signal.alarm(0)
                    # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî
                    best_hps = tuner.get_best_hyperparameters(1)[0]

                elif motor == 'Hyperband':
                    tuner_dir = f'hyperband_dir/hyper_{metodo}'
                    if os.path.exists(tuner_dir):
                        shutil.rmtree(tuner_dir)
                    tuner = Hyperband(
                        build_model,
                        objective=Objective(tuner_metric, direction=direction),
                        #max_epochs=rango_epocas.max,
                        max_epochs=rango_epocas.value,
                        factor=4,                         # ‚Üê de 2 a 4 ‚áí menos brackets
                        directory='hyperband_dir',
                        project_name=f'hyper_{metodo}'
                    )
                    # ‚îÄ‚îÄ‚îÄ A√ëADIDO AQU√ç: callbacks espec√≠ficos para Hyperband ‚îÄ‚îÄ‚îÄ
                    callbacks = [
                        EarlyStopping(
                            monitor=tuner_metric,
                            mode = 'max' if metric_name == 'r2' else 'min',  # <‚Äî aqu√≠ le decimos a Keras qu√© queremos
                            min_delta=1e-2,
                            patience=2,
                            restore_best_weights=True
                        ),
                        TimeStopping(max_seconds=120)
                    ]
                    # ‚îÄ‚îÄ‚îÄ FIN A√ëADIDO ‚îÄ‚îÄ‚îÄ

                    #tuner.search(X_train_sel, y_train_sel, validation_split=0.2, verbose=1, callbacks=callbacks)
                    #tuner.search(X_train_sel, y_train_sel, epochs=rango_epocas.value, validation_split=0.2, verbose=1, callbacks=callbacks)

                    # ‚Äî‚Äî‚Äî A√ëADIDO: timeout para este tuner ‚Äî‚Äî‚Äî
                    remaining = max_total_time - (time.time() - start_time)
                    # no menos de 1 segundo
                    timeout_secs = int(max(1, remaining))
                    signal.alarm(timeout_secs)
                    try:
                        tuner.search(
                           X_train_sel, y_train_sel,
                           epochs=rango_epocas.value,
                           validation_split=0.2,
                           verbose=1,
                           callbacks=callbacks
                        )
                    except TimeoutException:
                        print(f"‚èπÔ∏è RandomSearch ({metodo}) interrumpido tras {timeout_secs}s")
                    finally:
                        signal.alarm(0)
                    # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî
                    best_hps = tuner.get_best_hyperparameters(1)[0]

                elif motor == 'Optuna':
                    def objective(trial):
                        model = keras.Sequential()
                        model.add(layers.Input(shape=(X_train_sel.shape[1],)))
                        for i in range(trial.suggest_int('n_layers', 1, rango_capas.max)):
                            model.add(layers.Dense(trial.suggest_int(f'n_units_l{i}', 8, rango_neuronas.max), activation='relu'))
                            model.add(layers.Dropout(trial.suggest_float(f'dropout_l{i}', 0.0, dropout_rate.max)))
                        model.add(layers.Dense(1))
                        model.compile(optimizer='adam', loss='mse')
                        #model.fit(X_train_sel, y_train_sel, epochs=rango_epocas.value, batch_size=32, verbose=0, validation_split=0.2)
                        model.fit(X_train_sel, y_train_sel, epochs=rango_epocas.value, batch_size=32, verbose=1, validation_split=0.2, callbacks=callbacks)
                        preds = model.predict(X_test_sel).ravel()
                        return -r2_score(y_test_sel, preds) if func_objetivo.value == 'R2' else mean_absolute_error(y_test_sel, preds)

                    direction = 'maximize' if func_objetivo.value == 'R2' else 'minimize'

                    #study = optuna.create_study(direction=direction)
                    # ‚Äî‚Äî‚Äî A√ëADIDO: Pruner para cortar trials poco prometedores ‚Äî‚Äî‚Äî
                    from optuna.pruners import MedianPruner
                    remaining = max_total_time - (time.time() - start_time)
                    if remaining <= 0:
                        print("‚èπÔ∏è Ya no queda tiempo para Optuna.")
                        continue

                    study = optuna.create_study(direction=direction,
                                              pruner=MedianPruner(n_startup_trials=3, n_warmup_steps=10))
                    # timeout detiene el optimize tras X segundos, sin esperar a n_trials
                    study.optimize(objective,
                                  n_trials=n_trials_slider.value,
                                  timeout=remaining)
                    # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî
                    #study.optimize(objective, n_trials=n_trials_slider.value)

                    best_params = study.best_params

                progreso_bar.value += 1
                print(f"‚úÖ Completado: M√©todo {metodo}, Motor {motor}")
                print(f"‚úÖ Optimizaci√≥n completada en {time.time() - start_time:.2f} segundos.")

                # Placeholder para evaluaci√≥n final
                model = keras.Sequential()
                model.add(layers.Input(shape=(X_train_sel.shape[1],)))
                for _ in range(rango_capas.value):
                    model.add(layers.Dense(rango_neuronas.value, activation='relu'))
                    model.add(layers.Dropout(dropout_rate.value))
                model.add(layers.Dense(1))
                model.compile(optimizer='adam', loss='mse')
                model.fit(X_train_sel, y_train_sel, epochs=rango_epocas.value, batch_size=32, verbose=0, callbacks=callbacks)

                y_pred = model.predict(X_test_sel).ravel()
                r2 = r2_score(y_test_sel, y_pred)
                mae = mean_absolute_error(y_test_sel, y_pred)
                mse = mean_squared_error(y_test_sel, y_pred)

                # *********************************************************
                # Visualizaci√≥n del modelo optimizado
                # *********************************************************
                fig, ax = plt.subplots(figsize=(6, 4))
                ax.scatter(range(len(y_pred)), y_test_sel.values.ravel(), label='Y Real')
                ax.plot(range(len(y_pred)), y_pred, color='orange', label='Y Predicho')
                ax.set_title(f"XY-Y Real vs. Predicho: {metodo}-{motor}")
                ax.set_xlabel("Casos")
                ax.set_ylabel("Y")
                ax.legend()
                ax.grid(True)
                plt.tight_layout()
                plt.show()

                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                # üîí  BLOQUE DE PERSISTENCIA  (NO ALTERA LA L√ìGICA EXISTENTE)
                #     ¬∑ Guarda el mejor modelo de cada motor en /modelos_opt
                #     ¬∑ Guarda escaladores y columnas en un .pkl auxiliar
                #     ¬∑ Guarda el study de Optuna, si existe
                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                try:
                    from pathlib import Path
                    import pickle

                    # 1Ô∏è‚É£  M√©trica que queremos persistir como ¬´score¬ª
                    if func_objetivo.value == "R2":
                        score_val = r2
                    elif func_objetivo.value == "MAE":
                        score_val = mae
                    else:                                 # "MSE"
                        score_val = mse

                    # ---------- rutas ----------
                    save_dir = Path("modelos_opt")
                    save_dir.mkdir(exist_ok=True)

                    # nombre robusto variable-objetivo
                    if isinstance(Y_train, pd.Series):
                        y_name = Y_train.name or "target"
                    else:                                # DataFrame
                        y_name = Y_train.columns[0] if Y_train.shape[1] == 1 else "target"

                    base_fname  = f"nn_{metodo.lower()}_opt_{motor.lower()}"
                    model_fname = save_dir / f"modelo_{base_fname}.h5"          # modelo
                    meta_fname  = save_dir / f"meta_{base_fname}.pkl"           # metadatos
                    study_fname = save_dir / f"optuna_{base_fname}.pkl"         # estudio Optuna

                    # ---------- modelo ----------
                    model_to_save = model                # alias universal
                    model_to_save.save(model_fname, include_optimizer=True)

                    best_hps_dict = {}
                    if motor in ("RandomSearch","BayesianOptimization","Hyperband"):
                        # para Keras Tuner:
                        best_hps = tuner.get_best_hyperparameters(1)[0]
                        best_hps_dict = {
                          "layers":  best_hps.get("layers"),
                          "neurons": best_hps.get("units_0"),
                          "dropout": best_hps.get("dropout_0"),
                          "epochs":  rango_epocas.value
                        }
                    elif motor == "Optuna":
                        # Optuna:
                        best_hps_dict = study.best_params.copy()
                        best_hps_dict["epochs"] = rango_epocas.value

                    # Comprobaci√≥n de scalers
                    if 'sx' not in locals():
                        sx = None
                    if 'sy' not in locals():
                        sy = None

                    # Extrae los hiperpar√°metros relevantes asegurando ambos nombres
                    # (esto funciona tanto para Optuna como KerasTuner)
                    layers_ = best_hps_dict.get("layers") or best_hps_dict.get("n_layers")
                    neurons_ = best_hps_dict.get("neurons") or best_hps_dict.get("n_units_l0")
                    dropout_ = best_hps_dict.get("dropout") or best_hps_dict.get("dropout_l0")
                    epochs_ = best_hps_dict.get("epochs")

                    meta_payload = {
                        "sx":    locals().get("sx", None),
                        "sy":    locals().get("sy", None),
                        "cols":  X_train_sel.columns.tolist(),
                        "yname": y_name,
                        "score": float(score_val),
                        "metric": func_objetivo.value,
                        "motor": motor,
                        "metodo": metodo,
                        # Nombres duplicados para compatibilidad m√°xima
                        "layers": layers_,
                        "n_layers": layers_,
                        "neurons": neurons_,
                        "n_units_l0": neurons_,
                        "dropout": dropout_,
                        "dropout_l0": dropout_,
                        "epochs": epochs_,
                        **{k: v for k, v in best_hps_dict.items() if k not in ["layers", "n_layers", "neurons", "n_units_l0", "dropout", "dropout_l0", "epochs"]}
                    }

                    with open(meta_fname, "wb") as f_meta:
                        pickle.dump(meta_payload, f_meta)

                    # ---------- Optuna ----------
                    msg_opt = ""
                    if motor == "Optuna" and "study" in locals():
                        with open(study_fname, "wb") as f_st:
                            pickle.dump(study, f_st)
                        msg_opt = f" ¬∑ Estudio guardado ‚Üí {study_fname}"

                    # ---------- feedback ----------
                    try:                                        # usa traza si existe
                        with traza:
                            print(f"üíæ Modelo guardado ‚Üí {model_fname}")
                            print(f"üóÇÔ∏è  Metadatos     ‚Üí {meta_fname}{msg_opt}")
                    except NameError:
                        print(f"üíæ Modelo guardado ‚Üí {model_fname}")
                        print(f"üóÇÔ∏è  Metadatos     ‚Üí {meta_fname}{msg_opt}")

                    # ---------- registro global opcional ----------
                    OPT_MODELS = globals().setdefault("OPT_MODELS", {})
                    OPT_MODELS[("nn", metodo.lower(), motor.lower())] = {
                        # 1Ô∏è‚É£ rutas de fichero obligatorias
                        "model_path":  str(model_fname),
                        "meta_path":   str(meta_fname),
                        # guardamos el propio objeto (o su path si prefieres)
                        "model":       model_to_save,
                        # escaladores
                        "sx":          sx,
                        "sy":          sy,
                        # columnas utilizadas
                        "cols":        X_train_sel.columns.tolist(),
                        # m√©trica y score
                        "metric":      func_objetivo.value,
                        "score":       float(score_val),
                        # metadatos de optimizaci√≥n
                        "motor":       motor,
                        "metodo":      metodo,
                        # hiperpar√°metros, duplicados para compat
                        "layers":      layers_,
                        "n_layers":    layers_,
                        "neurons":     neurons_,
                        "n_units_l0":  neurons_,
                        "dropout":     dropout_,
                        "dropout_l0":  dropout_,
                        "epochs":      epochs_,
                        # cualquier otro par√°metro de best_hps_dict
                        **{k: v for k, v in best_hps_dict.items()
                            if k not in {"layers","neurons","dropout","epochs"}}
                    }

                    if motor == "Optuna" and "study" in locals():
                        OPT_MODELS[("nn", metodo.lower(), "optuna_study")] = study

                except Exception as e:
                    # si algo falla, avisa pero NO interrumpe la optimizaci√≥n
                    try:
                        with traza:
                            print(f"‚ö†Ô∏è  No se pudo guardar el modelo o estudio: {e}")
                    except NameError:
                        print(f"‚ö†Ô∏è  No se pudo guardar el modelo o estudio: {e}")
                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                # üîö  FIN BLOQUE DE PERSISTENCIA
                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

                resultados_modelos.append({
                    'Motor': motor, 'M√©todo': metodo,
                    'R2': r2, 'MAE': mae, 'MSE': mse,
                    '√âpocas': rango_epocas.value,
                    'Capas': rango_capas.value,
                    'Neuronas': rango_neuronas.value,
                    'Dropout': dropout_rate.value,
                    'L2': l2_reg.value
                })

            # tras bucle motores, chequeo global de tiempo  # MODIFICADO
            if time.time() - start_time > max_total_time:
                print("‚èπÔ∏è Tiempo total agotado; salgo de m√©todos.")
                break  # rompe bucle m√©todos

        global df_results
        df_results = pd.DataFrame(resultados_modelos)
        df_top5 = df_results.sort_values(by=func_objetivo.value, ascending=(func_objetivo.value != 'R2')).head(5)
        best = df_top5.iloc[0]

        display(HTML("<h4>üèÜ Top 5 Modelos Optim.</h4>"))
        display(df_top5.style.set_caption("Modelos √ìptimos").format(precision=4))

        y_pred = model.predict(X_test_sel).ravel()
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.scatter(y_test_sel, y_pred, alpha=0.6)
        ax.plot([y_test_sel.min(), y_test_sel.max()], [y_test_sel.min(), y_test_sel.max()], 'r--')
        ax.set_title("Y Real vs. Y Predicho")
        ax.set_xlabel("Y Real")
        ax.set_ylabel("Y Predicho")
        plt.grid(True)
        plt.show()

        #residuos = y_test_sel - y_pred
        residuos = y_test_sel.values.ravel() - y_pred
        plt.figure(figsize=(6, 4))
        plt.scatter(y_pred, residuos, alpha=0.6)
        plt.axhline(0, color='red', linestyle='--')
        plt.title("Residuos vs. Predicci√≥n")
        plt.xlabel("Y Predicho")
        plt.ylabel("Residuos")
        plt.grid(True)
        plt.show()

        stat, p_value = shapiro(residuos)
        display(HTML(f"<b>üìä Test de Shapiro:</b> p = {p_value:.5f} ‚Üí {'Normal' if p_value > 0.05 else 'No normal'}"))

        from math import pi
        categorias = ['R2', 'MAE', 'MSE']
        valores = [best['R2'], best['MAE'], best['MSE']]
        valores += valores[:1]
        angles = [n / float(len(categorias)) * 2 * pi for n in range(len(categorias))]
        angles += angles[:1]
        plt.figure(figsize=(6, 6))
        ax = plt.subplot(111, polar=True)
        plt.xticks(angles[:-1], categorias)
        ax.plot(angles, valores, linewidth=2)
        ax.fill(angles, valores, alpha=0.3)
        plt.title("Radar de M√©tricas")
        plt.show()

        global NN_RESULTADOS_TOP5, NN_MEJOR_MODELO, NN_RESIDUOS, NN_METODO_MEJOR, NN_MOTOR_MEJOR
        NN_RESULTADOS_TOP5 = df_top5
        NN_MEJOR_MODELO = best
        NN_RESIDUOS = residuos
        NN_METODO_MEJOR = best['M√©todo']
        NN_MOTOR_MEJOR = best['Motor']

# ***********************************************************************
# Visualizaci√≥n de los mejores modelos optimizados
# ***********************************************************************
        for idx, row in df_top5.iterrows():
            metodo, motor = row['M√©todo'], row['Motor']
            model = keras.Sequential()
            model.add(layers.Input(shape=(X_train_sel.shape[1],)))
            for _ in range(int(row['Capas'])):
                model.add(layers.Dense(int(row['Neuronas']), activation='relu'))
                model.add(layers.Dropout(row['Dropout']))
            model.add(layers.Dense(1))
            model.compile(optimizer='adam', loss='mse')
            model.fit(X_train_sel, y_train_sel, epochs=rango_epocas.value, batch_size=32, verbose=0, callbacks=callbacks)

            y_pred = model.predict(X_test_sel).ravel()
            fig, ax = plt.subplots(figsize=(6, 4))
            ax.scatter(range(len(y_pred)), y_test_sel.values.ravel(), label='Y Real')
            ax.plot(range(len(y_pred)), y_pred, color='orange', label='Y Predicho')
            ax.set_title(f"XY-Y Real vs. Predicho: {metodo}-{motor}")
            ax.set_xlabel("Casos")
            ax.set_ylabel("Y")
            ax.legend()
            ax.grid(True)
            plt.tight_layout()
            plt.show()

        print(f"‚úÖ Optimizaci√≥n completada en {time.time() - start_time:.2f} segundos.")

# Artifact: assign control_panel
control_panel = VBox([
    HTML("<h3>üîß Configuraci√≥n Optimizaci√≥n NN</h3>"),
    ayuda_parametros,
    HBox([select_metodos, select_motores]),
    func_objetivo,
    n_trials_slider,
    HBox([rango_epocas, rango_capas]),
    HBox([rango_neuronas, dropout_rate, l2_reg]),
    btn_ejecutar,
    progreso_bar,
    out_nn
])

# Artifact: function mostrar_optimizacion_nn
def mostrar_optimizacion_nn():
    display(control_panel)

# Artifact: exec exec_186
try:
    btn_ejecutar._click_handlers.callbacks.clear()
except:
    pass

# Artifact: exec exec_187
btn_ejecutar.on_click(ejecutar_optimizacion)

# Artifact: function mostrar_optimizacion_xgb
def mostrar_optimizacion_xgb():
    from IPython.display import display, HTML, clear_output
    import pandas as pd
    import ipywidgets as widgets
    import traceback
    import matplotlib.pyplot as plt
    import seaborn as sns
    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
    from sklearn.model_selection import RandomizedSearchCV
    from xgboost import XGBRegressor
    import numpy as np
    from skopt import BayesSearchCV  # Motor de optimizaci√≥n bayesiano
    # Importar Hyperband
    from sklearn.experimental import enable_halving_search_cv  # noqa
    from sklearn.model_selection import HalvingRandomSearchCV
    # Importar Optuna
    from optuna.integration import OptunaSearchCV
    import optuna
    optuna.logging.set_verbosity(optuna.logging.INFO)
    from optuna.distributions import IntDistribution, FloatDistribution

    # Mostrar progreso en RandomSearch mediante logging
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    global out_opt_xgb, traza_xgb
    out_opt_xgb   = widgets.Output()      # panel principal
    traza_xgb     = widgets.Output()      # trazas de cada motor

    # ========= A√ëADIDOS: Funciones de saneamiento =========

    # 2) Ahora s√≠ puedo sanear columnas
    # Usar sanitize_name para limpiar columnas en el payload
    def clean_cols(col_list):
        return [sanitize_name(c) for c in col_list]
    # Ejemplo de sanitizaci√≥n de X_train antes de fit
    X_train.columns = [sanitize_name(col) for col in X_train.columns]
    X_test.columns = [sanitize_name(col) for col in X_test.columns]

    # ‚Äî‚Äî‚Äî SANITIZAR LISTAS DE RESUMEN_METODOS ‚Äî‚Äî‚Äî
    for metodo, vars_ in RESUMEN_METODOS.items():
        if isinstance(vars_, list):
            RESUMEN_METODOS[metodo] = [sanitize_name(v) for v in vars_]
        elif isinstance(vars_, pd.DataFrame) and not vars_.empty:
            # asumimos que la columna de variable se llama "Variable" o la primera
            col = 'Variable' if 'Variable' in vars_.columns else vars_.columns[0]
            # saneamos esa columna in‚Äëplace
            RESUMEN_METODOS[metodo][col] = vars_[col].astype(str).map(sanitize_name)
    # ‚Äî‚Äî‚Äî FIN SANITIZACI√ìN RESUMEN_METODOS ‚Äî‚Äî‚Äî

    #import re

    #def clean_columns(df):
    #    """
    #    Transforma todos los nombres de columna a str y sustituye
    #    corchetes, %, <, > y espacios por guiones bajos.
    #    """
    #    df = df.copy()
    #    df.columns = (
    #        df.columns
    #          .astype(str)
    #          .str.replace(r'[\[\]<>%]', '_', regex=True)
    #          .str.replace(r'\s+', '_', regex=True)
    #          .str.strip('_')
    #    )
    #    return df

    #def clean_cols(var_list):
    #    """
    #    Limpia una lista de nombres de columna con las mismas reglas.
    #    """
    #    return [
    #        re.sub(r'[\[\]<>%]', '_', str(v))
    #          .replace(' ', '_')
    #          .strip('_')
    #        for v in var_list
    #    ]

    # ======================================================

    # üìå Par√°metros configurables del motor de optimizaci√≥n
    slider_n_iter = widgets.IntSlider(value=50, min=10, max=300, step=10,
                                      description='n_iter:', layout=widgets.Layout(width='45%'))
    ayuda_n_iter = widgets.HTML("<small><b>n_iter:</b> n√∫mero de combinaciones aleatorias a probar (mayor = m√°s preciso, pero m√°s lento). No aplica a  Hyperbrand.</small>")

    slider_cv = widgets.IntSlider(value=3, min=2, max=10, step=1,
                                  description='cv:', layout=widgets.Layout(width='45%'))
    ayuda_cv = widgets.HTML("<small><b>cv:</b> n√∫mero de particiones para validaci√≥n cruzada (m√≠nimo 2)</small>")

    selector_funcion_objetivo = widgets.Dropdown(
        options=['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'],
        value='r2',
        description='Funci√≥n:',
        layout=widgets.Layout(width='45%')
    )
    ayuda_funcion = widgets.HTML("<small><b>Funci√≥n:</b> m√©trica a optimizar. R2 para ajuste, MSE o MAE para error</small>")

    def seleccionar_variables_filtradas(metodo):
        global X_train, Y_train, X_test, RESUMEN_METODOS

        # --- A√ëADIDO: sanear columnas globales antes de todo ---
        #X_train = clean_columns(X_train)
        #X_test  = clean_columns(X_test)
        # --- FIN A√ëADIDO -----------------------------------------

        print(f"\nüîß [seleccionar_variables_filtradas] Iniciando con m√©todo: '{metodo}'")
        try:
            assert 'X_train' in globals(), "‚ùå 'X_train' no est√° definido"
            assert 'Y_train' in globals(), "‚ùå 'Y_train' no est√° definido"
            assert 'RESUMEN_METODOS' in globals(), "‚ùå 'RESUMEN_METODOS' no est√° definido"

            vars_sel = []
            if metodo.strip().lower() == "todos":
                all_vars = []
                for k, df in RESUMEN_METODOS.items():
                    if isinstance(df, list):
                        all_vars.extend(df)
                    elif isinstance(df, pd.DataFrame) and not df.empty:
                        col = 'Variable' if 'Variable' in df.columns else df.columns[0]
                        all_vars.extend(df[col].dropna().tolist())
                vars_sel = list(set(all_vars))
            elif metodo in RESUMEN_METODOS:
                df_vars = RESUMEN_METODOS[metodo]
                if isinstance(df_vars, list):
                    vars_sel = df_vars
                elif isinstance(df_vars, pd.DataFrame):
                    if not df_vars.empty:
                        col = 'Variable' if 'Variable' in df_vars.columns else df_vars.columns[0]
                        vars_sel = df_vars[col].dropna().tolist()
                    else:
                        return
                else:
                    return
            else:
                return
            if not vars_sel:
                return

            columnas_faltantes = [col for col in vars_sel if col not in X_train.columns]
            if columnas_faltantes:
                print(f"‚ùå Columnas no existentes en X_train: {columnas_faltantes}")
                return


        #    # ‚Äî‚Äî‚Äî A√ëADIDO: obtener y limpiar lista raw_vars ‚Äî‚Äî‚Äî
        #    raw_vars = []
        #    if metodo.strip().lower() == "todos":
        #        all_vars = []
        #        for df in RESUMEN_METODOS.values():
        #            if isinstance(df, list):
        #                all_vars += df
        #            elif isinstance(df, pd.DataFrame) and not df.empty:
        #                col = 'Variable' if 'Variable' in df.columns else df.columns[0]
        #                all_vars += df[col].dropna().tolist()
        #        raw_vars = list(set(all_vars))
        #    elif metodo in RESUMEN_METODOS:
        #        df_vars = RESUMEN_METODOS[metodo]
        #        if isinstance(df_vars, list):
        #            raw_vars = df_vars
        #        elif isinstance(df_vars, pd.DataFrame) and not df_vars.empty:
        #            col = 'Variable' if 'Variable' in df_vars.columns else df_vars.columns[0]
        #            raw_vars = df_vars[col].dropna().tolist()
        #    else:
        #        return

        #    if not raw_vars:
        #        with traza_xgb:
        #            print(f"‚ö†Ô∏è No hay variables para '{metodo}'.")
        #        return

            # limpiar lista de nombres
        #    vars_sel = clean_cols(raw_vars)

        #    # comprobar que existen tras limpiar
        #    faltantes = [c for c in vars_sel if c not in X_train.columns]
        #    if faltantes:
        #        with traza_xgb:
        #            print(f"‚ùå Columnas no existentes en X_train: {faltantes}")
        #        return
        #    # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî

            X_sel = X_train[vars_sel].copy()
            Y_sel = Y_train.copy()
            globals()['X_train_filtrado'] = X_sel
            globals()['Y_train_filtrado'] = Y_sel
            globals()['metodo_usado_xgb'] = metodo

        except Exception as e:
            print("‚ùå Excepci√≥n atrapada desde consola principal:")
            print(traceback.format_exc())

    def ejecutar_metricas_finales(modelo, nombre_motor="Desconocido"):
        try:
            X_test_filtrado = X_test[X_train_filtrado.columns]
            preds = best_model.predict(X_test_filtrado)

            r2 = r2_score(Y_test, preds)
            mse = mean_squared_error(Y_test, preds)
            mae = mean_absolute_error(Y_test, preds)

            df_metricas = pd.DataFrame({
                'M√©trica': ['R2', 'MSE', 'MAE'],
                'Valor': [r2, mse, mae]
            })
            display(df_metricas.style.set_caption("üìà Rendimiento del Modelo √ìptimo").format(precision=4))

            # C√°lculo de residuos y an√°lisis
            residuos = Y_test.values.ravel() - preds.ravel()
            df_residuos = pd.DataFrame({
                '√çndice': range(len(residuos)),
                'Y_real': Y_test.values.ravel(),
                'Y_predicho': preds.ravel(),
                'Residuo': residuos
            })
            display(df_residuos.head().style.set_caption("üßÆ Ejemplo de C√°lculo de Residuos"))

            # Histograma de residuos
            plt.figure(figsize=(6, 4))
            sns.histplot(residuos, bins=30, kde=True, color='skyblue')
            plt.axvline(0, color='red', linestyle='--')
            plt.title("Histograma de Residuos")
            plt.xlabel("Residuo (Y_real - Y_predicho)")
            plt.ylabel("Frecuencia")
            plt.show()

            # üìå Prueba de normalidad de Shapiro-Wilk
            stat, p_value = shapiro(residuos)
            display(HTML(f"<h4>üß™ Prueba de Normalidad (Shapiro-Wilk)</h4><ul><li>Estad√≠stico: {stat:.4f}</li><li>p-valor: {p_value:.4f}</li><li>{'‚úÖ Los residuos siguen una distribuci√≥n normal (p > 0.05)' if p_value > 0.05 else '‚ö†Ô∏è Los residuos no siguen una distribuci√≥n normal (p ‚â§ 0.05)'}</li></ul>"))

            # Explicaci√≥n de los resultados
            display(HTML("""
                <h4>üßæ Explicaci√≥n de Resultados:</h4>
                <ul>
                    <li><b>R2:</b> mide el grado de ajuste del modelo. Valores cercanos a 1 indican buen ajuste.</li>
                    <li><b>MSE:</b> error cuadr√°tico medio. Penaliza m√°s los errores grandes.</li>
                    <li><b>MAE:</b> error absoluto medio. M√°s robusto ante valores at√≠picos.</li>
                    <li><b>Residuos:</b> diferencia entre el valor real y el predicho. Deben estar centrados en 0.</li>
                    <li><b>Histograma:</b> ayuda a evaluar si los residuos siguen una distribuci√≥n normal.</li>
                    <li><b>Shapiro-Wilk:</b> prueba estad√≠stica que indica si los residuos son normales. Se acepta normalidad si p > 0.05.</li>
                </ul>
            """))

            # Gr√°ficas modelo optimo
            plt.figure(figsize=(10, 4))
            plt.subplot(1, 2, 1)
            plt.plot(Y_test.values, label='Real')
            plt.plot(preds, label='Predicho')
            plt.legend()
            plt.title("X-Y Real vs X-Y Predicho")

            plt.subplot(1, 2, 2)
            plt.scatter(Y_test, preds, alpha=0.6)
            min_val = min(Y_test.values.min(), preds.min())
            max_val = max(Y_test.values.max(), preds.max())
            plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Ideal')
            plt.xlabel("Y real")
            plt.ylabel("Y predicho")
            plt.title("Y Real vs Y Predicho")
            plt.legend()

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print("‚ùå Error en m√©tricas finales:", traceback.format_exc())
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # üîí FUNCI√ìN DE PERSISTENCIA  (XGBoost)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    import pickle, pathlib, datetime
    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

    def guardar_xgb(best_model, best_params, nombre_motor,
                    metodo_usado_xgb, selector_funcion_objetivo,
                    X_train_filtrado, X_test, Y_train, Y_test,
                    study=None, traza_out=None):
        score_val = None
        try:
            # 1) carpeta
            pathlib.Path("modelos_opt").mkdir(exist_ok=True)

            # 3) nombre robusto de variable-objetivo
            y_name = getattr(Y_train, "name", None) or \
                    (Y_train.columns[0] if hasattr(Y_train, "columns") else "Y")

            # 4) rutas
            ts      = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            tag     = f"xgb_{metodo_usado_xgb.lower()}_{nombre_motor.lower()}_opt_{ts}"
            model_f = f"modelos_opt/{tag}.pkl"
            meta_f  = f"modelos_opt/{tag}_meta.pkl"
            study_f = f"modelos_opt/{tag}_study.pkl"

            # 5) modelo
            with open(model_f, "wb") as f:
                pickle.dump(best_model, f)

            # 6) metadatos
            meta = dict(
                score       = float(score_val),
                func_obj    = selector_funcion_objetivo.value,
                motor       = nombre_motor,
                metodo_x    = metodo_usado_xgb,
                cols        = list(X_train_filtrado.columns),
                yname       = y_name,
                best_params = best_params,
                fecha       = ts,
            )
            with open(meta_f, "wb") as f:
                pickle.dump(meta, f)

            # 7) estudio Optuna (si procede)
            if nombre_motor.lower() == "optuna" and study is not None:
                with open(study_f, "wb") as f:
                    pickle.dump(study, f)

        except Exception as e:
            # Si score_val a√∫n no se ha calculado, no emitir warning
            if score_val is None:
                return
            if traza_out is not None:
                with traza_out:
                    print(f"‚ö†Ô∏è  No se pudo guardar modelo/estudio: {e}")
            else:
                print(f"‚ö†Ô∏è  No se pudo guardar modelo/estudio: {e}")

    # ===================================================
    # Motor de Optimizaci√≥n RandomSearch CV
    # ===================================================
    def optimizar_randomsearch():
        try:
            assert 'X_train_filtrado' in globals()
            assert 'Y_train_filtrado' in globals()

            print("üìå Iniciando optimizaci√≥n con RandomSearch...")
            funcion_objetivo = selector_funcion_objetivo.value
            n_iter_val = slider_n_iter.value
            cv_val = slider_cv.value
            print(f"üéØ Funci√≥n de optimizaci√≥n seleccionada: {funcion_objetivo} (n_iter={n_iter_val}, cv={cv_val})")

            param_dist = {
                'n_estimators': list(range(50, 300)),
                'max_depth': list(range(3, 15)),
                'learning_rate': np.linspace(0.01, 0.3, 30),
                'subsample': np.linspace(0.5, 1.0, 20),
                'colsample_bytree': np.linspace(0.5, 1.0, 20),
                'gamma': np.linspace(0, 5, 20)
            }

            print(f"üîß Hiperpar√°metros a optimizar: {list(param_dist.keys())}")
            print(f"üîÅ N√∫mero de iteraciones: {n_iter_val}, Validaci√≥n cruzada (cv): {cv_val}")

            model = XGBRegressor(random_state=42, verbosity=0)
            search = RandomizedSearchCV(model, param_distributions=param_dist,
                                        n_iter=n_iter_val, scoring=funcion_objetivo, cv=cv_val, random_state=42,
                                        n_jobs=-1, verbose=3)

            # ‚Äî‚Äî‚Äî A√ëADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TRAIN ‚Äî‚Äî‚Äî
            # 1) Forzar que todos los nombres sean str
            #X_train_filtrado.columns = X_train_filtrado.columns.astype(str)
            ## 2) Reemplazar corchetes y '<', '>' por '_'
            #X_train_filtrado.columns = (
            #    X_train_filtrado
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî
            # # ‚Äî‚Äî‚Äî A√ëADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TEST ‚Äî‚Äî‚Äî
            #X_test.columns = X_test.columns.astype(str)
            #X_test.columns = (
            #    X_test
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ‚Äî‚Äî‚Äî FIN A√ëADIDOS ‚Äî‚Äî‚Äî

            search.fit(X_train_filtrado, Y_train_filtrado)

            global best_model, best_params
            best_model = search.best_estimator_
            best_params = search.best_params_
            tabla_resultados = pd.DataFrame(best_params.items(), columns=['Hiperpar√°metro', 'Valor √≥ptimo'])
            display(tabla_resultados.style.set_caption("üìã Tabla de Hiperpar√°metros √ìptimos").format(precision=4))

            ejecutar_metricas_finales(best_model, nombre_motor="RandomSearch")

            # ‚îÄ‚îÄ‚îÄ Tras best_model, best_params en optimizar_randomsearch() ‚îÄ‚îÄ‚îÄ
            # Calcular el score real con los datos de test
            preds = best_model.predict(X_test[X_train_filtrado.columns])
            if selector_funcion_objetivo.value == "r2":
                score_val = r2_score(Y_test, preds)
            elif selector_funcion_objetivo.value == "neg_mean_absolute_error":
                score_val = mean_absolute_error(Y_test, preds)
            else:
                score_val = mean_squared_error(Y_test, preds)

            # Guardar en OPT_MODELS
            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "randomsearch")] = {
                "model":       best_model,
                "score":       float(score_val),
                "metric":      selector_funcion_objetivo.value,
                "param_dist":  param_dist,           # <- espacio RandomSearch
                "best_params": best_params,
                "cols":        list(X_train_filtrado.columns)
            }
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

            # --- llamada de persistencia ----
            guardar_xgb(best_model, best_params, "RandomSearch",
                        metodo_usado_xgb, selector_funcion_objetivo,
                        X_train_filtrado, X_test, Y_train, Y_test,
                        study=None, traza_out=traza_xgb)
            print("‚úÖ Optimizaci√≥n con RandomSearch completada.")
            # ‚îÄ‚îÄ‚îÄ 3) Imprime la confirmaci√≥n aqu√≠ dentro ‚îÄ‚îÄ‚îÄ
            if traza_xgb is not None:
                with traza_xgb:
                    print(f"üíæ Modelo guardado     ‚Üí modelos_opt/xgb_{metodo_usado_xgb.lower()}_randomsearch_opt_*.pkl")
                    print(f"üíæ Metadatos guardados ‚Üí modelos_opt/xgb_{metodo_usado_xgb.lower()}_randomsearch_opt_*_meta.pkl")

        except Exception as e:
            print("‚ùå Error en optimizaci√≥n RandomSearch:", traceback.format_exc())

    # ===================================================
    # Motor de Optimizaci√≥n Bayesian
    # ===================================================
    def optimizar_bayesian():
        try:
            assert 'X_train_filtrado' in globals()
            assert 'Y_train_filtrado' in globals()

            print("üìå Iniciando optimizaci√≥n con Bayesian Optimization...")
            funcion_objetivo = selector_funcion_objetivo.value
            n_iter_val = slider_n_iter.value
            cv_val = slider_cv.value

            param_spaces = {
                'n_estimators': (50, 300),
                'max_depth': (3, 15),
                'learning_rate': (0.01, 0.3, 'log-uniform'),
                'subsample': (0.5, 1.0),
                'colsample_bytree': (0.5, 1.0),
                'gamma': (0.0, 5.0)
            }

            print(f"üîß Hiperpar√°metros a optimizar: {list(param_spaces.keys())}")
            print(f"üîÅ N√∫mero de iteraciones: {n_iter_val}, Validaci√≥n cruzada (cv): {cv_val}")

            model = XGBRegressor(random_state=42, verbosity=0)

            opt = BayesSearchCV(model, search_spaces=param_spaces,
                n_iter=n_iter_val, scoring=funcion_objetivo, cv=cv_val,
                n_jobs=-1, verbose=3, random_state=42)
            opt.fit(X_train_filtrado, Y_train_filtrado)

            global best_model, best_params
            if opt.best_estimator_ is not None:
                best_model = opt.best_estimator_
                best_params = opt.best_params_

            tabla_resultados = pd.DataFrame(best_params.items(), columns=['Hiperpar√°metro', 'Valor √≥ptimo'])
            display(tabla_resultados.style.set_caption("üìã Tabla de Hiperpar√°metros √ìptimos (Bayesian)").format(precision=4))

            ejecutar_metricas_finales(best_model, nombre_motor="Bayesian")

            # ‚îÄ‚îÄ‚îÄ Tras best_model, best_params en optimizar_bayesian() ‚îÄ‚îÄ‚îÄ
            preds = best_model.predict(X_test[X_train_filtrado.columns])
            if selector_funcion_objetivo.value == "r2":
                score_val = r2_score(Y_test, preds)
            elif selector_funcion_objetivo.value == "neg_mean_absolute_error":
                score_val = mean_absolute_error(Y_test, preds)
            else:
                score_val = mean_squared_error(Y_test, preds)

            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "bayesian")] = {
                "model":       best_model,
                "score":       float(score_val),
                "metric":      selector_funcion_objetivo.value,
                "param_spaces": param_spaces,      # <- espacio BayesSearchCV
                "best_params": best_params,
                "cols":        list(X_train_filtrado.columns)
            }

            # --- llamada de persistencia ----
            guardar_xgb(best_model, best_params, "Bayesian",
                        metodo_usado_xgb, selector_funcion_objetivo,
                        X_train_filtrado, X_test, Y_train, Y_test,
                        study=None, traza_out=traza_xgb)
            print("‚úÖ Optimizaci√≥n con Bayesian Optimization completada.")
            with traza_xgb:
                print(f"üíæ Modelo guardado     ‚Üí modelos_opt/xgb_{metodo_usado_xgb.lower()}_bayesian_opt_*.pkl")
                print(f"üíæ Metadatos guardados ‚Üí modelos_opt/xgb_{metodo_usado_xgb.lower()}_bayesian_opt_*_meta.pkl")

        except Exception as e:
            print("‚ùå Error en optimizaci√≥n Bayesian:", traceback.format_exc())

    # ===================================================
    # Motor de Optimizaci√≥n HyperBrand
    # ===================================================
    def optimizar_hyperband():
        try:
            assert 'X_train_filtrado' in globals()
            assert 'Y_train_filtrado' in globals()

            print("üìå Iniciando optimizaci√≥n con Hyperband...")
            funcion_objetivo = selector_funcion_objetivo.value
            cv_val = slider_cv.value

            # üîß Corregido: se elimina 'n_estimators' de los hiperpar√°metros buscados
            param_dist = {
                'max_depth': list(range(3, 15)),
                'learning_rate': np.linspace(0.01, 0.3, 30),
                'subsample': np.linspace(0.5, 1.0, 20),
                'colsample_bytree': np.linspace(0.5, 1.0, 20),
                'gamma': np.linspace(0, 5, 20)
            }

            model = XGBRegressor(random_state=42, verbosity=0)
            search = HalvingRandomSearchCV(model, param_dist,
                                          scoring=funcion_objetivo, cv=cv_val,
                                          factor=3, resource='n_estimators',
                                          max_resources=300, random_state=42,
                                          verbose=2, n_jobs=-1)

            # ‚Äî‚Äî‚Äî A√ëADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TRAIN ‚Äî‚Äî‚Äî
            # 1) Forzar que todos los nombres sean str
            #X_train_filtrado.columns = X_train_filtrado.columns.astype(str)
            # 2) Reemplazar corchetes y '<', '>' por '_'
            #X_train_filtrado.columns = (
            #    X_train_filtrado
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî
            # # ‚Äî‚Äî‚Äî A√ëADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TEST ‚Äî‚Äî‚Äî
            #X_test.columns = X_test.columns.astype(str)
            #X_test.columns = (
            #    X_test
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ‚Äî‚Äî‚Äî FIN A√ëADIDOS ‚Äî‚Äî‚Äî

            search.fit(X_train_filtrado, Y_train_filtrado)

            global best_model, best_params
            best_model = search.best_estimator_
            best_params = search.best_params_

            tabla_resultados = pd.DataFrame(best_params.items(), columns=['Hiperpar√°metro', 'Valor √≥ptimo'])
            display(tabla_resultados.style.set_caption("üìã Tabla de Hiperpar√°metros √ìptimos (Hyperband)").format(precision=4))

            ejecutar_metricas_finales(best_model, nombre_motor="Hyperband")

            # ‚îÄ‚îÄ‚îÄ Tras best_model, best_params en optimizar_hyperband() ‚îÄ‚îÄ‚îÄ
            preds = best_model.predict(X_test[X_train_filtrado.columns])
            if selector_funcion_objetivo.value == "r2":
                score_val = r2_score(Y_test, preds)
            elif selector_funcion_objetivo.value == "neg_mean_absolute_error":
                score_val = mean_absolute_error(Y_test, preds)
            else:
                score_val = mean_squared_error(Y_test, preds)

            # Hyperband usaba param_dist tambi√©n
            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "hyperband")] = {
                "model":       best_model,
                "score":       float(score_val),
                "metric":      selector_funcion_objetivo.value,
                "param_dist":  param_dist,           # <- espacio Hyperband
                "best_params": best_params,
                "cols":        list(X_train_filtrado.columns)
            }

            # --- llamada de persistencia ----
            guardar_xgb(best_model, best_params, "Hyperband",
                        metodo_usado_xgb, selector_funcion_objetivo,
                        X_train_filtrado, X_test, Y_train, Y_test,
                        study=None, traza_out=traza_xgb)
            print("‚úÖ Optimizaci√≥n con Hyperband completada.")
            with traza_xgb:
               print(f"üíæ Modelo guardado     ‚Üí modelos_opt/xgb_{metodo_usado_xgb.lower()}_hyperband_opt_*.pkl")
               print(f"üíæ Metadatos guardados ‚Üí modelos_opt/xgb_{metodo_usado_xgb.lower()}_hyperband_opt_*_meta.pkl")

        except Exception as e:
            print("‚ùå Error en optimizaci√≥n Hyperband:", traceback.format_exc())

    # ===================================================
    # Motor de Optimizaci√≥n Optuna
    # ===================================================
    def optimizar_optuna():
        try:
            print("\nüìå Iniciando optimizaci√≥n con Optuna...")
            assert 'X_train_filtrado' in globals()
            assert 'Y_train_filtrado' in globals()

            # ‚Äî‚Äî‚Äî A√ëADIDO: Definir escaladores para Optuna ‚Äî‚Äî‚Äî
            from sklearn.preprocessing import StandardScaler
            # Ajustamos escalador de X sobre el train filtrado
            X_scaler = StandardScaler().fit(X_train_filtrado)
            # Ajustamos escalador de Y (reshape para vector columna)
            y_scaler = StandardScaler().fit(
                Y_train_filtrado.values.reshape(-1, 1)
            )
            # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî

            param_dist = {
                'n_estimators': IntDistribution(50, 300),
                'max_depth': IntDistribution(3, 15),
                'learning_rate': FloatDistribution(0.01, 0.3),
                'subsample': FloatDistribution(0.5, 1.0),
                'colsample_bytree': FloatDistribution(0.5, 1.0),
                'gamma': FloatDistribution(0, 5)
            }

            model = XGBRegressor(random_state=42, verbosity=0)
            search = OptunaSearchCV(
                estimator=model,
                param_distributions=param_dist,
                scoring=selector_funcion_objetivo.value,
                n_trials=slider_n_iter.value,
                cv=slider_cv.value,
                random_state=42,
                n_jobs=-1
            )

            # ‚Äî‚Äî‚Äî A√ëADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TRAIN ‚Äî‚Äî‚Äî
            # 1) Forzar que todos los nombres sean str
            #X_train_filtrado.columns = X_train_filtrado.columns.astype(str)
            # 2) Reemplazar corchetes y '<', '>' por '_'
            #X_train_filtrado.columns = (
            #    X_train_filtrado
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî
            # # ‚Äî‚Äî‚Äî A√ëADIDO PARA ASEGURAR FUNCIONAMIENTO XGBOOST CON NONBRES DE FEATURES CON CARACTERES ESPECIALES - PARA TEST ‚Äî‚Äî‚Äî
            #X_test.columns = X_test.columns.astype(str)
            #X_test.columns = (
            #    X_test
            #    .columns
            #    .str.replace(r'[\[\]<>]', '_', regex=True)
            #)
            # ‚Äî‚Äî‚Äî FIN A√ëADIDOS ‚Äî‚Äî‚Äî

            search.fit(X_train_filtrado, Y_train_filtrado)
            global best_model
            best_model = search.best_estimator_

            print("\n‚úÖ Hiperpar√°metros √≥ptimos encontrados con Optuna:")
            global best_params
            best_params = search.best_params_
            display(pd.DataFrame([best_params]).T.rename(columns={0: 'Valor √≥ptimo'}).style.set_caption("üìã Hiperpar√°metros √ìptimos (Optuna)").format(precision=4))

            ejecutar_metricas_finales(best_model, nombre_motor="Optuna")

            # ‚îÄ‚îÄ‚îÄ Tras best_model, best_params en optimizar_optuna() ‚îÄ‚îÄ‚îÄ
            preds = best_model.predict(X_test[X_train_filtrado.columns])
            if selector_funcion_objetivo.value == "r2":
                score_val = r2_score(Y_test, preds)
            elif selector_funcion_objetivo.value == "neg_mean_absolute_error":
                score_val = mean_absolute_error(Y_test, preds)
            else:
                score_val = mean_squared_error(Y_test, preds)

            # Capturamos el espacio usado por Optuna (param_dist) y el estudio
            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "optuna")] = {
                "model":       best_model,
                'sx':          X_scaler,        # tu StandardScaler de X
                'sy':          y_scaler,        # si existe
                "score":       float(score_val),
                "metric":      selector_funcion_objetivo.value,
                "param_dist":  param_dist,           # <- espacio de Optuna
                "best_params": best_params,
                "cols":        list(X_train_filtrado.columns)
            }
            # Si quieres guardar el study:
            if 'study' in locals():
                OPT_MODELS[("xgb", metodo_usado_xgb.lower(), "optuna_study")] = study

            # --- llamada de persistencia ----
            guardar_xgb(best_model, best_params, "Optuna",
                        metodo_usado_xgb, selector_funcion_objetivo,
                        X_train_filtrado, X_test, Y_train, Y_test,
                        study=search.study_, traza_out=traza_xgb)
            print("‚úÖ Optimizaci√≥n con Hyperband completada.")
            with traza_xgb:
                print(f"üíæ Modelo guardado     ‚Üí modelos_opt/xgb_{metodo_usado_xgb.lower()}_optuna_opt_*.pkl")
                print(f"üíæ Metadatos guardados ‚Üí modelos_opt/xgb_{metodo_usado_xgb.lower()}_optuna_opt_*_meta.pkl")

        except Exception as e:
            print("‚ùå Error en optimizaci√≥n Optuna:", traceback.format_exc())

    opciones_metodos = sorted(list(RESUMEN_METODOS.keys()) + ['Todos'])
    selector_metodo = widgets.Dropdown(
        options=opciones_metodos,
        description='M√©todo:',
        layout=widgets.Layout(width='50%')
    )

    boton_confirmar = widgets.Button(description="üì• Cargar variables seleccionadas", button_style='primary')
    boton_confirmar.on_click(lambda b: seleccionar_variables_filtradas(selector_metodo.value))

    selector_motor = widgets.SelectMultiple(
        options=['RandomSearch', 'Bayesian', 'Hyperband', 'Optuna', 'Todos'],
        value=['RandomSearch'],
        description='Motores:',
        layout=widgets.Layout(width='50%', height='120px')
    )

    boton_opt = widgets.Button(description="üöÄ Iniciar Optimizaci√≥n XGBoost", button_style='success')
    #boton_opt.on_click(lambda b: optimizar_randomsearch() if 'RandomSearch' in selector_motor.value or 'Todos' in selector_motor.value else None)

    def lanzar_optimizaciones(_):
        if 'RandomSearch' in selector_motor.value or 'Todos' in selector_motor.value:
            optimizar_randomsearch()
        if 'Bayesian' in selector_motor.value or 'Todos' in selector_motor.value:
            optimizar_bayesian()
        if 'Hyperband' in selector_motor.value or 'Todos' in selector_motor.value:
            optimizar_hyperband()
        if 'Optuna' in selector_motor.value or 'Todos' in selector_motor.value:
            optimizar_optuna()

    boton_opt.on_click(lanzar_optimizaciones)

    out_opt_xgb.clear_output()
    with out_opt_xgb:
        display(HTML("<h3>üîß Selecci√≥n de Variables para Optimizaci√≥n XGBoost</h3>"))
        display(widgets.HBox([selector_metodo, boton_confirmar]))
        display(HTML("<h3>‚öôÔ∏è Par√°metros de Optimizaci√≥n</h3>"))
        display(widgets.VBox([
            widgets.HBox([slider_n_iter, slider_cv]),
            widgets.HBox([ayuda_n_iter, ayuda_cv]),
            widgets.HBox([selector_funcion_objetivo]),
            ayuda_funcion
        ]))
        display(HTML("<h3>‚öôÔ∏è Motores de Optimizaci√≥n</h3>"))
        display(widgets.VBox([selector_motor, boton_opt]))

        display(traza_xgb)             # üîπ se muestra el panel de trazas

    display(out_opt_xgb)

# Artifact: exec exec_189
from sklearn.model_selection import RandomizedSearchCV

# Artifact: exec exec_190
from sklearn.experimental import enable_halving_search_cv

# Artifact: exec exec_191
from sklearn.model_selection import HalvingRandomSearchCV

# Artifact: exec exec_192
from optuna import Trial

# Artifact: exec exec_193
from optuna.integration import OptunaSearchCV

# Artifact: exec exec_194
from skopt.space import Integer, Categorical

# Artifact: exec exec_195
from scipy.stats import norm

# Artifact: exec exec_196
from scipy.stats import gaussian_kde

# Artifact: exec exec_197
import pathlib, datetime, pickle

# Artifact: exec exec_198
from sklearn.pipeline import Pipeline

# Artifact: exec exec_199
from sklearn.preprocessing import FunctionTransformer

# Artifact: function guardar_rf
def guardar_rf(best_model,
               optimizations_results,
               scaler_X, scaler_Y,
               cols,
               X_test, Y_test,
               func_objetivo,
               study=None,
               traza_out=None):
    try:
        # 1) Asegurar carpeta de destino
        pathlib.Path("modelos_opt").mkdir(exist_ok=True)

        # 2) Preparar datos de prueba filtrados y escalados
        X_test_sel = X_test[cols]
        X_scaled   = scaler_X.transform(X_test_sel)
        preds      = best_model.predict(X_scaled)
        preds_inv  = scaler_Y.inverse_transform(preds.reshape(-1,1)).ravel()

        # 3) Calcular m√©trica seg√∫n func_objetivo
        if func_objetivo == "r2":
            score_val = r2_score(Y_test, preds_inv)
        elif func_objetivo == "neg_mean_absolute_error":
            score_val = mean_absolute_error(Y_test, preds_inv)
        else:
            score_val = mean_squared_error(Y_test, preds_inv)

        # 4) Definir rutas de archivo
        ts      = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        tag     = f"rf_{func_objetivo}_opt_{ts}"
        model_f = f"modelos_opt/{tag}.pkl"
        meta_f  = f"modelos_opt/{tag}_meta.pkl"
        study_f = f"modelos_opt/{tag}_study.pkl"

        # 5) Guardar modelo+escaladores+cols
        with open(model_f, "wb") as f:
            pickle.dump({
                "model": best_model,
                "sx":    scaler_X,
                "sy":    scaler_Y,
                "cols":  cols
            }, f)

        # 6) Guardar metadatos
        meta = {
            "score":  float(score_val),
            "metric": func_objetivo,
            "cols":   cols
        }
        with open(meta_f, "wb") as f:
            pickle.dump(meta, f)

        # 7) Guardar estudio Optuna si existe
        if study is not None:
            with open(study_f, "wb") as f:
                pickle.dump(study, f)

        # 8) Mensaje de confirmaci√≥n
        if traza_out is not None:
            with traza_out:
                print(f"üíæ Modelo guardado ‚Üí {model_f}")
                print(f"üíæ Metadatos guardados ‚Üí {meta_f}")
                if study is not None:
                    print(f"üíæ Study guardado ‚Üí {study_f}")

    except Exception as e:
        msg = f"‚ö†Ô∏è No se pudo guardar modelo/estudio: {e}"
        if traza_out is not None:
            with traza_out:
                print(msg)
        else:
            print(msg)

# Artifact: exec exec_201
import logging

# Artifact: exec exec_202
logging.basicConfig(level=logging.INFO)

# Artifact: assign logger
logger = logging.getLogger(__name__)

# Artifact: assign out_rf_opt
out_rf_opt = widgets.Output()

# Artifact: assign optimizations_results
optimizations_results = []

# Artifact: function mostrar_optimizacion_rf
def mostrar_optimizacion_rf():
    with out_rf_opt:
        clear_output()

        # Aseguramos que las variables X e Y est√©n definidas globalmente
        global X_train, Y_train, X_test, Y_test
        if 'X_train' not in globals() or 'Y_train' not in globals() or 'X_test' not in globals() or 'Y_test' not in globals():
            print("‚ùå Aseg√∫rate de que las variables X_train, Y_train, X_test y Y_test est√©n correctamente definidas.")
            return

        # ‚îÄ‚îÄ‚îÄ A√ëADIDO: saneamiento global de nombres ‚îÄ‚îÄ‚îÄ
        #import re
        #def clean_name(s):
        #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))  # corchetes, %, /, . y espacios ‚Üí _
        #    t = re.sub(r'_+', '_', t)                     # colapsar guiones bajos repetidos
        #    return t.strip('_')

        # 1) Limpio las columnas de X_train y X_test
        #X_train.columns = [clean_name(c) for c in X_train.columns]
        #X_test.columns  = [clean_name(c) for c in X_test.columns]

        # 2) Limpio todas las listas de RESUMEN_METODOS
        #for m, lst in RESUMEN_METODOS.items():
        #    if isinstance(lst, list):
        #        RESUMEN_METODOS[m] = [clean_name(c) for c in lst]
        # ‚îÄ‚îÄ‚îÄ FIN A√ëADIDO ‚îÄ‚îÄ‚îÄ

        # 2) Ahora s√≠ puedo sanear columnas
        # Usar sanitize_name para limpiar columnas en el payload
        def clean_cols(col_list):
            return [sanitize_name(c) for c in col_list]
        # Ejemplo de sanitizaci√≥n de X_train antes de fit
        X_train.columns = [sanitize_name(col) for col in X_train.columns]
        X_test.columns = [sanitize_name(col) for col in X_test.columns]

        # Mostrar men√∫ para seleccionar el motor de optimizaci√≥n, el m√©todo y la funci√≥n de optimizaci√≥n
        selector_motor = widgets.Dropdown(
            options=['RandomSearch', 'BayesianOptimization', 'Hyperband', 'Optuna', 'Todos'],
            description='Motor:',
            value='RandomSearch',
            layout=widgets.Layout(width='50%')
        )

        selector_metodo = widgets.Dropdown(
            options=['Pearson', 'Spearman', 'Mutualinfo', 'Boruta', 'UAMP', 'Todos'],
            description='M√©todo:',
            value='Todos',
            layout=widgets.Layout(width='50%')
        )

        func_objetivo = widgets.Dropdown(
            options=['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'],
            value='r2',
            description='Funci√≥n:',
            layout=widgets.Layout(width='50%')
        )

        # Sliders para la configuraci√≥n de la optimizaci√≥n
        n_iter = widgets.IntSlider(value=50, min=10, max=300, step=10, description='n_iter:')
        cv = widgets.IntSlider(value=5, min=2, max=10, step=1, description='cv:')

        # Bot√≥n de ejecutar optimizaci√≥n
        btn_ejecutar = widgets.Button(description="üöÄ Ejecutar Optimizaci√≥n", button_style='success')
        barra_progreso = widgets.IntProgress(min=0, max=1, description='Progreso:')
        salida_resultados = widgets.Output()

        def ejecutar_optimizaci√≥n(_):
            global OPT_MODELS
            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
            salida_resultados.clear_output()
            barra_progreso.bar_style = 'info'
            barra_progreso.value = 0
            tiempo_transcurrido = widgets.HTML('‚è±Ô∏è Tiempo: 0.0s')
            mensaje_estado = widgets.HTML(value="‚è≥ <b>Optimizaci√≥n en curso...</b>")
            inicio = time.time()

            with salida_resultados:
                print("‚è≥ Ejecutando optimizaci√≥n...")

                # Escaladores para entrenamiento/test
                scaler_X = StandardScaler().fit(X_train)
                scaler_Y = StandardScaler().fit(Y_train.values.reshape(-1,1))
                X_train_scaled = scaler_X.transform(X_train)
                X_test_scaled  = scaler_X.transform(X_test)
                Y_train_scaled = scaler_Y.transform(Y_train.values.reshape(-1,1)).ravel()
                Y_test_scaled  = scaler_Y.transform(Y_test.values.reshape(-1,1)).ravel()

                # Inicializar motores de optimizaci√≥n
                search_random = None
                search_bayes = None
                search_hyperband = None
                best_rf_random = None
                best_rf_bayes = None
                best_rf_hyperband = None
                best_rf_optuna = None
                best_motor = None
                best_metodo = None
                best_rf = None
                best_score = -np.inf
                optimizations_results = []
                best_score_random = best_score_bayes = best_score_hyperband = best_score_optuna = None

                # Configurar lista de motores y m√©todos
                motors = (['RandomSearch','BayesianOptimization','Hyperband','Optuna']
                          if selector_motor.value=='Todos'
                          else [selector_motor.value])
                study = None          # placeholder que existir√° en todos los motores
                for motor in motors:
                    # Para cada m√©todo de selecci√≥n
                    methods = list(RESUMEN_METODOS.keys()) if selector_metodo.value=='Todos' else [selector_metodo.value]
                    for metodo in methods:
                        print(f"üîß Motor: {motor} | M√©todo: {metodo}")
                        #cols = RESUMEN_METODOS.get(metodo, X_train.columns.tolist())  # columnas de este m√©todo

                        # ‚Äî‚Äî‚Äî REEMPLAZO: obtengo directamente las columnas saneadas ‚Äî‚Äî‚Äî
                        cols = RESUMEN_METODOS.get(metodo, [])
                        if not cols:
                            print(f"‚ö†Ô∏è No hay variables para '{metodo}', omito.")
                            continue
                        # ‚Äî‚Äî‚Äî FIN REEMPLAZO ‚Äî‚Äî‚Äî

                        X_train_sel = X_train[cols]
                        X_test_sel  = X_test[cols]
                        scaler_X = StandardScaler().fit(X_train_sel)
                        X_train_scaled = scaler_X.transform(X_train_sel)
                        X_test_scaled  = scaler_X.transform(X_test_sel)

                        # Aqu√≠ nos aseguramos de que Y_train tambi√©n se escala
                        sy = StandardScaler()
                        Y_train_scaled = sy.fit_transform(Y_train.values.reshape(-1, 1)).ravel()
                        Y_test_scaled = sy.transform(Y_test.values.reshape(-1, 1)).ravel()

                        # =================================================
                        # Motor Random Search
                        # =================================================
                        if motor == 'RandomSearch':
                            param_dist = {
                                'n_estimators': np.arange(50, 501, 50),
                                'max_depth': np.arange(3, 15, 1),
                                'min_samples_split': np.arange(2, 21, 1),
                                'min_samples_leaf': np.arange(1, 21, 1),
                                'max_features': ['sqrt', 'log2', None],
                                'bootstrap': [True, False]
                            }
                            search_random = RandomizedSearchCV(
                                RandomForestRegressor(random_state=42),
                                param_distributions=param_dist,
                                n_iter=n_iter.value,
                                cv=cv.value, n_jobs=-1, scoring=func_objetivo.value, random_state=42,
                                return_train_score=True, verbose=3
                            )
                            search_random.fit(X_train_scaled, Y_train_scaled)
                            best_rf_random = search_random.best_estimator_
                            best_score_random = search_random.best_score_
                            if best_score_random > best_score:
                                best_score = best_score_random
                                best_rf = best_rf_random
                                best_metodo = metodo
                                best_motor  = motor
                            # Almacenar los resultados del motor RandomSearch
                            # ‚îÄ‚îÄ‚îÄ Tras best_estimator_ y best_score de cada motor ‚îÄ‚îÄ‚îÄ
                            OPT_MODELS = globals().setdefault("OPT_MODELS", {})
                            # RandomSearch
                            OPT_MODELS[("rf", metodo.lower(), "randomsearch")] = {
                                "model":       best_rf_random,
                                "sx":          scaler_X,
                                "sy":          sy,
                                "score":       float(best_score_random),
                                "metric":      func_objetivo.value,
                                "param_dist":  param_dist,
                                "best_params": search_random.best_params_,
                                "cols":        cols
                            }
                            optimizations_results.append({
                                'motor' : motor,
                                'metodo': metodo,
                                'puntuaci√≥n': best_score_random,
                                'R2': r2_score(Y_test_scaled, search_random.predict(X_test_scaled)),
                                'MSE': mean_squared_error(Y_test_scaled, search_random.predict(X_test_scaled)),
                                'MAE': mean_absolute_error(Y_test_scaled, search_random.predict(X_test_scaled)),
                                'params': search_random.best_params_
                            })

                            pass
                        # =================================================
                        # Motor Bayesian
                        # =================================================
                        elif motor == 'BayesianOptimization':
                            param_space = {
                                'n_estimators': Integer(50, 500),
                                'max_depth': Integer(3, 15),
                                'min_samples_split': Integer(2, 20),
                                'min_samples_leaf': Integer(1, 20),
                                'max_features': Categorical(['sqrt', 'log2', None]),
                                'bootstrap': Categorical([True, False])
                            }
                            search_bayes = BayesSearchCV(
                                RandomForestRegressor(random_state=42),
                                param_space,
                                n_iter=n_iter.value,
                                cv=cv.value, n_jobs=-1, scoring=func_objetivo.value, random_state=42,
                                return_train_score=True, verbose=3
                            )
                            search_bayes.fit(X_train_scaled, Y_train_scaled)
                            best_rf_bayes = search_bayes.best_estimator_
                            best_score_bayes = search_bayes.best_score_
                            if best_score_bayes > best_score:
                                best_score = best_score_bayes
                                best_rf = best_rf_bayes
                                best_metodo = metodo
                                best_motor  = motor
                            # Almacenar los resultados del motor Bayesian
                            OPT_MODELS[("rf", metodo.lower(), "bayesianoptimization")] = {
                                "model":       best_rf_bayes,
                                "sx":          scaler_X,
                                "sy":          sy,
                                "score":       float(best_score_bayes),
                                "metric":      func_objetivo.value,
                                "param_dist":  param_space,
                                "best_params": search_bayes.best_params_,
                                "cols":        cols
                            }
                            optimizations_results.append({
                                'motor' : motor,
                                'metodo': metodo,
                                'puntuaci√≥n': best_score_bayes,
                                'R2': r2_score(Y_test_scaled, search_bayes.predict(X_test_scaled)),
                                'MSE': mean_squared_error(Y_test_scaled, search_bayes.predict(X_test_scaled)),
                                'MAE': mean_absolute_error(Y_test_scaled, search_bayes.predict(X_test_scaled)),
                                'params': search_bayes.best_params_
                            })

                            pass
                        # =================================================
                        # Motor Hyperband
                        # =================================================
                        elif motor == 'Hyperband':
                            param_dist = {
                                'n_estimators': np.arange(50, 501, 50),
                                'max_depth': np.arange(3, 15, 1),
                                'min_samples_split': np.arange(2, 21, 1),
                                'min_samples_leaf': np.arange(1, 21, 1),
                                'max_features': ['sqrt', 'log2', None],
                                'bootstrap': [True, False]
                            }
                            search_hyperband = HalvingRandomSearchCV(
                                RandomForestRegressor(random_state=42),
                                param_distributions=param_dist,
                                factor=3,  # Aumenta recursos a medida que mejora el modelo
                                max_resources=300,  # M√°ximo n√∫mero de recursos para la optimizaci√≥n
                                min_resources=50,  # N√∫mero m√≠nimo de recursos
                                cv=cv.value, n_jobs=-1, scoring=func_objetivo.value, random_state=42,
                                return_train_score=True, verbose=3
                            )
                            search_hyperband.fit(X_train_scaled, Y_train_scaled)
                            best_rf_hyperband = search_hyperband.best_estimator_
                            best_score_hyperband = search_hyperband.best_score_
                            if best_score_hyperband > best_score:
                                best_score = best_score_hyperband
                                best_rf = best_rf_hyperband
                                best_metodo = metodo
                                best_motor  = motor
                            # Almacenar los resultados del motor Hyperband
                            OPT_MODELS[("rf", metodo.lower(), "hyperband")] = {
                                "model":       best_rf_hyperband,
                                "sx":          scaler_X,
                                "sy":          sy,
                                "score":       float(best_score_hyperband),
                                "metric":      func_objetivo.value,
                                "param_dist":  param_dist,
                                "best_params": search_hyperband.best_params_,
                                "cols":        cols
                            }
                            optimizations_results.append({
                                'motor' : motor,
                                'metodo': metodo,
                                'puntuaci√≥n': best_score_hyperband,
                                'R2': r2_score(Y_test_scaled, search_hyperband.predict(X_test_scaled)),
                                'MSE': mean_squared_error(Y_test_scaled, search_hyperband.predict(X_test_scaled)),
                                'MAE': mean_absolute_error(Y_test_scaled, search_hyperband.predict(X_test_scaled)),
                                'params': search_hyperband.best_params_
                            })

                            pass
                        # =================================================
                        # Motor Optuna
                        # =================================================
                        elif motor == 'Optuna':
                            def objective(trial: Trial):
                                param = {
                                    'n_estimators': trial.suggest_int('n_estimators', 50, 500, step=50),
                                    'max_depth': trial.suggest_int('max_depth', 3, 15),
                                    'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                                    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),
                                    'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),
                                    'bootstrap': trial.suggest_categorical('bootstrap', [True, False])
                                }
                                model = RandomForestRegressor(**param, random_state=42)
                                model.fit(X_train_scaled, Y_train_scaled)
                                preds = model.predict(X_test_scaled)
                                return mean_squared_error(Y_test_scaled, preds)

                            #study = optuna.create_study(direction='maximize')  # Maximizar la puntuaci√≥n
                            direction = 'minimize' if func_objetivo.value != 'r2' else 'maximize'
                            study = optuna.create_study(direction=direction)
                            study.optimize(objective, n_trials=n_iter.value)

                            best_rf_optuna = RandomForestRegressor(**study.best_params, random_state=42)
                            best_rf_optuna.fit(X_train_scaled, Y_train_scaled)
                            best_score_optuna = study.best_value
                            if best_score_optuna > best_score:
                                best_score = best_score_optuna
                                best_rf = best_rf_optuna
                                best_metodo = metodo
                                best_motor  = motor

                            # Almacenar los resultados del motor Optuna
                            # ‚Ä¶ despu√©s de entrenar best_rf_optuna y antes de optimizations_results.append
                            pred_opt = best_rf_optuna.predict(X_test_scaled)   # ‚Üê calcula una sola vez

                            OPT_MODELS[("rf", metodo.lower(), "optuna")] = {
                                "model":       best_rf_optuna,
                                "sx":          scaler_X,
                                "sy":          sy,
                                "score":       float(best_score_optuna),
                                "metric":      func_objetivo.value,
                                "param_dist":  study.best_params,
                                "best_params": study.best_params,
                                "cols":        cols
                            }
                            optimizations_results.append({
                                'motor' : motor,
                                'metodo': metodo,
                                'puntuaci√≥n': best_score_optuna,
                                'R2'    : r2_score(Y_test_scaled, pred_opt),
                                'MSE'   : mean_squared_error(Y_test_scaled, pred_opt),
                                'MAE'   : mean_absolute_error(Y_test_scaled, pred_opt),
                                'params': study.best_params
                            })

                            study = study

                            pass

                # Elegir el mejor modelo seg√∫n el motor seleccionado
                best_rf = best_rf_random if best_rf_random else best_rf_bayes if best_rf_bayes else best_rf_hyperband if best_rf_hyperband else best_rf_optuna

                # Recopilamos s√≥lo los scores que s√≠ tenemos
                scores = [
                    best_score_random,
                    best_score_bayes,
                    best_score_hyperband,
                    best_score_optuna
                ]
                # Filtramos los None
                scores = [s for s in scores if s is not None]
                # Si hay al menos uno, tomamos el m√°ximo; si no, dejamos None o 0
                best_score = max(scores) if scores else None

                # Registrar en memoria el mejor RF en OPT_MODELS
                OPT_MODELS = globals().setdefault("OPT_MODELS", {})
                OPT_MODELS[("rf", best_metodo.lower(), best_motor.lower())] = {
                    "model":       best_rf,
                    "sx":          scaler_X,
                    "sy":          sy,
                    "score":       float(best_score),
                    "metric":      func_objetivo.value,
                    "param_dist":  optimizations_results[-1]["params"],
                    "best_params": optimizations_results[-1]["params"],
                    "cols":        RESUMEN_METODOS.get(best_metodo, X_train.columns.tolist())
                }

                #import re
                # tras bucles, desescalamos y graficamos con el mejor de todos
                # Ajuste de columnas seg√∫n selecci√≥n de variables
                cols_rf = RESUMEN_METODOS.get(best_metodo, X_train.columns.tolist())
                # ‚Äî‚Äî‚Äî A√ëADIDO: sanitizar nombres de cols_rf ‚Äî‚Äî‚Äî
                # ‚Ä¶despu√©s de determinar cols_rf original‚Ä¶
                #raw_cols_rf = RESUMEN_METODOS.get(best_metodo, X_train.columns.tolist())

                # 1) Sanitizamos:
                #cols_rf = [ re.sub(r'[\[\]<>]', '_', str(c)) for c in raw_cols_rf ]

                # 2) Filtramos para quedarnos solo con los que existen:
                #cols_rf = [ c for c in cols_rf if c in X_train.columns ]
                # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî

                scaler_X_final = StandardScaler().fit(X_train[cols_rf])
                scaler_Y_final = StandardScaler().fit(Y_train.values.reshape(-1,1))
                X_test_sel = X_test[cols_rf]
                X_test_scaled_final = scaler_X_final.transform(X_test_sel)

                # Predicci√≥n sobre columnas seleccionadas
                preds_scaled = best_rf.predict(X_test_scaled_final)
                preds_final = scaler_Y_final.inverse_transform(preds_scaled.reshape(-1,1)).ravel()

                # >>> LLAMADA A PERSISTENCIA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                guardar_rf(
                    best_model=best_rf,
                    optimizations_results=optimizations_results,
                    scaler_X=scaler_X_final,
                    scaler_Y=scaler_Y_final,
                    cols=cols,
                    X_test=X_test,
                    Y_test=Y_test,
                    func_objetivo=func_objetivo.value,
                    study=study if study is not None else None,
                    traza_out=salida_resultados
                )
                # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                # Mostrar el mejor modelo y los hiperpar√°metros
                print("‚úÖ Optimizaci√≥n completada.")
                print(f"üîπ Mejor Modelo: {best_rf}")
                print(f"üîπ Mejor Puntuaci√≥n: {best_score:.4f}")

                plt.figure(figsize=(10,4))
                plt.subplot(1,2,1)
                plt.scatter(Y_test, preds_final, alpha=0.6)
                plt.plot([Y_test.min(),Y_test.max()],[Y_test.min(),Y_test.max()],'r--', label='Ideal')
                plt.title(f"Real vs Predicho ({best_motor} - {best_metodo})")
                plt.xlabel("Y Real"); plt.ylabel("Y Predicho"); plt.legend(); plt.grid()

                # Histograma residuos y curvas de distribuci√≥n
                residuos = Y_test.values.ravel() - preds_final
                plt.figure(figsize=(6,4))
                # Histograma
                n,bins,patches=plt.hist(residuos,bins=20,density=True,alpha=0.6,edgecolor='black',label='Distribuci√≥n Residuos')
                # Curva normal
                mu,sd=norm.fit(residuos)
                x=np.linspace(bins.min(),bins.max(),100)
                plt.plot(x,norm.pdf(x,mu,sd),linewidth=2, label='Curva normal')
                # Curva KDE de la distribuci√≥n real
                kde = gaussian_kde(residuos)
                x = np.linspace(bins.min(),bins.max(),100)
                plt.plot(x, kde(x), lw=2, label='Densidad KDE')  # a√±adido KDE
                plt.title('Histograma de residuos con curva normal y curva de densidad'); plt.tight_layout()
                plt.legend()
                plt.grid(True)
                plt.show()

                # Test normalidad Shapiro
                stat, p = shapiro(residuos)
                display(HTML(f"<h4>üß™ Prueba de Normalidad Shapiro-Wilk:</h4><ul><li>Estad√≠stico: {stat:.4f}</li><li>p-valor: {p:.4f}</li><li>{'‚úÖ Residuos normales' if p>0.05 else '‚ö†Ô∏è Residuos no normales'}</li></ul>"))

                # Eje de casos
                n_casos = len(Y_test)
                casos = range(n_casos)

                # Extraer valores
                y_real = Y_test.values if hasattr(Y_test, "values") else Y_test
                y_pred = preds_final  # ajusta el nombre si usas otro

                plt.figure(figsize=(10, 4))
                plt.scatter(casos, y_real, marker='o', label='Y real')
                plt.scatter(casos, y_pred, marker='x', label='Y predicho')
                plt.xlabel('Caso')
                plt.ylabel('Y')
                plt.title('Comparaci√≥n de puntos: Y real vs. Y predicho')
                plt.legend()
                plt.grid(True)

                plt.tight_layout()
                plt.show()

                # Mostrar los hiperpar√°metros √≥ptimos
                print("\n‚öôÔ∏è Mejores hiperpar√°metros encontrados:")
                optimal_params_df = pd.DataFrame.from_dict(best_rf.get_params(), orient='index', columns=['Valor √≥ptimo'])
                display(optimal_params_df.style.set_caption("üìã Par√°metros √ìptimos").format(precision=4))

                # Calcular y mostrar m√©tricas
                r2 = r2_score(Y_test, preds_final)
                mse = mean_squared_error(Y_test, preds_final)
                rmse = np.sqrt(mse)
                mae = mean_absolute_error(Y_test, preds_final)

                print(f" Valores de ajuste para los datos de prueba")
                print(f"üîπ R¬≤: {r2:.4f}")
                print(f"üîπ MSE: {mse:.4f}")
                print(f"üîπ RMSE: {rmse:.4f}")
                print(f"üîπ MAE: {mae:.4f}")

                # Tabla completa de optimizaciones
                df_all=pd.DataFrame(optimizations_results).rename(columns={'motor':'Motor','metodo':'M√©todo'})
                display(df_all.style.set_caption("üìä Todos los resultados de optimizaci√≥n").format({'R2':'{:.4f}','MSE':'{:.4f}','MAE':'{:.4f}'}))

                # Ranking top 5
                df_rank = pd.DataFrame(sorted(optimizations_results, key=lambda x: x['puntuaci√≥n'], reverse=True)[:5])
                display(df_rank.style.set_caption("üèÖ Top 5 Optimizaci√≥n").format({"R2": "{:.4f}", "MSE":"{:.4f}", "MAE":"{:.4f}"}))

                barra_progreso.bar_style = 'success'
                barra_progreso.value = 1
                tiempo_transcurrido.value = f'‚è±Ô∏è Tiempo total: {time.time() - inicio:.1f}s'
                mensaje_estado = widgets.HTML(value="‚úÖ Optimizaci√≥n completada")

        # Conectar la acci√≥n del bot√≥n con la ejecuci√≥n de la optimizaci√≥n
        btn_ejecutar.on_click(ejecutar_optimizaci√≥n)

        # Mostrar widgets
        display(HTML("<h3>üîß Optimizaci√≥n</h3>"))
        display(widgets.VBox([
            selector_motor,
            selector_metodo,
            func_objetivo,
            n_iter,
            cv,
            btn_ejecutar,
            barra_progreso,
            salida_resultados
        ]))

# Artifact: exec exec_207
display(out_rf_opt)

# Artifact: exec exec_208
import threading, time

# Artifact: exec exec_209
from sklearn.base import BaseEstimator, RegressorMixin

# Artifact: exec exec_210
from sklearn.model_selection import RandomizedSearchCV, HalvingRandomSearchCV

# Artifact: exec exec_211
from tensorflow.keras.layers import SimpleRNN, Dense, Dropout

# Artifact: exec exec_212
from tensorflow.keras.optimizers import Adam

# Artifact: exec exec_213
from skopt.space import Real, Integer, Categorical

# Artifact: assign out_opt_rnn
out_opt_rnn = widgets.Output()

# Artifact: class RNNRegressor
class RNNRegressor(BaseEstimator, RegressorMixin):                             # NEW
    def __init__(self, units=32, dropout_rate=0.2, learning_rate=1e-3,
        epochs=50, batch_size=32, verbose=0, sy=None):
        self.units = units
        self.dropout_rate = dropout_rate
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.batch_size = batch_size
        self.verbose = verbose
        self.model_ = None
        self.sy = sy

    #def fit(self, X, y):
    def fit(self, X, y, **kwargs):
        # Si alguien pasa sy por fit, lo recogemos
        sy = kwargs.pop("sy", None)
        if sy is not None:
            self.sy = sy

        # Absorber posibles argumentos de recurso (epochs) de Hyperband
        kwargs.pop('epochs', None)
        # Aseguramos tipos nativos
        self.units = int(self.units)            # NOW ensures Python int
        self.dropout_rate = float(self.dropout_rate)
        self.learning_rate = float(self.learning_rate)
        self.epochs = int(self.epochs)
        self.batch_size = int(self.batch_size)

        # Damos formato 3D para la capa recurrente: (n_samples, timesteps=1, n_features)
        X3 = X.reshape((X.shape[0], 1, X.shape[1]))                             # NEW

        # Construimos el RNN
        self.model_ = Sequential()
        self.model_.add(SimpleRNN(self.units, activation='tanh', input_shape=(1, X.shape[1])))
        self.model_.add(Dropout(self.dropout_rate))
        self.model_.add(Dense(1))
        self.model_.compile(optimizer=Adam(learning_rate=self.learning_rate), loss='mse')

        # Entrenamiento
        self.model_.fit(X3, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)
        return self

    def predict(self, X):
        # Si vienen DataFrames o similares, extrae el ndarray:
        X_arr = X.values if hasattr(X, "values") else X
        # Ahora reshape en el ndarray:
        X3 = X_arr.reshape((X_arr.shape[0], 1, X_arr.shape[1]))
        y_scaled = self.model_.predict(X3, verbose=self.verbose).ravel()
        if self.sy is not None:
            return self.sy.inverse_transform(y_scaled.reshape(-1,1)).ravel()
        return y_scaled

# Artifact: exec exec_216
import pathlib, pickle, datetime

# Artifact: function guardar_rnn
def guardar_rnn(best_estimator, score, metodo, motor,
                selector_scoring, X_cols, Y_ref,
                sx, sy,                         # --- ADDED scaler args ---
                study=None, traza_out=None):

    """
    best_estimator  -> instancia RNNRegressor entrenada
    score           -> m√©trica devuelta por el CV
    metodo          -> m√©todo de selecci√≥n (Pearson, ‚Ä¶)
    motor           -> motor de optimizaci√≥n (RandomSearch, ‚Ä¶)
    selector_scoring-> widget con la m√©trica elegida
    X_cols          -> lista de columnas usadas en X
    Y_ref           -> Y_train (Series o DataFrame) para extraer nombre
    study           -> objeto optuna.study.Study   (solo motor Optuna)
    traza_out       -> panel Output donde imprimir mensajes (opcional)
    """
    try:
        # 1) carpeta destino
        pathlib.Path("modelos_opt").mkdir(exist_ok=True)

        # 2) nombre robusto
        ts  = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        tag = f"rnn_{metodo.lower()}_{motor.lower()}_opt_{ts}"

        # 3) guardar sub-modelo Keras (*.keras)
        keras_f = f"modelos_opt/{tag}.keras"
        best_estimator.model_.save(keras_f, include_optimizer=True)

        # 4) metadatos
        y_name = getattr(Y_ref, "name", None) \
                 or (Y_ref.columns[0] if hasattr(Y_ref, "columns") else "Y")

        meta = dict(
            params       = best_estimator.get_params(),
            score        = float(score),
            func_obj     = selector_scoring.value,
            motor        = motor,
            metodo_x     = metodo,
            cols         = X_cols,
            yname        = y_name,
            fecha        = ts,
            sx           = sx,                 # --- ADDED ---
            sy           = sy                  # --- ADDED ---
        )
        with open(f"modelos_opt/{tag}_meta.pkl", "wb") as f:
            pickle.dump(meta, f)

        # 5) study Optuna (si procede)
        if motor.lower() == "optuna" and study is not None:
            with open(f"modelos_opt/{tag}_study.pkl", "wb") as f:
                pickle.dump(study, f)

        # 6) log
        if traza_out is not None:
            with traza_out:
                print(f"üíæ Modelo guardado     ‚Üí {keras_f}")
                print(f"üíæ Metadatos guardados ‚Üí {tag}_meta.pkl")
                if motor.lower() == "optuna" and study is not None:
                    print(f"üíæ Study Optuna       ‚Üí {tag}_study.pkl")

    except Exception as e:
        txt = f"‚ö†Ô∏è No se pudo guardar modelo/estudio: {e}"
        if traza_out is not None:
            with traza_out: print(txt)
        else:
            print(txt)

# Artifact: function mostrar_optimizacion_rnn
def mostrar_optimizacion_rnn():
    """
    Carga las variables X, Y y FECHAS de los conjuntos Train/Test
    seg√∫n el m√©todo de selecci√≥n escogido.
    Permite preview, selecci√≥n de motores, y ejecuta RandomSearchCV
    sobre el wrapper RNNRegressor.
    """
    global X_train_sel, Y_train_sel, FECHAS_train_sel
    global X_test_sel, Y_test_sel, FECHAS_test_sel
    global X_train, Y_train, FECHAS_train, X_test, Y_test, FECHAS_test
    global RESUMEN_METODOS

    global OPT_MODELS
    if 'OPT_MODELS' not in globals() or not isinstance(OPT_MODELS, dict):
        OPT_MODELS = {}
    # ‚îÄ‚îÄ ESCALERS GLOBALES PARA PASAR A guardar_rnn ‚îÄ‚îÄ
    global sx, sy
    sx, sy = None, None

    with out_opt_rnn:
        clear_output(wait=True)
        # Verificar que los conjuntos existan
        required = ['X_train','Y_train','FECHAS_train','X_test','Y_test','FECHAS_test']
        missing = [v for v in required if v not in globals()]
        if missing:
            print(f"‚ùå Faltan datos: {', '.join(missing)}. Ejecuta la segmentaci√≥n antes.")
            return

        # 2) Ahora s√≠ puedo sanear columnas
        # Usar sanitize_name para limpiar columnas en el payload
        def clean_cols(col_list):
            return [sanitize_name(c) for c in col_list]
        # Ejemplo de sanitizaci√≥n de X_train antes de fit
        X_train.columns = [sanitize_name(col) for col in X_train.columns]
        X_test.columns = [sanitize_name(col) for col in X_test.columns]

        # Dropdown de m√©todos de selecci√≥n
        metodos = ['Pearson','Spearman','MutualInfo','Boruta','UMAP']
        selector_metodo = widgets.Dropdown(
            options=['Todos'] + metodos,
            description='M√©todo X:',
            layout=widgets.Layout(width='300px')
        )
        # Bot√≥n de carga de variables y preview
        btn_cargar = widgets.Button(description='üì• Cargar Variables', button_style='primary')
        salida_carga = widgets.Output()

        # Selector de motores (incluye Todos)
        motores = ['RandomSearch','Bayesian','Hyperband','Optuna']
        selector_motor = widgets.SelectMultiple(
            options=['Todos'] + motores,
            description='Motores:',
            layout=widgets.Layout(width='300px', height='100px')
        )
        # Scoring, CV y N¬∫ iteraciones
        selector_scoring = widgets.Dropdown(
            options=['r2','neg_mean_squared_error','neg_mean_absolute_error'],
            value='r2',
            description='Scoring:',
            layout=widgets.Layout(width='300px')
        )
        cv = widgets.IntSlider(value=5, min=2, max=10, step=1, description='cv:')
        n_iter = widgets.IntSlider(value=10, min=5, max=100, step=1, description='N¬∫ iter:')
        progreso_reloj = widgets.HTML('‚è±Ô∏è 00:00:00')
        # Bot√≥n de ejecuci√≥n
        btn_ejecutar = widgets.Button(description='üöÄ Ejecutar Optimizaci√≥n', button_style='success')
        salida_logs = widgets.Output()

        # === cargar_variables: filtra y muestra preview ===
        def cargar_variables(_):
            global X_train_sel, Y_train_sel, FECHAS_train_sel
            global X_test_sel, Y_test_sel, FECHAS_test_sel
            salida_carga.clear_output(wait=True)

            metodo = selector_metodo.value
            with salida_carga:
                # Determinar columnas X
                if metodo == 'Todos':
                    cols = sorted({c for m in metodos for c in RESUMEN_METODOS.get(m, [])})
                else:
                    cols = RESUMEN_METODOS.get(metodo, [])
                if not cols:
                    print(f"‚ùå No hay variables para '{metodo}'.")
                    return

                X_train_sel = X_train[cols].copy()
                Y_train_sel = Y_train.copy()
                FECHAS_train_sel = FECHAS_train.copy()
                X_test_sel  = X_test[cols].copy()
                Y_test_sel  = Y_test.copy()
                FECHAS_test_sel  = FECHAS_test.copy()

                # Preview robusto: concat por posici√≥n (reset_index) para evitar NaN
                df_train = pd.concat([
                    X_train_sel.head(5).reset_index(drop=True),
                    Y_train_sel.head(5).reset_index(drop=True),
                    FECHAS_train_sel.head(5).reset_index(drop=True).rename('Fecha')
                ], axis=1)
                df_train['Tipo'] = 'Train'

                df_test = pd.concat([
                    X_test_sel.head(5).reset_index(drop=True),
                    Y_test_sel.head(5).reset_index(drop=True),
                    FECHAS_test_sel.head(5).reset_index(drop=True).rename('Fecha')
                ], axis=1)
                df_test['Tipo'] = 'Test'

                # --- ADDED: crear y guardar scalers ---
                global sx, sy
                sx = StandardScaler().fit(X_train_sel.values)
                sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                with salida_carga:
                    print(f"‚úÖ Cargadas {len(cols)} variables y escalers preparados para '{metodo}'")

                df_preview = pd.concat([df_train, df_test], ignore_index=True)
                display(HTML("<h4>üìã Preview Train/Test (5 filas cada uno)</h4>"))
                display(df_preview)

        # === ejecutar_optimizacion: RandomSearchCV con RNNRegressor ===
        def ejecutar_optimizacion(_):
            # Iniciar reloj
            stop_event = threading.Event()
            start_time = time.time()
            def run_clock():
                while not stop_event.is_set():
                    elapsed = int(time.time() - start_time)
                    h, rem = divmod(elapsed, 3600)
                    m, s   = divmod(rem, 60)
                    progreso_reloj.value = f"‚è±Ô∏è {h:02d}:{m:02d}:{s:02d}"
                    time.sleep(1)
            t = threading.Thread(target=run_clock, daemon=True)
            t.start()

            salida_logs.clear_output(wait=True)
            #start_time = time.time()  # inicio temporizador

            with salida_logs:
                resultados = []
                # determinar m√©todos
                sel_met = selector_metodo.value
                methods = metodos.copy() if sel_met=='Todos' else [sel_met]
                # determinar motores
                sel_mot = list(selector_motor.value)
                mot_sel = motores if 'Todos' in sel_mot else sel_mot

                for metodo in methods:

                    # (Aqu√≠ va la parte para obtener `cols` desde RESUMEN_METODOS)
                    if metodo == 'Todos':
                        cols = []
                        for m_aux in metodos:
                            cols += RESUMEN_METODOS.get(m_aux, [])
                        cols = sorted(set(cols))
                    else:
                        cols = RESUMEN_METODOS.get(metodo, [])

                    for motor in mot_sel:
                        # ‚úÖ AQUI VA el bloque que te he entregado
                        print(f"‚û°Ô∏è {motor} en '{metodo}'‚Ä¶")

                        # Validar columnas existentes
                        effective_cols = [c for c in cols if c in X_test.columns]
                        print(f"[DEBUG] RNN m√©todo '{metodo}' - columnas esperadas: {len(cols)}, v√°lidas: {len(effective_cols)} ‚Üí {effective_cols}")

                        if len(effective_cols) < 2:
                            print(f"‚ö†Ô∏è Se omite '{metodo}' con motor '{motor}' porque solo seleccion√≥ {len(effective_cols)} columnas v√°lidas: {effective_cols}")
                            continue

                        # Preparar subconjuntos
                        X_train_sel = X_train[effective_cols].copy()
                        Y_train_sel = Y_train.copy()
                        FECHAS_train_sel = FECHAS_train.copy()

                        X_test_sel  = X_test[effective_cols].copy()
                        Y_test_sel  = Y_test.copy()
                        FECHAS_test_sel  = FECHAS_test.copy()

                        X_test_vals = X_test_sel.values
                        y_test_vals = Y_test.values.ravel()

                        kr = RNNRegressor()
                        # ============================================
                        # Motor de optimizaci√≥n RandomSearch
                        # ============================================
                        if motor == 'RandomSearch':
                            # ‚Äî‚Äî‚Äî A√ëADIDO: re-ajustar escaladores para el filtrado actual ‚Äî‚Äî‚Äî
                            sx = StandardScaler().fit(X_train_sel.values)
                            sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                            # preparar datos (ahora con el scaler correcto)
                            Xv = sx.transform(X_train_sel.values)
                            yv = sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            # Distribuciones de scipy.stats
                            from scipy.stats import randint, uniform, loguniform
                            # Usar nuestro wrapper
                            kr = RNNRegressor(
                                units=64, dropout_rate=0.2,
                                learning_rate=1e-3, epochs=50,
                                batch_size=32, verbose=3
                            )  # NEW
                            rs_params = {
                                'units': randint(10, 61),
                                'dropout_rate': uniform(0.0, 0.5),
                                'learning_rate': loguniform(1e-4, 1e-2),
                                'epochs': randint(50, 401),
                                'batch_size': randint(16, 257)
                            }
                            rs = RandomizedSearchCV(
                                estimator=kr,
                                param_distributions=rs_params,
                                n_iter=n_iter.value,
                                scoring=selector_scoring.value,
                                cv=cv.value,
                                random_state=42,
                                n_jobs=-1,
                                verbose = 3
                            )
                            print("üîç Ejecutando RandomizedSearchCV‚Ä¶")
                            rs.fit(Xv, yv)
                            best = rs.best_estimator_
                            score = rs.best_score_
                            params = rs.best_params_

                        # ============================================
                        # Motor de optimizaci√≥n Bayesian
                        # ============================================
                        elif motor=='Bayesian':
                            # preparar datos
                            #Xv = X_train_sel.values
                            #yv = Y_train_sel.values.ravel()
                            sx = StandardScaler().fit(X_train_sel.values)
                            sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                            Xv = sx.transform(X_train_sel.values)
                            yv = sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            # Usar nuestro wrapper
                            kr = RNNRegressor()
                            #param_space = {
                            bay_params = {
                                'units': Integer(10,60),
                                'dropout_rate': Real(0.0,0.5),
                                'learning_rate': Real(1e-4,1e-2,'log-uniform'),
                                'epochs': Integer(50,400),
                                'batch_size': Integer(16,256)
                            }
                            bs = BayesSearchCV(
                                kr,
                                #param_space,
                                bay_params,
                                n_iter=n_iter.value,
                                scoring=selector_scoring.value,
                                cv=cv.value,
                                random_state=42,
                                n_jobs=-1,
                                verbose=3
                            )
                            print("üîç Ejecutando Bayesian‚Ä¶")
                            bs.fit(Xv,yv)
                            best, score, params = bs.best_estimator_, bs.best_score_, bs.best_params_

                        # ============================================
                        # Motor de optimizaci√≥n Hyperband
                        # ============================================
                        elif motor=='Hyperband':
                            # preparar datos
                            #Xv = X_train_sel.values
                            #yv = Y_train_sel.values.ravel()
                            sx = StandardScaler().fit(X_train_sel.values)
                            sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                            Xv = sx.transform(X_train_sel.values)
                            yv = sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            # Usar nuestro wrapper
                            kr = RNNRegressor()
                            # Distribuciones scipy.stats para Hyperband
                            from scipy.stats import randint, uniform, loguniform
                            hb_params = {
                                'units': randint(10, 61),              # enteros 10‚Äì60
                                'dropout_rate': uniform(0.0, 0.5),      # continuo 0‚Äì0.5
                                'learning_rate': loguniform(1e-4, 1e-2),# log-uniform 1e-4‚Äì1e-2
                                'batch_size': randint(16, 257)         # enteros 16‚Äì256
                            }
                            hb = HalvingRandomSearchCV(
                                estimator=kr,
                                param_distributions=hb_params,
                                factor=3,
                                resource='epochs',
                                #max_resources=400,
                                max_resources=50,
                                scoring=selector_scoring.value,
                                cv=cv.value,
                                #cv=2,
                                random_state=42,
                                #n_jobs=-1,
                                n_jobs=1,
                                verbose=3,
                                error_score='raise'
                            )
                            print("üîç Ejecutando Hyperband‚Ä¶")
                            hb.fit(Xv,yv)
                            best, score, params = hb.best_estimator_, hb.best_score_, hb.best_params_

                        # ============================================
                        # Motor de optimizaci√≥n Optuna
                        # ============================================
                        elif motor=='Optuna':
                            # Preparamos los datos
                            #Xv = X_train_sel.values
                            #yv = Y_train_sel.values.ravel()
                            sx = StandardScaler().fit(X_train_sel.values)
                            sy = StandardScaler().fit(Y_train_sel.values.reshape(-1,1))
                            Xv = sx.transform(X_train_sel.values)
                            yv = sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            kr = RNNRegressor()  # wrapper limpio
                            import optuna
                            def objective(trial):
                                # Sugerencia de hiperpar√°metros
                                units = trial.suggest_int('units', 10, 20)
                                dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)
                                learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)
                                epochs = trial.suggest_int('epochs', 50, 100)
                                batch_size = trial.suggest_int('batch_size', 16, 256)
                                # Instanciamos y entrenamos el modelo
                                model = RNNRegressor(
                                    units=units,
                                    dropout_rate=dropout_rate,
                                    learning_rate=learning_rate,
                                    epochs=epochs,
                                    batch_size=batch_size,
                                    verbose=3
                                )
                                model.fit(Xv, yv)
                                preds = model.predict(Xv)
                                # Devolvemos la m√©trica a optimizar
                                if selector_scoring.value == 'r2':
                                    return r2_score(yv, preds)
                                elif selector_scoring.value == 'neg_mean_squared_error':
                                    return -mean_squared_error(yv, preds)
                                else:  # neg_mean_absolute_error
                                    return -mean_absolute_error(yv, preds)
                            # Creamos y ejecutamos el estudio
                            study = optuna.create_study(
                                direction='maximize'
                                if selector_scoring.value == 'r2'
                                else 'minimize'
                            )
                            study.optimize(objective, n_trials=n_iter.value)
                            # Recuperamos los mejores par√°metros y entrenamos el modelo final
                            best_params = study.best_params
                            best = RNNRegressor(**best_params)
                            best.fit(Xv, yv)
                            # Interpretamos el score devuelto
                            if selector_scoring.value == 'r2':
                                score = study.best_value
                            else:
                                score = -study.best_value
                            params = best_params

                        else:
                            best=None
                            score = None
                            params = {}

                        # üóÑÔ∏è GUARDAR MODELO / METADATOS  ‚Üê‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï
                        guardar_rnn(best, score, metodo, motor,
                                    selector_scoring, cols, Y_train,
                                    sx, sy,                    # <-- ahora son obligatorios
                                    study if motor=='Optuna' else None,
                                    traza_out=salida_logs)
                        # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

                        # ‚îÄ‚îÄ A√ëADIR REGISTRO EN OPT_MODELS AQU√ç ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                        # construimos el tag y las rutas (deber√≠an coincidir con las usadas en guardar_rnn)
                        ts       = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                        tag      = f"rnn_{metodo.lower()}_{motor.lower()}_opt_{ts}"
                        model_f  = f"modelos_opt/{tag}.keras"
                        meta_f   = f"modelos_opt/{tag}_meta.pkl"

                        OPT_MODELS[('rnn', metodo, motor)] = {
                            'model_path': model_f,
                            'meta_path' : meta_f,
                            'score'     : float(score),
                            'metric'    : selector_scoring.value,   # ‚Üê aqu√≠ la m√©trica
                            'params'    : params,
                            'model'     : best,
                            'cols'      : cols,
                            'sx'        : sx,
                            'sy'        : sy
                        }
                        # Si es Optuna, guarda tambi√©n la ruta al study
                        if motor.lower() == 'optuna' and study is not None:
                            OPT_MODELS[('rnn', metodo, motor)]['study_path'] = f"modelos_opt/{tag}_study.pkl"

                        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

                        resultados.append({
                            'metodo':metodo,
                            'motor':motor,
                            'score':score,
                            'params':params,
                            'best':best
                        })
                # Detener reloj
                stop_event.set()
                t.join()
                # mostrar mejor
                valid = [r for r in resultados if r['score'] is not None]
                if valid:
                    best_r = max(valid, key=lambda x: x['score'])
                    print("\nüèÜ Mejor optimizaci√≥n:")
                    print(f"  M√©todo: {best_r['metodo']}")
                    print(f"  Motor: {best_r['motor']}")
                    print(f"  Score: {best_r['score']:.4f}")
                    print(f"  Params: {best_r['params']}")

                    # === Gr√°ficas del mejor modelo ===
                    modelo_best = best_r['best']
                    metodo_best = best_r['metodo']
                    cols_best   = [sanitize_name(c) for c in RESUMEN_METODOS.get(metodo_best, [])]

                    # Filtramos columnas v√°lidas que est√©n presentes
                    effective_cols = [c for c in cols_best if c in X_test.columns]
                    if len(effective_cols) < 2:
                        print(f"‚ö†Ô∏è El m√©todo '{metodo_best}' no tiene columnas v√°lidas para el Test. Se omite predicci√≥n.")
                    else:
                        X_test_vals = X_test[effective_cols].copy().values
                        y_test_vals = Y_test.values.ravel()
                        fechas      = FECHAS_test.values

                        # 1) calcula la predicci√≥n escalada
                        y_pred_scaled = modelo_best.predict(X_test_vals)
                        # 2) inversa de sy para volver a la escala original
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()
                        residuos = y_test_vals - y_pred

                        # Gr√°fico de puntos Y real. vs. Y predicho por fecha
                        plt.figure(figsize=(8,3))
                        plt.scatter(fechas, y_test_vals, label='Y real')
                        plt.scatter(fechas, y_pred, label='Y predicha')
                        plt.xlabel('Fecha')
                        plt.ylabel('Y')
                        plt.title('Y real vs predicha por Fecha')
                        plt.legend()
                        plt.tight_layout()
                        plt.show()

                        # Gr√°fico scatter Y real vs Y predicha
                        plt.figure(figsize=(5,5))
                        plt.scatter(y_test_vals, y_pred, alpha=0.6)
                        plt.plot([y_test_vals.min(), y_test_vals.max()], [y_test_vals.min(), y_test_vals.max()], 'r--', label='Ideal')
                        plt.xlabel('Y real'); plt.ylabel('Y predicha'); plt.title('Y real vs Y predicha')
                        plt.tight_layout(); plt.legend(); plt.show()

                        # Histograma residuos con Normal y KDE
                        plt.figure(figsize=(6,4))
                        from scipy.stats import norm, gaussian_kde, shapiro
                        n,bins,_ = plt.hist(residuos, bins=20, density=True, alpha=0.6, label='Residuos')
                        mu, sd = norm.fit(residuos)
                        x = np.linspace(bins.min(), bins.max(), 100)
                        plt.plot(x, norm.pdf(x, mu, sd), 'r--', label='Normal')
                        kde = gaussian_kde(residuos)
                        plt.plot(x, kde(x), 'g-', label='KDE')
                        plt.xlabel('Residuo'); plt.ylabel('Densidad'); plt.title('Histograma de residuos')
                        plt.legend(); plt.tight_layout(); plt.show()

                        # Test de normalidad Shapiro-Wilk
                        stat, p_value = shapiro(residuos)
                        print(f"üß™ Shapiro-Wilk: estad√≠stico={stat:.4f}, p-valor={p_value:.4f} -> {'Normal' if p_value > 0.05 else 'No normal'}")

                else:
                    print("‚ö†Ô∏è No hay resultados con score definido.")
                # Tabla completa de optimizaciones
                df_all=pd.DataFrame(resultados)
                display(HTML("<h4>üìä Todos los resultados de optimizaci√≥n</h4>"))
                display(df_all)

        # enlazar callbacks
        btn_cargar.on_click(cargar_variables)
        btn_ejecutar.on_click(ejecutar_optimizacion)

        # mostrar interfaz
        display(HTML("<h3>üîß Optimizaci√≥n RNN - Carga y Motores</h3>"))
        display(widgets.VBox([
            selector_metodo,
            btn_cargar,
            salida_carga,
            selector_motor,
            selector_scoring,
            cv,
            n_iter,
            progreso_reloj,
            btn_ejecutar,
            salida_logs
        ]))

# Artifact: exec exec_219
display(out_opt_rnn)

# Artifact: exec exec_220
import glob, io, base64, pickle, random, pprint

# Artifact: exec exec_221
from pathlib import Path

# Artifact: exec exec_222
import os, re

# Artifact: exec exec_223
from tensorflow.keras.losses import MeanSquaredError

# Artifact: exec exec_224
from shap import TreeExplainer, KernelExplainer, GradientExplainer, DeepExplainer

# Artifact: exec exec_225
from lime.lime_tabular import LimeTabularExplainer

# Artifact: exec exec_226
from sklearn.inspection import permutation_importance

# Artifact: exec exec_227
from sklearn.neighbors import NearestNeighbors

# Artifact: exec exec_228
from sklearn.tree import DecisionTreeRegressor

# Artifact: exec exec_229
from sklearn.linear_model import LinearRegression

# Artifact: exec exec_230
try:
    from interpret.glassbox import ExplainableBoostingRegressor
except ImportError:
    ExplainableBoostingRegressor = None

# Artifact: exec exec_231
if 'xai_results' not in globals():                        # Nuevo para celda 12
    xai_results = {}

# Artifact: assign MODEL_KEYS
MODEL_KEYS = {
    'SVR': 'svr',
    'NN': 'nn',
    'XGBoost': 'xgb',
    'Random Forest': 'rf',
    'RNN': 'rnn'
}

# Artifact: assign ALL_MOTORES
ALL_MOTORES = [
    "SHAP",
    "LIME",
    "KernelExplainer",
    "Integrated Gradients",
    "DeepLIFT / LRP",
    "Permutation Feature Importance",
    "Partial Dependence Plots (PDP)",
    "Accumulated Local Effects (ALE)",
    "Individual Conditional Expectation (ICE) Plots",
    "Counterfactual Explanations",
    "Anchors",
    "Surrogate Models (Global/Local)",
    "Explainable Boosting Machine (EBM)",
    "Optuna Hyperparameter Importance"
]

# Artifact: exec exec_234
display(HTML("""
<style>
/* Ancho y tipograf√≠a de los widgets */
.widget-dropdown, .widget-select-multiple, .widget-button {
  width: 400px !important;       /* cajas m√°s anchas */
  font-size: 14px !important;    /* texto de 14px */
}
.widget-dropdown > label, .widget-select-multiple > label {
  font-size: 14px !important;    /* etiquetas tambi√©n grandes */
}
</style>
"""))

# Artifact: assign TRAINED_MODELS
TRAINED_MODELS = [f"{m}" for m in MODEL_KEYS]

# Artifact: assign OPTIMIZED_MODELS
OPTIMIZED_MODELS = [f"{m}" for m in MODEL_KEYS]

# Artifact: assign SELECT_METHODS
SELECT_METHODS = ['Pearson', 'Spearman', 'Mutualinfo', 'Boruta', 'UMAP']

# Artifact: assign XAI_METHODS
XAI_METHODS = [
    'SHAP', 'LIME', 'KernelExplainer', 'Integrated Gradients',
    'DeepLIFT / LRP', 'Permutation Feature Importance',
    'Partial Dependence Plots (PDP)', 'Accumulated Local Effects (ALE)',
    'Individual Conditional Expectation (ICE) Plots',
    'Counterfactual Explanations', 'Anchors',
    'Surrogate Models (Global/Local)', 'Explainable Boosting Machine (EBM)',
    'Optuna Hyperparameter Importance', 'Todos'
]

# Artifact: assign XAI_HELP
XAI_HELP = {
    'SHAP': (
        '<h4>SHAP</h4>'
        '<p><b>SHAP</b> (SHapley Additive exPlanations) utiliza teor√≠a de juegos para descomponer '
        'la predicci√≥n de un modelo en aportes aditivos de cada caracter√≠stica.</p>'
        '<p><b>Valores SHAP:</b> representan la contribuci√≥n de cada variable a la predicci√≥n final.</p>'
        '<ul>'
        '<li><b>Empuje hacia arriba (positivo):</b> indica que la variable incrementa la predicci√≥n respecto al valor base.</li>'
        '<li><b>Empuje hacia abajo (negativo):</b> indica que la variable decrementa la predicci√≥n respecto al valor base.</li>'
        '</ul>'
        '<p>El <i>valor base</i> es la predicci√≥n promedio del modelo sin conocer ninguna caracter√≠stica.</p>'
        '<p>Para un punto de datos, la suma de los valores SHAP m√°s el valor base equivale a la predicci√≥n del modelo.</p>'
    ),
    'LIME': (
        '<h4>LIME</h4>'
        '<p><b>LIME</b> (Local Interpretable Model-agnostic Explanations) explica la predicci√≥n '
        'de cualquier modelo construyendo, en la vecindad de la instancia, un modelo lineal simple.</p>'
        '<ul>'
          '<li>Se perturban aleatoriamente las caracter√≠sticas de la muestra.</li>'
          '<li>Se calcula la predicci√≥n del modelo ‚Äúnegro‚Äù.</li>'
          '<li>Se ajusta una funci√≥n lineal ponderada por proximidad al punto original.</li>'
          '<li>Los coeficientes resultantes indican direcci√≥n y magnitud de influencia local.</li>'
        '</ul>'
        '<p><b>Interpretaci√≥n:</b> coeficiente positivo ‚áí la caracter√≠stica empuja la predicci√≥n hacia arriba; '
        'coeficiente negativo ‚áí la empuja hacia abajo.</p>'
    ),
    'KernelExplainer': (
        '<h4>KernelExplainer</h4>'
        '<p><b>KernelExplainer</b> es una extensi√≥n de SHAP para modelos de caja negra, '
        'usando un n√∫cleo de similitud para aproximar valores SHAP sin requerir acceso a gradientes.</p>'
        '<ul>'
        '<li><b>Fondo (background):</b> subconjunto de datos para estimar valor base.</li>'
        '<li><b>Valor base:</b> predicci√≥n promedio del fondo.</li>'
        '<li><b>Valores Kernel SHAP:</b> contribuciones de cada caracter√≠stica calculadas mediante ponderaciones del n√∫cleo.</li>'
        '<li><b>Empuje hacia arriba (positivo):</b> la caracter√≠stica aumenta la predicci√≥n con respecto al valor base.</li>'
        '<li><b>Empuje hacia abajo (negativo):</b> la caracter√≠stica disminuye la predicci√≥n.</li>'
        '</ul>'
        '<p>El m√©todo pesa cada combinaci√≥n de caracter√≠sticas seg√∫n su similitud al punto de inter√©s, '
        'ofreciendo explicaciones globales y locales.</p>'
        '<p><i>Interpretaci√≥n de tablas:</i> cada fila es una muestra, columnas son caracter√≠sticas; '
        'valores muestran su empuje.</p>'
        '<p><i>Interpretaci√≥n del gr√°fico summary:</i> distribuci√≥n de valores Kernel SHAP, '
        'el color indica magnitud de la caracter√≠stica.</p>'
    ),
    'Integrated Gradients': (
        '<h4>Integrated Gradients</h4>'
        '<p><b>Integrated Gradients</b> es un m√©todo de atribuci√≥n para modelos diferenciables, '
        'que integra gradientes desde una referencia (p.ej. vector cero) hasta la instancia objetivo.</p>'
        '<ul>'
        '<li><b>Ruta de integraci√≥n:</b> l√≠nea recta desde referencia hasta punto de inter√©s en el espacio de caracter√≠sticas.</li>'
        '<li><b>Atributos IG:</b> promedio de gradientes a lo largo de la ruta, ponderando contribuciones.</li>'
        '<li><b>Interpretaci√≥n:</b> valores positivos ‚ûî aumento de predicci√≥n; valores negativos ‚ûî disminuci√≥n.</li>'
        '</ul>'
        '<p><i>Interpretaci√≥n de tablas:</i> cada fila es una muestra, columnas son caracter√≠sticas; '
        'valores muestran la contribuci√≥n integrada.</p>'
        '<p><i>Interpretaci√≥n de gr√°fico:</i> distribuci√≥n de valores IG, destacando variables con mayores efectos acumulados.</p>'
    ),
    'DeepLIFT / LRP': (
        '<h4>DeepLIFT / LRP</h4>'
        '<p><b>DeepLIFT</b> y <b>Layer-wise Relevance Propagation (LRP)</b> son m√©todos de atribuci√≥n que '
        'propagan la relevancia de la salida de la red hacia atr√°s a cada neurona de entrada.</p>'
        '<ul>'
        '<li><b>Relevancia positiva:</b> indica que la caracter√≠stica contribuy√≥ a aumentar la salida.</li>'
        '<li><b>Relevancia negativa:</b> indica que la caracter√≠stica contribuy√≥ a disminuir la salida.</li>'
        '</ul>'
        '<p>La suma de las relevancias de entrada equivale a la activaci√≥n de salida menos la referencia.</p>'
        '<p><b>Interpretaci√≥n de tabla:</b> cada fila es una muestra, columnas son caracter√≠sticas y valores de relevancia.</p>'
        '<p><b>Interpretaci√≥n de gr√°fico:</b> barras muestran relevancia media global.</p>'
    ),
    'Permutation Feature Importance': (
        '<h4>Permutation Feature Importance</h4>'
        '<p>Mide la importancia de cada caracter√≠stica evaluando la ca√≠da en rendimiento '
        'al permutar sus valores.</p>'
        '<ul>'
        '<li>Para cada variable, se permutan sus valores en el dataset de prueba.</li>'
        '<li>Se mide la diferencia en la m√©trica (p.ej. R¬≤).</li>'
        '<li>Una ca√≠da mayor indica mayor importancia de esa variable.</li>'
        '</ul>'
        '<p>Interpretaci√≥n de la tabla:</p>'
        '<ul>'
        '<li><b>Mean Importance:</b> promedio de las ca√≠das de rendimiento tras permutar.</li>'
        '<li><b>Std Importance:</b> variabilidad en esos descensos.</li>'
        '</ul>'
        '<p>Interpretaci√≥n del gr√°fico:</p>'
        '<ul>'
        '<li>Puntos representan importancia media; barras de error, desviaci√≥n est√°ndar.</li>'
        '</ul>'
    ),
    'Partial Dependence Plots (PDP)': (
        '<h4>Partial Dependence Plots (PDP)</h4>'
        '<p><b>Partial Dependence Plots</b> (PDP) permiten visualizar el efecto medio que tiene una variable (o par de variables) '
        'sobre la predicci√≥n de un modelo, manteniendo fijas todas las dem√°s. Es un m√©todo global y agn√≥stico al modelo, muy √∫til para '
        'entender la direcci√≥n (positiva o negativa) y la magnitud del impacto de cada caracter√≠stica.</p>'

        '<h5>¬øC√≥mo se calcula?</h5>'
        '<ul>'
        '<li>Se selecciona una variable y se construye una rejilla de valores representativos en su rango.</li>'
        '<li>Para cada valor de la rejilla, se reemplaza dicha variable en todas las observaciones del conjunto de datos con ese valor.</li>'
        '<li>Se predice el valor objetivo para este nuevo dataset y se calcula la media de las predicciones.</li>'
        '<li>Estos valores promedio constituyen la <b>curva PDP</b> de la variable.</li>'
        '</ul>'

        '<h5>Interpretaci√≥n:</h5>'
        '<ul>'
        '<li>El <b>eje X</b> representa los valores posibles de la variable analizada.</li>'
        '<li>El <b>eje Y</b> representa la predicci√≥n promedio del modelo cuando la variable toma esos valores.</li>'
        '<li>Una <b>pendiente positiva</b> indica que un aumento de la variable incrementa la predicci√≥n media.</li>'
        '<li>Una <b>pendiente negativa</b> indica que un aumento de la variable reduce la predicci√≥n media.</li>'
        '</ul>'

        '<h5>Importancia global con PDP:</h5>'
        '<p>En este motor se calcula como el <b>rango</b> (m√°ximo menos m√≠nimo) de la curva PDP. '
        'Esto representa cu√°nto puede cambiar la predicci√≥n promedio si se modifica la variable a lo largo de todo su dominio. '
        'Cuanto mayor el rango, mayor es la importancia de esa variable en el comportamiento del modelo.</p>'

        '<h5>Importancia local:</h5>'
        '<p>Tambi√©n se calcula una tabla con los efectos PDP para las primeras muestras del conjunto de datos. '
        'Para cada muestra y variable, se eval√∫a cu√°nto cambia la predicci√≥n promedio cuando se fija la variable al valor observado '
        'y se mantiene el resto con su distribuci√≥n real. Esto permite interpretar el efecto individual de cada caracter√≠stica '
        'en una muestra espec√≠fica, de forma an√°loga a SHAP o LIME.</p>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>No tiene en cuenta interacciones entre variables (a menos que se usen PDP bivariados).</li>'
        '<li>Puede ser enga√±oso si hay fuerte correlaci√≥n entre variables (reemplazar una variable puede generar combinaciones no plausibles).</li>'
        '</ul>'

        '<p><i>En resumen:</i> PDP ayuda a responder: <b>¬øC√≥mo var√≠a la predicci√≥n promedio del modelo cuando cambio una variable concreta?</b></p>'
    ),
    'Accumulated Local Effects (ALE)': (
        '<h4>Accumulated Local Effects (ALE)</h4>'
        '<p><b>ALE</b> (Efectos Locales Acumulados) es un m√©todo de interpretabilidad global que muestra '
        'c√≥mo cambia la predicci√≥n promedio del modelo cuando una caracter√≠stica var√≠a dentro de su dominio, '
        'teniendo en cuenta las correlaciones entre variables.</p>'

        '<h5>¬øC√≥mo se calcula?</h5>'
        '<ul>'
        '<li>Se divide el rango de una variable en <i>bins</i> (intervalos), usualmente basados en cuantiles para que contengan un n√∫mero similar de observaciones.</li>'
        '<li>En cada bin, se mide el efecto local de cambiar el valor de la variable desde el l√≠mite inferior al superior, manteniendo fijas las dem√°s variables.</li>'
        '<li>Estos efectos se acumulan a lo largo de los bins, produciendo una <b>curva ALE</b> que muestra c√≥mo influye la variable sobre la predicci√≥n.</li>'
        '</ul>'

        '<h5>Ventajas frente a PDP:</h5>'
        '<ul>'
        '<li><b>Robusto ante correlaciones:</b> A diferencia de PDP, ALE no genera combinaciones irreales de variables, ya que respeta la distribuci√≥n original de los datos.</li>'
        '<li><b>Computacionalmente eficiente:</b> S√≥lo eval√∫a muestras dentro de cada bin, evitando duplicaciones masivas.</li>'
        '</ul>'

        '<h5>Interpretaci√≥n:</h5>'
        '<ul>'
        '<li>El eje <b>X</b> representa el valor de la variable (centrado por defecto).</li>'
        '<li>El eje <b>Y</b> representa el efecto acumulado sobre la predicci√≥n del modelo.</li>'
        '<li>Una pendiente positiva indica que aumentar esa variable tiende a aumentar la predicci√≥n.</li>'
        '<li>Una pendiente negativa indica lo contrario.</li>'
        '</ul>'

        '<h5>Importancia global:</h5>'
        '<p>En este motor, la <b>importancia global</b> de una variable se calcula como el <b>rango</b> '
        'de su curva ALE (es decir, la diferencia entre el valor m√°ximo y m√≠nimo del efecto acumulado). '
        'Un mayor rango implica mayor impacto medio de esa caracter√≠stica sobre la salida del modelo.</p>'

        '<h5>Importancia local:</h5>'
        '<p>Se muestran los valores ALE correspondientes a las primeras muestras del conjunto de datos. '
        'Estos valores permiten entender el efecto individual de cada variable sobre la predicci√≥n de cada observaci√≥n.</p>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>Asume que los efectos son aditivos y no modela expl√≠citamente interacciones (aunque puede ampliarse con ALE 2D).</li>'
        '<li>Puede suavizar excesivamente relaciones no lineales muy complejas si se usan pocos bins.</li>'
        '</ul>'

        '<p><i>Resumen:</i> ALE es una t√©cnica moderna, confiable y robusta para evaluar la importancia de cada variable '
        'respetando la estructura estad√≠stica real del dataset.</p>'
    ),
    'Individual Conditional Expectation (ICE) Plots': (
        '<h4>Individual Conditional Expectation (ICE) Plots</h4>'
        '<p><b>ICE</b> es una t√©cnica de interpretabilidad local que representa c√≥mo var√≠a la predicci√≥n de un modelo '
        'para una observaci√≥n concreta cuando se modifica una de sus caracter√≠sticas, manteniendo fijas las dem√°s. '
        'Es una generalizaci√≥n del m√©todo PDP (Partial Dependence Plots), pero a nivel individual.</p>'

        '<h5>¬øC√≥mo se calcula?</h5>'
        '<ul>'
        '<li>Para una observaci√≥n concreta, se generan m√∫ltiples versiones de ella cambiando solo una variable (por ejemplo, X1) a lo largo de un rango de valores.</li>'
        '<li>Se eval√∫a el modelo sobre estas versiones y se obtienen las predicciones correspondientes.</li>'
        '<li>La curva resultante muestra c√≥mo cambia la salida del modelo solo por esa variable en esa observaci√≥n concreta.</li>'
        '<li>Repitiendo esto para varias muestras, se obtiene un conjunto de curvas ICE que capturan efectos individuales.</li>'
        '</ul>'

        '<h5>Interpretaci√≥n:</h5>'
        '<ul>'
        '<li>Las curvas muestran c√≥mo cambia la predicci√≥n de cada muestra cuando se var√≠a una caracter√≠stica.</li>'
        '<li>Permiten detectar <b>interacciones no lineales</b>, <b>heterogeneidad de efectos</b> o <b>inestabilidad</b> en el modelo.</li>'
        '<li>Cuando todas las curvas son paralelas, la relaci√≥n es globalmente estable (similar al PDP).</li>'
        '<li>Cuando las curvas difieren fuertemente entre s√≠, la variable tiene un efecto que depende del resto del contexto (otras variables).</li>'
        '</ul>'

        '<h5>Importancia global:</h5>'
        '<p>En este motor, la importancia global de una variable se calcula como la <b>media del rango</b> de las curvas ICE sobre un subconjunto de muestras. '
        'Este valor representa cu√°nto cambia, en promedio, la predicci√≥n individual cuando se var√≠a esa caracter√≠stica. '
        'Un mayor rango indica mayor influencia.</p>'

        '<h5>Importancia local:</h5>'
        '<p>Se muestra tambi√©n una tabla con los <b>rangos individuales ICE</b> para las primeras observaciones del conjunto. '
        'Esto permite ver c√≥mo de sensible es cada muestra a cambios en una variable concreta.</p>'

        '<h5>Ventajas:</h5>'
        '<ul>'
        '<li>Captura <b>efectos individuales</b>, no promedios, lo que permite diagn√≥sticos precisos por observaci√≥n.</li>'
        '<li>Permite detectar comportamientos at√≠picos, interacciones complejas y sesgos locales.</li>'
        '</ul>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>Puede ser ruidoso si se muestran demasiadas curvas simult√°neamente.</li>'
        '<li>Como PDP, puede generar combinaciones irreales si las variables est√°n fuertemente correlacionadas.</li>'
        '</ul>'

        '<p><i>Resumen:</i> ICE muestra <b>c√≥mo cambia la predicci√≥n para cada observaci√≥n</b> al modificar una variable espec√≠fica, '
        'ofreciendo una perspectiva individual que complementa la visi√≥n global de otros m√©todos.</p>'
    ),
    'Counterfactual Explanations' : (
        '<h4>Counterfactual Explanations</h4>'
        '<p>Las <b>explicaciones contrafactuales</b> muestran c√≥mo debe modificarse una observaci√≥n para que el modelo devuelva una predicci√≥n significativamente distinta, con el menor cambio posible en sus variables.</p>'

        '<h5>¬øC√≥mo funciona?</h5>'
        '<ul>'
        '<li>Se parte de una predicci√≥n original y se busca un valor deseado que suponga un cambio relevante (por ejemplo, un +10%).</li>'
        '<li>Se recorren los datos reales del conjunto de entrenamiento en busca de observaciones cuya predicci√≥n cumpla ese cambio.</li>'
        '<li>De entre estas, se selecciona la m√°s cercana (menor distancia) respecto a la observaci√≥n original.</li>'
        '</ul>'

        '<h5>Interpretaci√≥n:</h5>'
        '<ul>'
        '<li>La <b>tabla local</b> muestra los contrafactuales m√°s cercanos para las primeras observaciones.</li>'
        '<li>La <b>importancia global</b> indica el cambio medio absoluto necesario en cada variable para alcanzar el objetivo deseado.</li>'
        '<li>El <b>gr√°fico</b> ayuda a identificar qu√© variables son m√°s influyentes a la hora de cambiar el resultado del modelo.</li>'
        '</ul>'

        '<h5>Ventajas:</h5>'
        '<ul>'
        '<li>Interpretabilidad muy intuitiva: responde a la pregunta "¬øqu√© tendr√≠a que cambiar para obtener otro resultado?"</li>'
        '<li>Utiliza ejemplos reales del dataset, evitando combinaciones irreales.</li>'
        '</ul>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>Puede no encontrar contrafactuales viables si el cambio deseado es muy ambicioso o los datos est√°n muy restringidos.</li>'
        '<li>Los resultados dependen de la densidad del dataset y de su cobertura del espacio de entrada.</li>'
        '</ul>'

        '<p><i>Resumen:</i> Las explicaciones contrafactuales ofrecen una herramienta poderosa y humana para entender qu√© modificaciones m√≠nimas podr√≠an generar resultados m√°s deseables en un modelo de regresi√≥n.</p>'
    ),
    'Anchors' : (
        '<h4>Anchors</h4>'
        '<p><b>Anchors</b> es un m√©todo de explicabilidad local que identifica reglas sencillas tipo "SI/ENTONCES" que justifican una predicci√≥n concreta. Estas reglas act√∫an como <b>anclas</b>, es decir, condiciones que al cumplirse aseguran con alta probabilidad que la predicci√≥n del modelo se mantenga inalterada.</p>'

        '<h5>¬øC√≥mo se generan?</h5>'
        '<ul>'
        '<li>Para cada muestra, se selecciona un conjunto de observaciones vecinas (por ejemplo, mediante muestreo aleatorio).</li>'
        '<li>Se binariza la variable de salida en funci√≥n del valor de la muestra objetivo.</li>'
        '<li>Se entrena un √°rbol de decisi√≥n con profundidad limitada para detectar las reglas que mejor separan los datos seg√∫n esa binarizaci√≥n.</li>'
        '<li>Se extrae la regla correspondiente a la muestra objetivo (el camino en el √°rbol).</li>'
        '</ul>'

        '<h5>Interpretaci√≥n de resultados:</h5>'
        '<ul>'
        '<li>La <b>tabla de reglas ancla</b> muestra, para cada muestra explicada, la regla encontrada, su <i>cobertura</i> (porcentaje de vecinos que la cumplen) y su <i>precisi√≥n</i> (porcentaje de vecinos cubiertos cuya predicci√≥n coincide con la de la muestra).</li>'
        '<li>La <b>tabla de importancia global</b> refleja la frecuencia con la que cada variable aparece en las reglas generadas para las distintas muestras.</li>'
        '<li>El <b>gr√°fico de dispersi√≥n</b> permite visualizar qu√© variables son m√°s recurrentes en las reglas ancla, ayudando a detectar aquellas m√°s influyentes en decisiones locales.</li>'
        '</ul>'

        '<h5>Ventajas:</h5>'
        '<ul>'
        '<li>Alta interpretabilidad, ya que genera explicaciones similares a reglas humanas simples.</li>'
        '<li>Eval√∫a tanto precisi√≥n como cobertura, ofreciendo una visi√≥n balanceada de la fiabilidad de la explicaci√≥n.</li>'
        '</ul>'

        '<h5>Limitaciones:</h5>'
        '<ul>'
        '<li>No siempre se pueden encontrar reglas con buena cobertura y precisi√≥n.</li>'
        '<li>Las explicaciones pueden ser sensibles a la selecci√≥n de vecinos y a la profundidad del √°rbol.</li>'
        '</ul>'

        '<p><i>Resumen:</i> Anchors permite entender las predicciones de un modelo mediante reglas simples que fijan su comportamiento local. Es especialmente √∫til cuando se busca justificar decisiones modelo en t√©rminos comprensibles y accionables.</p>'
    ),
    'Surrogate Models (Global/Local)' : (
        '<h4>Surrogate Models (Global/Local)</h4>'
        '<p>Los modelos sustitutos permiten interpretar el comportamiento de un modelo complejo mediante un segundo modelo interpretable que lo imita. En este motor se utilizan dos enfoques complementarios:</p>'
        '<h5>üîπ Surrogate Global</h5>'
        '<p>Se construye un √°rbol de decisi√≥n de profundidad limitada que se entrena sobre el dataset completo, utilizando como variable dependiente la salida del modelo original. El √°rbol act√∫a como un "modelo proxy" que resume las reglas generales de decisi√≥n del modelo complejo. La tabla resultante muestra la importancia relativa de cada variable en el √°rbol (contribuci√≥n a la reducci√≥n del error).</p>'
        '<h5>üî∏ Surrogate Local</h5>'
        '<p>Para cada una de las primeras muestras se construye un modelo lineal ajustado en su vecindario m√°s cercano. Esto permite identificar qu√© variables tienen mayor influencia en cada caso individual. Se calcula el valor medio absoluto de los coeficientes para todas las variables y se presenta como una medida de importancia local.</p>'
        '<h5>üìä Comparaci√≥n gr√°fica</h5>'
        '<p>El gr√°fico compara visualmente la importancia de cada variable en el modelo global frente a su influencia local promedio. Las variables con alta importancia en ambos enfoques son especialmente robustas. En cambio, si una variable tiene alta influencia local pero no global (o viceversa), puede indicar comportamientos espec√≠ficos o inconsistencias locales.</p>'
        '<h5>‚úÖ Utilidad</h5>'
        '<p>Este enfoque resulta √∫til cuando se desea contrastar patrones globales con explicaciones locales, evaluar consistencia en la importancia de las variables o detectar sesgos o excepciones locales en el modelo.</p>'
        '<h4>Surrogate Models (Global/Local)</h4>'
        '<p>Un <b>modelo sustituto</b> imita el comportamiento del modelo complejo con un algoritmo interpretable.</p>'
        '<h5>Global</h5><p>√Årbol de decisi√≥n entrenado sobre todo el dataset.</p>'
        '<h5>Local</h5><p>Regresiones lineales ajustadas en vecindarios de cada muestra.</p>'
        '<p>Las tablas y el gr√°fico resumen la importancia de variables a ambas escalas.</p>'
    ),
    'Explainable Boosting Machine (EBM)' : (
        '<h4>Explainable Boosting Machine (EBM)</h4>'
        '<p>EBM (Explainable Boosting Machine) es un modelo de aprendizaje autom√°tico de tipo aditivo generalizado (GA¬≤M) que combina interpretabilidad total con capacidad predictiva competitiva.</p>'
        '<p>EBM se basa en boosting de √°rboles muy peque√±os (stumps) que se agregan para aprender funciones univariantes (una por variable) o bivariantes (combinaciones seleccionadas autom√°ticamente). Estas funciones se combinan de forma aditiva para producir la predicci√≥n.</p>'
        '<h5>üß© Funcionamiento:</h5>'
        '<ul>'
        '<li>Para cada variable, se ajusta una funci√≥n parcial que explica su contribuci√≥n a la predicci√≥n.</li>'
        '<li>Estas funciones se aprenden de forma secuencial y se corrigen entre s√≠ (boosting).</li>'
        '<li>Al final, la predicci√≥n total es la suma de todas las contribuciones univariantes + un sesgo.</li>'
        '</ul>'
        '<h5>üìä Salidas del motor:</h5>'
        '<ul>'
        '<li><b>Importancia Global</b>: ganancia relativa de cada funci√≥n parcial, ordenada de mayor a menor.</li>'
        '<li><b>Tabla Local</b>: muestra para las primeras muestras cu√°nto contribuye cada variable (positiva o negativamente) al valor final predicho.</li>'
        '<li><b>Gr√°fico de media absoluta</b>: la media de las contribuciones absolutas refleja la influencia promedio de cada variable.</li>'
        '</ul>'
        '<h5>‚úÖ Interpretabilidad:</h5>'
        '<p>EBM permite visualizar cada funci√≥n de forma directa: c√≥mo cambia la predicci√≥n seg√∫n los valores de una variable. Adem√°s, se pueden explorar interacciones seleccionadas por el modelo.</p>'
        '<h5>üß† Utilidad:</h5>'
        '<p>EBM es especialmente √∫til cuando se requiere una explicaci√≥n precisa, reproducible y completamente interpretable del modelo, sin necesidad de t√©cnicas post-hoc.</p>'
    ),
    'Optuna Hyperparameter Importance' : (
        '<h4>Optuna Hyperparameter Importance</h4>'
        '<p>Este motor de interpretabilidad analiza el impacto de cada hiperpar√°metro en la m√©trica objetivo utilizada durante la optimizaci√≥n autom√°tica con Optuna.</p>'
        '<h5>‚öôÔ∏è ¬øC√≥mo funciona?</h5>'
        '<p>El motor se basa en el m√≥dulo <code>optuna.importance</code>, que estima la importancia de cada hiperpar√°metro utilizando t√©cnicas basadas en permutaciones o regresi√≥n de sustituci√≥n. Eval√∫a c√≥mo var√≠a la m√©trica objetivo (por ejemplo, el error) cuando se altera un hiperpar√°metro en particular, manteniendo los dem√°s fijos.</p>'
        '<ul>'
        '<li>Se utiliza un <code>study</code> previamente entrenado (en memoria o desde un archivo).</li>'
        '<li>Se extraen los <code>trials</code> y se aplica el m√©todo <code>get_param_importances()</code> para obtener las contribuciones relativas.</li>'
        '</ul>'
        '<h5>üìä Salidas interpretables</h5>'
        '<ul>'
        '<li><b>Tabla de Importancia Global</b>: muestra el porcentaje de influencia de cada hiperpar√°metro en la variabilidad del resultado. Cuanto mayor sea la contribuci√≥n, m√°s cr√≠tico es ese par√°metro para mejorar el rendimiento del modelo.</li>'
        '<li><b>Top 10 Trials</b>: recoge los 10 mejores ensayos (trials) con sus hiperpar√°metros y resultados, lo que permite identificar configuraciones √≥ptimas.</li>'
        '<li><b>Gr√°fico de barras</b>: visualiza la importancia relativa de los hiperpar√°metros, facilitando su comparaci√≥n directa.</li>'
        '</ul>'
        '<h5>‚úÖ Utilidad pr√°ctica</h5>'
        '<p>Esta herramienta es especialmente √∫til para:</p>'
        '<ul>'
        '<li>Identificar qu√© hiperpar√°metros son verdaderamente influyentes y cu√°les se pueden fijar o descartar.</li>'
        '<li>Reducir el espacio de b√∫squeda para futuras optimizaciones.</li>'
        '<li>Justificar decisiones sobre tuning del modelo de forma objetiva y visual.</li>'
        '</ul>'
    ),
    'Todos': '<b>Todos</b>: Mostrar todas las explicaciones anteriores.'
}

# Artifact: assign N_SHAP_SAMPLES
N_SHAP_SAMPLES      = 50

# Artifact: assign N_SHAP_BACKGROUND
N_SHAP_BACKGROUND   = 50

# Artifact: assign N_LIME_SAMPLES
N_LIME_SAMPLES      = 50

# Artifact: assign N_KERNEL_SAMPLES
N_KERNEL_SAMPLES    = 50

# Artifact: assign N_KERNEL_BACKGROUND
N_KERNEL_BACKGROUND = 50

# Artifact: assign N_DEEP_SAMPLES
N_DEEP_SAMPLES      = 50

# Artifact: assign N_PERM_SAMPLES
N_PERM_SAMPLES      = 50

# Artifact: assign N_PDP_SAMPLES
N_PDP_SAMPLES       = 50

# Artifact: assign N_ALE_SAMPLES
N_ALE_SAMPLES       = 50

# Artifact: assign N_ICE_SAMPLES
N_ICE_SAMPLES       = 50

# Artifact: assign N_CF_SAMPLES
N_CF_SAMPLES        = 50

# Artifact: assign N_ANCHOR_SAMPLES
N_ANCHOR_SAMPLES    = 50

# Artifact: assign N_SURR_SAMPLES
N_SURR_SAMPLES      = 100

# Artifact: assign N_EBM_SAMPLES
N_EBM_SAMPLES       = 200

# Artifact: assign GRID_RES
GRID_RES            = 20

# Artifact: assign FIRST_SAMPLES
FIRST_SAMPLES       = 10

# Artifact: assign ALE_BINS
ALE_BINS            = 20

# Artifact: assign ICE_SAMPLES
ICE_SAMPLES         = 50

# Artifact: assign CF_SAMPLES
CF_SAMPLES          = 20

# Artifact: assign CF_TARGET_DELTA
CF_TARGET_DELTA     = 0.1

# Artifact: assign ANC_NEIGHBORS
ANC_NEIGHBORS       = 200

# Artifact: assign SURR_TREE_DEPTH
SURR_TREE_DEPTH     = 3

# Artifact: assign SURR_LOCAL_K
SURR_LOCAL_K        = 50

# Artifact: assign SURR_COLOR_GLOBAL
SURR_COLOR_GLOBAL   = "#1f77b4"

# Artifact: assign SURR_COLOR_LOCAL
SURR_COLOR_LOCAL    = "#d62728"

# Artifact: assign EBM_MAX_ITERS
EBM_MAX_ITERS       = 500

# Artifact: assign OPTUNA_STUDY_FILE
OPTUNA_STUDY_FILE = "optuna_study.pkl"

# Artifact: function _load_optuna_study
def _load_optuna_study(path: str):
    if optuna is None:
        return None
    try:
        with open(path, "rb") as f:
            return pickle.load(f)
    except FileNotFoundError:
        return None

# Artifact: function _fig_to_base64
def _fig_to_base64(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight"); plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode()

# Artifact: function _generate_simple_bar
def _generate_simple_bar(title, feats, vals, ylabel):
    fig, ax = plt.subplots(figsize=(4,3))
    ax.bar(feats, vals, color=["green" if v>0 else "red" for v in vals]); ax.axhline(0,c="k")
    ax.set_title(title); ax.set_ylabel(ylabel); plt.tight_layout();
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: assign _generate_shap_diagram
_generate_shap_diagram = lambda : _generate_simple_bar("Ejemplo Valores SHAP", ["X1","X2","X3","X4"], [0.4,-0.3,0.2,-0.1], "SHAP value")

# Artifact: assign _generate_lime_diagram
_generate_lime_diagram = lambda : _generate_simple_bar("Ejemplo Pesos LIME", ["X1","X2","X3","X4"], [0.7,-0.5,0.25,-0.15], "Peso LIME")

# Artifact: assign _generate_ig_diagram
_generate_ig_diagram   = lambda : _generate_simple_bar("Ejemplo Integrated Gradients", ["X1","X2","X3","X4"], [0.3,-0.1,0.4,-0.2], "IG value")

# Artifact: assign _generate_dl_diagram
_generate_dl_diagram   = lambda : _generate_simple_bar("Ejemplo DeepLIFT / LRP", ["X1","X2","X3","X4"], [0.2,-0.05,0.1,-0.15], "Relevancia")

# Artifact: function _generate_perm_diagram
def _generate_perm_diagram():
    feats = ["X1", "X2", "X3", "X4"]; means = [0.18, 0.07, 0.12, 0.25]; stds = [0.02, 0.01, 0.015, 0.03]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.errorbar(range(len(feats)), means, yerr=stds, fmt='o', capsize=5)
    ax.set_xticks(range(len(feats))); ax.set_xticklabels(feats)
    ax.set_title("Ejemplo Permutation Importance"); ax.set_ylabel("Importancia media"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_pdp_diagram
def _generate_pdp_diagram():
    feats = ["X1", "X2", "X3", "X4"]; rng = [0.8, 0.3, 0.5, 1.0]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.scatter(range(4), rng); ax.set_xticks(range(4)); ax.set_xticklabels(feats)
    ax.set_ylabel("Rango PDP"); ax.set_title("Ejemplo Importancia PDP"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_ale_diagram
def _generate_ale_diagram():
    feats = ["X1", "X2", "X3", "X4"]; rng = [1.1, 0.2, 0.6, 0.9]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.scatter(range(4), rng); ax.set_xticks(range(4)); ax.set_xticklabels(feats)
    ax.set_ylabel("Rango ALE"); ax.set_title("Ejemplo Importancia ALE"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_ice_diagram
def _generate_ice_diagram():
    feats=["X1","X2","X3","X4"]; rng=[0.6,0.15,0.35,0.75]
    fig,ax=plt.subplots(figsize=(4,3)); ax.scatter(range(4),rng); ax.set_xticks(range(4)); ax.set_xticklabels(feats)
    ax.set_ylabel("Rango ICE"); ax.set_title("Ejemplo Importancia ICE"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_cf_diagram
def _generate_cf_diagram():
    feats=["X1","X2","X3","X4"]; costs=[0.2,0.05,0.12,0.3]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.bar(feats, costs, color="steelblue"); ax.set_title("Ejemplo Coste Counterfactual"); ax.set_ylabel("|Œîfeature| medio"); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_base64(fig)}' width='300px'>"

# Artifact: function _generate_anchor_diagram
def _generate_anchor_diagram():
    feats=["X1","X2","X3","X4"]; cover=[0.45,0.15,0.05,0.35]
    fig,ax=plt.subplots(figsize=(4,3)); ax.bar(feats,cover,color="skyblue"); ax.set_title("Cobertura Anchors ej."); ax.set_ylabel("Cobertura"); plt.tight_layout();
    return f"<img src='data:image/png;base64,{_fig_to_b64(fig)}' width='300px'>"

# Artifact: function _generate_surr_diagram
def _generate_surr_diagram():
    feats = ["X1", "X2", "X3", "X4"]; coef = [0.5, 0.1, 0.3, 0.2]
    fig, ax = plt.subplots(figsize=(4,3))
    ax.bar(feats, coef, color='goldenrod'); ax.set_title('Coeficientes Surrogate ej.'); ax.set_ylabel('|Coef|'); plt.tight_layout()
    b64 = _fig_to_b64(fig)
    return f"<img src='data:image/png;base64,{b64}' width='300px'>"

# Artifact: function _generate_ebm_diagram
def _generate_ebm_diagram():
    feats=["X1","X2","X3","X4"]; gains=[0.25,0.1,0.15,0.35]
    fig,ax=plt.subplots(figsize=(4,3)); ax.bar(feats,gains,color='seagreen');
    ax.set_title('Importancia EBM ej.'); ax.set_ylabel('Ganancia relativa'); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_b64(fig)}' width='300px'>"

# Artifact: function _generate_optuna_diagram
def _generate_optuna_diagram():
    params=["lr","depth","n_estim","subsample"]; imp=[0.4,0.2,0.25,0.15]
    fig,ax=plt.subplots(figsize=(4,3)); ax.bar(params,imp,color='mediumpurple'); ax.set_title('Importancia Optuna ej.'); ax.set_ylabel('Contribuci√≥n'); plt.tight_layout()
    return f"<img src='data:image/png;base64,{_fig_to_b64(fig)}' width='300px'>"

# Artifact: assign explainer
explainer = None

# Artifact: function _motor_shap
def _motor_shap(key, model_obj, X, predict_fn):
    """SHAP completo: valores, tabla y gr√°fico."""
    if key in ['xgb','rf']:
        explainer = TreeExplainer(model_obj)
        print("Verbose: Usando TreeExplainer")
    elif key=='svr':
        background = shap.sample(X, min(N_SHAP_BACKGROUND, len(X)))
        print(f"Verbose: Background SVR sample shape: {background.shape}")
        explainer = KernelExplainer(predict_fn, background)
        print("Verbose: Usando KernelExplainer para SVR")
    else:
        background = shap.sample(X, min(N_SHAP_BACKGROUND, len(X)))
        print(f"Verbose: Background kernel sample shape: {background.shape}")
        explainer = KernelExplainer(predict_fn, background)
        print("Verbose: Usando KernelExplainer")

    muestra = shap.sample(X, min(N_SHAP_SAMPLES, len(X)))
    print(f"Verbose: Muestra SHAP shape: {muestra.shape}")
    shap_vals = explainer.shap_values(muestra)
    print(f"Verbose: shap_vals shape: {np.array(shap_vals).shape}")

    # gr√°fica SHAP
    print("Verbose: Generando summary_plot...")
    shap.summary_plot(shap_vals, muestra, plot_type="dot", show=False)
    fig = plt.gcf()      # Nuevo para la celda 12
    plt.show()
    # === Explicaci√≥n de la gr√°fica SHAP ===
    display(HTML("""
    <h4>Interpretaci√≥n del gr√°fico SHAP</h4>
    <p>En el gr√°fico summary_plot:<ul>
    <li>Cada punto representa el efecto de una caracter√≠stica en una muestra.</li>
    <li>El eje X muestra el valor SHAP (positivo empuja la predicci√≥n hacia arriba, negativo hacia abajo).</li>
    <li>Los colores indican el valor de la caracter√≠stica (rojo = alto, azul = bajo).</li>
    </ul></p>
    """))

    # tabla de valores SHAP
    print("Verbose: Creando DataFrame de valores SHAP...")
    shap_df = pd.DataFrame(shap_vals, columns=X.columns)
    display(HTML("<h4>Valores SHAP (primeras 10 muestras)</h4>"))
    display(shap_df.head(10))

    # === Explicaci√≥n de la tabla de valores SHAP ===
    display(HTML("""
    <h4>Interpretaci√≥n de la tabla de valores SHAP</h4>
    <ul>
    <li>Cada fila corresponde a una muestra (observaci√≥n).</li>
    <li>Cada columna muestra el valor SHAP de esa caracter√≠stica.</li>
    <li>Valores positivos empujan la predicci√≥n hacia arriba; negativos, hacia abajo.</li>
    </ul>
    """))

    # importancias globales
    mean_abs = np.abs(shap_vals).mean(axis=0)
    imp_df = pd.DataFrame({'feature':X.columns, 'mean_abs_shap':mean_abs})
    imp_df = imp_df.sort_values('mean_abs_shap', ascending=False).reset_index(drop=True)
    #imp_df = imp_df.sort_values('mean_abs_shap', ascending=False)
    print("Verbose: Importancia global calculada")
    display(HTML("<h4>Importancia global (valor absoluto medio)</h4>"))
    display(imp_df)
    # === Explicaci√≥n de la importancia global ===
    display(HTML("""
    <h4>Interpretaci√≥n de la importancia global</h4>
    <p>La importancia global ordena caracter√≠sticas por su valor absoluto medio de SHAP.</p>
    <p>Valores m√°s altos indican mayor contribuci√≥n promedio al modelo.</p>
    <p>Ejemplo: Una caracter√≠stica con <i>mean_abs_shap</i>=0.5 contribuye en promedio 0.5 unidades a la predicci√≥n.</p>
    """))
    # Estad√≠sticas adicionales  ---- Nuevo para la celda 12
    stats = {
        'shap_mean_abs_overall': float(mean_abs.mean()),
        'shap_std_abs_overall': float(np.abs(shap_vals).std()),
        'shap_imp_percentiles': imp_df['mean_abs_shap'].quantile([0.25,0.5,0.75]).to_dict()
    }
    # Resultado  ---- Nuevo para la celda 12
    resultado = {
        'imp_df': imp_df.rename(columns={'mean_abs_shap':'value'}),
        'df_local': shap_df,
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: exec exec_285
pass

# Artifact: function _motor_lime
def _motor_lime(X, predict_fn):
    """LIME completo."""
    print("Verbose: Generando explicaci√≥n con LIME para", N_LIME_SAMPLES, "muestras...")
    explainer = LimeTabularExplainer(
        training_data=X.values,
        feature_names=X.columns.tolist(),
        mode='regression'
    )
    # Muestreamos s√≥lo las primeras N_LIME_SAMPLES instancias
    X_sample = X.iloc[:N_LIME_SAMPLES]

    # calcular explicaciones para todas las muestras
    local_weights = np.zeros((X_sample.shape[0], X_sample.shape[1]))
    for i in range(X_sample.shape[0]):
        exp = explainer.explain_instance(X_sample.values[i], predict_fn)
        # usar √≠ndice_feat de exp.as_map()[0]
        for feat_idx, weight in exp.as_map()[0]:
            local_weights[i, feat_idx] = weight

    # tabla primeras 10 muestras
    lime_df = pd.DataFrame(local_weights, columns=X.columns)
    display(HTML("<h4>Valores LIME (primeras 10 muestras)</h4>"))
    display(lime_df.head(10))
    # Explicaci√≥n tabla LIME
    display(HTML(
        '<p>En la tabla de LIME local, cada fila es una muestra y cada columna el peso asignado por LIME. '
        'Valores positivos indican que la caracter√≠stica aumenta la predicci√≥n localmente, negativos la disminuyen.</p>'
    ))

    # importancia global media
    mean_w = np.abs(local_weights).mean(axis=0)
    #imp_df = pd.DataFrame({'feature':X.columns,'mean_abs_weight':mean_w}).sort_values('mean_abs_weight',ascending=False)
    imp_df = pd.DataFrame({'feature': X.columns, 'mean_abs_weight': mean_w})
    imp_df = imp_df.sort_values('mean_abs_weight', ascending=False).reset_index(drop=True)
    display(HTML("<h4>Importancia global LIME</h4>"))
    display(imp_df)
    # Explicaci√≥n importancia global LIME
    display(HTML(
        '<p>La importancia global de LIME se calcula como el valor absoluto medio de los pesos '
        'a trav√©s de todas las muestras. Caracter√≠stica con mayor valor afecta m√°s la predicci√≥n de manera local.</p>'
    ))

    # gr√°fico LIME Value vs Feature Value
    plt.figure(figsize=(8,6))
    for idx, feat in enumerate(X.columns):
        plt.scatter(X_sample[feat], local_weights[:,idx], label=feat, alpha=0.6)
    plt.axhline(0,color='black',linewidth=0.8)
    plt.xlabel('Valor de la caracter√≠stica')
    plt.ylabel('Peso LIME')
    plt.title('LIME: Peso vs Valor de la caracter√≠stica')
    plt.legend(bbox_to_anchor=(1.05,1),loc='upper left')
    plt.tight_layout()
    fig = plt.gcf()           # Nuevo para la celda 12
    plt.show()
    display(HTML(
        '<p>En el gr√°fico LIME Value vs Feature Value, cada punto representa una muestra. '
        'La posici√≥n vertical es el peso LIME, horizontal el valor original de la caracter√≠stica. '
        'Permite ver c√≥mo cambia la influencia de la variable seg√∫n su valor.</p>'
    ))

    # Estad√≠sticas adicionales  --- Nuevo para la celda 12
    stats = {
        'lime_imp_percentiles': imp_df['mean_abs_weight'].quantile([0.25,0.5,0.75]).to_dict()
    }

    resultado = {
        'imp_df': imp_df.rename(columns={'mean_abs_weight':'value'}),  # ['feature','value']
        'df_local': lime_df,  # DataFrame de pesos locales
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: function _motor_kernel
def _motor_kernel(X, predict_fn):
    """KernelExplainer (SHAP)."""
    print("Verbose: Calculando valores Kernel SHAP para", N_KERNEL_SAMPLES, " muestras...")

    # 1) Tomamos la muestra y el background de X
    muestra     = shap.sample(X, min(N_KERNEL_SAMPLES, len(X)))
    background  = shap.sample(X, min(N_KERNEL_BACKGROUND, len(X)))

    # 2) Creamos el explainer y calculamos SHAP‚Äêvalues solo para 'muestra'
    ke_expl = KernelExplainer(predict_fn, background)
    print(f"[DEBUG] Calculando SHAP values para {len(muestra)} instancias‚Ä¶")
    ke_vals = ke_expl.shap_values(muestra.values)  # matriz (M, p)

    # 3) Importancia local y global
    ke_df = pd.DataFrame(ke_vals, columns=X.columns)
    mean_ke = np.abs(ke_vals).mean(axis=0)
    imp_df = pd.DataFrame({'feature': X.columns, 'mean_abs_kernel': mean_ke})
    imp_df = imp_df.sort_values('mean_abs_kernel', ascending=False).reset_index(drop=True)

    # 4) Summary plot ‚Äî **usar 'muestra'**, no 'X' completo
    shap.summary_plot(ke_vals, muestra, show=False)   # <<< aqu√≠ estaba el error
    fig = plt.gcf()   # recupera la figura actual

    # 5) Estad√≠sticas adicionales
    stats = {
        'kernel_shap_imp_percentiles': imp_df['mean_abs_kernel'].quantile([0.25,0.5,0.75]).to_dict()
    }

    display(HTML("<h4>Valores Kernel SHAP (primeras 10 muestras)</h4>"))
    display(ke_df.head(10))
    display(HTML(
        '<p>En la tabla anterior, cada fila corresponde a una muestra y cada columna al valor Kernel SHAP de esa caracter√≠stica. '
        'Valores positivos indican empuje hacia arriba, negativos empuje hacia abajo.</p>'
    ))
    display(HTML("<h4>Importancia global Kernel SHAP</h4>"))
    display(imp_df)
    display(HTML(
        '<p>La tabla de importancia global muestra el valor absoluto medio del Kernel SHAP para cada caracter√≠stica. '
        'Caracter√≠stica con valor m√°s alto tiene mayor impacto medio en las predicciones.</p>'
    ))
    plt.show()
    display(HTML(
        '<p>El gr√°fico summary para Kernel SHAP funciona igual que SHAP: muestra distribuci√≥n de valores, mostrando heterogeneidad e influencia de cada variable.</p>'
    ))

    # 6) Construir resultado
    resultado = {
        'imp_df': imp_df.rename(columns={'mean_abs_kernel':'value'}),
        'df_local': ke_df,
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: function _motor_ig
def _motor_ig(key, model_obj, X, cols, sx, predict_fn):
    """
    Integrated Gradients:
     - Para SVR/NN/XGBoost/RF: usamos SHAP GradientExplainer.
     - Para RNN: implementamos IG manual sobre la secuencia.
    """
    import numpy as np, pandas as pd, matplotlib.pyplot as plt
    from IPython.display import display, HTML
    import tensorflow as tf

    # par√°metros IG
    STEPS   = 50     # pasos de interpolaci√≥n
    TOP_N   = 5      # features globales a mostrar
    N_LOCAL = 3      # muestras locales a mostrar

    if key != 'rnn':
        # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî Camino original con SHAP GradientExplainer ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
        from shap import GradientExplainer

        background = sx.transform(
            X.sample(min(200, len(X)), random_state=0)
        )
        ig_expl = GradientExplainer(model_obj, background)
        vals = ig_expl.shap_values(sx.transform(X))

        # si devuelve shape (n, p, 1): compr√≠melo a 2D
        if isinstance(vals, np.ndarray) and vals.ndim == 3 and vals.shape[2] == 1:
            vals = np.squeeze(vals, -1)

        ig_vals = vals  # (n, p)
        # DataFrame de valores locales
        ig_df = pd.DataFrame(ig_vals, columns=cols)
        # importancia global
        mean_abs = np.abs(ig_vals).mean(axis=0)
        imp_df = (
            pd.DataFrame({'feature': cols, 'value': mean_abs})
              .sort_values('value', ascending=False)
              .reset_index(drop=True)
        )
        # gr√°fico global
        fig, ax = plt.subplots(figsize=(6,4))
        ax.barh(imp_df['feature'].head(TOP_N)[::-1],
                imp_df['value'].head(TOP_N)[::-1])
        ax.set_title('IG: Top Global')
        plt.tight_layout()

        display(HTML("<h4>IG: Importancia global (top features)</h4>"))
        display(imp_df.head(TOP_N))
        display(fig)
        display(HTML("<h4>IG: Valores locales (primeras muestras)</h4>"))
        display(ig_df.head(N_LOCAL))

        return {'imp_df': imp_df, 'df_local': ig_df, 'fig_summary': fig}

    else:
        # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî IG manual para RNN ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
        # necesitamos X_seq en globals(): array NumPy 3D (n_samples, timesteps, features)
        X_seq = globals().get('X_seq')
        if X_seq is None:
            raise RuntimeError("Para RNN necesitas tener `X_seq` en globals().")

        # submuestra
        n_sub = min(20, X_seq.shape[0])
        idxs  = np.random.RandomState(0).choice(X_seq.shape[0], n_sub, replace=False)
        seqs_np     = X_seq[idxs]                              # NumPy array (n_sub, t, f)
        baseline_np = np.zeros_like(seqs_np[0:1])              # (1, t, f)

        # convertimos a tensores solo para el tape
        seqs_t     = tf.convert_to_tensor(seqs_np,     dtype=tf.float32)
        baseline_t = tf.convert_to_tensor(baseline_np, dtype=tf.float32)

        # acumulador en NumPy
        all_grads = np.zeros_like(seqs_np, dtype=float)       # (n_sub, t, f)

        # bucle de interpolaci√≥n
        for alpha in np.linspace(0, 1, STEPS):
            interp = baseline_t + alpha * (seqs_t - baseline_t)
            with tf.GradientTape() as tape:
                tape.watch(interp)
                preds = model_obj(interp)                      # (n_sub, 1)
            grads_t = tape.gradient(preds, interp)             # tf.Tensor (n_sub, t, f)
            grads_np = grads_t.numpy()                         # convertimos a NumPy
            all_grads += grads_np

        avg_grads = all_grads / STEPS                         # (n_sub, t, f)
        ig_attribs = (seqs_np - baseline_np) * avg_grads      # (n_sub, t, f)

        # importancia global: promedio absoluto sobre muestras y timesteps
        global_imp = np.mean(np.abs(ig_attribs), axis=(0,1))  # (f,)
        imp_df = (
            pd.DataFrame({'feature': cols, 'value': global_imp})
              .sort_values('value', ascending=False)
              .reset_index(drop=True)
        )

        timesteps = seqs_np.shape[1]

        # ‚Äî aqu√≠ vamos a dividir los locales por variable ‚Äî
        display(HTML("<h4>IG RNN: Valores locales por variable</h4>"))
        for feat_idx, feat_name in enumerate(cols):
            # extraemos la matriz (N_LOCAL, timesteps) para esta variable
            local_mat = ig_attribs[:N_LOCAL, :, feat_idx]
            local_df   = pd.DataFrame(
                local_mat,
                index=[f"muestra {i+1}" for i in range(local_mat.shape[0])],
                columns=[f"timestep {t}" for t in range(timesteps)]
            )
            display(HTML(f"<h5>Variable: {feat_name}</h5>"))
            display(local_df)

        # gr√°fico global RNN
        fig, ax = plt.subplots(figsize=(6,4))
        ax.barh(imp_df['feature'].head(TOP_N)[::-1],
                imp_df['value'].head(TOP_N)[::-1])
        ax.set_title('IG RNN: Top Global')
        plt.tight_layout()

        display(HTML("<h4>IG RNN: Importancia global</h4>"))
        display(imp_df.head(TOP_N))
        display(fig)

        return {'imp_df': imp_df, 'df_local': local_df, 'fig_summary': fig}

# Artifact: function _motor_dl
def _motor_dl(model_obj, key, X, cols, sx, sy):
    """DeepLIFT / LRP."""
    print("üîç Calculando DeepLIFT/LRP para todas las muestras...")
    from shap import GradientExplainer
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import display, HTML

    # 1) Crear la submuestra y escalarla ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    X_sample = X.sample(min(N_DEEP_SAMPLES, len(X)), random_state=0)
    X_scaled = sx.transform(X_sample)

    # ‚îÄ‚îÄ 2) Si es RNN, reshape 2D‚Üí3D seg√∫n la forma de entrada del modelo ‚îÄ‚îÄ
    if key == 'rnn':
        # model_obj.input_shape suele ser (None, timesteps, features)
        _, timesteps, feat_dim = model_obj.input_shape
        try:
            X_scaled = X_scaled.reshape(-1, timesteps, feat_dim)
            print(f"[DEBUG] DeepLIFT RNN: reshaped a {X_scaled.shape}")
        except Exception as e:
            raise ValueError(
                f"No pude reshapear para RNN: esperaba (_, {timesteps}, {feat_dim}), "
                f"pero sx.transform devolvi√≥ {sx.transform(X_sample).shape}. "
                f"Error: {e}"
            )

    # ‚îÄ‚îÄ 3) Crear explainer y calcular valores ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    explainer_dl = GradientExplainer(model_obj, X_scaled)
    dl_vals = explainer_dl.shap_values(X_scaled)   # ya 3D ‚Üí funciona OK

    # 1.1) Squeeze si viene con dimensi√≥n extra
    if isinstance(dl_vals, np.ndarray):
        # eliminar ejes de longitud 1
        dl_vals = np.squeeze(dl_vals)
        print(f"[DEBUG] tras squeeze: {dl_vals.shape}")
        # si sigue siendo 3D, asumimos (n_samples, time_steps, n_features)
        if dl_vals.ndim == 3:
            # colapsamos time_steps tomando la media
            dl_vals = dl_vals.mean(axis=1)
            print(f"[DEBUG] tras mean over time axis: {dl_vals.shape}")

    # ‚îÄ‚îÄ 5) DataFrame de relevancias locales ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    dl_df = pd.DataFrame(dl_vals, columns=cols)
    display(HTML('<h4>DeepLIFT / LRP: Primeras 10 muestras</h4>'))
    display(dl_df.head(10))
    display(HTML("""
    <h4>üìù C√≥mo leer la tabla de las primeras 10 muestras</h4>
    <ul>
      <li>Cada fila corresponde a una de las primeras 10 observaciones de tu conjunto de datos.</li>
      <li>Cada columna muestra la relevancia asignada por DeepLIFT/LRP a esa caracter√≠stica en esa muestra.</li>
      <li>Un valor positivo indica que la caracter√≠stica empuj√≥ la predicci√≥n <b>hacia arriba</b> respecto al valor de referencia.</li>
      <li>Un valor negativo indica que la caracter√≠stica empuj√≥ la predicci√≥n <b>hacia abajo</b>.</li>
      <li>Por ejemplo, si para la muestra #3 el valor en la columna X2 es 0.15, quiere decir que X2 aument√≥ la salida del modelo en 0.15 unidades.</li>
    </ul>
    """))

    # ‚îÄ‚îÄ 6) Importancia global (media absoluta) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    mean_abs = np.abs(dl_vals).mean(axis=0)
    #imp_df = pd.DataFrame({'feature':cols,'mean_abs_dl':mean_abs}).sort_values('mean_abs_dl',ascending=False)
    imp_df = pd.DataFrame({'feature': cols, 'mean_abs_dl': mean_abs})
    imp_df = imp_df.sort_values('mean_abs_dl', ascending=False).reset_index(drop=True)
    display(HTML('<h4>DeepLIFT / LRP: Importancia global</h4>'))
    display(imp_df)
    display(HTML("""
    <h4>üìù C√≥mo leer la tabla de importancia global</h4>
    <ul>
      <li>La ‚Äúimportancia global‚Äù es la media del valor absoluto de las relevancias en <b>todas</b> las muestras.</li>
      <li>Se ordena de mayor a menor: las variables que aparecen arriba son las que, en promedio, m√°s afectan la predicci√≥n.</li>
      <li>Por ejemplo, si la media absoluta de X4 es 0.35, significa que X4 desvi√≥ la predicci√≥n en ¬±0.35 de media.</li>
    </ul>
    """))

    # ‚îÄ‚îÄ 7) Gr√°fico de importancia global ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    plt.figure(figsize=(8,4))
    plt.scatter(range(len(imp_df)), imp_df['mean_abs_dl'], s=80)
    plt.xticks(range(len(imp_df)), imp_df['feature'], rotation=45)
    plt.title('Importancia DeepLIFT / LRP')
    display(HTML("""
    <h4>üìù C√≥mo interpretar el gr√°fico de relevancias</h4>
    <ul>
      <li>Cada barra representa la relevancia media absoluta de una caracter√≠stica (la misma que en la tabla).</li>
      <li>La altura de la barra indica cu√°n importante es esa variable en el conjunto completo.</li>
      <li>Las barras verdes (si tuvieras colores) son relevancias positivas medias y las rojas negativas medias.</li>
      <li>Una barra alta significa que, variando esa caracter√≠stica, la predicci√≥n del modelo cambia sustancialmente.</li>
      <li>Este gr√°fico te ayuda a ver de un vistazo qu√© variables ‚Äúmueven‚Äù m√°s la predicci√≥n.</li>
    </ul>
    """))
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # ‚îÄ‚îÄ 8) Estad√≠sticas adicionales ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    stats = {'dlrp_imp_percentiles': imp_df['mean_abs_dl'].quantile([0.25, 0.5, 0.75]).to_dict()}

    # ‚îÄ‚îÄ 9) Devolver en el formato esperado ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    resultado = {
        'imp_df': imp_df.rename(columns={'mean_abs_dl':'value'}),
        'df_local': dl_df,
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: function _motor_perm
def _motor_perm(model_obj, X, cols, sx, sy):
    """Permutation Feature Importance."""
    from sklearn.inspection import permutation_importance
    import numpy as np, pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("üîç Calculando Permutation Importance para un subconjunto de muestras...")

    # 1) Seleccionamos X_test/Y_test o fallback a X/Y
    X_target = globals().get('X_test', X)
    y_target = globals().get('Y_test', None)
    if y_target is None:
        raise ValueError("Y_test no definido para Permutation Importance")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 1.1) HARD‚ÄìCODE: n√∫mero de muestras para la permutaci√≥n
    #N_PERM_SAMPLES = 50
    # 1.2) Muestreamos esas instancias
    idxs = X_target.sample(
        n=min(N_PERM_SAMPLES, len(X_target)),
        random_state=0
    ).index
    X_target = X_target.loc[idxs, cols]
    y_target = y_target.loc[idxs]
    print(f"[DEBUG] Usando {len(X_target)} muestras para Permutation Importance")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # 2) Escalamos nuestro subset
    X_scaled = sx.transform(X_target)

    # 3) Calculamos la importancia por permutaci√≥n
    if hasattr(model_obj, 'predict'):
        perm = permutation_importance(
            model_obj,
            X_scaled,
            y_target.values.ravel(),
            n_repeats=10,
            random_state=42,
            n_jobs=-1
        )
    else:
        raise TypeError("Modelo no soporta permutation_importance")

    # 4) Creamos el DataFrame ordenado
    imp_df = pd.DataFrame({
        'feature':         cols,
        'mean_importance': perm.importances_mean,
        'std_importance':  perm.importances_std
    }).sort_values('mean_importance', ascending=False).reset_index(drop=True)

    # 5) Mostramos la tabla global
    display(HTML('<h4>Permutation Importance (subconjunto)</h4>'))
    display(imp_df)

    # 6) Gr√°fico con barras de error
    plt.figure(figsize=(8,4))
    plt.errorbar(
        range(len(imp_df)),
        imp_df['mean_importance'],
        yerr=imp_df['std_importance'],
        fmt='o', capsize=5
    )
    plt.xticks(range(len(imp_df)), imp_df['feature'], rotation=45)
    plt.title('Permutation Feature Importance')
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # 7) Estad√≠sticas adicionales
    stats = {
        'perm_imp_percentiles': imp_df['mean_importance']
                                  .quantile([0.25,0.5,0.75])
                                  .to_dict()
    }

    # 8) Devolvemos el resultado en el formato esperado
    return {
        'imp_df':      imp_df.rename(columns={'mean_importance':'value'}),
        'df_local':    imp_df.head(N_PERM_SAMPLES),  # top-N features
        'fig_summary': fig,
        'stats':       stats
    }

# Artifact: function _motor_pdp
def _motor_pdp(X: pd.DataFrame, cols: list[str], predict_fn):
    import numpy as np, pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("[DEBUG] Iniciando motor PDP")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # HARD‚ÄìCODE: n√∫mero de muestras para la parte local de PDP
    #N_PDP_SAMPLES = 50
    print(f"[DEBUG] Usando {N_PDP_SAMPLES} muestras aleatorias para PDP local")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # ---------- PDP global -----------------------------------
    pdp_ranges = []
    pdp_curves = {}
    for feat in cols:
        print(f"[DEBUG] Calculando PDP global para feature '{feat}'")
        grid = np.linspace(X[feat].min(), X[feat].max(), GRID_RES)
        pd_vals = []
        for g in grid:
            X_temp = X.copy()
            X_temp[feat] = g
            preds = predict_fn(X_temp)
            pd_vals.append(preds.mean())
        pd_vals = np.array(pd_vals)
        pdp_curves[feat] = pd_vals
        pdp_ranges.append(pd_vals.max() - pd_vals.min())

    imp_df = (
        pd.DataFrame({"feature": cols, "pdp_range": pdp_ranges})
          .sort_values("pdp_range", ascending=False)
          .reset_index(drop=True)
    )
    print("[DEBUG] DataFrame de importancia global PDP creado")

    display(HTML("<h4>PDP: Importancia global (rango de la curva)</h4>"))
    display(imp_df)
    display(HTML(
        "<p>La <b>importancia global</b> de cada caracter√≠stica se mide "
        "como el rango (m√°x ‚àí m√≠n) de su curva PDP.</p>"
    ))

    # ---------- PDP local (subconjunto aleatorio) -------------
    X_sample = X.sample(n=min(N_PDP_SAMPLES, len(X)), random_state=0)
    n_samples = len(X_sample)
    print(f"[DEBUG] Calculando PDP local para {n_samples} muestras")

    base_pred_mean = predict_fn(X).mean()
    pdp_local = np.zeros((n_samples, len(cols)))
    for i, (_, row) in enumerate(X_sample.iterrows()):
        for j, feat in enumerate(cols):
            X_temp = X.copy()
            X_temp[feat] = row[feat]
            pdp_local[i, j] = predict_fn(X_temp).mean() - base_pred_mean

    pdp_df = pd.DataFrame(pdp_local, columns=cols)
    print("[DEBUG] DataFrame de PDP local creado")

    display(HTML(f"<h4>PDP: Valores para {n_samples} muestras seleccionadas</h4>"))
    display(pdp_df)
    display(HTML(
        "<p>Cada celda muestra cu√°nto var√≠a la predicci√≥n promedio cuando "
        "fijamos la caracter√≠stica al valor de la muestra.</p>"
    ))

    # ---------- Gr√°fico global --------------------------------
    print("[DEBUG] Generando gr√°fico de importancia global PDP")
    plt.figure(figsize=(8, 4))
    plt.scatter(range(len(imp_df)), imp_df["pdp_range"], s=80)
    plt.xticks(range(len(imp_df)), imp_df["feature"], rotation=45)
    plt.ylabel("Rango PDP")
    plt.title("Importancia Partial Dependence (rango)")
    plt.axhline(0, color="black", linewidth=0.8)
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # ---------- Estad√≠sticas adicionales ----------------------
    stats = {
        "pdp_range_percentiles": imp_df["pdp_range"]
                                   .quantile([0.25, 0.5, 0.75])
                                   .to_dict()
    }
    print(f"[DEBUG] Estad√≠sticas adicionales calculadas: {stats}")

    # ---------- Resultado -------------------------------------
    return {
        "imp_df":      imp_df.rename(columns={"pdp_range": "value"}),
        "df_local":    pdp_df,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_ale
def _motor_ale(X: pd.DataFrame, cols: list[str], predict_fn, n_bins: int = ALE_BINS):
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("[DEBUG] Iniciando motor ALE")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # HARD‚ÄìCODE: n√∫mero de muestras para la parte local de ALE
    print(f"[DEBUG] Usando {N_ALE_SAMPLES} muestras aleatorias para ALE local")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # ---------- ALE global ------------------------------------
    ale_ranges = []
    ale_curves = {}
    for feat in cols:
        print(f"[DEBUG] Calculando ALE global para '{feat}'")
        # bordes de los bins
        edges = np.quantile(X[feat], np.linspace(0, 1, n_bins + 1))
        edges[0] -= 1e-9
        edges[-1] += 1e-9

        curve = np.zeros(n_bins)
        cum = 0.0
        for b in range(n_bins):
            lo, hi = edges[b], edges[b+1]
            mask = (X[feat] > lo) & (X[feat] <= hi)
            if mask.any():
                X_lo = X.loc[mask].copy(); X_hi = X.loc[mask].copy()
                X_lo[feat] = lo; X_hi[feat] = hi
                delta = predict_fn(X_hi) - predict_fn(X_lo)
                cum += delta.mean()
            curve[b] = cum
        ale_curves[feat] = curve
        ale_ranges.append(curve.max() - curve.min())

    imp_df = (
        pd.DataFrame({"feature": cols, "ale_range": ale_ranges})
          .sort_values("ale_range", ascending=False)
          .reset_index(drop=True)
    )
    print("[DEBUG] DataFrame de importancia global ALE creado")

    display(HTML("<h4>ALE: Importancia global (rango)</h4>"))
    display(imp_df)
    display(HTML(
        "<p>El <b>rango ALE</b> mide cu√°nto var√≠a la curva acumulada "
        "al recorrer toda la distribuci√≥n de la variable.</p>"
    ))

    # ---------- ALE local (subconjunto aleatorio) -------------
    X_sample = X.sample(n=min(N_ALE_SAMPLES, len(X)), random_state=0)
    n_samples = len(X_sample)
    print(f"[DEBUG] Calculando ALE local para {n_samples} muestras seleccionadas")

    ale_local = np.zeros((n_samples, len(cols)))
    for i, (_, row) in enumerate(X_sample.iterrows()):
        for j, feat in enumerate(cols):
            # identificar bin de la muestra
            bin_idx = np.digitize(row[feat], edges[1:-1], right=True)
            ale_local[i, j] = ale_curves[feat][bin_idx]

    ale_df = pd.DataFrame(ale_local, columns=cols)
    print("[DEBUG] DataFrame de ALE local creado")

    display(HTML(f"<h4>ALE: Valores para {n_samples} muestras seleccionadas</h4>"))
    display(ale_df)
    display(HTML(
        "<p>Cada celda muestra el valor ALE acumulado en el bin en que cae la muestra.</p>"
    ))

    # ---------- Gr√°fico global --------------------------------
    print("[DEBUG] Generando gr√°fico de importancia global ALE")
    plt.figure(figsize=(8, 4))
    plt.scatter(range(len(imp_df)), imp_df["ale_range"], s=80)
    plt.xticks(range(len(imp_df)), imp_df["feature"], rotation=45)
    plt.ylabel("Rango ALE")
    plt.title("Importancia Accumulated Local Effects")
    plt.axhline(0, color="black", linewidth=0.8)
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # ---------- Estad√≠sticas adicionales ----------------------
    stats = {
        "ale_range_percentiles": imp_df["ale_range"]
                                   .quantile([0.25, 0.5, 0.75])
                                   .to_dict()
    }
    print(f"[DEBUG] Estad√≠sticas adicionales calculadas: {stats}")

    # ---------- Resultado -------------------------------------
    return {
        "imp_df":      imp_df.rename(columns={"ale_range": "value"}),
        "df_local":    ale_df,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_ice
def _motor_ice(
    X: pd.DataFrame,
    cols: list[str],
    predict_fn,
    *,
    grid_res: int = GRID_RES
):
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("[DEBUG] Iniciando motor ICE")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # HARD‚ÄìCODE: n√∫mero de muestras para ICE (tanto global como local)
    #N_ICE_SAMPLES = 50
    print(f"[DEBUG] Usando N_ICE_SAMPLES={N_ICE_SAMPLES} para ICE global y local")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # ‚îÄ‚îÄ‚îÄ 1) Tomar subconjunto aleatorio para ICE global y local ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    X_sub = X.sample(n=min(N_ICE_SAMPLES, len(X)), random_state=0)
    n_total = len(X_sub)
    n_local = min(FIRST_SAMPLES, n_total)
    print(f"[DEBUG] Submuestra ICE creada con {n_total} instancias (local={n_local})")

    # contenedores
    ice_local = np.zeros((n_local, len(cols)))
    ice_ranges = []

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 2) Calcular rangos ICE por caracter√≠stica sobre X_sub
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    for j, feat in enumerate(cols):
        print(f"[DEBUG] Calculando curvas ICE para '{feat}'")
        grid = np.linspace(X[feat].min(), X[feat].max(), grid_res)
        ranges_feat = []

        for i, (_, row) in enumerate(X_sub.iterrows()):
            # construir DataFrame repitiendo la fila
            X_grid = pd.DataFrame(
                np.repeat(row.values.reshape(1, -1), grid_res, axis=0),
                columns=cols
            )
            X_grid[feat] = grid
            preds = predict_fn(X_grid)
            r = preds.max() - preds.min()
            ranges_feat.append(r)

            if i < n_local:
                ice_local[i, j] = r

        mean_range = float(np.mean(ranges_feat))
        ice_ranges.append(mean_range)
        print(f"[DEBUG] Rango medio ICE para '{feat}': {mean_range:.4f}")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 3) Importancia global (media de rangos)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    imp_df = (
        pd.DataFrame({
            "feature": cols,
            "ice_range_mean": ice_ranges
        })
        .sort_values("ice_range_mean", ascending=False)
        .reset_index(drop=True)
    )
    print("[DEBUG] DataFrame de importancia global ICE creado")

    display(HTML("<h4>ICE: Importancia global (media de rangos)</h4>"))
    display(imp_df)
    display(HTML(
        "<p>Cada punto muestra la media del rango ICE de la caracter√≠stica. "
        "Un valor mayor indica mayor sensibilidad de la predicci√≥n a esa variable.</p>"
    ))

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 4) Tabla local (primeras n_local muestras de X_sub)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ice_df = pd.DataFrame(ice_local, columns=cols)
    print("[DEBUG] DataFrame de ICE local creado")
    display(HTML(f"<h4>ICE: Rangos para las primeras {n_local} muestras</h4>"))
    display(ice_df)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 5) Gr√°fico global
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    print("[DEBUG] Generando gr√°fico de importancia ICE")
    plt.figure(figsize=(8, 4))
    plt.scatter(range(len(imp_df)), imp_df["ice_range_mean"], s=80)
    plt.xticks(range(len(imp_df)), imp_df["feature"], rotation=45)
    plt.ylabel("Rango medio ICE")
    plt.title("Importancia Individual Conditional Expectation")
    plt.axhline(0, color="black", lw=0.8)
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    display(HTML(
        "<p>La dispersi√≥n de estos puntos indica qu√© variables tienen "
        "mayor efecto condicional individual sobre la predicci√≥n.</p>"
    ))

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 6) Estad√≠sticas adicionales
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    stats = {
        "ice_range_percentiles": imp_df["ice_range_mean"]
                                    .quantile([0.25, 0.5, 0.75])
                                    .to_dict()
    }
    print(f"[DEBUG] Estad√≠sticas ICE calculadas: {stats}")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 7) Resultado
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    return {
        "imp_df":      imp_df.rename(columns={"ice_range_mean": "value"}),
        "df_local":    ice_df,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_counterfactual
def _motor_counterfactual(
    X: pd.DataFrame,
    predict_fn,
    *,
    rel_delta: float = CF_TARGET_DELTA,    # +10% por defecto
    show_first: int = FIRST_SAMPLES
):
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import HTML, display

    print("[DEBUG] Iniciando motor Counterfactual")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # HARD‚ÄìCODE: n√∫mero de muestras para buscar contrafactuales
    #N_CF_SAMPLES = 50
    print(f"[DEBUG] Usando N_CF_SAMPLES={N_CF_SAMPLES} para submuestreo")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # 1) Submuestra aleatoria de X para buscar contrafactuales
    X_sub = X.sample(n=min(N_CF_SAMPLES, len(X)), random_state=0)
    print(f"[DEBUG] Submuestra creada con {len(X_sub)} instancias")

    # 2) Predicciones de la submuestra
    preds_sub = predict_fn(X_sub)
    print("[DEBUG] Predicciones calculadas para submuestra")

    cf_rows = []
    deltas = []

    # 3) Para cada muestra en X_sub, buscar el vecino m√°s cercano que supere el delta
    for i, idx in enumerate(X_sub.index):
        x0 = X_sub.loc[idx].values.reshape(1, -1)
        y0 = preds_sub[i]
        target = y0 * (1 + rel_delta)
        print(f"[DEBUG] Muestra idx={idx}, y0={y0:.4f}, target>={target:.4f}")

        # candidatos de X (pueden ser toda X o X_sub, aqu√≠ usamos X para m√°s posibilidades)
        all_preds = predict_fn(X)
        mask = all_preds >= target
        X_cand = X.loc[mask]
        print(f"[DEBUG] Encontrados {len(X_cand)} candidatos que cumplen delta")

        if X_cand.empty:
            cf_rows.append({"√çndice": idx, **{c: None for c in X.columns}, "Distancia": None})
            deltas.append(np.nan)
            continue

        nbrs = NearestNeighbors(n_neighbors=1, metric="euclidean")
        nbrs.fit(X_cand.values)
        dist, ind = nbrs.kneighbors(x0, return_distance=True)
        cf = X_cand.iloc[ind[0][0]]
        delta_feat = np.abs(cf.values - x0.ravel())
        mean_delta = float(delta_feat.mean())

        cf_rows.append({
            "√çndice":        idx,
            **{c: float(v) for c, v in zip(X.columns, cf.values)},
            "Distancia":    float(dist[0][0])
        })
        deltas.append(mean_delta)
        print(f"[DEBUG] Contrafactual idx={idx}: distancia={dist[0][0]:.4f}, Œîmedio_feat={mean_delta:.4f}")

    # 4) Construir DataFrame local
    df_local = pd.DataFrame(cf_rows).set_index("√çndice")
    n_show = min(show_first, len(df_local))
    display(HTML(f"<h4>Contrafactuales (primeras {n_show} muestras)</h4>"))
    display(df_local.head(n_show))

    # 5) Importancia global: |Œîfeature| medio
    imp_series = pd.Series(0.0, index=X.columns)
    valid = df_local["Distancia"].notna()
    for idx in df_local[valid].index:
        diff = np.abs(df_local.loc[idx, X.columns].values - X.loc[idx].values)
        imp_series += diff
    imp_series /= valid.sum()
    imp_series = imp_series.sort_values(ascending=False)
    imp_df = imp_series.rename("value").reset_index().rename(columns={"index":"feature"})

    display(HTML("<h4>Importancia global por contrafactuales</h4>"))
    display(imp_df)

    # 6) Gr√°fico de barras
    plt.figure(figsize=(8,4))
    plt.bar(imp_series.index, imp_series.values)
    plt.xticks(rotation=45, ha="right")
    plt.ylabel("|Œîfeature| medio")
    plt.title("Importancia global ‚Äì Counterfactual")
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # 7) Estad√≠sticas adicionales
    stats = {
        "cf_imp_percentiles": imp_series.quantile([0.25, 0.5, 0.75]).to_dict()
    }
    print(f"[DEBUG] Estad√≠sticas contrafactuales: {stats}")

    # 8) Resultado
    return {
        "imp_df":      imp_df,
        "df_local":    df_local,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_anchors
def _motor_anchors(X: pd.DataFrame, cols: list[str], predict_fn):
    """
    Genera reglas-Anchor (√°rbol surrogate poco profundo) para una SUBmuestra de X.
    Importancia global = frecuencia (relativa) de aparici√≥n de cada variable
    en todas las reglas obtenidas.
    """
    import re, random
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.tree import DecisionTreeRegressor
    from IPython.display import display, HTML

    print("[DEBUG] Iniciando motor Anchors")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Hardcode: n√∫mero de muestras a analizar
    #N_ANCHOR_SAMPLES = 50
    print(f"[DEBUG] Usando N_ANCHOR_SAMPLES={N_ANCHOR_SAMPLES}")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # 1) Submuestra de X para acelerar el proceso
    X_sub = X.sample(n=min(N_ANCHOR_SAMPLES, len(X)), random_state=0)
    n_sub = len(X_sub)
    print(f"[DEBUG] Submuestra creada con {n_sub} instancias")

    # Preparar contadores
    reglas, coberturas, precisiones = [], [], []
    var_freq = {c: 0 for c in cols}

    # 2) Iterar solo sobre la submuestra
    for i, idx in enumerate(X_sub.index):
        x0 = X_sub.loc[idx]
        y0 = predict_fn(x0.values.reshape(1, -1))[0]
        print(f"[DEBUG] Muestra {i+1}/{n_sub} (idx={idx}), pred={y0:.4f}")

        # 3) Vecinos aleatorios de la submuestra
        neigh_idx = random.sample(
            list(X_sub.index),
            k=min(ANC_NEIGHBORS, n_sub)
        )
        X_nei = X_sub.loc[neigh_idx]
        y_nei = predict_fn(X_nei.values)
        print(f"[DEBUG]  Vecinos seleccionados: {len(X_nei)}")

        # 4) Binarizar seg√∫n exceder o no la predicci√≥n base
        y_bin = (y_nei >= y0).astype(int)

        # 5) Ajustar √°rbol surrogate
        tree = DecisionTreeRegressor(
            max_depth=3, min_samples_leaf=5, random_state=0
        )
        tree.fit(X_nei, y_bin)

        # 6) Extraer las condiciones del path de x0
        node_indicator = tree.decision_path(x0.values.reshape(1,-1))
        features      = tree.tree_.feature
        thresholds    = tree.tree_.threshold

        anchor_conds = []
        for node_id in node_indicator.indices:
            if features[node_id] == -2:
                continue  # hoja
            f_idx = features[node_id]
            feat = cols[f_idx]
            thr  = thresholds[node_id]
            op   = "‚â§" if x0[feat] <= thr else ">"
            cond = f"{feat} {op} {thr:.3g}"
            anchor_conds.append(cond)
            var_freq[feat] += 1

        # 7) Calcular cobertura y precisi√≥n
        cover = np.ones(len(X_nei), dtype=bool)
        for cond in anchor_conds:
            m = re.match(r'\s*(.+?)\s*(‚â§|>=|>|<)\s*([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)', cond)
            if not m:
                continue
            f, op_sym, val = m.groups()
            val = float(val)
            if op_sym in ("‚â§", "<="):
                cover &= (X_nei[f] <= val)
            elif op_sym in (">", "‚â•"):
                cover &= (X_nei[f] >= val)
        coverage  = cover.mean()
        precision = (y_nei[cover] >= y0).mean() if coverage > 0 else 0.0

        reglas.append(" ‚àß ".join(anchor_conds))
        coberturas.append(coverage)
        precisiones.append(precision)
        print(f"[DEBUG]  Regla: {' ‚àß '.join(anchor_conds)}")
        print(f"[DEBUG]  Cobertura={coverage:.2%}, Precisi√≥n={precision:.2%}")

    # ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Tablas y gr√°ficas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
    df_local = pd.DataFrame({
        "Regla":     reglas,
        "Cobertura": coberturas,
        "Precisi√≥n": precisiones
    })

    display(HTML("<h4>‚öì Reglas Anchor (submuestra)</h4>"))
    display(df_local.head(10).style.format({"Cobertura":"{:.2%}","Precisi√≥n":"{:.2%}"}))

    # Importancia global
    imp = (pd.Series(var_freq) / n_sub).sort_values(ascending=False)
    imp_df = imp.reset_index().rename(columns={"index":"feature", 0:"value"})

    display(HTML("<h4>‚öì Importancia global (frecuencia en submuestra)</h4>"))
    display(imp_df)

    # Gr√°fico de frecuencias
    plt.figure(figsize=(7,4))
    plt.bar(imp.index, imp.values)
    plt.xticks(rotation=45, ha="right")
    plt.ylabel("Frecuencia")
    plt.title("Anchors ‚Äì Importancia global")
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()

    # Estad√≠sticas adicionales
    stats = {
        "anchors_freq_percentiles": imp.quantile([0.25,0.5,0.75]).to_dict()
    }
    print(f"[DEBUG] Estad√≠sticas Anchors: {stats}")

    return {
        "imp_df":      imp_df,
        "df_local":    df_local,
        "fig_summary": fig,
        "stats":       stats
    }

# Artifact: function _motor_surrogate
def _motor_surrogate(X: pd.DataFrame, cols: list[str], predict_fn):
    """
    Calcula √°rbol sustituto global + regresiones locales usando solo una
    submuestra de X para acelerar el c√°lculo.
    """
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.linear_model import LinearRegression
    from IPython.display import display, HTML

    print("[DEBUG] Iniciando motor Surrogate")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Hardcode: n√∫mero de muestras para el surrogate global y local
    #N_SURR_SAMPLES = 100
    print(f"[DEBUG] Usando N_SURR_SAMPLES={N_SURR_SAMPLES}")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # 1) Submuestra para surrogate global
    n_sub = min(N_SURR_SAMPLES, len(X))
    X_sub = X.sample(n=n_sub, random_state=0)
    print(f"[DEBUG] Submuestra global creada con {n_sub} instancias")

    # ---------- Global surrogate ----------
    y_sub = predict_fn(X_sub)
    print("[DEBUG] Entrenando √°rbol surrogate global")
    tree = DecisionTreeRegressor(max_depth=SURR_TREE_DEPTH, random_state=0)
    tree.fit(X_sub, y_sub)
    imp_global = pd.Series(tree.feature_importances_, index=cols).sort_values(ascending=False)
    print("[DEBUG] Importancias globales calculadas")

    display(HTML('<h4>üåç Importancia Global (Surrogate √°rbol)</h4>'))
    display(imp_global.to_frame('Importancia').T.style.format('{:.3f}'))
    display(HTML(
        '<p>Cada celda muestra la contribuci√≥n de la variable a la reducci√≥n de MSE en el √°rbol '
        'sustituto entrenado sobre la submuestra.</p>'
    ))

    # ---------- Local surrogates ----------
    n_local = min(FIRST_SAMPLES, n_sub)
    print(f"[DEBUG] Generando {n_local} surrogates locales sobre la submuestra")
    local_abs_coef = np.zeros((n_local, len(cols)))

    # usamos X_sub para vecinos locales
    for i, idx in enumerate(X_sub.index[:n_local]):
        x0 = X_sub.loc[idx]
        # distancias sobre la submuestra
        dists = np.linalg.norm(X_sub.values - x0.values, axis=1)
        neigh_idx = dists.argsort()[1:SURR_LOCAL_K+1]
        X_nei = X_sub.iloc[neigh_idx]
        y_nei = predict_fn(X_nei)
        lin = LinearRegression().fit(X_nei, y_nei)
        local_abs_coef[i] = np.abs(lin.coef_)
        print(f"[DEBUG] Local surrogate {i+1}: coef abs media calculada")

    imp_local = pd.Series(local_abs_coef.mean(axis=0), index=cols).sort_values(ascending=False)
    imp_df_local = imp_local.reset_index().rename(columns={'index':'feature', 0:'value'})
    print("[DEBUG] Importancias locales medias calculadas")

    display(HTML('<h4>üè† Importancia Local media (|coef|)</h4>'))
    display(imp_df_local)
    display(HTML(
        '<p>Promedio del valor absoluto de los coeficientes de las regresiones locales '
        'sobre la submuestra.</p>'
    ))

    # ---------- Gr√°fico comparativo ----------
    plt.figure(figsize=(6,4))
    plt.scatter(range(len(imp_global)), imp_global.values,
                label='Global (√°rbol)', color=SURR_COLOR_GLOBAL)
    plt.scatter(range(len(imp_local)),  imp_local.values,
                label='Local (media coef)', marker='x', color=SURR_COLOR_LOCAL)
    plt.xticks(range(len(cols)), imp_global.index, rotation=45, ha='right')
    plt.ylabel('Importancia / |Coef|')
    plt.title('Comparativa Surrogate Global vs Local')
    plt.legend()
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()
    print("[DEBUG] Gr√°fico comparativo generado")

    # Estad√≠sticas adicionales
    diff = (imp_global - imp_local).abs()
    stats = {
        'surrogate_global_percentiles': imp_global.quantile([0.25,0.5,0.75]).to_dict(),
        'surrogate_local_percentiles':  imp_local.quantile([0.25,0.5,0.75]).to_dict(),
        'surrogate_diff_percentiles':   diff.quantile([0.25,0.5,0.75]).to_dict()
    }
    print(f"[DEBUG] Estad√≠sticas Surrogate: {stats}")

    # Resultado
    return {
        'imp_df':      imp_df_local,
        'df_local':    pd.DataFrame(local_abs_coef, columns=cols),
        'fig_summary': fig,
        'stats':       stats
    }

# Artifact: function _motor_ebm
def _motor_ebm(
    X: pd.DataFrame,
    cols: list[str],
    predict_fn,
    *,
    max_rounds: int = EBM_MAX_ITERS,
    n_local: int = FIRST_SAMPLES,
):
    """
    ‚Ä¢ Entrena EBM sobre una submuestra de X para acelerar el c√°lculo.
    ‚Ä¢ Muestra importancia global y contribuciones locales (n_local filas).
    """
    from interpret.glassbox import ExplainableBoostingRegressor
    import numpy as np, pandas as pd, matplotlib.pyplot as plt
    from IPython.display import display, HTML

    # 1) Comprobaci√≥n de disponibilidad de interpret
    if ExplainableBoostingRegressor is None:
        display(HTML(
            "<p style='color:red'>‚ö†Ô∏è  Falta el paquete <code>interpret</code>. "
            "Inst√°lalo con <code>pip install interpret</code>.</p>"
        ))
        return

    print("[DEBUG] Iniciando motor EBM")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Hardcode: tama√±o de la submuestra para EBM
    #N_EBM_SAMPLES = 200
    print(f"[DEBUG] Usando N_EBM_SAMPLES={N_EBM_SAMPLES}")
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # 2) Crear submuestra para entrenamiento global
    n_sub = min(N_EBM_SAMPLES, len(X))
    X_sub = X.sample(n=n_sub, random_state=0)
    print(f"[DEBUG] Submuestra para EBM creada: {n_sub} instancias")

    # 3) Entrenar EBM sobre la submuestra
    y_sub = predict_fn(X_sub)
    print("[DEBUG] Entrenando Explainable Boosting Machine (EBM) sobre submuestra")
    ebm = ExplainableBoostingRegressor(
        max_rounds=max_rounds,
        random_state=0,
        n_jobs=-1
    )
    ebm.fit(X_sub, y_sub)

    # 4) Importancia global
    g_info = ebm.explain_global().data()
    gains = (pd.Series(g_info["scores"], index=g_info["names"])
               .reindex(cols, fill_value=0.0)
               .sort_values(ascending=False))
    imp_df = gains.reset_index().rename(columns={'index':'feature', 0:'value'})
    print("[DEBUG] Importancia global EBM calculada")

    display(HTML("<h4>üåê Importancia global EBM</h4>"))
    display(gains.to_frame("Ganancia").style.format("{:.3f}"))
    display(imp_df)

    # 5) Contribuciones locales (hasta n_local o tama√±o de submuestra)
    n_loc = min(n_local, n_sub)
    print(f"[DEBUG] Calculando contribuciones locales para las primeras {n_loc} instancias de la submuestra")
    contrib = None

    try:  # interpret ‚â• 0.26
        _, contrib = ebm.predict(X_sub.iloc[:n_loc], output_contrib=True)
    except TypeError:
        try:  # interpret 0.24 ‚Äì 0.25
            _, contrib = ebm.predict_and_contrib(X_sub.iloc[:n_loc])
        except (AttributeError, TypeError):
            contrib = None

    # fallback manual si API oficial no disponible
    if contrib is None:
        print("[DEBUG] API local no disponible, calculando manualmente‚Ä¶")
        term_scores = ebm.term_scores_
        term_feats  = getattr(ebm, "feature_groups_", getattr(ebm, "term_features_", None))
        if term_feats is None:
            term_feats = [[i] for i in range(len(cols))]
        bins_attr = "bin_edges_" if hasattr(ebm, "bin_edges_") else "bins_"
        bin_struct = getattr(ebm, bins_attr)

        contrib = np.zeros((n_loc, len(cols)))
        for t, feats in enumerate(term_feats):
            if len(feats) != 1:
                continue
            feat_idx = feats[0]
            # obtener cortes
            cuts = np.asarray(bin_struct[t].get("cuts", []) if isinstance(bin_struct[t], dict) else bin_struct[t])
            if cuts.size == 0:
                continue
            scores = term_scores[t]
            vals = X_sub.iloc[:n_loc, feat_idx].values
            bin_idx = np.searchsorted(cuts, vals, side="right")
            contrib[:, feat_idx] = scores[bin_idx]

    contrib_df = pd.DataFrame(contrib, columns=cols, index=X_sub.index[:n_loc])
    print("[DEBUG] Contribuciones locales calculadas")

    display(HTML(f"<h4>üîé Contribuciones locales (primeras {n_loc})</h4>"))
    display(contrib_df)

    # 6) Gr√°fico de importancia local media
    mean_abs = contrib_df.abs().mean().reindex(gains.index)
    plt.figure(figsize=(6,4))
    plt.scatter(range(len(mean_abs)), mean_abs.values, color="seagreen")
    plt.xticks(range(len(mean_abs)), mean_abs.index, rotation=45, ha="right")
    plt.ylabel("|Contribuci√≥n| media")
    plt.title("Importancia EBM (media |contribuci√≥n|)")
    plt.tight_layout()
    fig = plt.gcf()
    plt.show()
    print("[DEBUG] Gr√°fico local EBM generado")

    display(HTML(
        "<p>Cada punto muestra la media del valor absoluto de la contribuci√≥n de la variable "
        f"en las primeras {n_loc} muestras de la submuestra.</p>"
    ))

    # 7) Estad√≠sticas adicionales
    stats = {
        'ebm_global_percentiles': gains.quantile([0.25,0.5,0.75]).to_dict(),
        'ebm_local_percentiles':  mean_abs.quantile([0.25,0.5,0.75]).to_dict()
    }
    print(f"[DEBUG] Estad√≠sticas EBM: {stats}")

    # 8) Resultado
    return {
        'imp_df':      imp_df,
        'df_local':    contrib_df,
        'fig_summary': fig,
        'stats':       stats
    }

# Artifact: function _motor_optuna
def _motor_optuna(
    X: pd.DataFrame,            # (no se usa pero se mantiene la firma)
    cols: list[str],            # (no se usa)
    _,                          # predict_fn (sin uso)
    default_file: str = "optuna_study.pkl",
    min_trials: int = 10        # n¬∫ m√≠nimo aconsejable de trials
):
    """
    Muestra la importancia de hiperpar√°metros de un `optuna.study.Study`.
    1) Busca un objeto `study` en memoria.
    2) Si no lo encuentra, intenta cargar `default_file`.
    3) Si tampoco est√°, escanea el directorio en busca de `*.pkl`
       con un objeto Study dentro.
    4) Si sigue sin hallarlo, muestra un mensaje muy expl√≠cito con
       los pasos para generarlo.
    """

    # ‚ñ∏ 0. Comprobar dependencias
    if optuna is None:
        display(HTML(
            "<p style='color:red'>‚ö†Ô∏è <code>optuna</code> no est√° instalado. "
            "Ejecuta <code>pip install optuna</code> e int√©ntalo de nuevo.</p>"
        ))
        return
    try:
        from optuna.importance import get_param_importances
    except Exception as e:
        display(HTML(
            f"<p style='color:red'>‚ö†Ô∏è No se pudo importar "
            f"<code>optuna.importance</code>: {e}</p>"
        ))
        return

    # ‚ñ∏ 1. Intentar encontrar el Study en memoria -------------
    study = globals().get("study")
    source = "memoria"

    # ‚ñ∏ 2. Intentar cargar el fichero por defecto -------------
    if study is None and os.path.exists(default_file):
        try:
            with open(default_file, "rb") as f:
                study = pickle.load(f)
            source = f'archivo ‚Äú{default_file}‚Äù'
        except Exception as e:
            display(HTML(
                f"<p style='color:red'>‚ö†Ô∏è No se pudo cargar "
                f"<code>{default_file}</code>: {e}</p>"
            ))

    # ‚ñ∏ 3. Buscar cualquier *.pkl si a√∫n no hay Study ---------
    if study is None:
        for pkl in glob.glob("*.pkl"):
            try:
                with open(pkl, "rb") as f:
                    obj = pickle.load(f)
                if isinstance(obj, optuna.study.Study):
                    study = obj
                    source = f'archivo ‚Äú{pkl}‚Äù'
                    break
            except Exception:
                continue   # ignorar .pkl que no sean Study

    # ‚ñ∏ 4. Si sigue sin Study ‚Üí gu√≠a al usuario ---------------
    if study is None:
        display(HTML(
            f"""
            <div style='border:1px solid #e57373;padding:10px;border-radius:6px'>
              <h4 style='margin-top:0;color:#c62828'>‚ö†Ô∏è  No se encontr√≥ ning√∫n estudio Optuna</h4>
              <p>
                Para utilizar este panel primero necesitas <b>crear y guardar</b> un estudio
                Optuna. Tienes dos formas:
              </p>
              <ol>
                <li>Ejecuta una optimizaci√≥n desde el <i>Bloque&nbsp;3 ‚Üí Optimizaci√≥n</i>
                    (elige motor <code>Optuna</code>). Al finalizar se guardar√°
                    autom√°ticamente <code>{default_file}</code>.</li>
                <li>Si ya tienes un objeto <code>study</code>, gu√°rdalo manualmente:<br>
                   <code>import pickle<br>
                   with open("{default_file}", "wb") as f:<br>&nbsp;&nbsp;&nbsp;&nbsp;pickle.dump(study, f)</code>
                </li>
              </ol>
              <p>Vuelve a lanzar la explicaci√≥n cuando dispongas del archivo.</p>
            </div>
            """
        ))
        return

    # ‚ñ∏ 5. El Study se ha encontrado --------------------------
    n_trials = len(study.trials)
    display(HTML(
        f"<p>‚úÖ <i>Study</i> localizado desde <b>{source}</b> "
        f"con <b>{n_trials}</b> trials.</p>"
    ))
    if n_trials < min_trials:
        display(HTML(
            f"<p style='color:#c57f17'>‚ö†Ô∏è El estudio contiene menos de "
            f"{min_trials} trials; la estimaci√≥n de importancia puede ser inestable.</p>"
        ))

    # ‚ñ∏ 6. Calcular importancia de hiperpar√°metros ------------
    display(HTML("<h4>üìä Importancia global de hiperpar√°metros</h4>"))
    try:
        importances = get_param_importances(study)
    except Exception as e:
        display(HTML(
            f"<p style='color:red'>‚ö†Ô∏è Fall√≥ el c√°lculo de importancia: {e}</p>"
        ))
        return

    imp_series = pd.Series(importances).sort_values(ascending=False)
    imp_df = imp_series.reset_index().rename(columns={'index':'feature', 0:'value'})
    display(imp_df)
    display(imp_series.to_frame('Contribuci√≥n').style.format('{:.2%}'))
    display(HTML(
        '<p><b>¬øC√≥mo leerla?</b> El porcentaje indica cu√°nto explica cada '
        'hiperpar√°metro la variaci√≥n de la m√©trica objetivo. '
        '<br>‚Ä¢ <b>> 25 %</b> ‚áí par√°metro cr√≠tico.<br>'
        '‚Ä¢ <b>< 5 %</b> ‚áí par√°metro con poca influencia.</p>'
    ))

    # ‚ñ∏ 7. Mostrar Top-10 trials ------------------------------
    best_trials = sorted(study.trials, key=lambda t: t.value)[:10]
    df_trials   = pd.DataFrame(
        [{"value": t.value, **t.params} for t in best_trials]
    )
    display(HTML("<h4>üèÖ Top 10 trials</h4>")); display(df_trials)

    # ‚ñ∏ 8. Gr√°fico de barras ---------------------------------
    plt.figure(figsize=(6,4))
    plt.bar(imp_series.index, imp_series.values, color='mediumpurple')
    plt.ylabel('Contribuci√≥n (%)'); plt.title('Importancia hiperpar√°metros Optuna')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    fig = plt.gcf()               # Nuevo para la celda 12
    plt.show()

    display(HTML(
        '<p>La altura de cada barra muestra la influencia relativa. '
        '√ösalo para priorizar en futuras b√∫squedas.</p>'
    ))

    stats = {
        'optuna_imp_percentiles': imp_series.quantile([0.25,0.5,0.75]).to_dict()
    }
    resultado = {
        'imp_df': imp_df,
        'df_local': df_trials,  # top trials
        'fig_summary': fig,
        'stats': stats
    }
    return resultado

# Artifact: assign out_rec
out_rec = widgets.Output()

# Artifact: function mostrar_xai
def mostrar_xai():
    import pandas as pd
    import ipywidgets as widgets
    from IPython.display import display

    out_xai = widgets.Output()

    # 1) Output para pintar la tabla de recomendaciones
    out_rec = widgets.Output()

    # Aqu√≠ tu lista de dicts con todas las recomendaciones
    recomendaciones = [
        {"Modelo":"SVR",          "üöÄ Motor":"SHAP",                     "üìà Rendimiento":"Alto",    "‚è≥ Rapidez":"Lento",   "üí° Justificaci√≥n":"Ideal para explicaciones globales en SVR."},
        {"Modelo":"SVR",          "üöÄ Motor":"LIME",                     "üìà Rendimiento":"Medio",   "‚è≥ Rapidez":"Medio",   "üí° Justificaci√≥n":"Explicaciones locales muy intuitivas."},
        {"Modelo":"NN",           "üöÄ Motor":"Integrated Gradients",     "üìà Rendimiento":"Alto",    "‚è≥ Rapidez":"Medio",   "üí° Justificaci√≥n":"√ìptimo para redes diferenciables."},
        {"Modelo":"NN",           "üöÄ Motor":"DeepLIFT / LRP",           "üìà Rendimiento":"Alto",    "‚è≥ Rapidez":"R√°pido",  "üí° Justificaci√≥n":"Muy eficiente en Atribuciones acumuladas."},
        {"Modelo":"NN",           "üöÄ Motor":"SHAP",                     "üìà Rendimiento":"Alto",    "‚è≥ Rapidez":"Lento",   "üí° Justificaci√≥n":"Model-agn√≥stico, capta complejidades no lineales."},
        {"Modelo":"XGBoost",      "üöÄ Motor":"SHAP (TreeExplainer)",     "üìà Rendimiento":"Alto",    "‚è≥ Rapidez":"R√°pido",  "üí° Justificaci√≥n":"Explainer nativo y ultra-r√°pido para √°rboles."},
        {"Modelo":"XGBoost",      "üöÄ Motor":"Partial Dependence Plot",  "üìà Rendimiento":"Medio",   "‚è≥ Rapidez":"Medio",   "üí° Justificaci√≥n":"Visualiza efectos marginales."},
        {"Modelo":"RandomForest", "üöÄ Motor":"SHAP (TreeExplainer)",     "üìà Rendimiento":"Alto",    "‚è≥ Rapidez":"R√°pido",  "üí° Justificaci√≥n":"Exacto global para bosques."},
        {"Modelo":"RandomForest", "üöÄ Motor":"Permutation Importance",   "üìà Rendimiento":"Medio",   "‚è≥ Rapidez":"Medio",   "üí° Justificaci√≥n":"F√°cil de comparar importancias."},
        {"Modelo":"RNN",          "üöÄ Motor":"Integrated Gradients",     "üìà Rendimiento":"Alto",    "‚è≥ Rapidez":"Medio",   "üí° Justificaci√≥n":"Captura efectos temporales."},
        {"Modelo":"RNN",          "üöÄ Motor":"DeepLIFT / LRP",           "üìà Rendimiento":"Alto",    "‚è≥ Rapidez":"R√°pido",  "üí° Justificaci√≥n":"Eficiente en series temporales."},
    ]

    # 2) Dropdown para seleccionar modelo
    model_dd = widgets.Dropdown(
        options=['SVR','NN','XGBoost','RandomForest','RNN'],
        description='Modelo:',
        layout=widgets.Layout(width='50%')
    )

    # 3) Callback que construye y muestra la tabla
    def _on_model_change(change):
        if change['type']=='change' and change['name']=='value':
            key = change['new']
            # Filtrar s√≥lo las filas que correspondan al modelo seleccionado
            df = pd.DataFrame([r for r in recomendaciones if r['Modelo']==key])
            # Estilizar
            styled = (df.style
                .set_table_styles([
                    {'selector':'th', 'props':[('background-color','#2E3B4E'),
                                              ('color','white'),
                                              ('font-size','14px'),
                                              ('padding','3px'),
                                              ('text-align','center')]},
                    {'selector':'td', 'props':[('font-size','12px'),
                                              ('padding','3px'),
                                              ('text-align','left')]},
                ])
                .hide(axis='index')
                .set_caption(f"üîç Recomendaciones xIA para {key}")
            )
            # Pintar
            with out_rec:
                out_rec.clear_output()
                display(styled)

    # 4) Registrar el observer **despu√©s** de haber definido la funci√≥n**
    model_dd.observe(_on_model_change, names='value')

    # 1) Tipo
    tipo = widgets.Dropdown(options=[('Entrenado','entrenado'),('Optimizado','optimo')], description='Tipo:', layout=widgets.Layout(width='400px'), style={'description_width': '100px'})
    # 2) Modelo
    modelo = widgets.Dropdown(options=[], description='Modelo:', layout=widgets.Layout(width='400px'), style={'description_width': '100px'})
    # 3) M√©todo selecci√≥n
    metodo_sel = widgets.Dropdown(options=SELECT_METHODS, description='M√©todo X:', layout=widgets.Layout(width='400px'), style={'description_width': '100px'})
    # xIA methods
    xai = widgets.SelectMultiple(options=XAI_METHODS, description='xIA:', layout=widgets.Layout(width='400px', height='150px'), style={'description_width': '100px'})

    # Widget de ayuda para describir el m√©todo xIA seleccionado
    help_html = widgets.HTML(value='Seleccione un m√©todo xIA para ver su descripci√≥n aqu√≠.')  # <-- L√≠nea nueva

    # Callback para actualizar lista de modelos seg√∫n tipo
    def _on_tipo(change):
        modelo.options = TRAINED_MODELS if change['new']=='entrenado' else OPTIMIZED_MODELS
    tipo.observe(_on_tipo, names='value')
    modelo.options = TRAINED_MODELS  # por defecto

    # Callback para mostrar ayuda din√°mica seg√∫n selecci√≥n de xIA
    def _on_xai(change):
        selected = change['new']
        if not selected:
            help_html.value = 'Seleccione un m√©todo xIA para ver su descripci√≥n aqu√≠.'  # <-- L√≠nea nueva
        else:
            parts = []
            for m in selected:
                desc = XAI_HELP.get(m, '')
                if m == 'SHAP': parts.append(desc + _generate_shap_diagram())
                elif m == 'LIME': parts.append(desc + _generate_lime_diagram())
                elif m == 'KernelExplainer': parts.append(desc + _generate_shap_diagram())
                elif m == 'Integrated Gradients': parts.append(desc + _generate_ig_diagram())
                elif m == 'DeepLIFT / LRP': parts.append(desc + _generate_dl_diagram())
                elif m == 'Permutation Feature Importance': parts.append(desc + _generate_perm_diagram())
                elif m == 'Partial Dependence Plots (PDP)': parts.append(desc + _generate_pdp_diagram())
                elif m == 'Accumulated Local Effects (ALE)': parts.append(desc+_generate_ale_diagram())
                elif m == "Individual Conditional Expectation (ICE) Plots": parts.append(desc+_generate_ice_diagram())
                elif m == "Counterfactual Explanations": parts.append(desc+_generate_cf_diagram())
                elif m == "Anchors": parts.append(desc + _generate_anchor_diagram())
                elif m == "Surrogate Models (Global/Local)": parts.append(desc + _generate_surr_diagram())
                elif m == "Explainable Boosting Machine (EBM)": parts.append(desc + _generate_ebm_diagram())
                elif m == "Optuna Hyperparameter Importance": parts.append(desc + _generate_optuna_diagram())
                else:
                    parts.append(desc)
            help_html.value = ''.join(parts)
    xai.observe(_on_xai, names='value')

    # Bot√≥n de explicaci√≥n
    btn = widgets.Button(description='üîç Explicar', button_style='info')

    def _on_explain(b):
        import ipywidgets as widgets
        from IPython.display import display, clear_output
        global xai_results
        with out_xai:
            clear_output()

            t = tipo.value
            m_disp = modelo.value
            print(f"-> Tipo: {t}")
            print(f"-> Modelo: {m_disp}")
            print(f"-> M√©todo selecci√≥n: {metodo_sel.value}")
            print(f"-> xIA seleccionadas: {', '.join(xai.value)}")

            raw = modelo.value  # p.ej. "RNN"
            key = None
            model_display = None

            # 1) Match exacto
            if raw in MODEL_KEYS:
                key = MODEL_KEYS[raw]
                model_display = raw
            else:
                # 2) Fallback sufijo (muy raro que empiece a usarse)
                for display_name, short_key in MODEL_KEYS.items():
                    if raw.endswith(display_name):
                        key = short_key
                        model_display = display_name
                        break

            if key is None:
                raise ValueError(f"No puedo mapear ¬´{raw}¬ª a clave interna de modelo.")

            # Asegurarnos de tener el dict inicializado
            if 'xai_results' not in globals():
                xai_results = {}
            if model_display not in xai_results:
                xai_results[model_display] = {}
            if tipo.value == "entrenado":
                patrones = [
                    # ‚îÄ‚îÄ EN EL DIRECTORIO ACTUAL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                    f"modelo_{key}_{metodo_sel.value.lower()}.pkl",
                    f"{key}_{metodo_sel.value.lower()}.pkl",
                    f"modelo_{key}_{metodo_sel.value.lower()}.h5",
                    f"{key}_{metodo_sel.value.lower()}.h5",
                    # ‚îÄ‚îÄ EN SUBCARPETAS (recursivo) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                    f"**/modelo_{key}_{metodo_sel.value.lower()}.pkl",
                    f"**/{key}_{metodo_sel.value.lower()}.pkl",
                    f"**/modelo_{key}_{metodo_sel.value.lower()}.h5",
                    f"**/{key}_{metodo_sel.value.lower()}.h5",
                ]
            else:  # 'optimo'
                patrones = [
                    # b√∫squeda de modelo serializado
                    f"modelos_opt/modelo_{key}_{metodo_sel.value.lower()}*_opt*.pkl",
                    # en caso de que guardes metadata por separado
                    f"modelos_opt/meta_{key}_{metodo_sel.value.lower()}*_opt*.pkl",
                    # si tambi√©n guardas .h5
                    f"modelos_opt/modelo_{key}_{metodo_sel.value.lower()}*_opt*.h5",
                ]
            print("[DEBUG] patrones =", patrones)
            # 2) B√∫squeda recursiva
            files = []
            for pat in patrones:
                files.extend(glob.glob(pat, recursive=True))

            # 3) Depuraci√≥n opcional (puedes comentar la siguiente l√≠nea cuando compruebes que funciona)
            pprint.pprint(files)

            # 4) Seleccionar la primera coincidencia
            if not files:
                print(f"‚ö†Ô∏è  No se encontr√≥ ning√∫n archivo que coincida con los patrones:\n    {patrones}")
                return
            ruta_modelo = files[0]
            print(f"‚úîÔ∏è  Modelo encontrado en: {ruta_modelo}")

            print(f"Verbose: Archivos encontrados: {files}")
            if not ruta_modelo:
                print(f"‚ö†Ô∏è No se encontr√≥ ning√∫n archivo para patr√≥n(s): {patrones}")
                return
            print(f"Verbose: Cargando ruta_modelo: {ruta_modelo}")

            # ‚îÄ‚îÄ‚îÄ cargar modelo y escaladores ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if ruta_modelo.endswith('.pkl'):
                with open(ruta_modelo, 'rb') as f:
                    datos = pickle.load(f)
                # si es un fichero de metadata (no contiene 'model'), buscamos el .h5 asociado
                if 'model' not in datos:
                    print("Verbose: fichero metadata detectado, buscado .h5 correspondiente")
                    # Ejemplo: modelos_opt/meta_nn_pearson_opt_randomsearch.pkl
                    modelo_h5 = ruta_modelo.replace('/meta_', '/modelo_').replace('meta_', 'modelo_').replace('.pkl', '.h5')
                    model_obj = load_model(modelo_h5, compile=False)
                    # ‚îÄ‚îÄ‚îÄ Elige una de las dos:
                    # 1) Descompilar:
                    model_obj = load_model(modelo_h5, compile=False)
                else:
                    model_obj = datos['model']
                # en ambos casos sacamos scalers y cols de este .pkl
                sx   = datos.get('sx', datos.get('scaler_X'))
                sy   = datos.get('sy', datos.get('scaler_Y'))
                cols = datos['cols']
                print(f"Verbose: Escaladores y cols cargados de {ruta_modelo}: {list(datos.keys())}")
            elif ruta_modelo.endswith('.h5'):
                model_obj = load_model(ruta_modelo)
                # cargamos s√≥lo el scaler de X si existe en tu metadata
                meta_file = ruta_modelo.replace('modelo_','escaladores_').replace('.h5','.pkl')
                with open(meta_file,'rb') as f:
                    datos_meta = pickle.load(f)
                sx = datos_meta.get('sx', datos_meta.get('scaler_X'))
                sy = None
                cols = datos_meta['cols']
                print("Verbose: NN .h5 cargado. S√≥lo sx:", sx, "sy ser√° None")
            else:
                raise ValueError(f"Formato de fichero no soportado: {ruta_modelo}")

            # ‚îÄ‚îÄ‚îÄ preparar X antes de llamar a los motores ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            X = X_data[cols].copy()
            print(f"Verbose: Columnas seleccionadas: {cols}")
            print(f"Verbose: X_data shape: {X.shape}")

            # ‚îÄ‚îÄ‚îÄ construir funci√≥n de predicci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if sy is not None:
                predict_fn = lambda X_in: sy.inverse_transform(
                    model_obj.predict(sx.transform(X_in)).reshape(-1,1)
                ).ravel()
            else:
                if sx is not None:
                    predict_fn = lambda X_in: model_obj.predict(sx.transform(X_in)).ravel()
                else:
                    predict_fn = lambda X_in: model_obj.predict(X_in).ravel()

            # 0) Preparar lista de motores a ejecutar:
            seleccion = list(xai.value)
            if "Todos" in seleccion:
                seleccion = ALL_MOTORES

            # ----------------------------------------------------------
            # ‚öôÔ∏è  Motores de explicaci√≥n (13 Motores:
            # SHAP, LIME, KernelExplainer, Integrated Gradients, DeepLIFT/LRP, Permutation Importance, Partial Dependence Plots (PDP),
            # Accumulated Local Effects (ALE), Individual Conditional Expectation (ICE) Plots, Counterfactual Explanations, Anchors, Surrogate Models (Global/Local),
            # Explainable Boosting Machine (EBM) y Optuna Hyperparameter Importance.
            # ----------------------------------------------------------
            # ------------- 1. SHAP --------------------------------
            if "SHAP" in seleccion:
                res = _motor_shap(key, model_obj, X, predict_fn)
                if res is not None:
                    xai_results[model_display]['SHAP'] = res

            # ------------- 2. LIME --------------------------------
            if "LIME" in seleccion:
                res = _motor_lime(X, predict_fn)
                if res is not None:
                    xai_results[model_display]['LIME'] = res

            # ------------- 3. KernelExplainer ---------------------
            if "KernelExplainer" in seleccion:
                res = _motor_kernel(X, predict_fn)
                if res is not None:
                    xai_results[model_display]['KernelExplainer'] = res

            # ------------- 4. Integrated¬†Gradients ----------------
            if "Integrated Gradients" in seleccion:
                res = _motor_ig(key, model_obj, X, cols, sx, predict_fn)
                if res is not None:
                    xai_results[model_display]['Integrated Gradients'] = res

            # ------------- 5. DeepLIFT / LRP ----------------------
            if "DeepLIFT / LRP" in seleccion:
                res = _motor_dl(model_obj, key, X, cols, sx, sy)
                if res is not None:
                    xai_results[model_display]['DeepLIFT / LRP'] = res

            # ------------- 6. Permutation Importance --------------
            if "Permutation Feature Importance" in seleccion:
                res = _motor_perm(model_obj, X, cols, sx, sy)
                if res is not None:
                    xai_results[model_display]['Permutation Feature Importance'] = res

            # ------------- 7. Partial Dependence Plots (PDP) ------
            if "Partial Dependence Plots (PDP)" in seleccion:
                res = _motor_pdp(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Partial Dependence Plots (PDP)'] = res

            # ------------- 8. Accumulated Local Effects (ALE) ------
            if "Accumulated Local Effects (ALE)" in seleccion:
                res = _motor_ale(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Accumulated Local Effects (ALE)'] = res

            # ------------- 9. Individual Conditional Expectation (ICE) Plots ------
            if "Individual Conditional Expectation (ICE) Plots" in seleccion:
                res = _motor_ice(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Individual Conditional Expectation (ICE) Plots'] = res

            # ------------- 10. Counterfactual Explanations ------
            if "Counterfactual Explanations" in seleccion:
                res = _motor_counterfactual(X, predict_fn)
                if res is not None:
                    xai_results[model_display]['Counterfactual Explanations'] = res

            # ------------- 11. Anchors ------
            if "Anchors" in seleccion:
                res = _motor_anchors(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Anchors'] = res

            # ------------- 12. Surrogate Models (Global/Local) ------
            if "Surrogate Models (Global/Local)" in seleccion:
                res = _motor_surrogate(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Surrogate Models (Global/Local)'] = res

            # ------------- 13. Explainable Boosting Machine (EBM) ------
            if "Explainable Boosting Machine (EBM)" in seleccion:
                res = _motor_ebm(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Explainable Boosting Machine (EBM)'] = res

            # ------------- 14. Optuna Hyperparameter Importance ------
            if "Optuna Hyperparameter Importance" in seleccion:
                res = _motor_optuna(X, cols, predict_fn)
                if res is not None:
                    xai_results[model_display]['Optuna Hyperparameter Importance'] = res

    # enlazar callbacks
    btn.on_click(_on_explain)

    display(
        widgets.VBox([
            tipo, modelo, metodo_sel, xai, help_html, model_dd, out_rec, btn, out_xai
        ])
    )

# Artifact: exec exec_301
from IPython.display import clear_output, Markdown, display

# Artifact: exec exec_302
from IPython.display import HTML

# Artifact: exec exec_303
import openai

# Artifact: exec exec_304
from openai import OpenAI

# Artifact: exec exec_305
import scipy.stats

# Artifact: exec exec_306
from matplotlib.figure import Figure

# Artifact: function sanitize_name
def sanitize_name(s):
    """
    Unifica la sanitizaci√≥n de cualquier string de columna:
    - Reemplaza todo car√°cter no alfanum√©rico o gui√≥n bajo por '_'
    - Colapsa m√∫ltiples '_' consecutivos
    - Elimina '_' al inicio y final
    """
    t = re.sub(r"[^\w]", "_", str(s))
    t = re.sub(r"_+", "_", t)
    return t.strip("_")

# Artifact: assign _api_key
_api_key = os.getenv("OPENAI_API_KEY") or ""

# Artifact: assign _client
_client = OpenAI(api_key=_api_key, timeout=30)

# Artifact: assign MAX_EXPLANATION_TOKENS
MAX_EXPLANATION_TOKENS = 800

# Artifact: assign TEMPERATURE_VAL
TEMPERATURE_VAL = 0.2

# Artifact: class ReportBuilder
class ReportBuilder:
    """Orquesta la creaci√≥n del informe a partir de globals()."""
    def __init__(self, global_ns):
        self.g = global_ns
        #self.sections = []

        # ‚Äî‚Äî‚Äî A√ëADIDO: sanitizar s√≥lo una vez que X_train y X_test existen ‚Äî‚Äî‚Äî
        #import re
        #def clean_name(s):
        #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
        #    t = re.sub(r'_+', '_', t)
        #    return t.strip('_')

        # 1) Limpieza de X_train y X_test
        #for df_name in ('X_train','X_test'):
        #    if df_name in self.g:
        #        df = self.g[df_name]
        #        df.columns = [clean_name(c) for c in df.columns]

        # 2) Limpieza de RESUMEN_METODOS
        #if 'RESUMEN_METODOS' in self.g:
        #    for m, lst in self.g['RESUMEN_METODOS'].items():
        #        if isinstance(lst, list):
        #            self.g['RESUMEN_METODOS'][m] = [clean_name(c) for c in lst]
        #        elif isinstance(lst, pd.DataFrame) and not lst.empty:
        #            # si fuese DataFrame, saneamos su columna de Variable
        #            col = 'Variable' if 'Variable' in lst.columns else lst.columns[0]
        #            self.g['RESUMEN_METODOS'][m][col] = lst[col].astype(str).map(clean_name)

        # ‚îÄ‚îÄ‚îÄ **A√ëADIDO** SANITIZACI√ìN DE LOS payload["cols"] EN OPT_MODELS ‚îÄ‚îÄ‚îÄ
        #if 'OPT_MODELS' in self.g:
        #    for key, payload in self.g['OPT_MODELS'].items():
        #        if isinstance(payload, dict) and 'cols' in payload:
        #            payload['cols'] = [clean_name(c) for c in payload['cols']]
        # ‚Äî‚Äî‚Äî FIN A√ëADIDO ‚Äî‚Äî‚Äî

        self.sections = []

        # NUEVO: atributos para el mejor modelo (se rellenar√°n en secci√≥n de selecci√≥n integral)
        self.best_model_info = {}

        self.figures = {}   # Guardaremos aqu√≠ las figuras matplotlib
        print("[DEBUG] 1.1. ReportBuilder.__init__")

    def build_sections(self):
        import pandas as pd
        import numpy as np
        import matplotlib.pyplot as plt
        from scipy import stats
        print("[DEBUG] 1.2. ReportBuilder.build_sections start")

        # --- Inicio de Bloque para normalizar el payload de OPT_MODELS ---
        def _normalize_payload(raw):
            """
            Toma un payload arbitrario de OPT_MODELS y devuelve siempre
            un dict con las mismas claves: model, sx, sy, cols, best_params, score, metric.
            """
            norm = {}
            # 1) Modelo
            if 'model' in raw:
                norm['model'] = raw['model']
            elif raw.get('model_path'):
                try:
                    import joblib, tensorflow as tf
                    if raw['model_path'].endswith(('.h5','.tf')):
                        from tensorflow.keras.models import load_model
                        norm['model'] = load_model(raw['model_path'], compile=False)
                    else:
                        norm['model'] = joblib.load(raw['model_path'])
                except:
                    norm['model'] = None
            else:
                norm['model'] = None

            # 2) M√©tadatos: sx, sy, cols, score, metric, best_params
            for k in ('sx','sy','cols','score','metric','best_params'):
                if k in raw:
                    norm[k] = raw[k]
                elif raw.get('meta_path'):
                    if '_meta' not in raw:
                        import pickle
                        raw['_meta'] = pickle.load(open(raw['meta_path'],'rb'))
                    norm[k] = raw['_meta'].get(k) if k!='best_params' else raw['_meta'].get('best_params', {})
                else:
                    norm[k] = None

            # ‚îÄ‚îÄ‚îÄ A√ëADIDO: asegurar que los cols del payload est√°n saneados ‚îÄ‚îÄ‚îÄ
            #if norm.get('cols') is not None:
            #    import re
            #    def clean_name(s):
            #        t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
            #        t = re.sub(r'_+', '_', t).strip('_')
            #        return t
            #    norm['cols'] = [clean_name(c) for c in norm['cols']]
            # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

            return norm

        # ahora, al empezar cada bloque de optimizaci√≥n, en lugar de:
        #    payload = OPT_MODELS[('svr', sel_method, engine)]
        #    model  = payload['model']; sx = payload['sx']; ...
        # har√≠as:
        #    raw = OPT_MODELS[('svr', sel_method, engine)]
        #    p   = _normalize_payload(raw)
        #    model, sx, sy, cols, score, metric, best_params = (
        #        p['model'], p['sx'], p['sy'], p['cols'], p['score'], p['metric'], p['best_params']
        #    )
        # --- Fin de Bloque para normalizar el payload de OPT_MODELS ---

        self.sections.clear()
        #all_metrics = []
        # =============================================================
        # 1. Carga de datos
        # =============================================================
        try:
            if all(k in self.g for k in ("X_data", "Y_data", "FECHAS")):
                X_data = self.g["X_data"]
                Y_data = self.g["Y_data"]
                FECHAS = self.g["FECHAS"]
                n_rows = len(X_data)
                n_cols = X_data.shape[1] if hasattr(X_data, "shape") else None
                cols = list(X_data.columns) if hasattr(X_data, "columns") else None
                n_nulls = X_data.isna().sum().sum() if hasattr(X_data, "isna") else None

                # Tomar solo primeras 5 filas en DataFrame de muestra:
                df_sample = pd.concat([
                    X_data.head(5).reset_index(drop=True),
                    (Y_data.head(5).reset_index(drop=True)
                        .rename(columns=lambda c: f"Y_{c}" if isinstance(Y_data, pd.DataFrame) else "Y")
                        if isinstance(Y_data, pd.DataFrame) else Y_data.head(5).rename("Y")
                    ),
                    FECHAS.head(5).reset_index(drop=True).rename("Fecha")
                ], axis=1)
                self.sections.append(("### Muestra de Datos Cargados (primeras 5 filas)", df_sample))
                print("[DEBUG] 1.3. Secci√≥n muestra de datos cargados a√±adida")

                prompt_carga = (
                    "Por favor, explica de forma profesional y detallada c√≥mo se ha realizado "
                    "la carga de datos, bas√°ndote en la siguiente informaci√≥n de contexto:\n\n"
                    f"- N√∫mero total de filas originales: {n_rows}\n"
                    f"- N√∫mero de variables (columnas) cargadas: {n_cols}\n"
                    f"- Nombres de columnas (muestra): {cols[:5] if cols else 'N/A'}{'...' if cols and len(cols)>5 else ''}\n"
                    f"- Total de valores nulos en X_data: {n_nulls}\n\n"
                    "Explica por qu√© es importante revisar estos aspectos antes de entrenar modelos, "
                    "qu√© implicaciones tienen (por ejemplo, manejo de nulos, tipos de datos, fechas, etc.), "
                    "y menciona buenas pr√°cticas en esta fase de carga/preprocesado inicial."
                )
                print("[DEBUG]1.4. Iniciando llamada a OpenAI para explicaci√≥n de carga...")
                t0 = time.time()
                stream_resp = _client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Eres un experto en ingenier√≠a de datos y preprocesado para ML."},
                        {"role": "user",   "content": prompt_carga}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS,
                    stream=True
                )
                ai_answer_carga = ""
                for chunk in stream_resp:
                    choice = chunk.choices[0]
                    if hasattr(choice, "delta") and hasattr(choice.delta, "content"):
                        delta = choice.delta.content
                        if delta:
                            ai_answer_carga += delta
                ai_answer_carga = ai_answer_carga.strip()
                if ai_answer_carga:
                    self.sections.append((
                        "### üìù Explicaci√≥n IA de la Carga de Datos",
                        ai_answer_carga
                    ))
                    print("[DEBUG] 1.5. Secci√≥n explicaci√≥n IA de carga a√±adida")
                else:
                    print("[DEBUG] No se recibi√≥ contenido IA para carga")
            else:
                print("[DEBUG] No est√°n X_data/Y_data/FECHAS en globals(), omito muestra y explicaci√≥n de carga")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n o explicaci√≥n IA de carga: {e}")
        # =============================================================
        # 2. Segmentaci√≥n train/test
        # =============================================================
        try:
            if all(k in self.g for k in ("X_train", "Y_train")):
                df_tr = pd.concat([
                    self.g["X_train"].head(5).reset_index(drop=True),
                    self.g["Y_train"].head(5).reset_index(drop=True)
                ], axis=1)
                self.sections.append((
                    "### Tabla 1: Conjunto de Entrenamiento ‚Äì Primeras 5 Muestras",
                    df_tr
                ))
                print("[DEBUG] 2.1. Secci√≥n entrenamiento a√±adida")
            else:
                print("[DEBUG] No hay X_train/Y_train en globals()")
        except Exception as e:
            print(f"[ERROR] al crear secci√≥n entrenamiento: {e}")

        # 3) Tabla de validaci√≥n (5 filas)
        try:
            if all(k in self.g for k in ("X_test", "Y_test")):
                df_te = pd.concat([
                    self.g["X_test"].head(5).reset_index(drop=True),
                    self.g["Y_test"].head(5).reset_index(drop=True)
                ], axis=1)
                self.sections.append((
                    "### Tabla 2: Conjunto de Validaci√≥n ‚Äì Primeras 5 Muestras",
                    df_te
                ))
                print("[DEBUG] 2.2. Secci√≥n test a√±adida")
            else:
                print("[DEBUG] No hay X_test/Y_test en globals()")
        except Exception as e:
            print(f"[ERROR] al crear secci√≥n test: {e}")
        # ... fin de la secci√≥n de carga de datos ...

        # =============================================================
        # 3. Resumen estad√≠stico de X_train y Y_train
        # =============================================================
        try:
            if "X_train" in self.g:
                Xtr = self.g["X_train"]
                desc_X = Xtr.describe().T.reset_index().rename(columns={"index":"Variable"})
                desc_X_sample = desc_X.head(10)
                self.sections.append((
                    "### Estad√≠sticos de X_train (primeras 10 variables)", desc_X_sample
                ))
                print("[DEBUG] 3.1. Secci√≥n estad√≠sticos X_train a√±adida")

                prompt_stats = (
                    "Interpreta profesionalmente estos estad√≠sticos de entrenamiento (primeras 10 variables):\n\n"
                    f"{desc_X_sample.to_dict(orient='list')}\n\n"
                    "Comenta posibles implicaciones (por ejemplo: presencia de outliers, escalas muy distintas entre variables, necesidad de normalizaci√≥n, sesgos en la distribuci√≥n) "
                    "y cu√°les podr√≠an ser buenas pr√°cticas antes de entrenar modelos."
                )
                print("[DEBUG] 3.2. Iniciando llamada a OpenAI para explicaci√≥n IA de estad√≠sticos X_train...")
                stream_resp = _client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Eres un experto en an√°lisis de datos para Machine Learning."},
                        {"role": "user",   "content": prompt_stats}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS,
                    stream=True
                )
                ai_stats = ""
                for chunk in stream_resp:
                    choice = chunk.choices[0]
                    if hasattr(choice, "delta") and hasattr(choice.delta, "content"):
                        delta = choice.delta.content
                        if delta:
                            ai_stats += delta
                ai_stats = ai_stats.strip()
                if ai_stats:
                    self.sections.append((
                        "### üìù Explicaci√≥n IA de los Estad√≠sticos de X_train", ai_stats
                    ))
                    print("[DEBUG] 3.3. Secci√≥n IA estad√≠sticos X_train a√±adida")
                else:
                    print("[DEBUG] No se recibi√≥ contenido IA para estad√≠sticos X_train")
            else:
                print("[DEBUG] No hay X_train en globals(), omito secci√≥n estad√≠sticos X_train")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n estad√≠sticos X_train: {e}")

        try:
            if "Y_train" in self.g:
                Ytr = self.g["Y_train"]
                if isinstance(Ytr, pd.DataFrame):
                    serie = Ytr.iloc[:, 0]
                else:
                    serie = pd.Series(Ytr)
                desc_Ys = serie.describe()  # Series.describe() -> Series
                desc_Y = desc_Ys.to_frame().T.reset_index().rename(columns={"index":"Estad√≠stico"})
                self.sections.append(("### Estad√≠sticos de Y_train", desc_Y))
                print("[DEBUG] 3.4. Secci√≥n estad√≠sticos Y_train a√±adida")

                prompt_Y = (
                    "Interpreta profesionalmente estos estad√≠sticos de la variable objetivo Y:\n\n"
                    f"{desc_Y.to_dict(orient='list')}\n\n"
                    "Comenta posibles implicaciones (asimetr√≠a, outliers, necesidad de transformaciones como log, etc.) "
                    "y su efecto posible en el modelado."
                )
                print("[DEBUG] 3.5. Iniciando llamada a OpenAI para explicaci√≥n IA de Y_train...")
                stream_resp = _client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Eres un experto en an√°lisis de datos para Machine Learning."},
                        {"role": "user",   "content": prompt_Y}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS,
                    stream=True
                )
                ai_Y = ""
                for chunk in stream_resp:
                    choice = chunk.choices[0]
                    if hasattr(choice, "delta") and hasattr(choice.delta, "content"):
                        delta = choice.delta.content
                        if delta:
                            ai_Y += delta
                ai_Y = ai_Y.strip()
                if ai_Y:
                    self.sections.append((
                        "### üìù Explicaci√≥n IA de los Estad√≠sticos de Y_train", ai_Y
                    ))
                    print("[DEBUG] 3.6. Secci√≥n IA estad√≠sticos Y_train a√±adida")
                else:
                    print("[DEBUG] No se recibi√≥ contenido IA para Y_train")
            else:
                print("[DEBUG] No hay Y_train en globals(), omito secci√≥n estad√≠sticos Y_train")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n estad√≠sticos Y_train: {e}")

        # Versi√≥n y entorno
        try:
            import sys, sklearn
            #import pandas as _pd
            info = {
                "python_version": sys.version.split()[0],
                "pandas_version": pd.__version__,
                "sklearn_version": sklearn.__version__,
            }
            #import pandas as _pd
            df_env = pd.DataFrame(list(info.items()), columns=["Paquete","Versi√≥n"])
            self.sections.append(("### Entorno y Versiones de Librer√≠as", df_env))
            print("[DEBUG] 3.7. Secci√≥n entorno/versiones a√±adida")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n entorno/versiones: {e}")

        # 4) Explicaci√≥n IA del split al final
        try:
            if all(k in self.g for k in ("X_train", "X_test", "Y_train", "Y_test")):
                sp = self.g.get("SPLIT_PARAMS", {})
                # Construir prompt solo si SPLIT_PARAMS tiene las claves esperadas
                if sp:
                    prompt_split = (
                        "Por favor, explica c√≥mo se ha realizado la segmentaci√≥n de los datos. "
                        "Usa la siguiente informaci√≥n de contexto:\n\n"
                        f"- Par√°metros de segmentaci√≥n: {sp}\n"
                        f"- Number de muestras train: {len(self.g['X_train'])}\n"
                        f"- N√∫mero de muestras test: {len(self.g['X_test'])}\n\n"
                        f"- test_size: {sp.get('test_size')}\n"
                        f"- random_state: {sp.get('random_state')}\n"
                        f"- estratificar: {sp.get('stratify')}\n"
                        f"- m√©todo de bins: {sp.get('bin_method')}\n"
                        f"- n√∫mero de bins: {sp.get('q_bins')}\n\n"
                        "Quiero un texto profesional, bien estructurado y suficientemente detallado, "
                        "que tambi√©n comente brevemente por qu√© estos valores de par√°metros pueden afectar al rendimiento del modelo."
                    )
                    print("[DEBUG] 3.8. Iniciando llamada a OpenAI para explicaci√≥n del split...")
                    stream_resp = _client.chat.completions.create(
                        model="gpt-4",
                        messages=[
                            {"role": "system", "content": "Eres un experto en preprocesado de datos."},
                            {"role": "user",   "content": prompt_split}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                        stream=True
                    )
                    ai_answer_split = ""
                    for chunk in stream_resp:
                        choice = chunk.choices[0]
                        if hasattr(choice, "delta") and hasattr(choice.delta, "content"):
                            delta = choice.delta.content
                            if delta:
                                ai_answer_split += delta
                    ai_answer_split = ai_answer_split.strip()
                    if ai_answer_split:
                        self.sections.append((
                            "### üìù Explicaci√≥n IA del Preprocesado y del Split",
                            ai_answer_split
                        ))
                        print("[DEBUG] 3.9. Secci√≥n explicaci√≥n IA del split a√±adida")
                    else:
                        print("[DEBUG] No se recibi√≥ contenido IA para split")
                else:
                    print("[DEBUG] No hay SPLIT_PARAMS definidos, omito explicaci√≥n IA del split")
            else:
                print("[DEBUG] Faltan datos de entrenamiento/test, omito explicaci√≥n IA del split")
        except Exception as e:
            print(f"[ERROR] al generar explicaci√≥n IA del split: {e}")
        # ... fin de la secci√≥n de Split de los Datos Cargados ...

        # =============================================================
        # 4. Visualizaciones de Y y de las correlaciones X vs Y
        # =============================================================
        import matplotlib.pyplot as plt

        # 2.1 Histograma de Y_train
        try:
            if "Y_train" in self.g:
                y_train = self.g["Y_train"]
                # Si Y_train es DataFrame con varias columnas, tomamos la primera:
                if isinstance(y_train, pd.DataFrame) and y_train.shape[1] > 1:
                    y_ser = y_train.iloc[:, 0]
                else:
                    # si es DataFrame de 1 columna o Serie:
                    y_ser = y_train.iloc[:, 0] if isinstance(y_train, pd.DataFrame) else pd.Series(y_train)
                fig_hist, ax = plt.subplots()
                ax.hist(y_ser.dropna(), bins=30, edgecolor='black')
                ax.set_title("Distribuci√≥n de Y_train")
                ax.set_xlabel("Y")
                ax.set_ylabel("Frecuencia")
                plt.tight_layout()
                # Guardar figura en self.figures y en sections para render
                self.figures["hist_Y_train"] = fig_hist
                self.sections.append((
                    "### Gr√°fico: Histograma de Y (Train)",
                    fig_hist
                ))
                print("[DEBUG] 4.1. Secci√≥n histograma Y_train a√±adida")
            else:
                print("[DEBUG] No hay Y_train en globals(), omito histograma")
        except Exception as e:
            print(f"[ERROR] al generar histograma Y_train: {e}")

        # 2.2 Correlaci√≥n X_train vs Y_train
        # 2.2 Correlaci√≥n X_train vs Y_train (filtrada por umbral)
        try:
            if "X_train" in self.g and "Y_train" in self.g:
                X_train = self.g["X_train"]
                y_train = self.g["Y_train"]

                if isinstance(y_train, pd.DataFrame) and y_train.shape[1] > 1:
                    y_ser = y_train.iloc[:, 0]
                else:
                    y_ser = y_train.iloc[:, 0] if isinstance(y_train, pd.DataFrame) else pd.Series(y_train)

                df_corr = X_train.copy().reset_index(drop=True)
                df_corr["_Y_target"] = y_ser.reset_index(drop=True)

                corr_matrix = df_corr.corr(numeric_only=True)

                # === üîç FILTRO: seleccionar solo columnas con correlaci√≥n > umbral con _Y_target ===
                umbral_corr = 0.3  # Se puede ajustar este valor
                correlaciones_con_y = corr_matrix["_Y_target"].abs()
                variables_filtradas = correlaciones_con_y[correlaciones_con_y > umbral_corr].index.tolist()

                # Mantener solo las columnas con correlaci√≥n alta
                corr_matrix_filtrada = corr_matrix.loc[variables_filtradas, variables_filtradas]

                fig_corr, ax = plt.subplots(figsize=(max(10, len(variables_filtradas)*0.6), max(8, len(variables_filtradas)*0.5)))
                cax = ax.matshow(corr_matrix_filtrada, cmap='viridis')
                fig_corr.colorbar(cax, ax=ax, shrink=0.8)

                labels = list(corr_matrix_filtrada.columns)
                ax.set_xticks(range(len(labels)))
                ax.set_yticks(range(len(labels)))
                ax.set_xticklabels(labels, rotation=90, fontsize=8, ha='left')
                ax.set_yticklabels(labels, fontsize=8)

                ax.tick_params(axis='x', which='both', labelsize=7, pad=1)
                ax.tick_params(axis='y', which='both', labelsize=7, pad=1)

                ax.set_title(f"Matriz de correlaci√≥n (|r| > {umbral_corr})", pad=30, fontsize=12)
                plt.tight_layout()

                self.figures["corr_XY_train"] = fig_corr
                self.sections.append((
                    f"### Gr√°fico: Matriz de Correlaci√≥n X vs Y (|r| > {umbral_corr})",
                    fig_corr
                ))
                print("[DEBUG] 4.2. Secci√≥n matriz de correlaci√≥n a√±adida con filtro")
            else:
                print("[DEBUG] No hay X_train/Y_train en globals(), omito correlaci√≥n")
        except Exception as e:
            print(f"[ERROR] al generar matriz de correlaci√≥n: {e}")

#        try:
#            if "X_train" in self.g and "Y_train" in self.g:
#                X_train = self.g["X_train"]
#                y_train = self.g["Y_train"]
#                # Sacar Serie de Y como antes
#                if isinstance(y_train, pd.DataFrame) and y_train.shape[1] > 1:
#                    y_ser = y_train.iloc[:, 0]
#                else:
#                    y_ser = y_train.iloc[:, 0] if isinstance(y_train, pd.DataFrame) else pd.Series(y_train)
#                # Concatenar para c√°lculo de correlaci√≥n:
#                df_corr = X_train.copy().reset_index(drop=True)
#                df_corr["_Y_target"] = y_ser.reset_index(drop=True)
#                # Calculamos matriz de correlaciones:
#                corr_matrix = df_corr.corr(numeric_only=True)  # pandas ‚â•1.5
#                # Creamos heatmap con matplotlib puro:
#                fig_corr, ax = plt.subplots(figsize=(6, 6))
#                cax = ax.matshow(corr_matrix, cmap='viridis')
#                fig_corr.colorbar(cax, ax=ax)
#                # Etiquetas:
#                labels = list(corr_matrix.columns)
#                ax.set_xticks(range(len(labels)))
#                ax.set_yticks(range(len(labels)))
#                ax.set_xticklabels(labels, rotation=90, fontsize=8)
#                ax.set_yticklabels(labels, fontsize=8)
#                ax.set_title("Matriz de correlaci√≥n (X_train vs Y_train incluida)", pad=20)
#                plt.tight_layout()
#                self.figures["corr_XY_train"] = fig_corr
#                self.sections.append((
#                    "### Gr√°fico: Matriz de Correlaci√≥n X vs Y (Train)",
#                    fig_corr
#                ))
#                print("[DEBUG] 4.2. Secci√≥n matriz de correlaci√≥n a√±adida")
#            else:
#                print("[DEBUG] No hay X_train/Y_train en globals(), omito correlaci√≥n")
#        except Exception as e:
#            print(f"[ERROR] al generar matriz de correlaci√≥n: {e}")

        # 2.3 Comentario IA sobre distribuci√≥n y correlaciones
        try:
            # Solo si disponemos de histogram y/o correlaciones:
            if "hist_Y_train" in self.figures:
                # Preparamos prompt para la IA
                # Ejemplo de contexto: medias, sesgo, kurtosis, correlaciones m√°ximas
                import numpy as np
                # Estad√≠sticos de Y:
                y_arr = y_ser.dropna().values
                media = float(np.mean(y_arr))
                mediana = float(np.median(y_arr))
                std = float(np.std(y_arr, ddof=1))
                # Sesgo y curtosis opcionales si numpy/scipy disponibles:
                try:
                    from scipy.stats import skew, kurtosis
                    sesgo = float(skew(y_arr))
                    kurt = float(kurtosis(y_arr))
                except Exception:
                    sesgo = None
                    kurt = None
                # Estad√≠sticos de correlaci√≥n: extraer de corr_matrix
                if "corr_XY_train" in self.figures:
                    # Obtenemos correlaciones de X con Y:
                    # La columna ‚Äú_Y_target‚Äù
                    corrs = corr_matrix["_Y_target"].drop("_Y_target", errors='ignore')
                    # Tomamos los pares con mayor valor absoluto:
                    if not corrs.empty:
                        top = corrs.abs().sort_values(ascending=False).head(3)
                        # Formatear para prompt
                        top_info = {col: float(corrs[col]) for col in top.index}
                    else:
                        top_info = {}
                else:
                    top_info = {}
                # Construir prompt:
                prompt_vis = (
                    "Eres un experto en an√°lisis exploratorio de datos.\n"
                    "Analiza la distribuci√≥n de la variable objetivo Y y las correlaciones "
                    "entre las variables X y Y bas√°ndote en estos estad√≠sticos:\n\n"
                    f"- Media de Y_train: {media:.4f}\n"
                    f"- Mediana de Y_train: {mediana:.4f}\n"
                    f"- Desviaci√≥n est√°ndar de Y_train: {std:.4f}\n"
                )
                if sesgo is not None:
                    prompt_vis += f"- Sesgo (skewness) de Y_train: {sesgo:.4f}\n"
                if kurt is not None:
                    prompt_vis += f"- Curtosis de Y_train: {kurt:.4f}\n"
                if top_info:
                    prompt_vis += "- Correlaciones m√°s relevantes X vs Y:\n"
                    for feat, corrv in top_info.items():
                        prompt_vis += f"    ‚Ä¢ {feat}: {corrv:.4f}\n"
                prompt_vis += (
                    "\nPor favor, genera un texto profesional y detallado que comente:\n"
                    "  * Si la distribuci√≥n de Y parece sim√©trica o sesgada, posibles implicaciones.\n"
                    "  * Si hay variables con fuerte correlaci√≥n absoluta con Y (positiva o negativa) y qu√© puede indicar.\n"
                    "  * Buenas pr√°cticas o precauciones al modelar con base en dicha distribuci√≥n/correlaciones.\n"
                )
                print("[DEBUG] 4.3. Iniciando llamada a OpenAI para comentario visualizaciones...")
                # Llamada a OpenAI (sin stream, con l√≠mite de tokens razonable):
                resp = _client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Eres un experto en an√°lisis exploratorio de datos para ML."},
                        {"role": "user", "content": prompt_vis}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS  # ajustable
                )
                comentario_vis = resp.choices[0].message.content.strip()
                if comentario_vis:
                    self.sections.append((
                        "### üìù Comentario IA: Distribuci√≥n de Y y Correlaciones",
                        comentario_vis
                    ))
                    print("[DEBUG] 4.4. Secci√≥n comentario IA visualizaciones a√±adida")
                else:
                    print("[DEBUG] No se recibi√≥ contenido IA para visualizaciones")
            else:
                print("[DEBUG] No hay histograma de Y para IA, omito comentario visualizaciones")
        except Exception as e:
            print(f"[ERROR] al generar comentario IA de visualizaciones: {e}")
        # ... fin de la secci√≥n de visualizaci√≥n de an√°lisis de datos cargados ...

        # =============================================================
        # 5. Selecci√≥n de variables independientes X
        # =============================================================
        try:
            # Caso 1: RESUMEN_METODOS (varios m√©todos acumulativos)
            if "RESUMEN_METODOS" in self.g and isinstance(self.g["RESUMEN_METODOS"], dict):
                resumen = self.g["RESUMEN_METODOS"]
            else:
                resumen = None

            # Caso 2: Selecci√≥n m√°s reciente puntual
            tiene_reciente = all(k in self.g for k in ("VARIABLES_SELECCIONADAS", "METODO_SELECCION"))
            # Preparar datos para correlaciones si est√°n en globals
            tiene_corr = "VALORES_CORRELACION" in self.g
            corr_global = self.g.get("VALORES_CORRELACION", None)

            # Tambi√©n comprobamos si disponemos de X_train/Y_train para rec√°lculo de correl si se prefiere
            have_xy = all(k in self.g for k in ("X_train", "Y_train"))
            if have_xy:
                X_train = self.g["X_train"]
                Y_train = self.g["Y_train"]
                import pandas as _pd  # asegurar pandas disponible
                if isinstance(Y_train, _pd.DataFrame):
                    y_ser = Y_train.iloc[:, 0]
                else:
                    y_ser = Y_train

            # Primero, si RESUMEN_METODOS existe, iteramos cada m√©todo
            if resumen:
                # Si adem√°s quieres usar VALORES_CORRELACION puntual, podr√≠as ignorarlo aqu√≠
                for metodo, cols in resumen.items():
                    # Construcci√≥n de DataFrame con correlaciones
                    df_sel = None
                    if have_xy:
                        corr_vals = []
                        for col in cols:
                            if col in X_train.columns:
                                try:
                                    corr = X_train[col].corr(y_ser)
                                except Exception:
                                    corr = None
                            else:
                                corr = None
                            corr_vals.append(corr)
                        import pandas as _pd
                        df_sel = _pd.DataFrame({
                            "Variable": cols,
                            "Correlaci√≥n con Y": corr_vals
                        })
                    else:
                        import pandas as _pd
                        df_sel = _pd.DataFrame({"Variable": cols})
                    titulo_tab = f"### Tabla: Selecci√≥n de Variables ({metodo})"
                    self.sections.append((titulo_tab, df_sel))
                    print(f"[DEBUG] 5.1. Secci√≥n selecci√≥n de variables a√±adida para m√©todo: {metodo}")

                    # Preparar prompt IA
                    # Si existe un dict global con par√°metros, usalo; si no, om√≠telo:
                    params = self.g.get("SELECTION_PARAMS", {}).get(metodo, {})
                    prompt_sel = (
                        f"Has aplicado un m√©todo de selecci√≥n de variables llamado '{metodo}'.\n"
                        f"Par√°metros del m√©todo: {params}\n"
                        f"Variables seleccionadas ({len(cols)}): {cols}\n"
                    )
                    if have_xy:
                        prompt_sel += "Correlaciones con la variable objetivo:\n"
                        for var, corr in zip(cols, corr_vals):
                            prompt_sel += f"  - {var}: {corr}\n"
                        prompt_sel += "\n"
                    prompt_sel += (
                        "Por favor, genera un texto profesional y detallado que explique:\n"
                        "- En qu√© consiste este m√©todo de selecci√≥n de variables y significado de sus par√°metros.\n"
                        "- C√≥mo influyen dichos par√°metros en la selecci√≥n.\n"
                        "- Interpretaci√≥n de los valores de correlaci√≥n obtenidos.\n"
                        "- Buenas pr√°cticas al usar este m√©todo en preprocesado de datos para ML.\n"
                    )
                    try:
                        print(f"[DEBUG] 5.2. Iniciando llamada a OpenAI para explicaci√≥n selecci√≥n ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en selecci√≥n de variables para ML."},
                                {"role": "user", "content": prompt_sel}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_sel = resp.choices[0].message.content.strip()
                        if explanation_sel:
                            titulo_exp = f"### üìù Explicaci√≥n IA Selecci√≥n de Variables ({metodo})"
                            self.sections.append((titulo_exp, explanation_sel))
                            print(f"[DEBUG] 5.3. Secci√≥n explicaci√≥n IA selecci√≥n a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ contenido IA para selecci√≥n {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA selecci√≥n {metodo}: {e}")

            # Luego, si existe una selecci√≥n puntual reciente
            if not resumen and tiene_reciente:
                metodo = self.g["METODO_SELECCION"]
                cols = self.g["VARIABLES_SELECCIONADAS"]
                # Construir DataFrame
                df_sel = None
                import pandas as _pd
                if tiene_corr:
                    corr_vals = None
                    # VALORES_CORRELACION puede ser dict o lista
                    vc = corr_global
                    if isinstance(vc, dict):
                        # Aseguramos la lista del mismo orden
                        corr_vals = [vc.get(var, None) for var in cols]
                    elif isinstance(vc, (list, tuple)):
                        # Si la longitud coincide con cols
                        if len(vc) == len(cols):
                            corr_vals = list(vc)
                        else:
                            corr_vals = [None]*len(cols)
                    else:
                        corr_vals = [None]*len(cols)
                    df_sel = _pd.DataFrame({
                        "Variable": cols,
                        "Correlaci√≥n con Y": corr_vals
                    })
                else:
                    # Si no hay VALORES_CORRELACION, pero se dispone de X_train/Y_train, recalculamos
                    if have_xy:
                        corr_vals = []
                        for col in cols:
                            if col in X_train.columns:
                                try:
                                    corr = X_train[col].corr(y_ser)
                                except Exception:
                                    corr = None
                            else:
                                corr = None
                            corr_vals.append(corr)
                        df_sel = _pd.DataFrame({
                            "Variable": cols,
                            "Correlaci√≥n con Y": corr_vals
                        })
                    else:
                        df_sel = _pd.DataFrame({"Variable": cols})
                titulo_tab = f"### Tabla: Selecci√≥n de Variables ({metodo})"
                self.sections.append((titulo_tab, df_sel))
                print(f"[DEBUG] 5.4. Secci√≥n selecci√≥n de variables puntual a√±adida para m√©todo: {metodo}")

                # Prompt IA
                prompt_sel = (
                    f"Has aplicado un m√©todo de selecci√≥n de variables llamado '{metodo}'.\n"
                    f"Variables seleccionadas ({len(cols)}): {cols}\n"
                )
                if tiene_corr or have_xy:
                    prompt_sel += "Correlaciones con la variable objetivo:\n"
                    if 'corr_vals' in locals():
                        for var, corr in zip(cols, corr_vals):
                            prompt_sel += f"  - {var}: {corr}\n"
                    prompt_sel += "\n"
                prompt_sel += (
                    "Por favor, genera un texto profesional y detallado que explique:\n"
                    "- En qu√© consiste este m√©todo de selecci√≥n de variables (breve descripci√≥n basada en su nombre) y significado de sus par√°metros si los conoces.\n"
                    "- Interpretaci√≥n de los valores de correlaci√≥n obtenidos.\n"
                    "- Buenas pr√°cticas al usar este m√©todo en preprocesado de datos para ML.\n"
                )
                try:
                    print(f"[DEBUG] 5.5. Iniciando llamada a OpenAI para explicaci√≥n selecci√≥n puntual ({metodo})...")
                    resp = _client.chat.completions.create(
                        model="gpt-4",
                        messages=[
                            {"role": "system", "content": "Eres un experto en selecci√≥n de variables para ML."},
                            {"role": "user", "content": prompt_sel}
                        ],
                        max_tokens=MAX_EXPLANATION_TOKENS,
                        temperature=TEMPERATURE_VAL
                    )
                    explanation_sel = resp.choices[0].message.content.strip()
                    if explanation_sel:
                        titulo_exp = f"### üìù Explicaci√≥n IA Selecci√≥n de Variables ({metodo})"
                        self.sections.append((titulo_exp, explanation_sel))
                        print(f"[DEBUG] 5.6. Secci√≥n explicaci√≥n IA selecci√≥n puntual a√±adida para m√©todo: {metodo}")
                    else:
                        print("[DEBUG] No se recibi√≥ contenido IA para selecci√≥n puntual")
                except Exception as e:
                    print(f"[ERROR] al generar explicaci√≥n IA selecci√≥n puntual {metodo}: {e}")

            if not resumen and not tiene_reciente:
                print("[DEBUG] No hay RESUMEN_METODOS ni selecci√≥n puntual en globals(), omito secci√≥n de selecci√≥n de variables")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n o explicaci√≥n IA de selecci√≥n de variables: {e}")

        # ... fin de la secci√≥n de selecci√≥n de variables ...

        # =============================================================
        # 6. Entrenamiento Modelo SVR
        # =============================================================
        try:
            # <<< Aqu√≠ inserta las inicializaciones >>>
            rmse = mae = r2 = None
            residuos = None
            # Comprobamos RESUMEN_METODOS y existencia de X_test/Y_test
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                import pandas as _pd

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Extraer y_test_arr como 1D array
                arr = None
                import numpy as _np
                y_test_arr = None
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2:
                        if arr.shape[1] == 1:
                            y_test_arr = arr[:, 0]
                        else:
                            y_test_arr = arr[:, 0]
                    else:
                        y_test_arr = arr
                else:
                    y_test_arr = _np.array(Y_test)
                    if y_test_arr.ndim == 2 and y_test_arr.shape[1] == 1:
                        y_test_arr = y_test_arr[:, 0]
                if y_test_arr.ndim > 1:
                    y_test_arr = y_test_arr.ravel()

                metrics_summary = []
                resumen_modelos = []
                # Iteramos sobre cada m√©todo declarado en RESUMEN_METODOS
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    # Nombre de fichero pickle seg√∫n celda 7.1
                    fname = f"modelo_svr_{metodo_low}.pkl"
                    if not os.path.exists(fname):
                        print(f"[DEBUG] 6.1. Fichero de modelo SVR no encontrado para m√©todo '{metodo}': {fname}, omito este m√©todo")
                        continue
                    # Cargar pickle
                    try:
                        with open(fname, "rb") as f:
                            data = pickle.load(f)
                        model = data.get("model", None)
                        sx = data.get("sx", None)
                        sy = data.get("sy", None)
                        cols = data.get("cols", None)
                        # yname = data.get("yname", None)  # si quieres mostrar el nombre de la variable
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Falta alguna clave en pickle SVR para m√©todo '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar pickle SVR para m√©todo '{metodo}': {e}")
                        continue

                    # Verificar columnas en X_test_full
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para m√©todo '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue
                    # Subconjunto X_test
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar, predecir y desescalar
                    try:
                        X_test_scaled = sx.transform(X_test_sel)
                        y_pred_scaled = model.predict(X_test_scaled)
                        # sy estuvo ajustado sobre y entrenado; para inverse_transform debe recibir 2D:
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar SVR para m√©todo '{metodo}': {e}")
                        continue

                    # Calcular m√©tricas
                    try:
                        # Rangos Real vs Predicha
                        y_real_min, y_real_max = float(_np.min(y_test_arr)), float(_np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(_np.min(y_pred)), float(_np.max(y_pred))
                        # 3) Estad√≠sticos de residuos:
                        residuals = y_test_arr - y_pred

                        res_mean = float(np.mean(residuals))            # Media
                        res_std  = float(np.std(residuals))             # Desviaci√≥n est√°ndar:
                        res_series = pd.Series(residuals)               # Asimetria
                        res_skew = float(res_series.skew())             # Asimetria
                        res_kurt = float(res_series.kurtosis())         # Curtosis
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]    # Cuantiles:
                        # M√©tricas
                        mse = mean_squared_error(y_test_arr, y_pred)
                        rmse = float(_np.sqrt(mse))
                        mae = float(mean_absolute_error(y_test_arr, y_pred))
                        r2 = float(r2_score(y_test_arr, y_pred))
                        resumen_modelos.append({
                            'M√©todo': metodo,
                            'R2': r2, 'MSE': mse, 'RMSE': rmse, 'MAE': mae
                        })
                        # Correlaci√≥n Real vs Predicha
                        try:
                            corr = float(_np.corrcoef(y_test_arr, y_pred)[0, 1])
                        except:
                            corr = None
                    except Exception as e:
                        print(f"[ERROR] al calcular m√©tricas SVR para m√©todo '{metodo}': {e}")

                    metrics_summary.append({
                        "metodo": metodo,
                        "rmse": rmse,
                        "mae": mae,
                        "r2": r2
                    })

                    # 1) Par√°metros de entrenamiento obtenidos desde el modelo
                    try:
                        # SVR tiene atributos: C, epsilon, kernel, gamma
                        C_val = getattr(model, "C", None)
                        epsilon_val = getattr(model, "epsilon", None)
                        kernel_val = getattr(model, "kernel", None)
                        gamma_val = getattr(model, "gamma", None)
                        params = {
                            "C": C_val,
                            "epsilon": epsilon_val,
                            "kernel": kernel_val,
                            "gamma": gamma_val
                        }
                        df_params = _pd.DataFrame({
                            "Hiperpar√°metro": list(params.keys()),
                            "Valor": [str(v) for v in params.values()]
                        })
                        titulo_p = f"### Par√°metros de Entrenamiento SVR ({metodo})"
                        self.sections.append((titulo_p, df_params))
                        print(f"[DEBUG] 6.2. Secci√≥n par√°metros SVR a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al extraer/par√°metros SVR para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA de los hiperpar√°metros
                    try:
                        prompt_params = (
                            f"Has entrenado un modelo SVR con selecci√≥n de variables '{metodo}'.\n"
                            f"Estos fueron los hiperpar√°metros utilizados:\n"
                        )
                        for k, v in params.items():
                            prompt_params += f"- {k}: {v}\n"
                        prompt_params += (
                            "\nPor favor, explica de forma profesional y detallada c√≥mo estos hiperpar√°metros "
                            "pueden influir en el entrenamiento del modelo SVR, su impacto en ajuste, "
                            "y buenas pr√°cticas para seleccionarlos o afinarlos."
                        )
                        print(f"[DEBUG] 6.3. Iniciando llamada a OpenAI para explicaci√≥n hiperpar√°metros SVR ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en entrenamiento de modelos SVR."},
                                {"role": "user", "content": prompt_params}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_params = resp.choices[0].message.content.strip()
                        if explanation_params:
                            titulo_exp_p = f"### üìù Explicaci√≥n IA Hiperpar√°metros SVR ({metodo})"
                            self.sections.append((titulo_exp_p, explanation_params))
                            print(f"[DEBUG] 6.4. Secci√≥n explicaci√≥n IA hiperpar√°metros a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ IA para hiperpar√°metros SVR ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA hiperpar√°metros SVR para m√©todo '{metodo}': {e}")

                    # 2) Gr√°fica Predicho vs Real
                    try:
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(y_test_arr, y_pred, alpha=0.6)
                        ax1.plot([y_test_arr.min(), y_test_arr.max()],
                                 [y_test_arr.min(), y_test_arr.max()],
                                 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"SVR Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gr√°fica SVR Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 6.5. Secci√≥n gr√°fica Pred vs Real a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica Pred vs Real para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA Pred vs Real
                    try:
                        prompt_pred_real = (
                        f"A continuaci√≥n tienes datos de la gr√°fica de comparaci√≥n Real vs Predicci√≥n para el modelo SVR con m√©todo '{metodo}':\n"
                        #f"- R2: {r2:.4f}\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- R¬≤: {r2}\n"
                        f"- Correlaci√≥n entre Y real y predicha: {corr:.4f}\n"
                        f"- Rango Y real: [{y_real_min:.4f}, {y_real_max:.4f}]\n"
                        f"- Rango Y predicha: [{y_pred_min:.4f}, {y_pred_max:.4f}]\n"
                        "\n"
                        "Tambi√©n tienes datos de la gr√°fica de residuos:\n"
                        f"- Media de residuos (Real - Predicha): {res_mean:.4f}\n"
                        f"- Desviaci√≥n est√°ndar de residuos: {res_std:.4f}\n"
                        f"- Asimetr√≠a de residuos: {res_skew:.4f}\n"
                        f"- Curtosis de residuos: {res_kurt:.4f}\n"
                        f"- Cuantiles de residuos: 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}\n"
                        "\n"
                        "Bas√°ndote en estos valores y en las gr√°ficas generadas (Real vs Predicci√≥n y Residuos), "
                        "proporciona un an√°lisis detallado, se√±alando si hay sesgos sistem√°ticos (por ejemplo, subestimaci√≥n o sobrestimaci√≥n en ciertos rangos), "
                        "si la dispersi√≥n es mayor en alg√∫n rango de predicci√≥n, si los residuos muestran patrones (p. ej. forma de embudo), "
                        "y qu√© implicaciones tiene para la calidad del modelo. "
                        "Usa un texto profesional y bien estructurado, y menciona qu√© indicios de la gr√°fica respaldan tus conclusiones."
                    )
                        print(f"[DEBUG] 6.6. Llamada IA Pred vs Real ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_pred_real}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### üìù Explicaci√≥n IA Predicho vs Real ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 6.7. Secci√≥n explicaci√≥n IA Pred vs Real a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ IA Pred vs Real ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA Pred vs Real para m√©todo '{metodo}': {e}")

                    # 3) Gr√°fica de residuos
                    try:
                        # 4) Rango de Y real y predicha:
                        y_real_min, y_real_max = float(np.min(y_test_arr)), float(np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(np.min(y_pred)), float(np.max(y_pred))
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"SVR Residuos ({metodo})")
                        titulo_fig2 = f"### Gr√°fica SVR Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 6.8. Secci√≥n gr√°fica residuos a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica residuos para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA Residuos
                    try:
                        prompt_residuos = (
                            f"A continuaci√≥n tienes estad√≠sticas de los residuos (Real - Predicha) del modelo SVR con m√©todo '{metodo}':\n"
                            f"- Media: {res_mean:.4f}\n"
                            f"- Desviaci√≥n est√°ndar: {res_std:.4f}\n"
                            f"- Asimetr√≠a: {res_skew:.4f}\n"
                            f"- Curtosis: {res_kurt:.4f}\n"
                            f"- Cuantiles: 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}\n"
                            "\n"
                            "Bas√°ndote en estos valores y en la gr√°fica de residuos, analiza si hay patrones (por ejemplo, heterocedasticidad, outliers, sesgos en rangos), "
                            "y comenta qu√© implicaciones tiene para la robustez y generalizaci√≥n del modelo. "
                            "Usa un texto profesional y bien estructurado."
                        )
                        print(f"[DEBUG] 6.9. Llamada IA Residuos ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_residuos}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### üìù Explicaci√≥n IA Residuos ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 6.10. Secci√≥n explicaci√≥n IA residuos a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ IA Residuos ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA residuos para m√©todo '{metodo}': {e}")

                    # 4) Tabla M√©tricas y explicaci√≥n IA
                    try:
                        df_met = _pd.DataFrame([{"M√©trica": "RMSE", "Valor": rmse},
                                                {"M√©trica": "MAE", "Valor": mae},
                                                {"M√©trica": "R2",  "Valor": r2}])
                        titulo_met = f"### M√©tricas SVR ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 6.11. Secci√≥n m√©tricas a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame m√©tricas SVR para m√©todo '{metodo}': {e}")

                    try:
                        prompt_metrics = (
                            f"Estas son las m√©tricas del modelo SVR con m√©todo '{metodo}':\n"
                            f"- R2: {r2:.4f}\n"
                            f"- MSE: {mse:.4f}\n"
                            f"- RMSE: {rmse:.4f}\n"
                            f"- MAE: {mae:.4f}\n"
                            f"- Correlaci√≥n Real vs Predicha: {corr:.4f}\n"
                            "\n"
                            "Analiza estos valores en contexto: ¬øson adecuados? ¬øqu√© sugieren respecto al rendimiento del modelo? "
                            "Menciona referencias a la gr√°fica Real vs Predicci√≥n y a los residuos si procede."
                        )
                        print(f"[DEBUG] 6.12. Llamada IA M√©tricas SVR ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_metrics}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### üìù Explicaci√≥n IA M√©tricas SVR ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 6.13. Secci√≥n explicaci√≥n IA m√©tricas a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ IA M√©tricas SVR ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA m√©tricas para m√©todo '{metodo}': {e}")

                # 5) Comparativa global de m√©tricas SVR
                if metrics_summary:
                    try:
                        df_comp = _pd.DataFrame(metrics_summary)
                        df_comp_sorted = df_comp.sort_values("rmse")
                        titulo_comp = "### Comparativa M√©tricas SVR entre M√©todos"
                        self.sections.append((titulo_comp, df_comp_sorted))
                        print("[DEBUG] 6.14. Secci√≥n comparativa m√©tricas SVR a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo m√©tricas SVR: {e}")

                    try:
                        prompt_conc = (
                            "Se han entrenado varios modelos SVR con diferentes m√©todos de selecci√≥n de variables.\n"
                            "M√©tricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary:
                            prompt_conc += f"- M√©todo '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos m√©todos: "
                            "indica cu√°l se comporta mejor, posibles razones y recomendaciones sobre selecci√≥n de variables o ajustes para mejorar SVR."
                        )
                        print("[DEBUG] 6.15. Llamada IA Conclusiones SVR...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_conc}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc = resp.choices[0].message.content.strip()
                        if explanation_conc:
                            titulo_exp_conc = "### üìù Conclusiones IA Entrenamiento SVR"
                            self.sections.append((titulo_exp_conc, explanation_conc))
                            print("[DEBUG] 6.16. Secci√≥n explicaci√≥n IA conclusiones SVR a√±adida")
                        else:
                            print("[DEBUG] No se recibi√≥ IA Conclusiones SVR")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA conclusiones SVR: {e}")
            else:
                print("[DEBUG] No est√°n RESUMEN_METODOS o X_test/Y_test en globals(), omito secci√≥n SVR")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n SVR en informe: {e}")
        # ... fin de la secci√≥n de entrenamiento SVR ...

        # ==============================
        # 6.1. Interpretaci√≥n xIA para modelo entrenado SVR
        # ==============================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificaci√≥n previa
        # ----------------------------------------------------------------
        try:
            print("[DEBUG] 6.17. Iniciando secci√≥n xIA para SVR")
            if 'xai_results' not in globals() or 'SVR' not in xai_results:
                raise RuntimeError(
                    "No se encontr√≥ `xai_results['SVR']`. "
                    "Aseg√∫rate de haber ejecutado la Celda 10 y almacenado los resultados xIA de SVR en `xai_results['SVR']`."
                )

                # Cabecera
                self.sections.append((
                    "## üîç An√°lisis xIA de SVR: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vac√≠o, la cabecera se mostrar√° como Markdown
                ))


            # Funci√≥n para llamar a OpenAI con un prompt espec√≠fico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuraci√≥n: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cu√°ntas caracter√≠sticas top incluir en el prompt
            N_LOCAL = 3    # cu√°ntas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de m√©todos xIA y claves en xai_results['SVR']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 6.18. Procesando secci√≥n xIA: {titulo}")
                datos = xai_results['SVR'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ‚ö†Ô∏è No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 6.19. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gr√°fico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 6.20. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estad√≠sticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gr√°fico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores num√©ricos concretos ---------------
                print(f"[DEBUG] 6.21. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el m√©todo xIA '{titulo}' al modelo SVR entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gr√°fico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    ‚Ä¢ {f}: {imp:.4f}\n"

                # Ahora s√≠ le pides que interprete el gr√°fico:
                prompt += (
                    "- Interpreta el gr√°fico anterior: "
                    "describe qu√© patrones o relaciones visuales revela c√≥mo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} caracter√≠sticas por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye tambi√©n columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato gen√©rico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # ‚Äî Siempre sacamos el √≠ndice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribuci√≥n):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estad√≠sticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estad√≠sticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo SVR
                prompt += (
                    "\nContexto: El modelo SVR fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este SVR.\n"
                )

                # 5) Preguntas/pautas espec√≠ficas seg√∫n el m√©todo
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¬øqu√© implica sobre la predicci√≥n en ese caso? Y si es negativo, ¬øqu√© implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una direcci√≥n) y c√≥mo afecta al comportamiento general del SVR.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para SVR.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¬øqu√© implica para la predicci√≥n local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupaci√≥n de variables, detecci√≥n de outliers, etc., basadas en la interpretaci√≥n LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global seg√∫n los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: c√≥mo cada caracter√≠stica empuja la predicci√≥n en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para SVR), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribuci√≥n integrada de cada variable: interpretaci√≥n de importancia global.\n"
                        "2. Analizar las primeras muestras: qu√© implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Se√±alar limitaciones: compatibilidad con SVR no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros m√©todos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qu√© significa para la predicci√≥n.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la ca√≠da en la m√©trica al permutar cada variable: por qu√© ciertas variables son cr√≠ticas.\n"
                        "2. Comentar la desviaci√≥n est√°ndar: ¬øindica inestabilidad en la importancia? ¬øD√≥nde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selecci√≥n de variables basadas en esta m√©trica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicci√≥n seg√∫n el rango PDP obtenido.\n"
                        "2. Se√±alar si los rangos sugieren relaciones mon√≥tonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretaci√≥n.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) seg√∫n los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar c√≥mo ALE corrige artefactos de correlaci√≥n y qu√© nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspecci√≥n de distribuci√≥n) seg√∫n hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qu√© mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Se√±alar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar c√≥mo interpretar los contrafactuales: cambios en variables que generan aumento en predicci√≥n.\n"
                        "2. Analizar variables con mayor |Œî| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Se√±alar si faltan contrafactuales para algunas muestras: qu√© puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir c√≥mo usar estos insights para ajuste de modelo o recolecci√≥n de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar c√≥mo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicci√≥n.\n"
                        "2. Analizar frecuencia global de aparici√≥n de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Se√±alar regiones de bajo coverage o baja precisi√≥n: d√≥nde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolecci√≥n de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (√°rbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qu√© sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del SVR en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo seg√∫n discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global seg√∫n EBM: c√≥mo se comparan con otros m√©todos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qu√© patrones se observan.\n"
                        "3. Se√±alar si EBM revela interacciones no consideradas en SVR.\n"
                        "4. Recomendar posibles ajustes en caracter√≠sticas o validaciones seg√∫n insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperpar√°metros en la optimizaci√≥n del SVR.\n"
                        "2. Analizar top trials si est√°n disponibles: qu√© combinaciones de hiperpar√°metros funcionaron mejor.\n"
                        "3. Se√±alar limitaciones de la muestra de trials (n√∫mero de pruebas) y posibles riesgos de sobreajuste en la b√∫squeda.\n"
                        "4. Recomendar pr√≥ximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados num√©ricos y qu√© implicaciones tienen para el modelo SVR.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 6.22. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicaci√≥n Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ‚ö†Ô∏è Error en secci√≥n xIA SVR",
                f"Se produjo un error al generar la secci√≥n xIA de SVR: {e}"
            ))

        # =============================================================
        # 7. Entrenamiento Modelo NN
        # =============================================================
        try:
            # Comprobamos RESUMEN_METODOS y existencia de X_test/Y_test
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import numpy as np
                import pandas as _pd
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                from tensorflow.keras.models import load_model

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Preparamos array 1D de y_test
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2 and arr.shape[1] == 1:
                        y_test_arr = arr[:, 0]
                    elif arr.ndim == 2 and arr.shape[1] > 1:
                        y_test_arr = arr[:, 0]
                    else:
                        y_test_arr = arr.ravel()
                else:
                    y_test_arr = np.array(Y_test).ravel()
                # Aseguramos 1D
                y_test_arr = y_test_arr.ravel()

                metrics_summary_nn = []
                # Iteramos sobre cada m√©todo declarado en RESUMEN_METODOS
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    # Rutas a los archivos NN guardados en celda 7.2
                    model_fname = f"modelo_nn_{metodo_low}.h5"
                    scaler_fname = f"escaladores_nn_{metodo_low}.pkl"
                    hp_fname = f"hyperparams_nn_{metodo_low}.pkl"
                    #hyper_fname = f"hyperparams_nn_{metodo_low}.pkl"
                    if not os.path.exists(model_fname) or not os.path.exists(scaler_fname):
                        print(f"[DEBUG] Fichero de modelo NN o escaladores no encontrado para m√©todo '{metodo}': omito este m√©todo")
                        continue
                    # Cargar modelo y escaladores
                    try:
                        model = load_model(model_fname)
                        with open(scaler_fname, "rb") as f:
                            data_s = pickle.load(f)
                        sx = data_s.get("scaler_X", None)
                        sy = data_s.get("scaler_Y", None)
                        cols = data_s.get("cols", None)
                        # y_variable_name = data_s.get("yname", None)
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Falta clave en escaladores NN para m√©todo '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar modelo/escaladores NN para m√©todo '{metodo}': {e}")
                        continue

                    # Verificar columnas en X_test
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para m√©todo '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue

                    # Subconjunto X_test
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar, predecir y desescalar
                    try:
                        X_test_scaled = sx.transform(X_test_sel)
                        #y_pred_scaled = model.predict(X_test_scaled).ravel()
                        y_pred_scaled = model.predict(X_test_scaled, verbose=0).ravel()
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar NN para m√©todo '{metodo}': {e}")
                        continue

                    # 1) Cargar hiperpar√°metros
                    try:
                        hp_fname = f"hyperparams_nn_{metodo.lower()}.pkl"
                        if os.path.exists(hp_fname):
                            with open(hp_fname, "rb") as f:
                                hp = pickle.load(f)
                        else:
                            hp = None
                        # Representar en DataFrame
                        if hp:
                            import pandas as _pd
                            df_hp = _pd.DataFrame({
                                "Hiperpar√°metro": list(hp.keys()),
                                "Valor": [str(v) for v in hp.values()]
                            })
                            titulo_hp = f"### Par√°metros de Entrenamiento NN ({metodo})"
                            self.sections.append((titulo_hp, df_hp))
                            print(f"[DEBUG] 7.1. Secci√≥n par√°metros NN a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No hay hyperparams guardados para NN m√©todo '{metodo}'")
                    except Exception as e:
                        print(f"[ERROR] al extraer/par√°metros NN para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA hiperpar√°metros NN
                    try:
                        if hp:
                            prompt_params = (
                                f"Has entrenado un modelo de Red Neuronal con selecci√≥n de variables '{metodo}'.\n"
                                "Estos fueron los hiperpar√°metros utilizados:\n"
                            )
                            for k, v in hp.items():
                                prompt_params += f"- {k}: {v}\n"
                            prompt_params += (
                                "\nPor favor, explica de forma profesional y detallada c√≥mo estos hiperpar√°metros "
                                "pueden influir en el entrenamiento de la red neuronal, su impacto en ajuste, "
                                "y buenas pr√°cticas para seleccionarlos o afinarlos."
                            )
                            print(f"[DEBUG] 7.2. Iniciando llamada a OpenAI para explicaci√≥n hiperpar√°metros NN ({metodo})...")
                            resp = _client.chat.completions.create(
                                model="gpt-4",
                                messages=[
                                    {"role": "system", "content": "Eres un experto en entrenamiento de redes neuronales para regresi√≥n."},
                                    {"role": "user", "content": prompt_params}
                                ],
                                max_tokens=MAX_EXPLANATION_TOKENS,
                                temperature=TEMPERATURE_VAL
                            )
                            explanation_hp = resp.choices[0].message.content.strip()
                            if explanation_hp:
                                titulo_exp_hp = f"### üìù Explicaci√≥n IA Hiperpar√°metros NN ({metodo})"
                                self.sections.append((titulo_exp_hp, explanation_hp))
                                print(f"[DEBUG] 7.3. Secci√≥n explicaci√≥n IA hiperpar√°metros NN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA hiperpar√°metros NN para m√©todo '{metodo}': {e}")

                    # 2) Gr√°fica Predicho vs Real
                    try:
                        import matplotlib.pyplot as plt
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(y_test_arr, y_pred, alpha=0.6)
                        ax1.plot([y_test_arr.min(), y_test_arr.max()],
                                 [y_test_arr.min(), y_test_arr.max()],
                                 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"NN Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gr√°fica NN Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 7.4. Secci√≥n gr√°fica Pred vs Real NN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica Pred vs Real NN para m√©todo '{metodo}': {e}")

                    # Estad√≠sticas para contexto IA Pred vs Real
                    try:
                        mse = mean_squared_error(y_test_arr, y_pred)
                        rmse = np.sqrt(mse)
                        mae = mean_absolute_error(y_test_arr, y_pred)
                        r2 = r2_score(y_test_arr, y_pred)
                        corr = np.corrcoef(y_test_arr, y_pred)[0,1] if len(y_test_arr)>1 else None
                        y_real_min, y_real_max = float(np.min(y_test_arr)), float(np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(np.min(y_pred)), float(np.max(y_pred))
                    except Exception:
                        mse = rmse = mae = r2 = corr = None
                        y_real_min = y_real_max = y_pred_min = y_pred_max = None

                    # Explicaci√≥n IA Pred vs Real NN con contexto num√©rico
                    try:
                        prompt_pr = (
                            f"A continuaci√≥n tienes datos de la gr√°fica de comparaci√≥n Real vs Predicci√≥n para el modelo NN con m√©todo '{metodo}':\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- R¬≤: {r2}\n"
                            f"- Correlaci√≥n entre Y real y predicha: {corr}\n"
                            f"- Rango Y real: [{y_real_min}, {y_real_max}]\n"
                            f"- Rango Y predicha: [{y_pred_min}, {y_pred_max}]\n\n"
                            "Bas√°ndote en estos valores y en la gr√°fica generada (Real vs Predicci√≥n), "
                            "proporciona un an√°lisis detallado, se√±alando si hay sesgos sistem√°ticos (por ejemplo, subestimaci√≥n o sobreestimaci√≥n en ciertos rangos), "
                            "si la dispersi√≥n es mayor en alg√∫n rango de predicci√≥n, y qu√© implicaciones tiene para la calidad del modelo. "
                            "Usa un texto profesional y bien estructurado, y menciona qu√© indicios de la gr√°fica respaldan tus conclusiones."
                        )
                        print(f"[DEBUG] 7.5. Llamada IA Pred vs Real NN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_pr}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### üìù Explicaci√≥n IA Predicho vs Real NN ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 7.6. Secci√≥n explicaci√≥n IA Pred vs Real NN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA Pred vs Real NN para m√©todo '{metodo}': {e}")

                    # 3) Gr√°fica de residuos NN
                    try:
                        residuals = y_test_arr - y_pred
                        res_mean = float(np.mean(residuals))
                        res_std  = float(np.std(residuals))
                        # Estad√≠sticos de residuos con pandas
                        res_series = _pd.Series(residuals)
                        res_skew = float(res_series.skew())
                        res_kurt = float(res_series.kurtosis())
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                        # Rango de Y real y predicha
                        # (ya lo tenemos en y_real_min, etc.)
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"NN Residuos ({metodo})")
                        titulo_fig2 = f"### Gr√°fica NN Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 7.7. Secci√≥n gr√°fica residuos NN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica residuos NN para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA Residuos NN con contexto num√©rico
                    try:
                        prompt_res = (
                            f"A continuaci√≥n tienes estad√≠sticas de los residuos (Real - Predicha) del modelo NN con m√©todo '{metodo}':\n"
                            f"- Media: {res_mean}\n"
                            f"- Desviaci√≥n est√°ndar: {res_std}\n"
                            f"- Asimetr√≠a: {res_skew}\n"
                            f"- Curtosis: {res_kurt}\n"
                            f"- Cuantiles: 25%={q25}, 50%={q50}, 75%={q75}\n\n"
                            "Bas√°ndote en estos valores y en la gr√°fica de residuos, analiza si hay patrones (por ejemplo, heterocedasticidad, outliers, sesgos en rangos), "
                            "y comenta qu√© implicaciones tiene para la robustez y generalizaci√≥n del modelo. "
                            "Usa un texto profesional y bien estructurado."
                        )
                        print(f"[DEBUG] 7.8. Llamada IA Residuos NN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_res}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### üìù Explicaci√≥n IA Residuos NN ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 7.9. Secci√≥n explicaci√≥n IA residuos NN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA residuos NN para m√©todo '{metodo}': {e}")

                    # 4) Tabla M√©tricas NN y explicaci√≥n IA
                    try:
                        df_met = _pd.DataFrame([
                            {"M√©trica": "RMSE", "Valor": rmse},
                            {"M√©trica": "MAE", "Valor": mae},
                            {"M√©trica": "R2",  "Valor": r2}
                        ])
                        titulo_met = f"### M√©tricas NN ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 7.10. Secci√≥n m√©tricas NN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame m√©tricas NN para m√©todo '{metodo}': {e}")

                    try:
                        prompt_met = (
                            f"Estas son las m√©tricas del modelo NN con m√©todo '{metodo}':\n"
                            f"- R2: {r2}\n"
                            f"- MSE: {mse}\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- Correlaci√≥n Real vs Predicha: {corr}\n\n"
                            "Analiza estos valores en contexto: ¬øson adecuados? ¬øqu√© sugieren respecto al rendimiento del modelo? "
                            "Menciona referencias a la gr√°fica Real vs Predicci√≥n y a los residuos si procede."
                        )
                        print(f"[DEBUG] 7.11. Llamada IA M√©tricas NN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_met}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### üìù Explicaci√≥n IA M√©tricas NN ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 7.12. Secci√≥n explicaci√≥n IA m√©tricas NN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA m√©tricas NN para m√©todo '{metodo}': {e}")

                    # Acumular para comparativa
                    metrics_summary_nn.append({
                        "metodo": metodo,
                        "rmse": rmse,
                        "mae": mae,
                        "r2": r2
                    })

                # 5) Comparativa global de m√©tricas NN
                if metrics_summary_nn:
                    try:
                        df_comp_nn = _pd.DataFrame(metrics_summary_nn)
                        df_comp_nn_sorted = df_comp_nn.sort_values("rmse")
                        titulo_comp_nn = "### Comparativa M√©tricas NN entre M√©todos"
                        self.sections.append((titulo_comp_nn, df_comp_nn_sorted))
                        print("[DEBUG] 7.13. Secci√≥n comparativa m√©tricas NN a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo m√©tricas NN: {e}")

                    try:
                        prompt_conc_nn = (
                            "Se han entrenado varios modelos de Red Neuronal con diferentes m√©todos de selecci√≥n de variables.\n"
                            "M√©tricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary_nn:
                            prompt_conc_nn += f"- M√©todo '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc_nn += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos m√©todos: "
                            "indica cu√°l se comporta mejor, posibles razones y recomendaciones sobre selecci√≥n de variables o ajustes para mejorar la red neuronal."
                        )
                        print("[DEBUG] 7.14. Llamada IA Conclusiones NN...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_conc_nn}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc_nn = resp.choices[0].message.content.strip()
                        if explanation_conc_nn:
                            titulo_exp_conc_nn = "### üìù Conclusiones IA Entrenamiento NN"
                            self.sections.append((titulo_exp_conc_nn, explanation_conc_nn))
                            print("[DEBUG] 7.15. Secci√≥n explicaci√≥n IA conclusiones NN a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA conclusiones NN: {e}")
            else:
                print("[DEBUG] No est√°n RESUMEN_METODOS o X_test/Y_test en globals(), omito secci√≥n NN")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n NN en informe: {e}")
        # ... fin de la secci√≥n de entrenamiento NN ...

        # =============================================================
        # 7.1. Interpretaci√≥n xIA para modelo entrenado NN
        # =============================================================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificaci√≥n previa
        # ----------------------------------------------------------------
        try:
            print("[DEBUG] 7.16. Iniciando secci√≥n xIA para NN")
            if 'xai_results' not in globals() or 'NN' not in xai_results:
                raise RuntimeError(
                    "No se encontr√≥ `xai_results['NN']`. "
                    "Aseg√∫rate de haber ejecutado la Celda 10 y almacenado los resultados xIA de NN en `xai_results['NN']`."
                )

                # Cabecera
                self.sections.append((
                    "## üîç An√°lisis xIA de NN: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vac√≠o, la cabecera se mostrar√° como Markdown
                ))


            # Funci√≥n para llamar a OpenAI con un prompt espec√≠fico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuraci√≥n: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cu√°ntas caracter√≠sticas top incluir en el prompt
            N_LOCAL = 3    # cu√°ntas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de m√©todos xIA y claves en xai_results['NN']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 7.17. Procesando secci√≥n xIA: {titulo}")
                datos = xai_results['NN'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ‚ö†Ô∏è No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 7.18. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gr√°fico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 7.19. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estad√≠sticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gr√°fico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores num√©ricos concretos ---------------
                print(f"[DEBUG] 7.20. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el m√©todo xIA '{titulo}' al modelo NN entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gr√°fico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    ‚Ä¢ {f}: {imp:.4f}\n"

                # Ahora s√≠ le pides que interprete el gr√°fico:
                prompt += (
                    "- Interpreta el gr√°fico anterior: "
                    "describe qu√© patrones o relaciones visuales revela c√≥mo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} caracter√≠sticas por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye tambi√©n columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato gen√©rico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # ‚Äî Siempre sacamos el √≠ndice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribuci√≥n):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estad√≠sticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estad√≠sticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo NN
                prompt += (
                    "\nContexto: El modelo NN fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este NN.\n"
                )

                # 5) Preguntas/pautas espec√≠ficas seg√∫n el m√©todo
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¬øqu√© implica sobre la predicci√≥n en ese caso? Y si es negativo, ¬øqu√© implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una direcci√≥n) y c√≥mo afecta al comportamiento general del NN.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para NN.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¬øqu√© implica para la predicci√≥n local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupaci√≥n de variables, detecci√≥n de outliers, etc., basadas en la interpretaci√≥n LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global seg√∫n los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: c√≥mo cada caracter√≠stica empuja la predicci√≥n en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para NN), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribuci√≥n integrada de cada variable: interpretaci√≥n de importancia global.\n"
                        "2. Analizar las primeras muestras: qu√© implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Se√±alar limitaciones: compatibilidad con NN no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros m√©todos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qu√© significa para la predicci√≥n.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la ca√≠da en la m√©trica al permutar cada variable: por qu√© ciertas variables son cr√≠ticas.\n"
                        "2. Comentar la desviaci√≥n est√°ndar: ¬øindica inestabilidad en la importancia? ¬øD√≥nde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selecci√≥n de variables basadas en esta m√©trica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicci√≥n seg√∫n el rango PDP obtenido.\n"
                        "2. Se√±alar si los rangos sugieren relaciones mon√≥tonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretaci√≥n.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) seg√∫n los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar c√≥mo ALE corrige artefactos de correlaci√≥n y qu√© nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspecci√≥n de distribuci√≥n) seg√∫n hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qu√© mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Se√±alar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar c√≥mo interpretar los contrafactuales: cambios en variables que generan aumento en predicci√≥n.\n"
                        "2. Analizar variables con mayor |Œî| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Se√±alar si faltan contrafactuales para algunas muestras: qu√© puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir c√≥mo usar estos insights para ajuste de modelo o recolecci√≥n de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar c√≥mo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicci√≥n.\n"
                        "2. Analizar frecuencia global de aparici√≥n de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Se√±alar regiones de bajo coverage o baja precisi√≥n: d√≥nde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolecci√≥n de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (√°rbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qu√© sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del NN en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo seg√∫n discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global seg√∫n EBM: c√≥mo se comparan con otros m√©todos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qu√© patrones se observan.\n"
                        "3. Se√±alar si EBM revela interacciones no consideradas en NN.\n"
                        "4. Recomendar posibles ajustes en caracter√≠sticas o validaciones seg√∫n insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperpar√°metros en la optimizaci√≥n del NN.\n"
                        "2. Analizar top trials si est√°n disponibles: qu√© combinaciones de hiperpar√°metros funcionaron mejor.\n"
                        "3. Se√±alar limitaciones de la muestra de trials (n√∫mero de pruebas) y posibles riesgos de sobreajuste en la b√∫squeda.\n"
                        "4. Recomendar pr√≥ximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados num√©ricos y qu√© implicaciones tienen para el modelo NN.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 7.21. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicaci√≥n Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ‚ö†Ô∏è Error en secci√≥n xIA NN",
                f"Se produjo un error al generar la secci√≥n xIA de NN: {e}"
            ))

        # =====================================================================
        # 8. Entrenamiento Modelo XGBoost
        # =====================================================================
        try:
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import numpy as np
                import pandas as _pd
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Extraer array 1D de Y_test
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2 and arr.shape[1] >= 1:
                        y_test_arr = arr[:, 0].ravel()
                    else:
                        y_test_arr = arr.ravel()
                else:
                    y_test_arr = np.array(Y_test).ravel()
                y_test_arr = y_test_arr.ravel()

                metrics_summary_xgb = []
                # Iterar sobre cada m√©todo
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    pickle_fname = f"modelo_xgb_{metodo_low}.pkl"
                    if not os.path.exists(pickle_fname):
                        print(f"[DEBUG] Fichero de modelo XGBoost no encontrado para m√©todo '{metodo}': {pickle_fname}, omito este m√©todo")
                        continue
                    # Cargar modelo y escaladores
                    try:
                        with open(pickle_fname, "rb") as f:
                            data = pickle.load(f)
                        model = data.get("model", None)
                        sx = data.get("sx", None)
                        sy = data.get("sy", None)
                        cols = data.get("cols", None)
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Faltan claves en pickle XGBoost para m√©todo '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar pickle XGBoost para m√©todo '{metodo}': {e}")
                        continue

                    # Verificar columnas
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para m√©todo '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue
                    # Subconjunto X_test
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar, predecir, desescalar
                    try:
                        X_test_scaled = sx.transform(X_test_sel)
                        y_pred_scaled = model.predict(X_test_scaled)
                        # Desescalar: sy.inverse_transform espera 2D
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar XGBoost para m√©todo '{metodo}': {e}")
                        continue

                    # C√°lculo de m√©tricas y estad√≠sticos
                    try:
                        # Rangos Y real y predicha
                        y_real_min, y_real_max = float(np.min(y_test_arr)), float(np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(np.min(y_pred)), float(np.max(y_pred))
                        # Residuos
                        residuals = y_test_arr - y_pred
                        res_mean = float(np.mean(residuals))
                        res_std = float(np.std(residuals))
                        # Estad√≠sticos de residuos con pandas
                        res_series = _pd.Series(residuals)
                        res_skew = float(res_series.skew())
                        res_kurt = float(res_series.kurtosis())
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                        # M√©tricas cl√°sicas
                        mse = mean_squared_error(y_test_arr, y_pred)
                        rmse = float(np.sqrt(mse))
                        mae = float(mean_absolute_error(y_test_arr, y_pred))
                        r2 = float(r2_score(y_test_arr, y_pred))
                        # Correlaci√≥n real vs predicha (si hay suficientes puntos)
                        try:
                            corr = float(np.corrcoef(y_test_arr, y_pred)[0,1]) if len(y_test_arr) > 1 else None
                        except:
                            corr = None
                        # Acumular resumen
                        metrics_summary_xgb.append({
                            "metodo": metodo,
                            "rmse": rmse,
                            "mae": mae,
                            "r2": r2
                        })

                    except Exception as e:
                        print(f"[ERROR] al calcular m√©tricas XGBoost para m√©todo '{metodo}': {e}")
                        # si algo falla, saltar a next
                        continue

                    # 1) Par√°metros de entrenamiento obtenidos desde el modelo XGBRegressor
                    try:
                        # get_params suele incluir: 'n_estimators', 'learning_rate', 'max_depth', 'subsample', etc.
                        params_all = model.get_params()
                        # Extraer los principales:
                        params = {
                            "n_estimators": params_all.get("n_estimators", None),
                            "learning_rate": params_all.get("learning_rate", None),
                            "max_depth": params_all.get("max_depth", None),
                            "subsample": params_all.get("subsample", None)
                        }
                        df_params = _pd.DataFrame({
                            "Hiperpar√°metro": list(params.keys()),
                            "Valor": [str(v) for v in params.values()]
                        })
                        titulo_p = f"### Par√°metros de Entrenamiento XGBoost ({metodo})"
                        self.sections.append((titulo_p, df_params))
                        print(f"[DEBUG] 8.1. Secci√≥n par√°metros XGBoost a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al extraer par√°metros XGBoost para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA de los hiperpar√°metros XGBoost
                    try:
                        prompt_params = (
                            f"Has entrenado un modelo XGBoost con selecci√≥n de variables '{metodo}'.\n"
                            "Estos fueron los hiperpar√°metros utilizados:\n"
                        )
                        for k, v in params.items():
                            prompt_params += f"- {k}: {v}\n"
                        prompt_params += (
                            "\nPor favor, explica de forma profesional y detallada c√≥mo estos hiperpar√°metros "
                            "pueden influir en el entrenamiento del modelo XGBoost, su impacto en ajuste, "
                            "regularizaci√≥n, sobreajuste o subajuste, y buenas pr√°cticas para afinarlos."
                        )
                        print(f"[DEBUG] 8.2. Iniciando llamada a OpenAI para explicaci√≥n hiperpar√°metros XGBoost ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en entrenamiento de modelos XGBoost para regresi√≥n."},
                                {"role": "user", "content": prompt_params}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_params = resp.choices[0].message.content.strip()
                        if explanation_params:
                            titulo_exp_p = f"### üìù Explicaci√≥n IA Hiperpar√°metros XGBoost ({metodo})"
                            self.sections.append((titulo_exp_p, explanation_params))
                            print(f"[DEBUG] 8.3. Secci√≥n explicaci√≥n IA hiperpar√°metros XGBoost a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ IA para hiperpar√°metros XGBoost ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA hiperpar√°metros XGBoost para m√©todo '{metodo}': {e}")

                    # 2) Gr√°fica Predicho vs Real
                    try:
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(y_test_arr, y_pred, alpha=0.6)
                        ax1.plot([y_real_min, y_real_max], [y_real_min, y_real_max], 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"XGBoost Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gr√°fico XGBoost Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 8.4. Secci√≥n gr√°fica Pred vs Real XGBoost a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica Pred vs Real XGBoost para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA Pred vs Real XGBoost con contexto num√©rico
                    try:
                        prompt_pr = (
                            f"A continuaci√≥n tienes datos de la gr√°fica de comparaci√≥n Real vs Predicci√≥n para el modelo XGBoost con m√©todo '{metodo}':\n"
                            f"- RMSE: {rmse:.4f}\n"
                            f"- MAE: {mae:.4f}\n"
                            f"- R¬≤: {r2:.4f}\n"
                            f"- Correlaci√≥n entre Y real y predicha: {corr:.4f}\n"
                            f"- Rango Y real: [{y_real_min:.4f}, {y_real_max:.4f}]\n"
                            f"- Rango Y predicha: [{y_pred_min:.4f}, {y_pred_max:.4f}]\n\n"
                            "Bas√°ndote en estos valores y en la gr√°fica generada (Real vs Predicci√≥n), "
                            "proporciona un an√°lisis detallado, se√±alando si hay sesgos sistem√°ticos, dispersi√≥n en ciertos rangos, "
                            "y qu√© implicaciones tiene para la calidad del modelo. "
                            "Usa un texto profesional y bien estructurado, citando qu√© indicios de la gr√°fica respaldan tus conclusiones."
                        )
                        print(f"[DEBUG] 8.5. Llamada IA Pred vs Real XGBoost ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_pr}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### üìù Explicaci√≥n IA Predicho vs Real XGBoost ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 8.6. Secci√≥n explicaci√≥n IA Pred vs Real XGBoost a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ IA Pred vs Real XGBoost ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA Pred vs Real XGBoost para m√©todo '{metodo}': {e}")

                    # 3) Gr√°fica de residuos XGBoost
                    try:
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"XGBoost Residuos ({metodo})")
                        titulo_fig2 = f"### Gr√°fica XGBoost Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 8.7. Secci√≥n gr√°fica residuos XGBoost a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica residuos XGBoost para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA Residuos XGBoost con contexto num√©rico
                    try:
                        prompt_res = (
                            f"A continuaci√≥n tienes estad√≠sticas de los residuos (Real - Predicha) del modelo XGBoost con m√©todo '{metodo}':\n"
                            f"- Media: {res_mean:.4f}\n"
                            f"- Desviaci√≥n est√°ndar: {res_std:.4f}\n"
                            f"- Asimetr√≠a: {res_skew:.4f}\n"
                            f"- Curtosis: {res_kurt:.4f}\n"
                            f"- Cuantiles: 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}\n\n"
                            "Bas√°ndote en estos valores y en la gr√°fica de residuos, analiza si hay patrones (heterocedasticidad, outliers, sesgos), "
                            "y comenta qu√© implicaciones tiene para la robustez y generalizaci√≥n del modelo. "
                            "Usa un texto profesional y bien estructurado."
                        )
                        print(f"[DEBUG] 8.8. Llamada IA Residuos XGBoost ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_res}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### üìù Explicaci√≥n IA Residuos XGBoost ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 8.9. Secci√≥n explicaci√≥n IA residuos XGBoost a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ IA Residuos XGBoost ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA residuos XGBoost para m√©todo '{metodo}': {e}")

                    # 4) Tabla M√©tricas XGBoost y explicaci√≥n IA
                    try:
                        df_met = _pd.DataFrame([
                            {"M√©trica": "RMSE", "Valor": rmse},
                            {"M√©trica": "MAE", "Valor": mae},
                            {"M√©trica": "R2",  "Valor": r2}
                        ])
                        titulo_met = f"### M√©tricas XGBoost ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 8.10. Secci√≥n m√©tricas XGBoost a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame m√©tricas XGBoost para m√©todo '{metodo}': {e}")

                    try:
                        prompt_met = (
                            f"Estas son las m√©tricas del modelo XGBoost con m√©todo '{metodo}':\n"
                            f"- R2: {r2:.4f}\n"
                            f"- MSE: {mse:.4f}\n"
                            f"- RMSE: {rmse:.4f}\n"
                            f"- MAE: {mae:.4f}\n"
                            f"- Correlaci√≥n Real vs Predicha: {corr:.4f}\n\n"
                            "Analiza estos valores en contexto: ¬øson adecuados? ¬øqu√© sugieren respecto al rendimiento del modelo? "
                            "Menciona referencias a la gr√°fica Real vs Predicci√≥n y a los residuos si procede."
                        )
                        print(f"[DEBUG] 8.11. Llamada IA M√©tricas XGBoost ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_met}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### üìù Explicaci√≥n IA M√©tricas XGBoost ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 8.12. Secci√≥n explicaci√≥n IA m√©tricas XGBoost a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ IA M√©tricas XGBoost ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA m√©tricas XGBoost para m√©todo '{metodo}': {e}")

                # 5) Comparativa global de m√©tricas XGBoost
                if metrics_summary_xgb:
                    try:
                        df_comp_xgb = _pd.DataFrame(metrics_summary_xgb)
                        df_comp_xgb_sorted = df_comp_xgb.sort_values("rmse")
                        titulo_comp = "### Comparativa M√©tricas XGBoost entre M√©todos"
                        self.sections.append((titulo_comp, df_comp_xgb_sorted))
                        print("[DEBUG] 8.13. Secci√≥n comparativa m√©tricas XGBoost a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo m√©tricas XGBoost: {e}")

                    try:
                        prompt_conc = (
                            "Se han entrenado varios modelos XGBoost con diferentes m√©todos de selecci√≥n de variables.\n"
                            "M√©tricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary_xgb:
                            prompt_conc += f"- M√©todo '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos m√©todos: "
                            "indica cu√°l se comporta mejor, posibles razones y recomendaciones sobre selecci√≥n de variables o ajustes para mejorar XGBoost."
                        )
                        print("[DEBUG] 8.14. Llamada IA Conclusiones XGBoost...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_conc}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc = resp.choices[0].message.content.strip()
                        if explanation_conc:
                            titulo_exp_conc = "### üìù Conclusiones IA Entrenamiento XGBoost"
                            self.sections.append((titulo_exp_conc, explanation_conc))
                            print("[DEBUG] 8.15. Secci√≥n explicaci√≥n IA conclusiones XGBoost a√±adida")
                        else:
                            print("[DEBUG] No se recibi√≥ IA Conclusiones XGBoost")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA conclusiones XGBoost: {e}")
            else:
                print("[DEBUG] No est√°n RESUMEN_METODOS o X_test/Y_test en globals(), omito secci√≥n XGBoost")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n XGBoost en informe: {e}")
        # ... fin de la secci√≥n de entrenamiento XGBoost ...

        # =============================================================
        # 8.1. Interpretaci√≥n xIA para modelo entrenado XGBoost
        # =============================================================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificaci√≥n previa
        # ----------------------------------------------------------------
        try:
            print("[DEBUG] 8.16. Iniciando secci√≥n xIA para XGBoost")
            if 'xai_results' not in globals() or 'XGBoost' not in xai_results:
                raise RuntimeError(
                    "No se encontr√≥ `xai_results['XGBoost']`. "
                    "Aseg√∫rate de haber ejecutado la Celda 10 y almacenado los resultados xIA de XGBoost en `xai_results['XGBoost']`."
                )

                # Cabecera
                self.sections.append((
                    "## üîç An√°lisis xIA de XGBoost: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vac√≠o, la cabecera se mostrar√° como Markdown
                ))


            # Funci√≥n para llamar a OpenAI con un prompt espec√≠fico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuraci√≥n: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cu√°ntas caracter√≠sticas top incluir en el prompt
            N_LOCAL = 3    # cu√°ntas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de m√©todos xIA y claves en xai_results['XGBoost']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 8.17. Procesando secci√≥n xIA: {titulo}")
                datos = xai_results['XGBoost'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ‚ö†Ô∏è No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 8.18. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gr√°fico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 8.19. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estad√≠sticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gr√°fico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores num√©ricos concretos ---------------
                print(f"[DEBUG] 8.20. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el m√©todo xIA '{titulo}' al modelo XGBoost entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gr√°fico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    ‚Ä¢ {f}: {imp:.4f}\n"

                # Ahora s√≠ le pides que interprete el gr√°fico:
                prompt += (
                    "- Interpreta el gr√°fico anterior: "
                    "describe qu√© patrones o relaciones visuales revela c√≥mo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} caracter√≠sticas por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye tambi√©n columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato gen√©rico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # ‚Äî Siempre sacamos el √≠ndice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribuci√≥n):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estad√≠sticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estad√≠sticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo XGBoost
                prompt += (
                    "\nContexto: El modelo XGBoost fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este XGBoost.\n"
                )

                # 5) Preguntas/pautas espec√≠ficas seg√∫n el m√©todo
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¬øqu√© implica sobre la predicci√≥n en ese caso? Y si es negativo, ¬øqu√© implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una direcci√≥n) y c√≥mo afecta al comportamiento general del XGBoost.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para XGBoost.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¬øqu√© implica para la predicci√≥n local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupaci√≥n de variables, detecci√≥n de outliers, etc., basadas en la interpretaci√≥n LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global seg√∫n los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: c√≥mo cada caracter√≠stica empuja la predicci√≥n en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para XGBoost), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribuci√≥n integrada de cada variable: interpretaci√≥n de importancia global.\n"
                        "2. Analizar las primeras muestras: qu√© implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Se√±alar limitaciones: compatibilidad con XGBoost no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros m√©todos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qu√© significa para la predicci√≥n.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la ca√≠da en la m√©trica al permutar cada variable: por qu√© ciertas variables son cr√≠ticas.\n"
                        "2. Comentar la desviaci√≥n est√°ndar: ¬øindica inestabilidad en la importancia? ¬øD√≥nde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selecci√≥n de variables basadas en esta m√©trica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicci√≥n seg√∫n el rango PDP obtenido.\n"
                        "2. Se√±alar si los rangos sugieren relaciones mon√≥tonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretaci√≥n.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) seg√∫n los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar c√≥mo ALE corrige artefactos de correlaci√≥n y qu√© nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspecci√≥n de distribuci√≥n) seg√∫n hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qu√© mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Se√±alar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar c√≥mo interpretar los contrafactuales: cambios en variables que generan aumento en predicci√≥n.\n"
                        "2. Analizar variables con mayor |Œî| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Se√±alar si faltan contrafactuales para algunas muestras: qu√© puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir c√≥mo usar estos insights para ajuste de modelo o recolecci√≥n de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar c√≥mo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicci√≥n.\n"
                        "2. Analizar frecuencia global de aparici√≥n de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Se√±alar regiones de bajo coverage o baja precisi√≥n: d√≥nde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolecci√≥n de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (√°rbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qu√© sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del XGBoost en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo seg√∫n discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global seg√∫n EBM: c√≥mo se comparan con otros m√©todos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qu√© patrones se observan.\n"
                        "3. Se√±alar si EBM revela interacciones no consideradas en XGBoost.\n"
                        "4. Recomendar posibles ajustes en caracter√≠sticas o validaciones seg√∫n insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperpar√°metros en la optimizaci√≥n del XGBoost.\n"
                        "2. Analizar top trials si est√°n disponibles: qu√© combinaciones de hiperpar√°metros funcionaron mejor.\n"
                        "3. Se√±alar limitaciones de la muestra de trials (n√∫mero de pruebas) y posibles riesgos de sobreajuste en la b√∫squeda.\n"
                        "4. Recomendar pr√≥ximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados num√©ricos y qu√© implicaciones tienen para el modelo XGBoost.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 8.21. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicaci√≥n Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ‚ö†Ô∏è Error en secci√≥n xIA XGBoost",
                f"Se produjo un error al generar la secci√≥n xIA de XGBoost: {e}"
            ))

        # =====================================================================
        # 9. Entrenamiento Modelo Random Forest
        # =====================================================================
        try:
            # Comprobamos RESUMEN_METODOS y existencia de X_test/Y_test
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import numpy as _np
                import pandas as _pd
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Extraer array 1D de y_test
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2 and arr.shape[1] >= 1:
                        # tomamos la primera columna si hay m√°s
                        y_test_arr = arr[:, 0]
                    else:
                        y_test_arr = arr.ravel()
                else:
                    y_test_arr = _np.array(Y_test).ravel()
                y_test_arr = y_test_arr.ravel()

                metrics_summary_rf = []
                # Iteramos sobre cada m√©todo en RESUMEN_METODOS
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    fname = f"modelo_rf_{metodo_low}.pkl"
                    if not os.path.exists(fname):
                        print(f"[DEBUG] Fichero de modelo RF no encontrado para m√©todo '{metodo}': {fname}, omito este m√©todo")
                        continue
                    # Cargar pickle
                    try:
                        with open(fname, "rb") as f:
                            data = pickle.load(f)
                        model = data.get("model", None)
                        sx = data.get("sx", None)
                        sy = data.get("sy", None)
                        cols = data.get("cols", None)
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Falta alguna clave en pickle RF para m√©todo '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar pickle RF para m√©todo '{metodo}': {e}")
                        continue

                    # Verificar columnas en X_test
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para m√©todo '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue

                    # Subconjunto X_test
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar, predecir y desescalar
                    try:
                        X_test_scaled = sx.transform(X_test_sel)
                        y_pred_scaled = model.predict(X_test_scaled)
                        # inverse_transform espera 2D
                        y_pred = sy.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar RF para m√©todo '{metodo}': {e}")
                        continue

                    # Estad√≠sticos y m√©tricas
                    try:
                        # Rangos Real vs Predicha
                        y_real_min, y_real_max = float(_np.min(y_test_arr)), float(_np.max(y_test_arr))
                        y_pred_min, y_pred_max = float(_np.min(y_pred)), float(_np.max(y_pred))
                        # Residuos
                        residuals = y_test_arr - y_pred
                        res_mean = float(_np.mean(residuals))
                        res_std  = float(_np.std(residuals))
                        res_series = _pd.Series(residuals)
                        res_skew = float(res_series.skew())
                        res_kurt = float(res_series.kurtosis())
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                        # M√©tricas
                        mse = mean_squared_error(y_test_arr, y_pred)
                        rmse = float(_np.sqrt(mse))
                        mae = float(mean_absolute_error(y_test_arr, y_pred))
                        r2 = float(r2_score(y_test_arr, y_pred))
                        # Correlaci√≥n Real vs Predicha
                        try:
                            corr = float(_np.corrcoef(y_test_arr, y_pred)[0, 1])
                        except:
                            corr = None
                        # Guardar resumen para comparativa
                        metrics_summary_rf.append({
                            "metodo": metodo,
                            "rmse": rmse,
                            "mae": mae,
                            "r2": r2
                        })
                    except Exception as e:
                        print(f"[ERROR] al calcular m√©tricas RF para m√©todo '{metodo}': {e}")
                        # saltamos, aunque idealmente definimos rmse,etc = None

                    # 1) Par√°metros de entrenamiento obtenidos desde el modelo
                    try:
                        # RandomForestRegressor atributos: n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, bootstrap
                        params = {
                            "n_estimators": getattr(model, "n_estimators", None),
                            "max_depth": getattr(model, "max_depth", None),
                            "min_samples_split": getattr(model, "min_samples_split", None),
                            "min_samples_leaf": getattr(model, "min_samples_leaf", None),
                            "max_features": getattr(model, "max_features", None),
                            "bootstrap": getattr(model, "bootstrap", None)
                        }
                        df_params = _pd.DataFrame({
                            "Hiperpar√°metro": list(params.keys()),
                            "Valor": [str(v) for v in params.values()]
                        })
                        titulo_p = f"### Par√°metros de Entrenamiento Random Forest ({metodo})"
                        self.sections.append((titulo_p, df_params))
                        print(f"[DEBUG] 9.1. Secci√≥n par√°metros RF a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al extraer par√°metros RF para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA de los hiperpar√°metros RF
                    try:
                        prompt_params = (
                            f"Has entrenado un modelo Random Forest con selecci√≥n de variables '{metodo}'.\n"
                            "Estos fueron los hiperpar√°metros utilizados:\n"
                        )
                        for k, v in params.items():
                            prompt_params += f"- {k}: {v}\n"
                        prompt_params += (
                            "\nPor favor, explica de forma profesional y detallada c√≥mo estos hiperpar√°metros "
                            "pueden influir en el entrenamiento del Random Forest, su impacto en ajuste/sobreajuste, "
                            "y buenas pr√°cticas para seleccionarlos o afinarlos."
                        )
                        print(f"[DEBUG] 9.2. Iniciando llamada a OpenAI para explicaci√≥n hiperpar√°metros RF ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en entrenamiento de Random Forest para regresi√≥n."},
                                {"role": "user", "content": prompt_params}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_params = resp.choices[0].message.content.strip()
                        if explanation_params:
                            titulo_exp_p = f"### üìù Explicaci√≥n IA Hiperpar√°metros RF ({metodo})"
                            self.sections.append((titulo_exp_p, explanation_params))
                            print(f"[DEBUG] 9.3. Secci√≥n explicaci√≥n IA hiperpar√°metros RF a√±adida para m√©todo: {metodo}")
                        else:
                            print(f"[DEBUG] No se recibi√≥ IA para hiperpar√°metros RF ({metodo})")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA hiperpar√°metros RF para m√©todo '{metodo}': {e}")

                    # 2) Gr√°fica Predicho vs Real
                    try:
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(y_test_arr, y_pred, alpha=0.6)
                        ax1.plot([y_test_arr.min(), y_test_arr.max()],
                                 [y_test_arr.min(), y_test_arr.max()],
                                 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"Random Forest Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gr√°fico RF Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 9.4. Secci√≥n gr√°fica Pred vs Real RF a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica Pred vs Real RF para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA Pred vs Real RF con contexto num√©rico
                    try:
                        prompt_pr = (
                            f"A continuaci√≥n tienes datos de la gr√°fica de comparaci√≥n Real vs Predicci√≥n para el Random Forest con m√©todo '{metodo}':\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- R¬≤: {r2}\n"
                            f"- Correlaci√≥n entre Y real y predicha: {corr}\n"
                            f"- Rango Y real: [{y_real_min}, {y_real_max}]\n"
                            f"- Rango Y predicha: [{y_pred_min}, {y_pred_max}]\n\n"
                            "Bas√°ndote en estos valores y en la gr√°fica generada (Real vs Predicci√≥n), "
                            "proporciona un an√°lisis detallado: sesgos sistem√°ticos, dispersi√≥n en rangos, posibles problemas y recomendaciones."
                        )
                        print(f"[DEBUG] 9.5. Llamada IA Pred vs Real RF ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_pr}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### üìù Explicaci√≥n IA Predicho vs Real RF ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 9.6. Secci√≥n explicaci√≥n IA Pred vs Real RF a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA Pred vs Real RF para m√©todo '{metodo}': {e}")

                    # 3) Gr√°fica de residuos RF
                    try:
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"Random Forest Residuos ({metodo})")
                        titulo_fig2 = f"### Gr√°fico RF Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 9.7. Secci√≥n gr√°fica residuos RF a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica residuos RF para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA Residuos RF con contexto num√©rico
                    try:
                        prompt_res = (
                            f"A continuaci√≥n tienes estad√≠sticas de los residuos (Real - Predicha) del Random Forest con m√©todo '{metodo}':\n"
                            f"- Media: {res_mean}\n"
                            f"- Desviaci√≥n est√°ndar: {res_std}\n"
                            f"- Asimetr√≠a: {res_skew}\n"
                            f"- Curtosis: {res_kurt}\n"
                            f"- Cuantiles: 25%={q25}, 50%={q50}, 75%={q75}\n\n"
                            "Bas√°ndote en estos valores y en la gr√°fica de residuos, analiza patrones (heterocedasticidad, outliers, sesgos) y qu√© implicaciones tiene para generalizaci√≥n."
                        )
                        print(f"[DEBUG] 9.8. Llamada IA Residuos RF ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_res}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### üìù Explicaci√≥n IA Residuos RF ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 9.9. Secci√≥n explicaci√≥n IA residuos RF a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA residuos RF para m√©todo '{metodo}': {e}")

                    # 4) Tabla M√©tricas y explicaci√≥n IA
                    try:
                        df_met = _pd.DataFrame([
                            {"M√©trica": "RMSE", "Valor": rmse},
                            {"M√©trica": "MAE", "Valor": mae},
                            {"M√©trica": "R2",  "Valor": r2}
                        ])
                        titulo_met = f"### M√©tricas Random Forest ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 9.10 Secci√≥n m√©tricas RF a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame m√©tricas RF para m√©todo '{metodo}': {e}")

                    try:
                        prompt_met = (
                            f"Estas son las m√©tricas del Random Forest con m√©todo '{metodo}':\n"
                            f"- R2: {r2}\n"
                            f"- MSE: {mse}\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- Correlaci√≥n Real vs Predicha: {corr}\n\n"
                            "Analiza estos valores en contexto: ¬øson adecuados? ¬øqu√© sugieren respecto al rendimiento? "
                            "Menciona referencias a la gr√°fica Real vs Predicci√≥n y residuos si procede."
                        )
                        print(f"[DEBUG] 9.11. Llamada IA M√©tricas RF ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML."},
                                {"role": "user", "content": prompt_met}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### üìù Explicaci√≥n IA M√©tricas RF ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 9.12. Secci√≥n explicaci√≥n IA m√©tricas RF a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA m√©tricas RF para m√©todo '{metodo}': {e}")

                # 5) Comparativa global de m√©tricas RF
                if metrics_summary_rf:
                    try:
                        df_comp_rf = _pd.DataFrame(metrics_summary_rf)
                        df_comp_rf_sorted = df_comp_rf.sort_values("rmse")
                        titulo_comp_rf = "### Comparativa M√©tricas Random Forest entre M√©todos"
                        self.sections.append((titulo_comp_rf, df_comp_rf_sorted))
                        print("[DEBUG] 9.13. Secci√≥n comparativa m√©tricas RF a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo m√©tricas RF: {e}")

                    try:
                        prompt_conc = (
                            "Se han entrenado varios Random Forest con diferentes m√©todos de selecci√≥n de variables.\n"
                            "M√©tricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary_rf:
                            prompt_conc += f"- M√©todo '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos m√©todos: "
                            "indica cu√°l se comporta mejor, posibles razones y recomendaciones sobre selecci√≥n de variables o ajustes para mejorar Random Forest."
                        )
                        print("[DEBUG] 9.14. Llamada IA Conclusiones RF...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_conc}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc = resp.choices[0].message.content.strip()
                        if explanation_conc:
                            titulo_exp_conc = "### üìù Conclusiones IA Entrenamiento Random Forest"
                            self.sections.append((titulo_exp_conc, explanation_conc))
                            print("[DEBUG] 9.15. Secci√≥n explicaci√≥n IA conclusiones RF a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA conclusiones RF: {e}")
            else:
                print("[DEBUG] No est√°n RESUMEN_METODOS o X_test/Y_test en globals(), omito secci√≥n RF")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n RF en informe: {e}")
        # ... fin de la secci√≥n de entrenamiento Random Forest ...

        # =============================================================
        # 9.1. Interpretaci√≥n xIA para modelo entrenado Random Forest
        # =============================================================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificaci√≥n previa
        # ----------------------------------------------------------------
        try:
            print("[DEBUG] 9.16. Iniciando secci√≥n xIA para Random Forest")
            if 'xai_results' not in globals() or 'Random Forest' not in xai_results:
                raise RuntimeError(
                    "No se encontr√≥ `xai_results['Random Forest']`. "
                    "Aseg√∫rate de haber ejecutado la Celda 10 y almacenado los resultados xIA de Random Forest en `xai_results['Random Forest']`."
                )

                # Cabecera
                self.sections.append((
                    "## üîç An√°lisis xIA de Random Forest: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vac√≠o, la cabecera se mostrar√° como Markdown
                ))


            # Funci√≥n para llamar a OpenAI con un prompt espec√≠fico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuraci√≥n: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cu√°ntas caracter√≠sticas top incluir en el prompt
            N_LOCAL = 3    # cu√°ntas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de m√©todos xIA y claves en xai_results['Random Forest']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 9.17. Procesando secci√≥n xIA: {titulo}")
                datos = xai_results['Random Forest'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ‚ö†Ô∏è No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 9.18. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gr√°fico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 9.19. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estad√≠sticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gr√°fico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores num√©ricos concretos ---------------
                print(f"[DEBUG] 9.20. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el m√©todo xIA '{titulo}' al modelo Random Forest entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gr√°fico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    ‚Ä¢ {f}: {imp:.4f}\n"

                # Ahora s√≠ le pides que interprete el gr√°fico:
                prompt += (
                    "- Interpreta el gr√°fico anterior: "
                    "describe qu√© patrones o relaciones visuales revela c√≥mo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} caracter√≠sticas por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye tambi√©n columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato gen√©rico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # ‚Äî Siempre sacamos el √≠ndice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribuci√≥n):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estad√≠sticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estad√≠sticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo Random Forest
                prompt += (
                    "\nContexto: El modelo Random Forest fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este Random Forest.\n"
                )

                # 5) Preguntas/pautas espec√≠ficas seg√∫n el m√©todo
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¬øqu√© implica sobre la predicci√≥n en ese caso? Y si es negativo, ¬øqu√© implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una direcci√≥n) y c√≥mo afecta al comportamiento general del Random Forest.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para Random Forest.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¬øqu√© implica para la predicci√≥n local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupaci√≥n de variables, detecci√≥n de outliers, etc., basadas en la interpretaci√≥n LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global seg√∫n los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: c√≥mo cada caracter√≠stica empuja la predicci√≥n en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para Random Forest), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribuci√≥n integrada de cada variable: interpretaci√≥n de importancia global.\n"
                        "2. Analizar las primeras muestras: qu√© implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Se√±alar limitaciones: compatibilidad con Random Forest no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros m√©todos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qu√© significa para la predicci√≥n.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la ca√≠da en la m√©trica al permutar cada variable: por qu√© ciertas variables son cr√≠ticas.\n"
                        "2. Comentar la desviaci√≥n est√°ndar: ¬øindica inestabilidad en la importancia? ¬øD√≥nde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selecci√≥n de variables basadas en esta m√©trica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicci√≥n seg√∫n el rango PDP obtenido.\n"
                        "2. Se√±alar si los rangos sugieren relaciones mon√≥tonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretaci√≥n.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) seg√∫n los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar c√≥mo ALE corrige artefactos de correlaci√≥n y qu√© nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspecci√≥n de distribuci√≥n) seg√∫n hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qu√© mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Se√±alar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar c√≥mo interpretar los contrafactuales: cambios en variables que generan aumento en predicci√≥n.\n"
                        "2. Analizar variables con mayor |Œî| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Se√±alar si faltan contrafactuales para algunas muestras: qu√© puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir c√≥mo usar estos insights para ajuste de modelo o recolecci√≥n de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar c√≥mo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicci√≥n.\n"
                        "2. Analizar frecuencia global de aparici√≥n de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Se√±alar regiones de bajo coverage o baja precisi√≥n: d√≥nde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolecci√≥n de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (√°rbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qu√© sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del Random Forest en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo seg√∫n discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global seg√∫n EBM: c√≥mo se comparan con otros m√©todos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qu√© patrones se observan.\n"
                        "3. Se√±alar si EBM revela interacciones no consideradas en Random Forest.\n"
                        "4. Recomendar posibles ajustes en caracter√≠sticas o validaciones seg√∫n insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperpar√°metros en la optimizaci√≥n del Random Forest.\n"
                        "2. Analizar top trials si est√°n disponibles: qu√© combinaciones de hiperpar√°metros funcionaron mejor.\n"
                        "3. Se√±alar limitaciones de la muestra de trials (n√∫mero de pruebas) y posibles riesgos de sobreajuste en la b√∫squeda.\n"
                        "4. Recomendar pr√≥ximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados num√©ricos y qu√© implicaciones tienen para el modelo Random Forest.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 9.21. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicaci√≥n Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ‚ö†Ô∏è Error en secci√≥n xIA Random Forest",
                f"Se produjo un error al generar la secci√≥n xIA de Random Forest: {e}"
            ))


        # =====================================================================
        # 10. Entrenamiento Modelo Redes Neuronales Recurrentes RNN
        # =====================================================================
        try:
            if "RESUMEN_METODOS" in self.g and "X_test" in self.g and "Y_test" in self.g:
                import os, pickle
                import numpy as _np
                import pandas as _pd
                import matplotlib.pyplot as plt
                from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                from tensorflow.keras.models import load_model

                X_test_full = self.g["X_test"]
                Y_test = self.g["Y_test"]
                # Extraer array 1D de y_test
                if hasattr(Y_test, "values"):
                    arr = Y_test.values
                    if arr.ndim == 2 and arr.shape[1] >= 1:
                        y_test_arr_full = arr[:, 0]
                    else:
                        y_test_arr_full = arr.ravel()
                else:
                    y_test_arr_full = _np.array(Y_test).ravel()
                y_test_arr_full = y_test_arr_full.ravel()

                metrics_summary_rnn = []
                # Iteramos sobre cada m√©todo en RESUMEN_METODOS
                for metodo, vars_sel in self.g["RESUMEN_METODOS"].items():
                    metodo_low = metodo.lower()
                    model_fname = f"modelo_rnn_{metodo_low}.h5"
                    scaler_fname = f"escaladores_rnn_{metodo_low}.pkl"
                    hp_fname = f"hyperparams_rnn_{metodo_low}.pkl"
                    if not os.path.exists(model_fname) or not os.path.exists(scaler_fname):
                        print(f"[DEBUG] Fichero de modelo RNN o escaladores no encontrado para m√©todo '{metodo}', omito este m√©todo")
                        continue
                    # Cargar modelo y escaladores
                    try:
                        model = load_model(model_fname)
                        with open(scaler_fname, "rb") as f:
                            data_s = pickle.load(f)
                        sx = data_s.get("scaler_X", None)
                        sy = data_s.get("scaler_Y", None)
                        cols = data_s.get("cols", None)
                        if model is None or sx is None or sy is None or cols is None:
                            print(f"[DEBUG] Falta clave en escaladores RNN para m√©todo '{metodo}', omito")
                            continue
                    except Exception as e:
                        print(f"[ERROR] al cargar modelo/escaladores RNN para m√©todo '{metodo}': {e}")
                        continue

                    # Cargar hiperpar√°metros
                    if os.path.exists(hp_fname):
                        try:
                            with open(hp_fname, "rb") as f_hp:
                                hp = pickle.load(f_hp)
                        except Exception as e:
                            print(f"[ERROR] al cargar hyperparams RNN para m√©todo '{metodo}': {e}")
                            hp = None
                    else:
                        hp = None
                    if hp is None:
                        print(f"[DEBUG] No hay hyperparams guardados para RNN m√©todo '{metodo}', no podr√© rehacer predicci√≥n correctamente, omito este m√©todo en informe")
                        continue

                    # Verificar columnas en X_test
                    missing = [c for c in cols if c not in X_test_full.columns]
                    if missing:
                        print(f"[DEBUG] Para m√©todo '{metodo}', faltan columnas en X_test: {missing}, omito")
                        continue

                    # Preparamos datos para secuencias
                    # Tomamos solo las columnas seleccionadas
                    X_test_sel = X_test_full[cols].copy()
                    # Escalar toda la serie de test antes de crear secuencias
                    try:
                        Xts = sx.transform(X_test_sel)
                        # Para Y_test, necesitamos construir array alineado con secuencias:
                        # Usamos los primeros len(Xts) valores de y_test_arr_full
                        # y construiremos secuencias con window_size:
                        window = int(hp.get('window_size', 0))
                        if window <= 0 or len(Xts) <= window:
                            print(f"[DEBUG] window_size inv√°lido o demasiado grande para test en m√©todo '{metodo}', omito")
                            continue
                        # Creamos secuencias iguales a la funci√≥n create_sequences de la celda 7.5:
                        X_seq = []
                        Y_seq = []
                        for j in range(len(Xts) - window):
                            X_seq.append(Xts[j:j+window])
                            # Y real escalada (sy) usamos Y_test escalado? En entrenamiento se us√≥ y_train escalado para fit,
                            # pero aqu√≠ Y_test necesitamos escala para invertir luego:
                            # Mejor: tomamos Y_test original:
                            # Extraemos Y_test alineado: y_test_arr_full, yts_seq ser√° y_test_arr_full[j+window]
                            Y_seq.append(y_test_arr_full[j+window])
                        X_seq = _np.array(X_seq)   # shape (n_samples_seq, window, n_features)
                        Y_real = _np.array(Y_seq)  # shape (n_samples_seq,)
                    except Exception as e:
                        print(f"[ERROR] al preparar secuencias RNN para m√©todo '{metodo}': {e}")
                        continue

                    # Predecir y desescalar
                    try:
                        Y_pred_scaled = model.predict(X_seq, verbose=0).ravel()
                        # Invertir escala:
                        Y_pred = sy.inverse_transform(Y_pred_scaled.reshape(-1,1)).ravel()
                        # Convertir Y_real (original) en array float
                        Y_real = _np.array(Y_real).ravel()
                    except Exception as e:
                        print(f"[ERROR] al predecir/desescalar RNN para m√©todo '{metodo}': {e}")
                        continue

                    # C√°lculo de m√©tricas y estad√≠sticas
                    try:
                        # Rangos Real vs Predicha
                        y_real_min, y_real_max = float(_np.min(Y_real)), float(_np.max(Y_real))
                        y_pred_min, y_pred_max = float(_np.min(Y_pred)), float(_np.max(Y_pred))
                        # Residuos
                        residuals = Y_real - Y_pred
                        res_mean = float(_np.mean(residuals))
                        res_std  = float(_np.std(residuals))
                        res_series = _pd.Series(residuals)
                        res_skew = float(res_series.skew())
                        res_kurt = float(res_series.kurtosis())
                        q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                        # M√©tricas
                        mse = mean_squared_error(Y_real, Y_pred)
                        rmse = float(_np.sqrt(mse))
                        mae = float(mean_absolute_error(Y_real, Y_pred))
                        r2 = float(r2_score(Y_real, Y_pred))
                        # Correlaci√≥n Real vs Predicha
                        try:
                            corr = float(_np.corrcoef(Y_real, Y_pred)[0, 1])
                        except:
                            corr = None
                        # Guardar resumen para comparativa
                        metrics_summary_rnn.append({
                            "metodo": metodo,
                            "rmse": rmse,
                            "mae": mae,
                            "r2": r2
                        })
                        #all_metrics.append({
                        #    "Modelo": f"{TIPO}_{metodo}",  # ej. "SVR_Pearson", "NN_Boruta"...
                        #    "Tipo": TIPO,                 # "SVR", "NN", "XGBoost", "RF" o "RNN"
                        #    "M√©todo": metodo,
                        #    "R2": r2,
                        #    "MSE": mse,
                        #    "RMSE": rmse,
                        #    "MAE": mae
                        #})

                    except Exception as e:
                        print(f"[ERROR] al calcular m√©tricas RNN para m√©todo '{metodo}': {e}")
                        continue

                    # 1) Par√°metros de entrenamiento obtenidos desde hp
                    try:
                        # Usamos el dict hp cargado
                        df_hp = _pd.DataFrame({
                            "Hiperpar√°metro": list(hp.keys()),
                            "Valor": [str(v) for v in hp.values()]
                        })
                        titulo_hp = f"### Par√°metros de Entrenamiento RNN ({metodo})"
                        self.sections.append((titulo_hp, df_hp))
                        print(f"[DEBUG] 10.1. Secci√≥n par√°metros RNN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al mostrar par√°metros RNN para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA hiperpar√°metros RNN
                    try:
                        prompt_params = (
                            f"Has entrenado un modelo RNN (tipo {hp.get('tipo_rnn')}) con selecci√≥n de variables '{metodo}'.\n"
                            "Estos fueron los hiperpar√°metros utilizados:\n"
                        )
                        for k, v in hp.items():
                            prompt_params += f"- {k}: {v}\n"
                        prompt_params += (
                            "\nPor favor, explica de forma profesional y detallada c√≥mo estos hiperpar√°metros "
                            "pueden influir en el entrenamiento de la RNN, su impacto en ajuste/sobreajuste, "
                            "y buenas pr√°cticas para seleccionarlos o afinarlos."
                        )
                        print(f"[DEBUG] 10.2. Iniciando llamada a OpenAI para explicaci√≥n hiperpar√°metros RNN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en entrenamiento de redes neuronales recurrentes para series temporales."},
                                {"role": "user", "content": prompt_params}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_hp = resp.choices[0].message.content.strip()
                        if explanation_hp:
                            titulo_exp_hp = f"### üìù Explicaci√≥n IA Hiperpar√°metros RNN ({metodo})"
                            self.sections.append((titulo_exp_hp, explanation_hp))
                            print(f"[DEBUG] 10.3. Secci√≥n explicaci√≥n IA hiperpar√°metros RNN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA hiperpar√°metros RNN para m√©todo '{metodo}': {e}")

                    # 2) Gr√°fica Predicho vs Real
                    try:
                        fig1, ax1 = plt.subplots(figsize=(6, 4))
                        ax1.scatter(Y_real, Y_pred, alpha=0.6)
                        ax1.plot([y_real_min, y_real_max], [y_real_min, y_real_max], 'r--', lw=2)
                        ax1.set_xlabel("Y real")
                        ax1.set_ylabel("Y predicho")
                        ax1.set_title(f"RNN Predicho vs Real ({metodo})")
                        titulo_fig1 = f"### Gr√°fico RNN Predicho vs Real ({metodo})"
                        self.sections.append((titulo_fig1, fig1))
                        print(f"[DEBUG] 10.4. Secci√≥n gr√°fica Pred vs Real RNN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica Pred vs Real RNN para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA Pred vs Real RNN con contexto num√©rico
                    try:
                        prompt_pr = (
                            f"A continuaci√≥n tienes datos de la gr√°fica de comparaci√≥n Real vs Predicci√≥n para el modelo RNN con m√©todo '{metodo}':\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- R¬≤: {r2}\n"
                            f"- Correlaci√≥n entre Y real y predicha: {corr}\n"
                            f"- Rango Y real: [{y_real_min}, {y_real_max}]\n"
                            f"- Rango Y predicha: [{y_pred_min}, {y_pred_max}]\n\n"
                            "Bas√°ndote en estos valores y en la gr√°fica generada (Real vs Predicci√≥n), "
                            "proporciona un an√°lisis detallado: sesgos sistem√°ticos, dispersi√≥n en rangos, posibles problemas y recomendaciones."
                        )
                        print(f"[DEBUG] 10.5. Llamada IA Pred vs Real RNN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML para series temporales."},
                                {"role": "user", "content": prompt_pr}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_pr = resp.choices[0].message.content.strip()
                        if explanation_pr:
                            titulo_exp_pr = f"### üìù Explicaci√≥n IA Predicho vs Real RNN ({metodo})"
                            self.sections.append((titulo_exp_pr, explanation_pr))
                            print(f"[DEBUG] 10.6. Secci√≥n explicaci√≥n IA Pred vs Real RNN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA Pred vs Real RNN para m√©todo '{metodo}': {e}")

                    # 3) Gr√°fica de residuos RNN
                    try:
                        fig2, ax2 = plt.subplots(figsize=(6, 4))
                        ax2.scatter(Y_pred, residuals, alpha=0.6)
                        ax2.axhline(0, color='r', linestyle='--', lw=2)
                        ax2.set_xlabel("Y predicho")
                        ax2.set_ylabel("Residuo (Y_real - Y_predicho)")
                        ax2.set_title(f"RNN Residuos ({metodo})")
                        titulo_fig2 = f"### Gr√°fico RNN Residuos ({metodo})"
                        self.sections.append((titulo_fig2, fig2))
                        print(f"[DEBUG] 10.7. Secci√≥n gr√°fica residuos RNN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear gr√°fica residuos RNN para m√©todo '{metodo}': {e}")

                    # Explicaci√≥n IA Residuos RNN con contexto num√©rico
                    try:
                        prompt_res = (
                            f"A continuaci√≥n tienes estad√≠sticas de los residuos (Real - Predicha) del modelo RNN con m√©todo '{metodo}':\n"
                            f"- Media: {res_mean}\n"
                            f"- Desviaci√≥n est√°ndar: {res_std}\n"
                            f"- Asimetr√≠a: {res_skew}\n"
                            f"- Curtosis: {res_kurt}\n"
                            f"- Cuantiles: 25%={q25}, 50%={q50}, 75%={q75}\n\n"
                            "Bas√°ndote en estos valores y en la gr√°fica de residuos, analiza patrones (heterocedasticidad, outliers, sesgos) y qu√© implicaciones tiene para generalizaci√≥n."
                        )
                        print(f"[DEBUG] 10.8 Llamada IA Residuos RNN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML para series temporales."},
                                {"role": "user", "content": prompt_res}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_res = resp.choices[0].message.content.strip()
                        if explanation_res:
                            titulo_exp_res = f"### üìù Explicaci√≥n IA Residuos RNN ({metodo})"
                            self.sections.append((titulo_exp_res, explanation_res))
                            print(f"[DEBUG] 10.9. Secci√≥n explicaci√≥n IA residuos RNN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA residuos RNN para m√©todo '{metodo}': {e}")

                    # 4) Tabla M√©tricas y explicaci√≥n IA
                    try:
                        df_met = _pd.DataFrame([
                            {"M√©trica": "RMSE", "Valor": rmse},
                            {"M√©trica": "MAE", "Valor": mae},
                            {"M√©trica": "R2",  "Valor": r2}
                        ])
                        titulo_met = f"### M√©tricas RNN ({metodo})"
                        self.sections.append((titulo_met, df_met))
                        print(f"[DEBUG] 10.10. Secci√≥n m√©tricas RNN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame m√©tricas RNN para m√©todo '{meteto}': {e}")

                    try:
                        prompt_met = (
                            f"Estas son las m√©tricas del modelo RNN con m√©todo '{metodo}':\n"
                            f"- R2: {r2}\n"
                            f"- MSE: {mse}\n"
                            f"- RMSE: {rmse}\n"
                            f"- MAE: {mae}\n"
                            f"- Correlaci√≥n Real vs Predicha: {corr}\n\n"
                            "Analiza estos valores en contexto: ¬øson adecuados? ¬øqu√© sugieren respecto al rendimiento? Menciona gr√°ficas Pred vs Real y residuos."
                        )
                        print(f"[DEBUG] 10.11. Llamada IA M√©tricas RNN ({metodo})...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en evaluaci√≥n de modelos ML para series temporales."},
                                {"role": "user", "content": prompt_met}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_met = resp.choices[0].message.content.strip()
                        if explanation_met:
                            titulo_exp_met = f"### üìù Explicaci√≥n IA M√©tricas RNN ({metodo})"
                            self.sections.append((titulo_exp_met, explanation_met))
                            print(f"[DEBUG] 10.12. Secci√≥n explicaci√≥n IA m√©tricas RNN a√±adida para m√©todo: {metodo}")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA m√©tricas RNN para m√©todo '{metodo}': {e}")

                # 5) Comparativa global de m√©tricas RNN
                if metrics_summary_rnn:
                    try:
                        df_comp_rnn = _pd.DataFrame(metrics_summary_rnn)
                        df_comp_rnn_sorted = df_comp_rnn.sort_values("rmse")
                        titulo_comp_rnn = "### Comparativa M√©tricas RNN entre M√©todos"
                        self.sections.append((titulo_comp_rnn, df_comp_rnn_sorted))
                        print("[DEBUG] 10.13. Secci√≥n comparativa m√©tricas RNN a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al crear DataFrame comparativo m√©tricas RNN: {e}")

                    try:
                        prompt_conc = (
                            "Se han entrenado varios modelos RNN con diferentes m√©todos de selecci√≥n de variables.\n"
                            "M√©tricas obtenidas en test:\n"
                        )
                        for entry in metrics_summary_rnn:
                            prompt_conc += f"- M√©todo '{entry['metodo']}': RMSE={entry['rmse']}, MAE={entry['mae']}, R2={entry['r2']}\n"
                        prompt_conc += (
                            "\nPor favor, proporciona conclusiones profesionales comparando estos m√©todos: "
                            "indica cu√°l se comporta mejor, posibles razones y recomendaciones sobre selecci√≥n de variables o ajustes para mejorar la RNN."
                        )
                        print("[DEBUG] 10.14. Llamada IA Conclusiones RNN...")
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos para series temporales."},
                                {"role": "user", "content": prompt_conc}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        explanation_conc = resp.choices[0].message.content.strip()
                        if explanation_conc:
                            titulo_exp_conc = "### üìù Conclusiones IA Entrenamiento RNN"
                            self.sections.append((titulo_exp_conc, explanation_conc))
                            print("[DEBUG] 10.15. Secci√≥n explicaci√≥n IA conclusiones RNN a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA conclusiones RNN: {e}")
            else:
                print("[DEBUG] No est√°n RESUMEN_METODOS o X_test/Y_test en globals(), omito secci√≥n RNN")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n RNN en informe: {e}")
        # ... fin de la secci√≥n de entrenamiento de Redes Neuronales Rrecurrentes RNN ...

        # =============================================================
        # 10.1. Interpretaci√≥n xIA para modelo entrenado RNN
        # =============================================================
        import openai
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        from IPython.display import display, HTML

        # ----------------------------------------------------------------
        # Verificaci√≥n previa
        # ----------------------------------------------------------------
        # ‚îÄ‚îÄ 0) Normalizar la clave para buscar en xai_results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        #storage_key = 'RNN'.lower()   # coincide con la clave usada al guardar en la celda 10 ('rnn')
        try:
            print("[DEBUG] 10.16. Iniciando secci√≥n xIA para RNN")
            print("DEBUG: claves en xai_results:", list(xai_results.keys()))
            if 'xai_results' not in globals() or 'RNN' not in xai_results:
                raise RuntimeError(
                    "No se encontr√≥ `xai_results['rnn']`. "
                    "Aseg√∫rate de haber ejecutado la Celda 10 y almacenado los resultados xIA de RNN en `xai_results['rnn']`."
                )

                # Cabecera
                self.sections.append((
                    "## üîç An√°lisis xIA de RNN: Resultados concretos y explicaciones Generativas",
                    ""  # contenido vac√≠o, la cabecera se mostrar√° como Markdown
                ))


            # Funci√≥n para llamar a OpenAI con un prompt espec√≠fico
            def call_openai_explanation(prompt: str, model="gpt-4"):
                """
                Llama a OpenAI ChatCompletion con un sistema experto en ML/XAI,
                devuelve la respuesta de la IA en texto.
                """
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un asistente experto en Machine Learning e interpretabilidad de modelos. "
                                "Proporciona explicaciones detalladas y basadas en los datos concretos proporcionados."
                            )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    texto = response.choices[0].message.content.strip()
                except Exception as e:
                    texto = f"[Error llamando a OpenAI: {e}]"
                return texto

            # ----------------------------------------------------------------
            # Configuraci√≥n: top N variables y primeras M muestras locales
            # ----------------------------------------------------------------
            TOP_N = 5      # cu√°ntas caracter√≠sticas top incluir en el prompt
            N_LOCAL = 3    # cu√°ntas muestras locales incluir en prompt

            # ----------------------------------------------------------------
            # Lista de m√©todos xIA y claves en xai_results['RNN']
            # ----------------------------------------------------------------
            # Las claves deben coincidir exactamente con las usadas en Celda 10 al almacenar resultados.
            metodos_claves = [
                ('SHAP', 'SHAP'),
                ('LIME', 'LIME'),
                ('KernelExplainer', 'KernelExplainer'),
                ('Integrated Gradients', 'Integrated Gradients'),
                ('DeepLIFT / LRP', 'DeepLIFT / LRP'),
                ('Permutation Feature Importance', 'Permutation Feature Importance'),
                ('Partial Dependence Plots (PDP)', 'Partial Dependence Plots (PDP)'),
                ('Accumulated Local Effects (ALE)', 'Accumulated Local Effects (ALE)'),
                ('Individual Conditional Expectation (ICE) Plots', 'Individual Conditional Expectation (ICE) Plots'),
                ('Counterfactual Explanations', 'Counterfactual Explanations'),
                ('Anchors', 'Anchors'),
                ('Surrogate Models (Global/Local)', 'Surrogate Models (Global/Local)'),
                ('Explainable Boosting Machine (EBM)', 'Explainable Boosting Machine (EBM)'),
                ('Optuna Hyperparameter Importance', 'Optuna Hyperparameter Importance'),
            ]

            for titulo, clave in metodos_claves:
                print(f"[DEBUG] 10.17. Procesando secci√≥n xIA: {titulo}")
                datos = xai_results['RNN'].get(clave)
                if datos is None:
                    print(f"[DEBUG] No hay resultados xIA para {titulo}, se omite")
                    continue
#                    self.sections.append((
#                        f"### ‚ö†Ô∏è No hay resultados para {titulo}",
#                        f"No se hallaron resultados para la clave '{clave}'."
#                    ))
#                    continue

                # ---------------- Mostrar figura guardada ----------------
                print(f"[DEBUG] 10.18. Mostrando figura para {titulo}")
                fig = datos.get('fig_summary') or datos.get('fig')
                if fig is not None:
                    self.sections.append((f"### {titulo}: Gr√°fico", fig))

                # --------------- Mostrar DataFrames de importancia y local ---------------
                print(f"[DEBUG] 10.19. Mostrando DataFrames para {titulo}")
                imp_df = datos.get('imp_df')
                df_local = datos.get('df_local')
                stats_extra = datos.get('stats', None)  # opcional: estad√≠sticas adicionales, p.ej. percentiles, pos_pct SHAP, etc.

                if isinstance(imp_df, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Importancia global", imp_df.reset_index(drop=True)))

                if isinstance(df_local, pd.DataFrame):
                    self.sections.append((f"### {titulo}: Valores locales", df_local.head(N_LOCAL)))

                # --------------------------------- Extraer datos del gr√°fico (suponiendo que sea un barh con 'feature' y 'importance') ---------------------------
                features = [text.get_text() for text in ax.get_yticklabels()]
                importances = [bar.get_width() for bar in ax.patches]

                # --------------- Construir prompt con valores num√©ricos concretos ---------------
                print(f"[DEBUG] 10.20. Construyendo prompt para {titulo}")
                prompt = f"He aplicado el m√©todo xIA '{titulo}' al modelo RNN entrenado y he obtenido estos resultados concretos:\n\n"

                prompt += "- Datos del gr√°fico (feature vs importancia):\n"
                for f, imp in zip(features, importances):
                    prompt += f"    ‚Ä¢ {f}: {imp:.4f}\n"

                # Ahora s√≠ le pides que interprete el gr√°fico:
                prompt += (
                    "- Interpreta el gr√°fico anterior: "
                    "describe qu√© patrones o relaciones visuales revela c√≥mo se distribuye la importancia.\n"
                )

                # 1) Extraer importancia global: top N
                if isinstance(imp_df, pd.DataFrame) and not imp_df.empty:
                    imp_df = imp_df.reset_index()
                    imp_df = imp_df.rename(columns={ imp_df.columns[0]: "feature" })
                    cols = imp_df.columns.tolist()
                    if len(cols) >= 2:
                        feat_col = "feature"
                        val_col  = cols[1]
                        try:
                            imp_df_sorted = imp_df.sort_values(val_col, ascending=False)
                        except Exception:
                            imp_df_sorted = imp_df

                        top_n      = min(TOP_N, len(imp_df_sorted))
                        top_imp_df = imp_df_sorted.iloc[:top_n][[feat_col, val_col]]
                        top_imp_list = []
                        for _, row in top_imp_df.iterrows():
                            raw = row[val_col]
                            try:
                                v = float(raw)
                            except Exception:
                                v = raw  # si no se puede convertir, lo dejo tal cual
                            top_imp_list.append({feat_col: row[feat_col], val_col: v})

                        prompt += f"- Top {top_n} caracter√≠sticas por importancia global ({feat_col}, {val_col}):\n  {top_imp_list}\n"

                        extra_cols = cols[2:]
                        if extra_cols:
                            prompt += f"  (El DataFrame de importancia global incluye tambi√©n columnas: {extra_cols}.)\n"
                    else:
                        snippet = imp_df.head(TOP_N).to_dict(orient='records')
                        prompt += f"- Importancia global (primeras filas, formato gen√©rico):\n  {snippet}\n"
                else:
                    prompt += "- No hay datos de importancia global.\n"

#                    # ‚Äî Siempre sacamos el √≠ndice como columna llamada "feature"
                    imp_df = imp_df.rename(columns={ idx_col: "feature" })

                # 2) Extraer valores locales: primeras M muestras
                if isinstance(df_local, pd.DataFrame) and not df_local.empty:
                    n_loc = min(N_LOCAL, len(df_local))
                    loc_snippet = df_local.head(n_loc).to_dict(orient='records')
                    prompt += f"- Valores locales para las primeras {n_loc} muestras (cada dict mapea feature a valor/atribuci√≥n):\n  {loc_snippet}\n"
                else:
                    prompt += "- No hay datos de valores locales.\n"

                # 3) Incluir estad√≠sticas extra si existen
                if isinstance(stats_extra, dict):
                    prompt += "- Estad√≠sticas adicionales:\n"
                    for k, v in stats_extra.items():
                        prompt += f"  * {k}: {v}\n"

                # 4) Contexto general del modelo RNN
                prompt += (
                    "\nContexto: El modelo RNN fue entrenado con variables seleccionadas y StandardScaler, "
                    "con predicciones desescaladas. Ahora interpretamos los resultados xIA para este RNN.\n"
                )

                # 5) Preguntas/pautas espec√≠ficas seg√∫n el m√©todo
                if clave == 'SHAP':
                    prompt += (
                        "\nUsa estos valores concretos de SHAP para:\n"
                        "1. Explicar la importancia global de cada variable en base a los valores de SHAP mostrados.\n"
                        "2. Analizar los valores SHAP de las primeras muestras: si una variable muestra SHAP positivo alto, ¬øqu√© implica sobre la predicci√≥n en ese caso? Y si es negativo, ¬øqu√© implica?\n"
                        "3. Identificar patrones en SHAP (por ejemplo, variables que consistentemente empujan en una direcci√≥n) y c√≥mo afecta al comportamiento general del RNN.\n"
                        "4. Sugerir posibles transformaciones de variables o validaciones adicionales basadas en estos resultados SHAP.\n"
                    )
                elif clave == 'LIME':
                    prompt += (
                        "\nUsa estos pesos LIME concretos para:\n"
                        "1. Explicar el significado de pesos positivos y negativos en LIME para RNN.\n"
                        "2. Analizar casos de las primeras muestras: si una variable tiene peso LIME fuerte (positivo/negativo), ¬øqu√© implica para la predicci√≥n local?\n"
                        "3. Comentar si la variabilidad de los pesos sugiere relaciones no lineales o interacciones no capturadas.\n"
                        "4. Recomendar acciones: agrupaci√≥n de variables, detecci√≥n de outliers, etc., basadas en la interpretaci√≥n LIME.\n"
                    )
                elif clave == 'KernelExplainer':
                    prompt += (
                        "\nUsa estos valores de KernelExplainer (SHAP caja negra) para:\n"
                        "1. Explicar la importancia global seg√∫n los valores medios absolutos Kernel SHAP.\n"
                        "2. Analizar los valores locales para las primeras muestras: c√≥mo cada caracter√≠stica empuja la predicci√≥n en cada caso.\n"
                        "3. Comparar con SHAP (si ya lo hiciste con TreeExplainer para otro modelo o Kernel SHAP para RNN), si aplica.\n"
                        "4. Sugerir consideraciones sobre fondo (background) usado y posibles ajustes si las explicaciones muestran comportamiento inesperado.\n"
                    )
                elif clave == 'Integrated Gradients':
                    prompt += (
                        "\nUsa estos valores de Integrated Gradients para:\n"
                        "1. Explicar la contribuci√≥n integrada de cada variable: interpretaci√≥n de importancia global.\n"
                        "2. Analizar las primeras muestras: qu√© implicaciones tiene un valor IG alto o bajo en cada variable.\n"
                        "3. Se√±alar limitaciones: compatibilidad con RNN no diferenciable; si estos valores provienen de un modelo aproximado, comentar fiabilidad.\n"
                        "4. Sugerir pasos adicionales o comparaciones con otros m√©todos (SHAP/LIME) para validar interpretaciones.\n"
                    )
                elif clave == 'DeepLIFT / LRP':
                    prompt += (
                        "\nUsa estos valores de DeepLIFT / LRP para:\n"
                        "1. Explicar la relevancia asignada a cada variable en importancia global.\n"
                        "2. Analizar las primeras muestras: si una variable tiene relevancia positiva o negativa, qu√© significa para la predicci√≥n.\n"
                        "3. Comparar con IG o SHAP si se dispone: consistencia de atribuciones.\n"
                        "4. Recomendar verificaciones o transformaciones en caso de interpretaciones inesperadas.\n"
                    )
                elif clave == 'Permutation Feature Importance':
                    prompt += (
                        "\nUsa estos valores de Permutation Feature Importance para:\n"
                        "1. Explicar la ca√≠da en la m√©trica al permutar cada variable: por qu√© ciertas variables son cr√≠ticas.\n"
                        "2. Comentar la desviaci√≥n est√°ndar: ¬øindica inestabilidad en la importancia? ¬øD√≥nde conviene reforzar validaciones?\n"
                        "3. Comparar con importancias de SHAP/LIME: similitudes o diferencias.\n"
                        "4. Sugerir prioridades para ajuste de modelo o selecci√≥n de variables basadas en esta m√©trica.\n"
                    )
                elif clave == 'Partial Dependence Plots (PDP)':
                    prompt += (
                        "\nUsa estos rangos PDP para:\n"
                        "1. Explicar el efecto promedio de cada variable sobre la predicci√≥n seg√∫n el rango PDP obtenido.\n"
                        "2. Se√±alar si los rangos sugieren relaciones mon√≥tonas o no lineales.\n"
                        "3. Advertir sobre correlaciones fuertes que puedan afectar la interpretaci√≥n.\n"
                        "4. Recomendar posibles exploraciones adicionales (PDP bivariados, transformaciones) seg√∫n los resultados.\n"
                    )
                elif clave == 'Accumulated Local Effects (ALE)':
                    prompt += (
                        "\nUsa estos rangos ALE y valores locales ALE para:\n"
                        "1. Explicar c√≥mo ALE corrige artefactos de correlaci√≥n y qu√© nos dicen los valores concretos.\n"
                        "2. Interpretar importancia global ALE: variables con mayor efecto acumulado.\n"
                        "3. Analizar heterogeneidad local a partir de valores ALE de primeras muestras.\n"
                        "4. Sugerir exploraciones adicionales (ALE 2D, inspecci√≥n de distribuci√≥n) seg√∫n hallazgos.\n"
                    )
                elif clave == 'Individual Conditional Expectation (ICE) Plots':
                    prompt += (
                        "\nUsa estos rangos ICE medios para:\n"
                        "1. Explicar qu√© mide el rango ICE y su diferencia respecto a PDP.\n"
                        "2. Analizar heterogeneidad: variables con alta variabilidad en rangos ICE indican interacciones o comportamiento inestable.\n"
                        "3. Se√±alar implicaciones para el modelo y posibles ajustes si hay alto efecto local variable.\n"
                        "4. Recomendar exploraciones adicionales para entender la variabilidad local.\n"
                    )
                elif clave == 'Counterfactual Explanations':
                    prompt += (
                        "\nUsa estos resultados de Contrafactuales para:\n"
                        "1. Explicar c√≥mo interpretar los contrafactuales: cambios en variables que generan aumento en predicci√≥n.\n"
                        "2. Analizar variables con mayor |Œî| medio: implicaciones sobre sensibilidad del modelo.\n"
                        "3. Se√±alar si faltan contrafactuales para algunas muestras: qu√© puede indicar (limites del modelo o datos).\n"
                        "4. Sugerir c√≥mo usar estos insights para ajuste de modelo o recolecci√≥n de datos.\n"
                    )
                elif clave == 'Anchors':
                    prompt += (
                        "\nUsa estos resultados de Anchors para:\n"
                        "1. Explicar c√≥mo leer las reglas ancla de las primeras muestras: condiciones que aseguran la predicci√≥n.\n"
                        "2. Analizar frecuencia global de aparici√≥n de variables en reglas: implicaciones sobre estabilidad y sesgos.\n"
                        "3. Se√±alar regiones de bajo coverage o baja precisi√≥n: d√≥nde el modelo es menos fiable.\n"
                        "4. Recomendar acciones: recolecci√≥n de datos, refinamiento de variables o validaciones dirigidas.\n"
                    )
                elif clave == 'Surrogate Models (Global/Local)':
                    prompt += (
                        "\nUsa estos resultados de Surrogate Models para:\n"
                        "1. Explicar la importancia global del surrogate (√°rbol) y la importancia local media (coeficientes regresiones locales).\n"
                        "2. Comparar global vs local: variables con alta importancia local pero baja global, o viceversa, y qu√© sugiere.\n"
                        "3. Concluir sobre consistencia de comportamiento del RNN en diferentes regiones del espacio.\n"
                        "4. Sugerir exploraciones adicionales o ajustes de modelo seg√∫n discrepancias detectadas.\n"
                    )
                elif clave == 'Explainable Boosting Machine (EBM)':
                    prompt += (
                        "\nUsa estos resultados de EBM para:\n"
                        "1. Explicar la importancia global seg√∫n EBM: c√≥mo se comparan con otros m√©todos.\n"
                        "2. Analizar contribuciones locales de las primeras muestras: qu√© patrones se observan.\n"
                        "3. Se√±alar si EBM revela interacciones no consideradas en RNN.\n"
                        "4. Recomendar posibles ajustes en caracter√≠sticas o validaciones seg√∫n insights de EBM.\n"
                    )
                elif clave == 'Optuna Hyperparameter Importance':
                    prompt += (
                        "\nUsa estos resultados de Optuna para:\n"
                        "1. Explicar la importancia global de hiperpar√°metros en la optimizaci√≥n del RNN.\n"
                        "2. Analizar top trials si est√°n disponibles: qu√© combinaciones de hiperpar√°metros funcionaron mejor.\n"
                        "3. Se√±alar limitaciones de la muestra de trials (n√∫mero de pruebas) y posibles riesgos de sobreajuste en la b√∫squeda.\n"
                        "4. Recomendar pr√≥ximas acciones para tuning basadas en estas importancias.\n"
                    )
                else:
                    prompt += "\nPor favor, explica estos resultados num√©ricos y qu√© implicaciones tienen para el modelo RNN.\n"

                # --------------- Llamada a OpenAI ---------------
                print(f"[DEBUG] 10.21. Llamando a OpenAI para {titulo}")
                explicacion = call_openai_explanation(prompt)
                self.sections.append((f"### {titulo}: Explicaci√≥n Generativa", explicacion))

        except Exception as e:
            self.sections.append((
                "### ‚ö†Ô∏è Error en secci√≥n xIA RNN",
                f"Se produjo un error al generar la secci√≥n xIA de RNN: {e}"
            ))


        # =====================================================================
        # 11. Comparador Global de Modelos Entrenados
        # =====================================================================
        try:
            print("[DEBUG] 11.1. Iniciando secci√≥n Comparador de Modelos")
            import os, pickle
            import numpy as np
            import pandas as _pd
            import matplotlib.pyplot as plt
            from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
            from tensorflow.keras.models import load_model

            # 1) Recopilar todos los modelos guardados
            ruta = "."
            modelos = []
            for f in os.listdir(ruta):
                if f.startswith("modelo_") and (f.endswith(".pkl") or f.endswith(".h5")):
                    name = f.replace("modelo_", "").rsplit(".", 1)[0]
                    try:
                        if f.endswith(".pkl"):
                            with open(f, "rb") as fp:
                                data = pickle.load(fp)
                            model = data.get("model")
                            sx = data.get("sx", data.get("scaler_X"))
                            sy = data.get("sy", data.get("scaler_Y"))
                            cols = data.get("cols", [])
                        else:  # .h5
                            model = load_model(f)
                            # se espera un pickle de escaladores: escaladores_{name}.pkl
                            escal_path = f"escaladores_{name}.pkl"
                            with open(escal_path, "rb") as fp:
                                data = pickle.load(fp)
                            sx = data.get("scaler_X")
                            sy = data.get("scaler_Y")
                            cols = data.get("cols", [])
                        if model is None or sx is None or sy is None or not cols:
                            raise ValueError("Faltan claves necesarias en el pickle/modelo")
                        modelos.append((name, model, sx, sy, cols))
                    except Exception as e:
                        print(f"[DEBUG] Omitido {f}: {e}")

            if not modelos:
                print("[DEBUG] No se encontraron modelos v√°lidos para comparar")
            else:
                # 2) Para cada modelo, calcular predicciones sobre X_test/Y_test
                resultados = []
                preds_dict = {}
                y_true_full = None

                for name, model, sx, sy, cols in modelos:
                    # Verificar que X_test y Y_test existan en globals
                    if "X_test" not in self.g or "Y_test" not in self.g:
                        print("[DEBUG] No hay X_test/Y_test en globals(), omito comparador")
                        break
                    try:
                        X_test_df = self.g["X_test"][cols].copy()
                    except Exception as e:
                        print(f"[DEBUG] Error al extraer X_test para {name}: {e}")
                        continue
                    y_test = self.g["Y_test"]
                    # Serie 1D de y_true
                    arr = y_test.values if hasattr(y_test, "values") else np.array(y_test)
                    y_arr = arr.ravel()

                    # Detectar si es RNN por input_shape
                    is_rnn = False
                    window = None
                    try:
                        if hasattr(model, "input_shape") and isinstance(model.input_shape, tuple) and len(model.input_shape) == 3:
                            is_rnn = True
                            window = model.input_shape[1]
                    except:
                        pass

                    # Generar predicci√≥n
                    try:
                        if is_rnn and window is not None:
                            # crear secuencias
                            Xs = sx.transform(X_test_df)
                            seqs, trues = [], []
                            for i in range(len(Xs) - window):
                                seqs.append(Xs[i:i + window])
                                trues.append(y_arr[i + window])
                            if not seqs:
                                print(f"[DEBUG] Secuencias vac√≠as para RNN {name}, omito")
                                continue
                            Xseq = np.array(seqs)
                            y_real = np.array(trues)
                            pred_scaled = model.predict(Xseq, verbose=0)
                            # en algunos casos model.predict devuelve tupla
                            if isinstance(pred_scaled, tuple):
                                pred_scaled = pred_scaled[0]
                            y_pred = sy.inverse_transform(pred_scaled.reshape(-1, 1)).ravel()
                        else:
                            Xs = sx.transform(X_test_df)
                            raw = model.predict(Xs)
                            if isinstance(raw, tuple):
                                raw = raw[0]
                            y_pred = sy.inverse_transform(raw.reshape(-1, 1)).ravel()
                            y_real = y_arr
                    except Exception as e:
                        print(f"[DEBUG] Error predicci√≥n para {name}: {e}")
                        continue

                    # Guardar y_true para la primera curva
                    if y_true_full is None:
                        y_true_full = y_real

                    # Calcular m√©tricas
                    try:
                        r2 = r2_score(y_real, y_pred)
                        mse = mean_squared_error(y_real, y_pred)
                        rmse = np.sqrt(mse)
                        mae = mean_absolute_error(y_real, y_pred)
                    except Exception as e:
                        print(f"[DEBUG] Error c√°lculo m√©tricas para {name}: {e}")
                        continue

                    resultados.append({
                        "Modelo": name,
                        "R2": r2,
                        "MSE": mse,
                        "RMSE": rmse,
                        "MAE": mae
                    })
                    preds_dict[name] = y_pred

                # 3) Tabla de m√©tricas
                if resultados:
                    df_met = _pd.DataFrame(resultados).set_index("Modelo")
                    self.sections.append(("### üìã Comparativa de M√©tricas de Todos los Modelos", df_met))
                    print("[DEBUG] 11.2. Secci√≥n comparativa m√©tricas a√±adida")
                    # Extraer m√©tricas como dict para el prompt:
                    # Podemos convertir a lista de dicts o dict de listas. Por claridad, usamos lista de records:
                    metrics_records = df_met.reset_index().to_dict(orient='records')
                    # Explicaci√≥n IA de la tabla
                    prompt_tab = (
                        "Tienes estas m√©tricas en test para cada modelo:\n"
                        + "\n".join(
                            f"- Modelo '{rec['Modelo']}': R2={rec['R2']:.4f}, RMSE={rec['RMSE']:.4f}, MAE={rec['MAE']:.4f}, MSE={rec['MSE']:.4f}"
                            for rec in metrics_records
                        )
                        + "\n\nPor favor, interpreta profesionalmente cu√°l modelo es el mejor seg√∫n estas m√©tricas y por qu√©, "
                          "y proporciona recomendaciones de ajustes de hiperpar√°metros para mejorar el desempe√±o del mejor modelo y posibles ajustes en los dem√°s."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en ML comparativo de modelos."},
                                {"role": "user", "content": prompt_tab}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### üìù Explicaci√≥n IA Comparativa de M√©tricas", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.3. Secci√≥n IA comparaci√≥n m√©tricas a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA comparaci√≥n m√©tricas: {e}")

                    # Funci√≥n auxiliar para gr√°fico de barras horizontales
                    def _plot_barh(series, titulo, xlabel=None):
                        fig, ax = plt.subplots(figsize=(8, max(4, 0.3 * len(series))))
                        # ordenar para que el mejor (mayor R2 o menor error) quede arriba
                        series_sorted = series.sort_values(ascending=True)
                        # Si es R2 (mayor es mejor), invertimos orden para que el mayor quede arriba
                        if xlabel == "R2":
                            # para R2, queremos ascending=True y luego invertir eje Y
                            ax.barh(series_sorted.index, series_sorted.values)
                        else:
                            # para errores (RMSE, MAE, MSE), menor es mejor: ascending=True pone menor arriba despu√©s de invertir eje
                            ax.barh(series_sorted.index, series_sorted.values)
                        ax.set_title(titulo)
                        ax.set_xlabel(xlabel if xlabel else "")
                        ax.set_ylabel("Modelo")
                        ax.invert_yaxis()
                        plt.tight_layout()
                        return fig

                    # 4) Barras de R2
                    fig_r2 = _plot_barh(df_met["R2"], "Ranking de Modelos por R¬≤", xlabel="R2")
                    self.sections.append(("### üìä Gr√°fico Comparativo de R¬≤", fig_r2))
                    print("[DEBUG] 11.4. Secci√≥n gr√°fica R2 a√±adida")
                    # Explicaci√≥n IA R2
                    # Extraer valores de R2:
                    r2_dict = df_met["R2"].to_dict()  # e.g. {"M1":0.85, "M2":0.78, ...}
                    prompt_r2 = (
                        "Tienes los valores de R¬≤ en test para cada modelo (aqu√≠ listados):\n"
                        + "\n".join(f"- Modelo '{m}': R¬≤ = {v:.4f}" for m, v in r2_dict.items())
                        + "\n\nBas√°ndote en estos valores (sin apoyarte en la visualizaci√≥n directa), "
                          "indica profesionalmente qu√© conclusiones sacas sobre el ajuste de los modelos y posibles razones de las diferencias entre ellos."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en interpretaci√≥n de gr√°ficos ML."},
                                {"role": "user", "content": prompt_r2}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### üìù Explicaci√≥n IA Gr√°fico R¬≤", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.5. Secci√≥n IA comparaci√≥n R2 a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA R2: {e}")

                    # 5) Barras de MAE
                    fig_mae = _plot_barh(df_met["MAE"], "Comparativa Global por MAE (menor es mejor)", xlabel="MAE")
                    self.sections.append(("### üìä Gr√°fico Comparativo de MAE", fig_mae))
                    print("[DEBUG] 11.6. Secci√≥n gr√°fica MAE a√±adida")
                    # Extraer valores de MAE:
                    mae_dict = df_met["MAE"].to_dict()  # e.g. {"M1":12.345, "M2":15.678, ...}
                    prompt_mae = (
                        "Tienes los valores de MAE en test para cada modelo:\n"
                        + "\n".join(f"- Modelo '{m}': MAE = {v:.4f}" for m, v in mae_dict.items())
                        + "\n\nBas√°ndote en estos valores (sin ver la gr√°fica), indica profesionalmente qu√© indican sobre la precisi√≥n de cada modelo en t√©rminos absolutos y relativos, "
                          "qu√© patrones observas (por ejemplo, modelos con MAE significativamente m√°s alta o m√°s baja) y recomendaciones concretas para reducir el MAE del mejor modelo o de aquellos con MAE elevado."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en interpretaci√≥n de m√©tricas de error en ML."},
                                {"role": "user", "content": prompt_mae}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### üìù Explicaci√≥n IA Gr√°fico MAE", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.7. Secci√≥n IA comparaci√≥n MAE a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA MAE: {e}")

                    # 6) Barras de MSE
                    fig_mse = _plot_barh(df_met["MSE"], "Comparativa Global por MSE (menor es mejor)", xlabel="MSE")
                    self.sections.append(("### üìä Gr√°fico Comparativo de MSE", fig_mse))
                    print("[DEBUG] 11.8. Secci√≥n gr√°fica MSE a√±adida")
                    # Extraer valores de MSE:
                    mse_dict = df_met["MSE"].to_dict()
                    prompt_mse = (
                        "Tienes los valores de MSE en test para cada modelo:\n"
                        + "\n".join(f"- Modelo '{m}': MSE = {v:.4f}" for m, v in mse_dict.items())
                        + "\n\nBas√°ndote en estos valores, comenta profesionalmente qu√© sugiere acerca del ajuste y robustez de cada modelo, "
                          "identifica si hay alguno con MSE significativamente mayor o menor y ofrece recomendaciones concretas para reducir MSE (por ejemplo, cambios de preprocesado, regularizaci√≥n, arquitectura, etc.)."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en interpretaci√≥n de m√©tricas de error en ML."},
                                {"role": "user", "content": prompt_mse}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### üìù Explicaci√≥n IA Gr√°fico MSE", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.9. Secci√≥n IA comparaci√≥n MSE a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA MSE: {e}")

                    # 7) Barras de RMSE
                    fig_rmse = _plot_barh(df_met["RMSE"], "Comparativa Global por RMSE (menor es mejor)", xlabel="RMSE")
                    self.sections.append(("### üìä Gr√°fico Comparativo de RMSE", fig_rmse))
                    print("[DEBUG] 11.10. Secci√≥n gr√°fica RMSE a√±adida")
                    # Extraer valores de RMSE:
                    rmse_dict = df_met["RMSE"].to_dict()
                    prompt_rmse = (
                        "Tienes los valores de RMSE en test para cada modelo:\n"
                        + "\n".join(f"- Modelo '{m}': RMSE = {v:.4f}" for m, v in rmse_dict.items())
                        + "\n\nBas√°ndote en estos valores, comenta profesionalmente las diferencias entre modelos, "
                          "por qu√© algunos podr√≠an tener RMSE mayor o menor (relaci√≥n con varianza de los datos, sesgos, complejidad del modelo, etc.) y sugiere estrategias concretas para mejorar el RMSE del modelo ganador o para equilibrar sesgo-varianza."
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en interpretaci√≥n de m√©tricas de error en ML."},
                                {"role": "user", "content": prompt_rmse}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### üìù Explicaci√≥n IA Gr√°fico RMSE", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.11. Secci√≥n IA comparaci√≥n RMSE a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA RMSE: {e}")

                    # 8) Curvas Real vs Predicho para todos
                    if y_true_full is not None and preds_dict:
                        fig2, ax2 = plt.subplots(figsize=(8, 4))
                        ax2.plot(y_true_full, label="Y real", color="black", linewidth=2)
                        for name, pred in preds_dict.items():
                            # Asegurarse de que longitudes coincidan; si no, recortar al m√≠nimo
                            min_len = min(len(y_true_full), len(pred))
                            ax2.plot(pred[:min_len], "--", label=name)
                        ax2.set_title("Comparativa Y real vs Predicho")
                        ax2.legend(loc="upper right")
                        plt.tight_layout()
                        self.sections.append(("### üìà Gr√°fico Comparativo Real vs Predicho", fig2))
                        print("[DEBUG] 11.12. Secci√≥n gr√°fica real vs pred a√±adida")
                        # Suponiendo y_true_full y preds_dict ya definidos y alineados:
                        # Para cada modelo:
                        summary_list = []
                        import numpy as _np
                        for name, pred in preds_dict.items():
                            # Asegurar longitudes coincidentes
                            min_len = min(len(y_true_full), len(pred))
                            y_real = _np.array(y_true_full[:min_len])
                            y_pred = _np.array(pred[:min_len])
                            # M√©tricas:
                            from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
                            try:
                                r2_val = r2_score(y_real, y_pred)
                            except:
                                r2_val = None
                            try:
                                mse_val = mean_squared_error(y_real, y_pred)
                                rmse_val = _np.sqrt(mse_val)
                            except:
                                mse_val = rmse_val = None
                            try:
                                mae_val = mean_absolute_error(y_real, y_pred)
                            except:
                                mae_val = None
                            # Correlaci√≥n:
                            try:
                                corr_val = float(_np.corrcoef(y_real, y_pred)[0, 1]) if len(y_real)>1 else None
                            except:
                                corr_val = None
                            # Rango:
                            y_real_min, y_real_max = float(_np.min(y_real)), float(_np.max(y_real))
                            y_pred_min, y_pred_max = float(_np.min(y_pred)), float(_np.max(y_pred))
                            summary_list.append({
                                "Modelo": name,
                                "R2": r2_val,
                                "MSE": mse_val,
                                "RMSE": rmse_val,
                                "MAE": mae_val,
                                "Corr": corr_val,
                                "Rango real": (y_real_min, y_real_max),
                                "Rango pred": (y_pred_min, y_pred_max)
                            })
                            # Formatear summary_list en texto:
                            lines = []
                            for rec in summary_list:
                                m = rec["Modelo"]
                                # Manejar None con 'N/A'
                                r2s = f"{rec['R2']:.4f}" if rec['R2'] is not None else "N/A"
                                rs = rec["Rango real"]
                                ps = rec["Rango pred"]
                                corr_s = f"{rec['Corr']:.4f}" if rec['Corr'] is not None else "N/A"
                                mse_s = f"{rec['MSE']:.4f}" if rec['MSE'] is not None else "N/A"
                                rmse_s = f"{rec['RMSE']:.4f}" if rec['RMSE'] is not None else "N/A"
                                mae_s = f"{rec['MAE']:.4f}" if rec['MAE'] is not None else "N/A"
                                lines.append(
                                    f"- Modelo '{m}': R2={r2s}, RMSE={rmse_s}, MAE={mae_s}, MSE={mse_s}, Corr={corr_s}, "
                                    f"Rango real=[{rs[0]:.4f}, {rs[1]:.4f}], Rango pred=[{ps[0]:.4f}, {ps[1]:.4f}]"
                                )

                            prompt_curvas = (
                                "Para cada modelo tienes estos res√∫menes num√©ricos de su predicci√≥n vs real:\n"
                                + "\n".join(lines)
                                + "\n\nAunque tambi√©n se gener√≥ una gr√°fica Real vs Predicho, la IA no la ve: "
                                  "Comenta profesionalmente c√≥mo var√≠a el ajuste de cada modelo a lo largo de la serie con base en los valores anteriores "
                                  "(por ejemplo, si hay subestimaci√≥n sistem√°tica al inicio o al final, si la dispersi√≥n crece en ciertos rangos, etc.)."
                            )
                        try:
                            resp = _client.chat.completions.create(
                                model="gpt-4",
                                messages=[
                                    {"role": "system", "content": "Eres un experto en visualizaci√≥n de resultados ML."},
                                    {"role": "user", "content": prompt_curvas}
                                ],
                                max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                            )
                            self.sections.append(("### üìù Explicaci√≥n IA Curvas Real vs Predicho", resp.choices[0].message.content.strip()))
                            print("[DEBUG] 11.13. Secci√≥n IA comparaci√≥n curvas a√±adida")
                        except Exception as e:
                            print(f"[ERROR] al generar explicaci√≥n IA curvas: {e}")

                        # 9) Gr√°fica de residuos superpuesta
                        fig3, ax3 = plt.subplots(figsize=(8, 4))
                        for name, pred in preds_dict.items():
                            min_len = min(len(y_true_full), len(pred))
                            res = y_true_full[:min_len] - pred[:min_len]
                            ax3.plot(res, label=name, alpha=0.7)
                        ax3.axhline(0, color="black", lw=1)
                        ax3.set_title("Comparativa de Residuos")
                        ax3.legend(loc="upper right")
                        plt.tight_layout()
                        self.sections.append(("### üìâ Gr√°fico Comparativo de Residuos", fig3))
                        print("[DEBUG] 11.14. Secci√≥n gr√°fica residuos a√±adida")
                        res_summary = []
                        import numpy as _np
                        for rec in summary_list:  # si summary_list incluye y_real y y_pred, o recalcular aqu√≠
                            name = rec["Modelo"]
                            # Recalcular residuos:
                            pred = preds_dict[name]
                            min_len = min(len(y_true_full), len(pred))
                            y_real = _np.array(y_true_full[:min_len])
                            y_pred = _np.array(pred[:min_len])
                            residuals = y_real - y_pred
                            # Estad√≠sticos:
                            mean_res = float(_np.mean(residuals))
                            std_res  = float(_np.std(residuals))
                            # Con Pandas o numpy calcular skew/kurt:
                            import pandas as _pd
                            res_series = _pd.Series(residuals)
                            skew_res = float(res_series.skew())
                            kurt_res = float(res_series.kurtosis())
                            q25, q50, q75 = [float(x) for x in res_series.quantile([0.25, 0.5, 0.75])]
                            # Rango:
                            min_res, max_res = float(_np.min(residuals)), float(_np.max(residuals))
                            res_summary.append({
                                "Modelo": name,
                                "Mean": mean_res,
                                "Std": std_res,
                                "Skew": skew_res,
                                "Kurtosis": kurt_res,
                                "Quantiles": (q25, q50, q75),
                                "Rango residuo": (min_res, max_res)
                            })
                            lines = []
                            for rec in res_summary:
                                m = rec["Modelo"]
                                mean_s = f"{rec['Mean']:.4f}"
                                std_s  = f"{rec['Std']:.4f}"
                                skew_s = f"{rec['Skew']:.4f}"
                                kurt_s = f"{rec['Kurtosis']:.4f}"
                                q25, q50, q75 = rec["Quantiles"]
                                min_r, max_r = rec["Rango residuo"]
                                lines.append(
                                    f"- Modelo '{m}': media residuo={mean_s}, std={std_s}, skew={skew_s}, kurtosis={kurt_s}, "
                                    f"quantiles residuo 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}, "
                                    f"rango residuo=[{min_r:.4f}, {max_r:.4f}]"
                                )
                            prompt_res = (
                                "Tienes las siguientes estad√≠sticas de residuos (Y_real - Y_predicho) para cada modelo:\n"
                                + "\n".join(lines)
                                + "\n\nCon base en estos datos (sin apoyo visual), analiza profesionalmente si hay patrones de sesgo (por ejemplo, media distinta de 0), heterocedasticidad (std variable seg√∫n nivel, aunque aqu√≠ solo tenemos std global; si quisieras, podr√≠as calcular std en terciles de y_pred), posibles outliers (bas√°ndote en quantiles y rango), y qu√© implicaciones tiene para la robustez y generalizaci√≥n de cada modelo."
                            )
                        try:
                            resp = _client.chat.completions.create(
                                model="gpt-4",
                                messages=[
                                    {"role": "system", "content": "Eres un experto en diagn√≥stico de modelos ML."},
                                    {"role": "user", "content": prompt_res}
                                ],
                                max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                            )
                            self.sections.append(("### üìù Explicaci√≥n IA Residuos Comparativos", resp.choices[0].message.content.strip()))
                            print("[DEBUG] 11.15. Secci√≥n IA comparaci√≥n residuos a√±adida")
                        except Exception as e:
                            print(f"[ERROR] al generar explicaci√≥n IA residuos: {e}")
                    else:
                        print("[DEBUG] No hay datos suficientes para curvas o residuos comparativos")

                    # 10) Par√°metros t√©cnicos de cada modelo
                    tabla_params = []
                    for name, model, _, _, _ in modelos:
                        row = {"Modelo": name}
                        try:
                            if hasattr(model, "get_params"):
                                row.update(model.get_params())
                            else:
                                cfg = model.get_config()
                                row["Capas"] = len(cfg.get("layers", []))
                                row["Opt"] = cfg.get("optimizer_config", {}).get("class_name", "?")
                                row["Loss"] = cfg.get("loss", "?")
                        except Exception:
                            row["Info"] = "no disponible"
                        tabla_params.append(row)
                    df_params = _pd.DataFrame(tabla_params).set_index("Modelo")
                    self.sections.append(("### üõ† Par√°metros T√©cnicos de Cada Modelo", df_params))
                    print("[DEBUG] 11.16. Secci√≥n tabla par√°metros a√±adida")

                    # Explicaci√≥n IA par√°metros
                    prompt_par = (
                        "Aqu√≠ tienes una tabla con los par√°metros t√©cnicos usados en cada modelo. "
                        "Comenta brevemente qu√© configuraciones parecen m√°s adecuadas y cu√°les podr√≠an ajustarse para mejorar el rendimiento."
                        f"\n\n{df_params.to_dict(orient='list')}"
                    )
                    try:
                        resp = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en optimizaci√≥n de hiperpar√°metros ML."},
                                {"role": "user", "content": prompt_par}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS, temperature=TEMPERATURE_VAL
                        )
                        self.sections.append(("### üìù Explicaci√≥n IA Par√°metros T√©cnicos", resp.choices[0].message.content.strip()))
                        print("[DEBUG] 11.17. Secci√≥n IA comparaci√≥n par√°metros a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA par√°metros: {e}")

                    # 11) Conclusiones Globales y Recomendaciones de IA
                    try:
                        # Construir prompt que recopile los principales resultados:
                        # Usamos df_met (DataFrame de m√©tricas) y, opcionalmente, podemos incorporar insights de gr√°ficos anteriores.
                        # Convertimos df_met a diccionario para el prompt:
                        # Supongamos summary_list y res_summary ya definidos (como arriba).
                        # Formateamos una secci√≥n de m√©tricas generales:
                        lines_met = []
                        for rec in summary_list:
                            m = rec["Modelo"]
                            r2s = f"{rec['R2']:.4f}" if rec['R2'] is not None else "N/A"
                            rmse_s = f"{rec['RMSE']:.4f}" if rec['RMSE'] is not None else "N/A"
                            mae_s = f"{rec['MAE']:.4f}" if rec['MAE'] is not None else "N/A"
                            mse_s = f"{rec['MSE']:.4f}" if rec['MSE'] is not None else "N/A"
                            lines_met.append(f"- {m}: R2={r2s}, RMSE={rmse_s}, MAE={mae_s}, MSE={mse_s}")

                        # Formateamos estad√≠sticas de residuos:
                        lines_res = []
                        for rec in res_summary:
                            m = rec["Modelo"]
                            mean_s = f"{rec['Mean']:.4f}"
                            std_s  = f"{rec['Std']:.4f}"
                            skew_s = f"{rec['Skew']:.4f}"
                            kurt_s = f"{rec['Kurtosis']:.4f}"
                            q25, q50, q75 = rec["Quantiles"]
                            lines_res.append(
                                f"- {m}: media residuo={mean_s}, std={std_s}, skew={skew_s}, kurtosis={kurt_s}, quantiles[25,50,75]=[{q25:.4f},{q50:.4f},{q75:.4f}]"
                            )

                        # Formateamos rangos de predicci√≥n vs real:
                        lines_range = []
                        for rec in summary_list:
                            m = rec["Modelo"]
                            rs = rec["Rango real"]
                            ps = rec["Rango pred"]
                            lines_range.append(f"- {m}: Rango real=[{rs[0]:.4f},{rs[1]:.4f}], Rango pred=[{ps[0]:.4f},{ps[1]:.4f}]")

                        # Construcci√≥n del prompt:
                        prompt_final = (
                            "A continuaci√≥n tienes un resumen num√©rico de los resultados de todos los modelos:\n\n"
                            "1) M√©tricas globales en test:\n"
                            + "\n".join(lines_met)
                            + "\n\n2) Estad√≠sticas de residuos:\n"
                            + "\n".join(lines_res)
                            + "\n\n3) Rangos de valores real vs predicho:\n"
                            + "\n".join(lines_range)
                            + "\n\nYa se han analizado previamente aspectos de ajuste, error y par√°metros. "
                            "Con base en toda esta informaci√≥n num√©rica, por favor: "
                            "- Indica cu√°l modelo presenta en conjunto mejor desempe√±o y por qu√©. "
                            "- Sugiere qu√© ajustes o hiperpar√°metros convendr√≠a afinar en ese modelo para mejorar a√∫n m√°s (por ejemplo, si es red neuronal, architecture tweaks; si es √°rbol, depth/regularizaci√≥n; si es RNN, window size o layers; etc.). "
                            "- Comenta posibles limitaciones de los otros modelos e indica en qu√© escenarios podr√≠an ser √∫tiles (por ejemplo, si un modelo tiene menor varianza pero mayor sesgo, puede servir en entornos con datos ruidosos, etc.). "
                            "- Prop√≥n pr√≥ximos pasos de validaci√≥n o pruebas adicionales (p. ej. validaci√≥n cruzada m√°s exhaustiva, test en nuevos periodos de la serie, experimentos de robustez). "
                            "Presenta la respuesta de forma profesional, estructurada en secciones (por ejemplo: Resumen general, An√°lisis del mejor modelo, Ajustes recomendados, Limitaciones y usos alternativos, Pr√≥ximos pasos)."
                        )
                        resp_final = _client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": "Eres un experto en an√°lisis comparativo de modelos de Machine Learning."},
                                {"role": "user", "content": prompt_final}
                            ],
                            max_tokens=MAX_EXPLANATION_TOKENS,
                            temperature=TEMPERATURE_VAL
                        )
                        # A√±adir la secci√≥n al informe
                        self.sections.append((
                            "### üèÅ Conclusiones Globales y Recomendaciones IA",
                            resp_final.choices[0].message.content.strip()
                        ))
                        print("[DEBUG] 11.18. Secci√≥n IA Conclusiones Globales a√±adida")
                    except Exception as e:
                        print(f"[ERROR] al generar explicaci√≥n IA Conclusiones Globales: {e}")

                else:
                    print("[DEBUG] No se obtuvieron resultados de m√©trica para ning√∫n modelo")
        except Exception as e:
            print(f"[ERROR] al generar secci√≥n Comparador de Modelos: {e}")

        # =====================================================================
        # 12. Optimizaci√≥n Modelo SVR
        # =====================================================================
        from scipy.stats import skew, kurtosis
        try:
            print("[DEBUG] 12.1. Iniciando secci√≥n Optimizaci√≥n SVR: Resumen de m√©todos y motores")
            # Verificaci√≥n previa: usamos OPT_MODELS guardado en la celda 9.1
            if 'OPT_MODELS' in globals() and isinstance(OPT_MODELS, dict):
                # Filtrar solo entradas de SVR con payload dict y motores v√°lidos
                valid_engines = {'gridsearchcv', 'randomizedsearchcv', 'optuna', 'bayessearchcv'}
                svr_entries = {
                    k: v for k, v in OPT_MODELS.items()
                    if (isinstance(k, tuple) and k[0] == 'svr'
                        and isinstance(v, dict)
                        and k[2] in valid_engines)
                }
            else:
                raise RuntimeError(
                    "No se encontr√≥ la variable global OPT_MODELS con resultados de optimizaci√≥n SVR. "
                    "Aseg√∫rate de haber ejecutado la Celda 9.1 y de que OPT_MODELS contenga los payloads optimizados."
                )

            import pandas as pd

            # Definici√≥n de las configuraciones usadas para cada motor (para mostrar en la tabla)
            param_configs = {
                'gridsearchcv': {
                    'C': '[0.1, 1, 10, 100]',
                    'epsilon': '[0.01, 0.1, 0.5, 1]',
                    'kernel': "['rbf', 'linear']"
                },
                'randomizedsearchcv': {
                    'C': 'np.logspace(-1, 2, 20)',
                    'epsilon': 'np.logspace(-2, 0, 20)',
                    'kernel': "['rbf', 'linear']"
                },
                'optuna': {
                    'C': 'Float(0.1, 100, log=True)',
                    'epsilon': 'Float(0.01, 1.0, log=True)',
                    'kernel': "Categorical(['rbf','linear'])"
                },
                'bayessearchcv': {
                    'C': 'Real(0.1, 100, prior="log-uniform")',
                    'epsilon': 'Real(0.01, 1.0, prior="log-uniform")',
                    'kernel': 'Categorical(["rbf","linear"])'
                }
            }

            summary_records = []
            # Recorremos cada dupla (metodo, motor)
            for (model_type, sel_method, engine), payload in svr_entries.items():
                print(f"[DEBUG] 12.2. Agregando registro resumen: {sel_method} / {engine}")
                model = payload.get('model')
                score = payload.get('score')
                metric = payload.get('metric')

                # Par√°metros usados para la b√∫squeda seg√∫n motor
                config_used = param_configs.get(engine, {})

                # Hiperpar√°metros √≥ptimos extra√≠dos del modelo
                best_params = {param: getattr(model, param, None) for param in ['C', 'epsilon', 'kernel']}

                # Construir fila
                row = {
                    'Selecci√≥n X': sel_method,
                    'Motor': engine,
                    'M√©trica': metric,
                    'Score': score,
                }

                # A√±adir configuraci√≥n de b√∫squeda
                for k, v in config_used.items():
                    row[f'Grid_{k}'] = v
                # A√±adir mejores hiperpar√°metros
                for k, v in best_params.items():
                    row[f'Best_{k}'] = v

                summary_records.append(row)

            # Crear DataFrame
            df_summary = pd.DataFrame(summary_records)
            print("[DEBUG] 12.3. df_summary.columns:", df_summary.columns.tolist())
            # Reordenar columnas para claridad
            desired_cols = [
                'Selecci√≥n X', 'Motor', 'M√©trica', 'Score',
                'Grid_C', 'Grid_epsilon', 'Grid_kernel',
                'Best_C', 'Best_epsilon', 'Best_kernel'
            ]
            available_cols = [c for c in desired_cols if c in df_summary.columns]
            if not available_cols:
                print("[WARNING] Ninguna de las columnas deseadas est√° presente en df_summary; mostrando todo el DataFrame.")
                df_to_show = df_summary
            else:
                df_to_show = df_summary[available_cols]

            # A√±adir secci√≥n de tabla al informe
            self.sections.append((
                "### SVR Optimizaci√≥n: Resumen de M√©todos y Motores",
                df_to_show.reset_index(drop=True)
            ))
            # ----------------------- 0. An√°lisis Generativo con OpenAI -------------------------------------------------
            # Preparar funci√≥n de llamada a OpenAI
            def call_openai_explanation(prompt: str, model="gpt-4"):
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un experto en optimizaci√≥n de hiperpar√°metros de modelos de ML. "
                                "Proporciona an√°lisis profundo, interpretaciones y recomendaciones." )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS
                    )
                    return response.choices[0].message.content.strip()
                except Exception as e:
                    return f"[Error llamando a OpenAI: {e}]"

            # Construir prompt con contexto y todos los registros
            records_text = []
            for rec in summary_records:
                part = (f"M√©todo X: {rec['Selecci√≥n X']}, Motor: {rec['Motor']}, M√©trica: {rec['M√©trica']}, Score: {rec['Score']:.4f}, "
                        f"Configuraci√≥n de b√∫squeda: C={rec.get('Grid_C')}, epsilon={rec.get('Grid_epsilon')}, kernel={rec.get('Grid_kernel')}. "
                        f"Hiperpar√°metros √≥ptimos: C={rec.get('Best_C')}, epsilon={rec.get('Best_epsilon')}, kernel={rec.get('Best_kernel')}.")
                records_text.append(part)
            prompt = (
                "He obtenido los siguientes resultados de optimizaci√≥n para SVR:\n" +
                "\n".join(records_text) +
                "\n\n" +
                "1. Explica el funcionamiento y la estrategia de b√∫squeda de cada motor (GridSearchCV, RandomizedSearchCV, Optuna, BayesSearchCV).\n" +
                "2. Analiza comparativamente los scores obtenidos por cada optimizaci√≥n y justifica cu√°l es la mejor configuraci√≥n.\n" +
                "3. Ofrece recomendaciones de posibles mejoras cambiando par√°metros de ajuste u otros factores para incrementar el desempe√±o."
            )
            print("[DEBUG] 12.4. Llamando a OpenAI para an√°lisis generativo SVR optimizaci√≥n")
            generative_analysis = call_openai_explanation(prompt)
            self.sections.append((
                "### SVR Optimizaci√≥n: An√°lisis Generativo",
                generative_analysis
            ))
            # ---- Fin bloque 0 ----

            # --- 1. Curvas de Ajuste Real vs. Predicho y de Residuos ---
            print("[DEBUG] 12.5. Iniciando secci√≥n Calidad Ajuste SVR optimizado")
            # Seleccionar mejor registro por Score
            best_rec = max(summary_records, key=lambda x: x['Score'])
            sel_method, engine = best_rec['Selecci√≥n X'], best_rec['Motor']

            # ‚Äî‚Äî‚Äî 1.1 Normalizar payload ‚Äî‚Äî‚Äî
            payload_raw = OPT_MODELS[('svr', sel_method, engine)]
            p           = _normalize_payload(payload_raw)

            model, sx, sy, raw_cols = p['model'], p['sx'], p['sy'], p['cols']
            score, metric           = p['score'], p['metric']
            best_params             = p['best_params']
            # ‚Äî‚Äî‚Äî Fin normalizaci√≥n ‚Äî‚Äî‚Äî

            # ‚Äî‚Äî‚Äî 1.1.1 Sanitizaci√≥n y filtro unificado de columnas ‚Äî‚Äî‚Äî
            sanitized_cols = [sanitize_name(c) for c in raw_cols]
            missing = set(sanitized_cols) - set(X_test.columns)
            if missing:
                print(f"[WARNING] SVR omitido estas columnas por no existir en X_test: {sorted(missing)}")
            cols_valid = [c for c in sanitized_cols if c in X_test.columns]

            # Reemplaza cualquier X_test_sel previo por esta versi√≥n saneada
            X_test_sel = X_test[cols_valid].copy()
            # ‚Äî‚Äî‚Äî Fin de sanitizaci√≥n ‚Äî‚Äî‚Äî

            # ‚Äî‚Äî‚Äî 1.1.1 Saneamiento y filtro de columnas ‚Äî‚Äî‚Äî
            #import re
            #def clean_name(s):
            #    # id√©ntico a tu celda 9.x
            #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
            #    t = re.sub(r'_+', '_', t)
            #    return t.strip('_')

            # Limpio cada nombre y luego lo filtro
            #cols = [ clean_name(c) for c in raw_cols ]
            #cols_valid = [c for c in cols if c in X_test.columns]
            #missing = set(cols) - set(cols_valid)
            #if missing:
            #    print(f"[WARNING] SVR omitido estas columnas por no existir en X_test: {sorted(missing)}")

            # Ahora ya puedo indexar con total seguridad
            #X_test_sel = X_test[cols_valid].copy()
            y_true     = Y_test.values.ravel()
            X_test_scaled = sx.transform(X_test_sel)
            y_pred     = sy.inverse_transform(
                            model.predict(X_test_scaled).reshape(-1,1)
                        ).ravel()
            # ‚Äî‚Äî‚Äî Fin saneamiento SVR ‚Äî‚Äî‚Äî

            # ‚Äî‚Äî‚Äî 1.1 Normalizar payload
            #payload_raw        = OPT_MODELS[('svr', sel_method, engine)]
            #p                  = _normalize_payload(payload_raw)

            #model, sx, sy, cols = p['model'], p['sx'], p['sy'], p['cols']
            #score, metric      = p['score'], p['metric']
            #best_params        = p['best_params']
            # ‚Äî‚Äî‚Äî Fin normalizaci√≥n

            # ‚Äî‚Äî‚Äî Unificar saneamiento de columnas seg√∫n entrenamiento ‚Äî‚Äî‚Äî
            #import re
            #def clean_name(s):
            #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
            #    t = re.sub(r'_+', '_', t)
            #    return t.strip('_')

            #cols = [ clean_name(c) for c in cols ]
            # ‚Äî‚Äî‚Äî Fin unificaci√≥n ‚Äî‚Äî‚Äî

            # Preparar datos de prueba
            #X_test_sel = X_test[cols].copy()
            #y_true = Y_test.values.ravel()
            #X_test_scaled = sx.transform(X_test_sel)
            #y_pred = sy.inverse_transform(model.predict(X_test_scaled).reshape(-1,1)).ravel()

            # C√°lculo de residuos y estad√≠sticas
            residuals = y_true - y_pred
            mean_res = float(np.mean(residuals))
            std_res = float(np.std(residuals))
            skew_res = float(skew(residuals))
            kurt_res = float(kurtosis(residuals))
            q25, q50, q75 = [float(x) for x in np.quantile(residuals, [0.25, 0.5, 0.75])]

            # Gr√°fica Predicho vs Real
            fig1, ax1 = plt.subplots(figsize=(6,4))
            ax1.scatter(y_true, y_pred, alpha=0.6)
            ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
            ax1.set_xlabel("Y real")
            ax1.set_ylabel("Y predicho")
            ax1.set_title(f"SVR Optimizado (Mejor: {sel_method}-{engine}) Predicho vs Real")
            self.sections.append((
                f"### SVR Optimizado: Predicho vs Real ({sel_method}-{engine})", fig1
            ))

            # Gr√°fica Residuos
            fig2, ax2 = plt.subplots(figsize=(6,4))
            ax2.scatter(y_pred, residuals, alpha=0.6)
            ax2.axhline(0, color='r', linestyle='--', lw=2)
            ax2.set_xlabel("Y predicho")
            ax2.set_ylabel("Residuo")
            ax2.set_title(f"SVR Optimizado (Mejor) Residuos ({sel_method}-{engine})")
            self.sections.append((
                f"### SVR Optimizado: Residuos ({sel_method}-{engine})", fig2
            ))

            # Tabla de estad√≠sticas de residuos
            df_stats = pd.DataFrame({
                'M√©trica': ['Media', 'Desviaci√≥n', 'Skew', 'Kurtosis', '25%', '50%', '75%'],
                'Valor': [mean_res, std_res, skew_res, kurt_res, q25, q50, q75]
            })
            self.sections.append((
                f"### SVR Optimizado: Estad√≠sticas de Residuos ({sel_method}-{engine})", df_stats
            ))

            # An√°lisis generativo de calidad de ajuste
            prompt2 = (
                f"Para el mejor modelo SVR optimizado con selecci√≥n {sel_method} y motor {engine}, "
                f"tienes los siguientes datos:\n"
                f"- Rango Y real: [{float(y_true.min()):.4f}, {float(y_true.max()):.4f}]\n"
                f"- Rango Y pred: [{float(y_pred.min()):.4f}, {float(y_pred.max()):.4f}]\n"
                f"- Estad√≠sticas residuos: media={mean_res:.4f}, std={std_res:.4f}, skew={skew_res:.4f}, kurtosis={kurt_res:.4f}, "
                f"quantiles 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}.\n\n"
                "1. Analiza la calidad del ajuste bas√°ndote en la gr√°fica Predicho vs Real y la de residuos.\n"
                "2. Comenta sobre sesgos sistem√°ticos, heterocedasticidad y normalidad de errores.\n"
                "3. Ofrece recomendaciones para mejorar el fit si hay problemas detectados."
            )
            analysis2 = call_openai_explanation(prompt2)
            self.sections.append((
                "### SVR Optimizado: An√°lisis Calidad Ajuste", analysis2
            ))
            # ---- Fin bloque 1 ----

            # --- 2. Importancia Relativa de Hiperpar√°metros ---
            import seaborn as sns
            # 2.1 Heatmap Score vs Best_C y Best_epsilon
            heat = df_summary.pivot(index='Best_C', columns='Best_epsilon', values='Score')
            fig_heat, ax_heat = plt.subplots(figsize=(6,5))
            sns.heatmap(heat, annot=True, fmt='.4f', ax=ax_heat)
            ax_heat.set_title('SVR Optimizado: Heatmap Score vs C y Œµ')
            self.sections.append((
                '### SVR Optimizado: Heatmap Score vs C y Œµ', fig_heat
            ))

            # 2.2 Sensibilidad ¬±10%
            sens = []
            for rec in summary_records:
                for param in ['C','epsilon']:
                    base = rec[f'Best_{param}']
                    if base is None: continue
                    for factor,label in [(1.1,'+10%'),(0.9,'-10%')]:
                        sens.append({
                            'Par√°metro':param,
                            'Cambio':label,
                            '% Score':rec['Score']*(factor-1)*100,
                            'Selecci√≥n X':rec['Selecci√≥n X'],
                            'Motor':rec['Motor']
                        })
            df_sens = pd.DataFrame(sens)
            fig_sens, ax_sens = plt.subplots(figsize=(6,4))
            sns.barplot(data=df_sens, x='% Score', y='Par√°metro', hue='Cambio', ax=ax_sens)
            ax_sens.set_title('SVR Opt: Sensibilidad Score ¬±10%')
            self.sections.append((
                '### SVR Optimizado: Sensibilidad del Score', fig_sens
            ))

            # 2.3 An√°lisis IA de Importancia
            def call_openai_explanation(prompt, model='gpt-4'):
                resp = _client.chat.completions.create(
                    model=model,
                    messages=[
                        {'role':'system','content':'Eres un experto en an√°lisis de hiperpar√°metros de ML.'},
                        {'role':'user','content':prompt}
                    ],
                    temperature=TEMPERATURE_VAL,
                    max_tokens=MAX_EXPLANATION_TOKENS
                )
                return resp.choices[0].message.content.strip()

            lines = [f"{r['Par√°metro']} {r['Cambio']} => {r['% Score']:.2f}%" for r in sens]
            prompt_param = (
                "Sensibilidad de Score al ¬±10% en C y Œµ:\n" + "\n".join(lines) +
                "\n\nExplica qu√© hiperpar√°metro impulsa m√°s mejora y por qu√©, y sugiere focos de tuning."    )
            print("[DEBUG] 12.6. Llamando IA importancia hiperpar√°metros")
            analysis_hp = call_openai_explanation(prompt_param)
            self.sections.append((
                '### SVR Optimizado: IA Importancia Hiperpar√°metros', analysis_hp
            ))
            # ---- Fin bloque 2 ----

            # --- 3. Distribuci√≥n de M√©tricas en Validaci√≥n Cruzada ---
            from sklearn.model_selection import cross_validate
            import seaborn as sns
            print("[DEBUG] 12.7. Calculando distribuci√≥n de m√©tricas CV para el mejor modelo optimizado")

            # 3. Identificar mejor modelo optimizado
            best_rec       = max(summary_records, key=lambda x: x['Score'])
            sel_method_cv, engine_cv = best_rec['Selecci√≥n X'], best_rec['Motor']

            # --- Normalizar extracci√≥n de payload ---
            payload_raw_cv = OPT_MODELS[('svr', sel_method_cv, engine_cv)]
            p_cv           = _normalize_payload(payload_raw_cv)
            model_cv, sx_cv, sy_cv, cols_cv = (
                p_cv['model'], p_cv['sx'], p_cv['sy'], p_cv['cols']
            )
            # ----------------------------------------

            # Preparar datos de entrenamiento escalados
            X_cv = X_train[cols_cv].copy()
            y_cv = Y_train.values.ravel()
            X_cv_scaled = sx_cv.transform(X_cv)

            # Cross-validate con m√∫ltiples m√©tricas
            cv_results = cross_validate(
                model_cv, X_cv_scaled, y_cv,
                cv=5,
                scoring={
                    'r2':'r2',
                    'neg_mse':'neg_mean_squared_error',
                    'neg_mae':'neg_mean_absolute_error'
                },
                return_train_score=False
            )

            # Procesar resultados
            r2_scores   = cv_results['test_r2']
            mse_scores  = [-v for v in cv_results['test_neg_mse']]
            mae_scores  = [-v for v in cv_results['test_neg_mae']]
            rmse_scores = np.sqrt(mse_scores)

            df_cv = pd.DataFrame({
                'R2': r2_scores,
                'MSE': mse_scores,
                'MAE': mae_scores,
                'RMSE': rmse_scores
            })

            # 3.1 Boxplot de m√©tricas por fold
            fig_cv, ax_cv = plt.subplots(figsize=(6, 4))
            sns.boxplot(data=df_cv, ax=ax_cv)
            ax_cv.set_title('SVR Optimizado: Distribuci√≥n de M√©tricas CV')
            self.sections.append((
                '### SVR Optimizado: Distribuci√≥n de M√©tricas CV', fig_cv
            ))

            # 3.2 Tabla con media ¬± desviaci√≥n
            stats_cv = df_cv.agg(['mean', 'std']).T.reset_index().rename(columns={
                'index':'M√©trica', 'mean':'Media', 'std':'Desviaci√≥n'
            })
            self.sections.append((
                '### SVR Optimizado: Estad√≠sticas CV por Fold', stats_cv
            ))

            # 3.3 An√°lisis Generativo IA de estabilidad
            prompt_cv = (
                f"Valores CV por fold (R2: {r2_scores.tolist()}, MAE: {mae_scores}, RMSE: {rmse_scores}).\n"
                "¬øQu√© nos dice la dispersi√≥n sobre la estabilidad del modelo?"
            )
            print("[DEBUG] 12.8. Llamando IA para estabilidad en CV")
            analysis_cv = call_openai_explanation(prompt_cv)
            self.sections.append((
                '### SVR Optimizado: An√°lisis Estabilidad CV', analysis_cv
            ))
            # ---- Fin bloque 3 ----

            # --- 4. Secci√≥n Calidad Ajuste Mejor Modelo Optimizado SVR ---
            # --- 4.1. Curvas de Aprendizaje y Validaci√≥n para SVR Optimizado ---
            from sklearn.model_selection import learning_curve, validation_curve
            print("[DEBUG] 12.9. Calculando curvas de aprendizaje y validaci√≥n para SVR optimizado")

            # 4.1 Seleccionar el mejor payload para curvas de aprendizaje
            best_rec       = max(summary_records, key=lambda x: x['Score'])
            sel_method, engine = best_rec['Selecci√≥n X'], best_rec['Motor']

            # --- Normalizamos la extracci√≥n del payload ---
            payload_raw    = OPT_MODELS[('svr', sel_method, engine)]
            p              = _normalize_payload(payload_raw)
            model, sx, sy, cols = p['model'], p['sx'], p['sy'], p['cols']
            # -----------------------------------------------

            # Preparar datos de entrenamiento
            X_train_sel = X_train[cols].copy()
            y_train = Y_train.values.ravel()
            X_train_scaled = sx.transform(X_train_sel)

            # Curva de aprendizaje (R¬≤)
            train_sizes, train_scores, val_scores = learning_curve(
                model, X_train_scaled, y_train,
                cv=3, scoring='r2', train_sizes=np.linspace(0.1, 1.0, 5), n_jobs=-1
            )
            train_mean = np.mean(train_scores, axis=1)
            val_mean = np.mean(val_scores, axis=1)
            fig_lc, ax_lc = plt.subplots(figsize=(6, 4))
            ax_lc.plot(train_sizes, train_mean, 'o-', label='Train R¬≤')
            ax_lc.plot(train_sizes, val_mean, 'o-', label='CV R¬≤')
            ax_lc.set_title('Curva de Aprendizaje SVR Optimizado')
            ax_lc.set_xlabel('Tama√±o del set de entrenamiento')
            ax_lc.set_ylabel('R¬≤')
            ax_lc.legend()
            self.sections.append((
                '### SVR Optimizado: Curva de Aprendizaje', fig_lc
            ))

            # --- 4.2. Curva de validaci√≥n para hiperpar√°metro C
            param_range_C = np.logspace(-1, 2, 5)
            train_scores_C, val_scores_C = validation_curve(
                model, X_train_scaled, y_train,
                param_name='C', param_range=param_range_C,
                cv=3, scoring='r2', n_jobs=-1
            )
            fig_vc_C, ax_vc_C = plt.subplots(figsize=(6, 4))
            ax_vc_C.plot(param_range_C, np.mean(train_scores_C, axis=1), 'o-', label='Train R¬≤')
            ax_vc_C.plot(param_range_C, np.mean(val_scores_C, axis=1), 'o-', label='CV R¬≤')
            ax_vc_C.set_xscale('log')
            ax_vc_C.set_title('Curva de Validaci√≥n: C')
            ax_vc_C.set_xlabel('C')
            ax_vc_C.set_ylabel('R¬≤')
            ax_vc_C.legend()
            self.sections.append((
                '### SVR Optimizado: Curva de Validaci√≥n C', fig_vc_C
            ))

            # --- 4.3. Curva de validaci√≥n para hiperpar√°metro epsilon
            param_range_e = np.logspace(-2, 0, 5)
            train_scores_e, val_scores_e = validation_curve(
                model, X_train_scaled, y_train,
                param_name='epsilon', param_range=param_range_e,
                cv=3, scoring='r2', n_jobs=-1
            )
            fig_vc_e, ax_vc_e = plt.subplots(figsize=(6, 4))
            ax_vc_e.plot(param_range_e, np.mean(train_scores_e, axis=1), 'o-', label='Train R¬≤')
            ax_vc_e.plot(param_range_e, np.mean(val_scores_e, axis=1), 'o-', label='CV R¬≤')
            ax_vc_e.set_xscale('log')
            ax_vc_e.set_title('Curva de Validaci√≥n: Epsilon')
            ax_vc_e.set_xlabel('Epsilon')
            ax_vc_e.set_ylabel('R¬≤')
            ax_vc_e.legend()
            self.sections.append((
                '### SVR Optimizado: Curva de Validaci√≥n Epsilon', fig_vc_e
            ))

            # --- 4.4. Interpretaci√≥n IA de las Curvas de Aprendizaje y Validaci√≥n ---
            # Extraemos estad√≠sticas para el prompt
            lc_train = train_mean.tolist()
            lc_val   = val_mean.tolist()
            vc_C_train = np.mean(train_scores_C, axis=1).tolist()
            vc_C_val   = np.mean(val_scores_C, axis=1).tolist()
            vc_e_train = np.mean(train_scores_e, axis=1).tolist()
            vc_e_val   = np.mean(val_scores_e, axis=1).tolist()
            sizes = train_sizes.tolist()
            C_vals = param_range_C.tolist()
            e_vals = param_range_e.tolist()

            prompt_curvas = (
                "He generado para el SVR optimizado las siguientes curvas:\n"
                f"- Curva de Aprendizaje (R¬≤): tama√±os={sizes}, train={lc_train}, CV={lc_val}\n"
                f"- Curva de Validaci√≥n para C (R¬≤): C={C_vals}, train={vc_C_train}, CV={vc_C_val}\n"
                f"- Curva de Validaci√≥n para Œµ (R¬≤): Œµ={e_vals}, train={vc_e_train}, CV={vc_e_val}\n\n"
                "1. Interpreta cada curva: ¬øqu√© nos dice sobre sesgo (under-/overfitting) y varianza?\n"
                "2. Se√±ala si hay se√±ales de under-/overfitting o alta varianza seg√∫n cada gr√°fica.\n"
                "3. Concluye recomendaciones generales para mejorar el aprendizaje (por ejemplo, ajustar C, Œµ, m√°s datos, regularizaci√≥n, etc.)."
            )

            print("[DEBUG] 12.10. Llamando a OpenAI para interpretaci√≥n IA de curvas")
            analisis_curvas = call_openai_explanation(prompt_curvas)
            self.sections.append((
                "### SVR Optimizado: Interpretaci√≥n IA de Curvas",
                analisis_curvas
            ))
            # ---- Fin bloque 4 ----

            # --- 5. Curvas de Calibraci√≥n y Predicci√≥n de Intervalos ---
            from sklearn.calibration import calibration_curve
            print("[DEBUG] 12.11. Calculando curva de calibraci√≥n y predicci√≥n de intervalos para el mejor modelo optimizado SVR")

            # Identificar mejor modelo optimizado
            best_rec_ci       = max(summary_records, key=lambda x: x['Score'])
            sel_method_ci, engine_ci = best_rec_ci['Selecci√≥n X'], best_rec_ci['Motor']

            # --- Normalizamos la extracci√≥n del payload ---
            payload_raw_ci   = OPT_MODELS[('svr', sel_method_ci, engine_ci)]
            p_ci             = _normalize_payload(payload_raw_ci)
            model_ci, sx_ci, sy_ci, cols_ci = p_ci['model'], p_ci['sx'], p_ci['sy'], p_ci['cols']
            # -----------------------------------------------

            # Preparar datos de prueba
            X_test_ci = X_test[cols_ci].copy()
            y_true_ci = Y_test.values.ravel()
            X_test_scaled_ci = sx_ci.transform(X_test_ci)

            # ‚îÄ‚îÄ Predicci√≥n raw ‚îÄ‚îÄ
            y_pred_raw_ci = model_ci.predict(X_test_scaled_ci)

            # ‚îÄ‚îÄ Desescalado (si tienes sy_ci) ‚îÄ‚îÄ
            if sy_ci is not None:
                # sy_ci es tu StandardScaler para y
                y_pred_ci = sy_ci.inverse_transform(
                    y_pred_raw_ci.reshape(-1,1)
                ).ravel()
            else:
                y_pred_ci = y_pred_raw_ci.ravel()

            # 5.1 Curva de calibraci√≥n (binned reliability plot para regresi√≥n)
            import pandas as _pd
            bins = 10
            print("[DEBUG] 12.12. Calculando curva de calibraci√≥n manual para regresi√≥n SVR optimizado")
            df_cal = _pd.DataFrame({'y_pred': y_pred_ci, 'y_true': y_true_ci})
            # Crear bins seg√∫n cuantiles en predicci√≥n
            try:
                df_cal['bin'] = _pd.qcut(df_cal['y_pred'], q=bins, duplicates='drop')
            except Exception:
                df_cal['bin'] = _pd.cut(df_cal['y_pred'], bins=bins)
            # Agrupar para obtener promedio predicho vs observado
            #grp = df_cal.groupby('bin').agg({'y_pred': 'mean', 'y_true': 'mean'})
            grp = df_cal.groupby('bin', observed=True).agg({'y_pred': 'mean', 'y_true': 'mean'})
            prob_pred = grp['y_pred'].values
            prob_true = grp['y_true'].values
            fig_cal, ax_cal = plt.subplots(figsize=(6, 4))
            ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2)
            ax_cal.plot([prob_pred.min(), prob_pred.max()], [prob_pred.min(), prob_pred.max()], 'k--')
            ax_cal.set_xlabel('Predicci√≥n promedio en bin')
            ax_cal.set_ylabel('Valor real promedio')
            ax_cal.set_title('SVR Optimizado: Curva de Calibraci√≥n')
            self.sections.append((
                '### SVR Optimizado: Curva de Calibraci√≥n', fig_cal
            ))

            # 5.2 Intervalos de predicci√≥n ¬±1 STD de residuos
            residuals_ci = y_true_ci - y_pred_ci
            std_res_ci = np.std(residuals_ci)
            upper = y_pred_ci + std_res_ci
            lower = y_pred_ci - std_res_ci
            fig_int, ax_int = plt.subplots(figsize=(6, 4))
            ax_int.plot(y_true_ci, label='Y real')
            ax_int.plot(y_pred_ci, label='Predicci√≥n')
            ax_int.fill_between(range(len(y_pred_ci)), lower, upper, alpha=0.3, label='¬±1 STD residuo')
            ax_int.set_xlabel('√çndice de muestra')
            ax_int.set_ylabel('Valor')
            ax_int.set_title('SVR Optimizado: Intervalos de Predicci√≥n')
            ax_int.legend()
            self.sections.append((
                '### SVR Optimizado: Intervalos de Predicci√≥n', fig_int
            ))

            # 5.3 An√°lisis Generativo IA de incertidumbre y calibraci√≥n
            prompt_ci = (
                f"Curva de calibraci√≥n (prob_pred: {prob_pred.tolist()}, prob_true: {prob_true.tolist()}) y "
                f"intervalos de predicci√≥n ¬±1 STD (std_res={std_res_ci:.4f}).\n"
                "1. ¬øSon fiables los intervalos de incertidumbre?"
                "2. ¬øObservas infravaloraci√≥n de errores altos?"
            )
            print("[DEBUG] 12.13. Llamando IA para an√°lisis de incertidumbre y calibraci√≥n SVR")
            analysis_ci = call_openai_explanation(prompt_ci)
            self.sections.append((
                '### SVR Optimizado: An√°lisis de Incertidumbre y Calibraci√≥n', analysis_ci
            ))
            # ---- Fin bloque 5 ----

            # --- Secci√≥n 6: Resumen Ejecutivo y Road-Map de Siguientes Pasos ---
            # 6.1. Bloque Markdown con puntos clave para stakeholders
            summary_md = (
                "**Puntos Clave:**\n"
                f"- **Mejor combinaci√≥n:** {sel_method_ci}-{engine_ci} con score={best_rec_ci['Score']:.4f}.\n"
                f"- **Grado de robustez:** Variabilidad CV={val_mean.std():.4f}, residuos (std={std_res_ci:.4f}).\n"
                f"- **Puntos d√©biles:** identificar picos de error y alta varianza en ciertos rangos.\n"
                f"- **Recomendaciones inmediatas:** ampliar CV, explorar HalvingGridSearchCV, recolectar m√°s datos."
            )
            self.sections.append((
                '### Resumen Ejecutivo y Road-Map', summary_md
            ))

            # 6.2. An√°lisis Generativo IA para desarrollar cada punto clave y generar resumen ejecutivo
            prompt_exec = (
                "Eres un investigador cient√≠fico para el Instituto de Procesos Sostenibles de la Universidad de Valladolid. "
                "A continuaci√≥n se presentan los puntos clave de la optimizaci√≥n SVR:\n"
                f"{summary_md}\n"
                "Desarrolla un an√°lisis detallado en p√°rrafos separados para cada punto (Mejor combinaci√≥n, Grado de robustez, Puntos d√©biles, Recomendaciones inmediatas), "
                "y finaliza con un resumen ejecutivo de 3 p√°rrafos resumiendo hallazgos y pr√≥ximos pasos para los stakeholders."
            )
            print("[DEBUG] 12.14. Llamando IA para Resumen Ejecutivo y Road-Map SVR optimizaci√≥n")
            analysis_exec = call_openai_explanation(prompt_exec)
            self.sections.append((
                '### Resumen Ejecutivo IA', analysis_exec
            ))

        except Exception as e:
            self.sections.append((
                "### ‚ö†Ô∏è Error en secci√≥n Optimizaci√≥n SVR",
                f"Se produjo un error al generar el resumen de m√©todos y motores: {e}"
            ))

        # =============================================================================
        # 13. Optimizaci√≥n Modelo Optimizaci√≥n NN
        # =============================================================================
        try:
            print("[DEBUG] 13.1. Iniciando secci√≥n Optimizaci√≥n NN: Resumen de m√©todos y motores")
            # Verificaci√≥n previa: usamos OPT_MODELS guardado en la celda 9.2
            if 'OPT_MODELS' in globals() and isinstance(OPT_MODELS, dict):
                valid_engines = {'randomsearch', 'bayesianoptimization', 'hyperband', 'optuna'}
                nn_entries = {
                    k: v for k, v in OPT_MODELS.items()
                    if (isinstance(k, tuple) and k[0] == 'nn' and isinstance(v, dict) and k[2] in valid_engines)
                }
            else:
                raise RuntimeError(
                    "No se encontr√≥ la variable global OPT_MODELS con resultados de optimizaci√≥n NN. "
                    "Aseg√∫rate de haber ejecutado la Celda 9.2 y de que OPT_MODELS contenga los payloads optimizados."
                )

            import pickle
            import pandas as pd
            import numpy as np
            import matplotlib.pyplot as plt
            import seaborn as sns
            from scipy.stats import skew, kurtosis
            from tensorflow.keras.models import load_model
            import tensorflow as tf
            from tensorflow import keras
            from tensorflow.keras import layers as keras_layers
            from scikeras.wrappers import KerasRegressor
            from sklearn.model_selection import learning_curve

            #import re

            #def _clean_col(name):
            #    # sustituye [, ], <, >, % por _
            #    return re.sub(r'[\[\]<>%]', '_', str(name))

            # ‚Äî‚Äî‚Äî 1.1.1 Sanitizaci√≥n y filtro unificado de columnas ‚Äî‚Äî‚Äî
            #sanitized_cols = [sanitize_name(c) for c in raw_cols]
            #missing = set(sanitized_cols) - set(X_test.columns)
            #if missing:
            #    print(f"[WARNING] SVR omitido estas columnas por no existir en X_test: {sorted(missing)}")
            #cols_valid = [c for c in sanitized_cols if c in X_test.columns]

            #X_test_sel = X_test[cols_valid].copy()

            # Par√°metros de b√∫squeda usados en cada motor (para documentar)
            param_configs = {
                'randomsearch': { 'layers': 'hp.Int("layers", 1, max_layers)', 'units': 'hp.Int("units_i", min_units, max_units)', 'dropout': 'hp.Float("dropout_i", 0.0, max_dropout)' },
                'bayesianoptimization': { 'layers': 'hp.Int("layers", 1, max_layers)', 'units': 'hp.Int("units_i", min_units, max_units)', 'dropout': 'hp.Float("dropout_i", 0.0, max_dropout)' },
                'hyperband': { 'layers': 'hp.Int("layers", 1, max_layers)', 'units': 'hp.Int("units_i", min_units, max_units)', 'dropout': 'hp.Float("dropout_i", 0.0, max_dropout)' },
                'optuna': { 'layers': 'suggest_int("n_layers", 1, max_layers)', 'units': 'suggest_int("n_units_l{i}", min_units, max_units)', 'dropout': 'suggest_float("dropout_l{i}", 0.0, max_dropout)' }
            }

            summary_records = []
            # Iterar cada combinaci√≥n m√©todo/motor
            for (_, sel_method, engine), payload in nn_entries.items():
                print(f"[DEBUG] 13.2. Agregando registro resumen NN: {sel_method} / {engine}")

                # 1) m√©tricas
                score = payload.get('score')
                metric = payload.get('metric')

                # Par√°metros de b√∫squeda documentados
                config_used = param_configs.get(engine, {})

                # 3) hiperpar√°metros √≥ptimos
                if engine in ("randomsearch","bayesianoptimization","hyperband"):
                    best_params = {
                        "layers":  payload.get("layers"),
                        "neurons": payload.get("neurons"),
                        "dropout": payload.get("dropout"),
                        "epochs":  payload.get("epochs")
                    }
                else:  # optuna
                    best_params = {
                        "layers":  payload.get("n_layers"),
                        "neurons": payload.get("n_units_l0"),
                        "dropout": payload.get("dropout_l0"),
                        "epochs":  payload.get("epochs")
                    }

                # Construir fila de resumen
                row = {
                    'Selecci√≥n X': sel_method,
                    'Motor': engine,
                    'M√©trica': metric,
                    'Score': score
                }
                # A√±adir configuraci√≥n de b√∫squeda al row
                for k, v in config_used.items():
                    row[f'Config_{k}'] = v
                # A√±adir mejores hiperpar√°metros al row
                for k, v in best_params.items():
                    row[f'Best_{k}'] = v

                summary_records.append(row)

            # Crear DataFrame de resumen y reordenar columnas
            df_summary_nn = pd.DataFrame(summary_records)
            desired_cols = [
                'Selecci√≥n X', 'Motor', 'M√©trica', 'Score',
                'Config_layers', 'Config_units', 'Config_dropout',
                'Best_layers', 'Best_neurons', 'Best_dropout', 'Best_epochs'
            ]
            available_cols = [c for c in desired_cols if c in df_summary_nn.columns]
            df_to_show_nn = df_summary_nn[available_cols] if available_cols else df_summary_nn

            # A√±adir secci√≥n de tabla al informe
            self.sections.append((
                "### NN Optimizaci√≥n: Resumen de M√©todos y Motores",
                df_to_show_nn.reset_index(drop=True)
            ))

            # ‚Äî‚Äî‚Äî‚Äî‚Äî Preselecci√≥n global del mejor modelo NN ‚Äî‚Äî‚Äî‚Äî‚Äî
            if df_summary_nn['M√©trica'].iloc[0] == 'R2':
                idx_best_nn = df_summary_nn['Score'].idxmax()
            else:
                idx_best_nn = df_summary_nn['Score'].idxmin()

            best_entry_nn = df_summary_nn.loc[idx_best_nn]
            sel_method_nn = best_entry_nn['Selecci√≥n X']
            engine_nn     = best_entry_nn['Motor']

            payload_raw = OPT_MODELS[('nn', sel_method, engine)]
            p = _normalize_payload(payload_raw)
            model        = p['model']
            sx, sy, cols = p['sx'], p['sy'], p['cols']
            score, metric, best_params = p['score'], p['metric'], p['best_params']

            # Precargo payload_best para usar en todos los bloques
            payload_best = p    # ya tienes el payload ‚Äúnormalizado‚Äù en p, no necesitas nn_entries aqu√≠

            # --- 0. An√°lisis Generativo IA de Tabla de Resumen ---
            def call_openai_explanation(prompt: str, model="gpt-4"):
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un experto en optimizaci√≥n de redes neuronales. "
                                "Analiza los resultados y ofrece conclusiones detalladas." )},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS
                    )
                    return response.choices[0].message.content.strip()
                except Exception as e:
                    print(f"[DEBUG] ¬°Exception atrapada en Optimizaci√≥n NN!: {type(e).__name__}: {e}")
                    return f"[Error llamando a OpenAI: {e}]"

            # Construir prompt a partir de summary_records
            records_text = []
            for rec in summary_records:
                records_text.append(
                    f"M√©todo X: {rec['Selecci√≥n X']}, Motor: {rec['Motor']}, "
                    f"M√©trica: {rec['M√©trica']}, Score: {rec['Score']:.4f}, "
                    f"Config: layers={rec.get('Config_layers')}, units={rec.get('Config_units')}, dropout={rec.get('Config_dropout')}, "
                    f"Best: layers={rec.get('Best_layers')}, neurons={rec.get('Best_neurons')}, "
                    f"dropout={rec.get('Best_dropout')}, epochs={rec.get('Best_epochs')}"
                )
            prompt = (
                "He obtenido los siguientes resultados de optimizaci√≥n para la Red Neuronal:\n"
                + "\n".join(records_text)
                + "\n\n"
                + "1. Describe e interpreta cada combinaci√≥n m√©todo/motor.\n"
                + "2. Se√±ala cu√°l configuraci√≥n ofrece mejor desempe√±o y por qu√©.\n"
                + "3. Proporciona recomendaciones para futuros ajustes de HPO."
            )
            print("[DEBUG] 13.3. Llamando IA para an√°lisis generativo NN optimizaci√≥n")
            generative_analysis_nn = call_openai_explanation(prompt)
            self.sections.append((
                "### NN Optimizaci√≥n: An√°lisis Generativo",
                generative_analysis_nn
            ))
            # --- Fin Bloque 0 ---

            # --- 1. Curvas de Ajuste Real vs. Predicho y Residuos ---
            print("[DEBUG] 13.4. Entrando en Bloque 1: Curvas Predicho vs Real")
            from scipy.stats import skew, kurtosis
            # Seleccionar mejor configuraci√≥n seg√∫n Score
            if df_summary_nn.empty:
                raise RuntimeError("No hay registros de optimizaci√≥n NN para generar curvas.")
            # Definir criterio de ordenamiento: maximizar R2, minimizar errores
            if df_summary_nn['M√©trica'].iloc[0] == 'R2':
                idx_best = df_summary_nn['Score'].idxmax()
            else:
                idx_best = df_summary_nn['Score'].idxmin()
            best_row = df_summary_nn.loc[idx_best]
            sel_method = best_row['Selecci√≥n X']
            engine = best_row['Motor']

            # ‚Äî‚Äî‚Äî 1.1 Normalizar payload
            payload_raw   = OPT_MODELS[('nn', sel_method, engine)]
            p             = _normalize_payload(payload_raw)

            model         = p['model']
            sx, sy, cols  = p['sx'], p['sy'], p['cols']
            score, metric = p['score'], p['metric']
            best_params   = p['best_params']

            import tensorflow as tf  # necesario para custom_objects al cargar el modelo
            from tensorflow.keras.models import load_model

            # ‚Äî‚Äî‚Äî Sanitizaci√≥n unificada de columnas para NN ‚Äî‚Äî‚Äî
            # 1) Partimos de `cols` (payload['cols'])
            raw_cols_nn = cols  # o p['cols'] si lo extraes ah√≠ mismo

            # 2) Aplicamos `sanitize_name` a cada nombre
            sanitized_cols = [sanitize_name(c) for c in raw_cols_nn]

            # 3) Detectamos columnas faltantes en X_test
            missing = set(sanitized_cols) - set(X_test.columns)
            if missing:
                print(f"[WARNING] NN omitido estas columnas por no existir en X_test: {sorted(missing)}")

            # 4) Nos quedamos solo con las columnas v√°lidas
            cols_valid = [c for c in sanitized_cols if c in X_test.columns]

            # 5) Selecci√≥n segura de test y predicci√≥n
            X_test_sel    = X_test[cols_valid].copy()

            # Preparar datos de prueba
            # ‚Äî SANITIZACI√ìN DE cols antes de indexar X_test
            #cols_clean = [_clean_col(c) for c in cols]
            #X_test_sel = X_test[cols_clean].copy()
            #X_test_sel = X_test[cols].copy()
            y_true = Y_test.values.ravel()
            if sx is not None:
                X_test_scaled = sx.transform(X_test_sel)
            else:
                # No se encontr√≥ scaler, usar datos sin transformar
                X_test_scaled = X_test_sel.values
                raw_pred = model.predict(X_test_scaled).ravel()
            if sy is not None:
                # Aplicar inverse transform si existe scaler de salida
                y_pred = sy.inverse_transform(raw_pred.reshape(-1,1)).ravel()
            else:
                y_pred = raw_pred

            # Gr√°fica Predicho vs Real
            fig1, ax1 = plt.subplots(figsize=(6,4))
            ax1.scatter(y_true, y_pred, alpha=0.6)
            ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
            ax1.set_xlabel("Y real"); ax1.set_ylabel("Y predicho")
            ax1.set_title(f"NN Optimizado ({sel_method}-{engine}) Predicho vs Real")
            self.sections.append((
                f"### NN Optimizaci√≥n: Predicho vs Real ({sel_method}-{engine})", fig1
            ))

            # Gr√°fica Residuos
            residuals = y_true - y_pred
            fig2, ax2 = plt.subplots(figsize=(6,4))
            ax2.scatter(y_pred, residuals, alpha=0.6)
            ax2.axhline(0, color='r', linestyle='--', lw=2)
            ax2.set_xlabel("Y predicho"); ax2.set_ylabel("Residuo")
            ax2.set_title(f"NN Optimizado ({sel_method}-{engine}) Residuos")
            self.sections.append((
                f"### NN Optimizaci√≥n: Residuos ({sel_method}-{engine})", fig2
            ))

            # Tabla de estad√≠sticas de residuos
            stats_df = pd.DataFrame({
                'M√©trica': ['Media', 'Desviaci√≥n', 'Skew', 'Kurtosis', '25%', '50%', '75%'],
                'Valor': [residuals.mean(), residuals.std(), skew(residuals), kurtosis(residuals), *np.quantile(residuals, [0.25,0.5,0.75])]
            })
            self.sections.append((
                f"### NN Optimizaci√≥n: Estad√≠sticas de Residuos ({sel_method}-{engine})", stats_df
            ))

            # --- An√°lisis Generativo IA de Curvas de Ajuste (NN) ---
            # Construimos un √∫nico f-string multil√≠nea para asegurar que todo el texto llegue al modelo
            prompt_curvas = f"""
            Para el mejor modelo NN optimizado con selecci√≥n {sel_method} y motor {engine} tenemos los siguientes datos:
            - Rango Y real: [{float(y_true.min()):.4f}, {float(y_true.max()):.4f}]
            - Rango Y predicho: [{float(y_pred.min()):.4f}, {float(y_pred.max()):.4f}]
            - Estad√≠sticas de residuos:
              ‚Ä¢ media = {residuals.mean():.4f}
              ‚Ä¢ std   = {residuals.std():.4f}
              ‚Ä¢ skew  = {skew(residuals):.4f}
              ‚Ä¢ kurtosis = {kurtosis(residuals):.4f}
              ‚Ä¢ quantiles: 25%={float(np.quantile(residuals, 0.25)):.4f},
                          50%={float(np.quantile(residuals, 0.50)):.4f},
                          75%={float(np.quantile(residuals, 0.75)):.4f}

            1. Analiza detalladamente la gr√°fica Predicho vs Real: di si hay desviaciones sistem√°ticas, cu√°n cerca est√°n los puntos de la diagonal, y si observas heterocedasticidad o patrones claros.
            2. Analiza la gr√°fica de residuos: describe la dispersi√≥n, si hay colas pesadas o asimetr√≠as.
            3. Comenta sobre la normalidad de los errores y posibles fuentes de sesgo.
            4. Prop√≥n recomendaciones pr√°cticas para mejorar el ajuste (p. ej. refinar hiperpar√°metros, transformar variables, etc.).
            """
            analysis_curvas = call_openai_explanation(prompt_curvas)
            self.sections.append((
                "### NN Optimizaci√≥n: An√°lisis Curvas Ajuste", analysis_curvas
            ))
            # --- Fin bloque 1 ---

            # --- 2. Importancia Relativa de Hiperpar√°metros ---
            # 2.1 Heatmap Score vs Best_layers y Best_neurons
            heat_nn = df_summary_nn.pivot(index='Best_layers', columns='Best_neurons', values='Score')
            fig_heat_nn, ax_heat_nn = plt.subplots(figsize=(6,5))
            sns.heatmap(heat_nn, annot=True, fmt='.4f', ax=ax_heat_nn)
            ax_heat_nn.set_title('NN Optimizado: Heatmap Score vs Capas y Neuronas')
            self.sections.append((
                '### NN Optimizado: Heatmap Score vs Capas y Neuronas', fig_heat_nn
            ))

            # 2.2 Sensibilidad ¬±10%
            sens_nn = []
            for rec in summary_records:
                for param in ['layers','neurons']:
                    base = rec.get(f'Best_{param}')
                    if base is None: continue
                    for factor,label in [(1.1,'+10%'),(0.9,'-10%')]:
                        sens_nn.append({
                            'Par√°metro': param,
                            'Cambio': label,
                            '% Score': rec['Score'] * (factor - 1) * 100,
                            'Selecci√≥n X': rec['Selecci√≥n X'],
                            'Motor': rec['Motor']
                        })
            df_sens_nn = pd.DataFrame(sens_nn)
            fig_sens_nn, ax_sens_nn = plt.subplots(figsize=(6,4))
            sns.barplot(data=df_sens_nn, x='% Score', y='Par√°metro', hue='Cambio', ax=ax_sens_nn)
            ax_sens_nn.set_title('NN Opt: Sensibilidad Score ¬±10%')
            self.sections.append((
                '### NN Optimizado: Sensibilidad del Score', fig_sens_nn
            ))

            # 2.3 An√°lisis IA de Importancia Relativa
            lines_nn = [f"{r['Par√°metro']} {r['Cambio']} => {r['% Score']:.2f}%" for r in sens_nn]
            prompt_hp_nn = (
                "Sensibilidad de Score al ¬±10% en Capas y Neuronas:\n" +
                "\n".join(lines_nn) +
                "\n\nExplica qu√© hiperpar√°metro impulsa m√°s mejora y por qu√©, y sugiere focos de tuning futuros para la red neuronal."
            )
            print("[DEBUG] 13.5. Llamando IA importancia hiperpar√°metros NN")
            analysis_hp_nn = call_openai_explanation(prompt_hp_nn)
            self.sections.append((
                '### NN Optimizado: IA Importancia Hiperpar√°metros', analysis_hp_nn
            ))
            # --- Fin bloque 2 ---

            # --- 3. Distribuci√≥n de M√©tricas en Validaci√≥n Cruzada (manual para Keras NN) ---
            print("[DEBUG] 13.6. Calculando distribuci√≥n de m√©tricas CV para el mejor modelo NN optimizado (manual)")

            from sklearn.model_selection import KFold

            # Identificar mejor configuraci√≥n NN
            if df_summary_nn['M√©trica'].iloc[0] == 'R2':
                idx_best = df_summary_nn['Score'].idxmax()
            else:
                idx_best = df_summary_nn['Score'].idxmin()
            row_best = df_summary_nn.loc[idx_best]
            sel_method_cv, engine_cv = row_best['Selecci√≥n X'], row_best['Motor']

            # ‚Äî‚Äî‚Äî 1.1 Normalizar payload
            payload_raw = OPT_MODELS[('nn', sel_method, engine)]
            p           = _normalize_payload(payload_raw)

            model        = p['model']
            sx, sy, cols = p['sx'], p['sy'], p['cols']
            score        = p['score']
            metric       = p['metric']
            best_params  = p['best_params']

            # Cargar metadatos y mejor modelo
            payload_cv  = nn_entries[('nn', sel_method_cv, engine_cv)]
            best_params = {
                'layers':  payload_cv.get('layers')   or payload_cv.get('n_layers'),
                'neurons': payload_cv.get('neurons')  or payload_cv.get('n_units_l0'),
                'dropout': payload_cv.get('dropout')  or payload_cv.get('dropout_l0'),
                'epochs':  payload_cv.get('epochs')
            }

            # Preparar datos
            sx_cv, sy_cv, cols_cv = (
                payload_cv.get('sx'),
                payload_cv.get('sy'),
                payload_cv.get('cols'),
            )

            # ‚Äî‚Äî‚Äî Sanitizaci√≥n y filtro unificado de columnas para CV en NN ‚Äî‚Äî‚Äî
            # 1) Partimos de cols_cv (del payload normalizado)
            raw_cols_cv = cols_cv

            # 2) Aplicamos sanitize_name a cada nombre
            sanitized_cols_cv = [sanitize_name(c) for c in raw_cols_cv]

            # 3) Detectamos columnas faltantes en X_train
            missing_cv = set(sanitized_cols_cv) - set(X_train.columns)
            if missing_cv:
                print(f"[WARNING] NN omitido estas columnas en CV por no existir en X_train: {sorted(missing_cv)}")

            # 4) Nos quedamos solo con las que s√≠ existen
            cols_cv_valid = [c for c in sanitized_cols_cv if c in X_train.columns]

            # 5) Ahora indexamos sin NameError
            X_cv = X_train[cols_cv_valid].copy()
            y_cv = Y_train.values.ravel()
            X_cv_scaled = sx_cv.transform(X_cv.values) if sx_cv is not None else X_cv.values


            # ‚Äî SANITIZACI√ìN DE cols_cv antes de indexar X_train
            #cols_cv_clean = [_clean_col(c) for c in cols_cv]
            #X_cv = X_train[cols_cv_clean].copy()
            #X_cv = X_train[cols_cv].copy()
            #y_cv = Y_train.values.ravel()
            #X_cv_scaled = sx_cv.transform(X_cv) if sx_cv is not None else X_cv.values

            # Manual K-Fold CV
            kf = KFold(n_splits=5, shuffle=True, random_state=42)
            r2_scores, mse_scores, mae_scores = [], [], []
            for train_idx, val_idx in kf.split(X_cv_scaled):
                X_tr, X_val = X_cv_scaled[train_idx], X_cv_scaled[val_idx]
                y_tr, y_val = y_cv[train_idx], y_cv[val_idx]
                # Reconstruir modelo con mejores hiperpar√°metros
                model_cv_fold = keras.Sequential()
                model_cv_fold.add(layers.Input(shape=(X_tr.shape[1],)))
                for _ in range(int(best_params['layers'])):
                    model_cv_fold.add(layers.Dense(int(best_params['neurons']), activation='relu'))
                    model_cv_fold.add(layers.Dropout(float(best_params['dropout'])))
                model_cv_fold.add(layers.Dense(1))
                model_cv_fold.compile(optimizer='adam', loss='mse')
                model_cv_fold.fit(X_tr, y_tr, epochs=int(best_params['epochs']), verbose=0)
                preds = model_cv_fold.predict(X_val).ravel()
                r2_scores.append(r2_score(y_val, preds))
                mse_scores.append(mean_squared_error(y_val, preds))
                mae_scores.append(mean_absolute_error(y_val, preds))
            rmse_scores = [np.sqrt(m) for m in mse_scores]

            # DataFrame de resultados CV
            import pandas as pd
            cv_df_nn = pd.DataFrame({'R2': r2_scores, 'MSE': mse_scores, 'MAE': mae_scores, 'RMSE': rmse_scores})

            # 3.1 Boxplot m√©tricas por fold
            fig_cv_nn, ax_cv_nn = plt.subplots(figsize=(6,4))
            sns.boxplot(data=cv_df_nn, ax=ax_cv_nn)
            ax_cv_nn.set_title('NN Optimizado: Distribuci√≥n de M√©tricas CV')
            self.sections.append((
                '### NN Optimizado: Distribuci√≥n de M√©tricas CV', fig_cv_nn
            ))
            # 3.2 Tabla media ¬± desviaci√≥n
            stats_cv_nn = cv_df_nn.agg(['mean','std']).T.reset_index().rename(columns={'index':'M√©trica','mean':'Media','std':'Desviaci√≥n'})
            self.sections.append((
                '### NN Optimizado: Estad√≠sticas CV por Fold', stats_cv_nn
            ))
            # 3.3 An√°lisis IA de estabilidad
            import numpy as np
            # Generar prompt con m√°ximo contexto
            hyperparams = best_params
            # Estad√≠sticas agregadas para IA
            data_summary = (
                f"- R2: media={cv_df_nn['R2'].mean():.4f}, std={cv_df_nn['R2'].std():.4f}\n"
                f"- MSE: media={cv_df_nn['MSE'].mean():.4f}, std={cv_df_nn['MSE'].std():.4f}\n"
                f"- MAE: media={cv_df_nn['MAE'].mean():.4f}, std={cv_df_nn['MAE'].std():.4f}\n"
                f"- RMSE: media={cv_df_nn['RMSE'].mean():.4f}, std={cv_df_nn['RMSE'].std():.4f}"
            )
            prompt_cv_nn = (
                f"Para la red neuronal optimizada con m√©todo '{sel_method_cv}' y motor '{engine_cv}', "
                f"se realiz√≥ una validaci√≥n cruzada de 5 folds obteniendo los siguientes scores por fold:\n"
                f"- R2: {r2_scores}\n"
                f"- MSE: {mse_scores}\n"
                f"- MAE: {mae_scores}\n"
                f"- RMSE: {rmse_scores}\n\n"
                f"Resumen estad√≠stico por m√©trica:\n{data_summary}\n\n"
                "Los hiperpar√°metros √≥ptimos usados fueron:\n"
                f"- Capas: {hyperparams['layers']}\n"
                f"- Neuronas: {hyperparams['neurons']}\n"
                f"- Dropout: {hyperparams['dropout']}\n"
                f"- √âpocas: {hyperparams['epochs']}\n\n"
                "1. Analiza detalladamente la dispersi√≥n de cada m√©trica por fold y comenta sobre la robustez del modelo.\n"
                "2. Identifica posibles fuentes de variabilidad y su impacto en la generalizaci√≥n.\n"
                "3. Sugiere acciones concretas para mejorar la estabilidad del modelo "
                "(p.ej., regularizaci√≥n adicional, recopilaci√≥n de m√°s datos, ajustes de HPO, etc.)."
            )
            print("[DEBUG] 13.7. Llamando IA para estabilidad en CV NN (manual)")

            analysis_cv_nn = call_openai_explanation(prompt_cv_nn)
            self.sections.append((
                '### NN Optimizado: An√°lisis Estabilidad CV', analysis_cv_nn
            ))
            # --- Fin bloque 3 ---

            # --- 4. Curvas de Aprendizaje y Validaci√≥n para NN Optimizado ---
            print("[DEBUG] 13.8. Bloque 4: Curvas de Aprendizaje para NN optimizado sin wrapper SKLearn")

            import pickle, numpy as np
            from sklearn.model_selection import KFold

            # --- normalizo payload para extraer modelo y scalers ---
            payload_raw = OPT_MODELS[('nn', sel_method_nn, engine_nn)]
            p           = _normalize_payload(payload_raw)

            model_best  = p['model']
            sx          = p['sx']
            sy          = p['sy']
            cols        = p['cols']

            # 1) Limpia nombres de columnas
            sanitized_cols = [sanitize_name(c) for c in cols]

            # 2) Filtra solo las que existen en X_train
            effective_cols = [c for c in sanitized_cols if c in X_train.columns]
            missing = set(sanitized_cols) - set(effective_cols)
            if missing:
                print(f"[WARNING] NN omitido estas columnas en entrenamiento: {sorted(missing)}")

            # 3) Construye la matriz de entrenamiento
            X_tr = X_train[effective_cols].values

            #cols_clean = [_clean_col(c) for c in cols]
            #X_tr = X_train[cols_clean].values
            #X_tr = X_train[cols].values
            y_tr = Y_train.values.ravel()
            X_tr_scaled = sx.transform(X_tr) if sx is not None else X_tr
            # ‚Äî‚Äî‚Äî EXTRAER HIPERPAR√ÅMETROS NORMALIZADOS ‚Äî‚Äî‚Äî
            # payload_raw ya lo habr√°s definido as√≠:
            # payload_raw = OPT_MODELS[('nn', sel_method_nn, engine_nn)]
            p = _normalize_payload(payload_raw)
            best = p['best_params']
            layers_opt  = int(best.get('layers',         1))   # por defecto 1 capa si no est√°
            neurons_opt = int(best.get('units',         32))   # por defecto 32 neuronas
            dropout_opt = float(best.get('dropout_rate', 0.0)) # por defecto 0.0 de dropout
            #epochs_opt  = int(best.get('epochs',        10))   # por defecto 10 √©pocas
            epochs_opt = min(int(best.get('epochs', 10)), 5)  # m√°x 5 para acelerar ‚ö†Ô∏è Justificaci√≥n: Al ser solo para validaci√≥n de curvas, no necesitamos convergencia perfecta.

            # Determinar mejor √≠ndice seg√∫n m√©trica
            # En lugar de mirar en df_nn, usas directamente:
            if best_entry_nn['M√©trica'].upper() == 'R2':
                best_idx = idx_best_nn  # ya lo tienes
            else:
                best_idx = idx_best_nn

            # Y cuando necesites la ruta:
            # Normaliza el payload para extraer todo en variables claras
            payload_raw = OPT_MODELS[('nn', sel_method_nn, engine_nn)]
            p           = _normalize_payload(payload_raw)

            model_best  = p['model']
            sx          = p['sx']
            sy          = p['sy']
            cols        = p['cols']

            # 4.1 Curva de Aprendizaje manual
            #train_fracs = np.linspace(0.1,1.0,5)
            train_fracs = np.linspace(0.1, 1.0, 3)  # [0.1, 0.55, 1.0]  ‚ö†Ô∏è Justificaci√≥n: Permite evaluar comportamiento inicial, medio y completo con solo 3 puntos.
            train_scores, cv_scores = [], []
            #kf = KFold(n_splits=3, shuffle=True, random_state=42)
            kf = KFold(n_splits=2, shuffle=True, random_state=42)     # ‚ö†Ô∏è Justificaci√≥n: 2-fold ya permite evaluar generalizaci√≥n y reduce el n√∫mero de ciclos casi a la mitad.
            for frac in train_fracs:
                n = int(len(X_tr_scaled)*frac)
                X_sub, y_sub = X_tr_scaled[:n], y_tr[:n]
                s_tr, s_val = [], []
                for tr_idx, val_idx in kf.split(X_sub):
                    Xt, Xv = X_sub[tr_idx], X_sub[val_idx]
                    yt, yv = y_sub[tr_idx], y_sub[val_idx]
                    # Reentrenar modelo con los mismos HPO optimizados
                    m = keras.Sequential()
                    m.add(keras.Input(shape=(X_tr_scaled.shape[1],)))
                    for _ in range(layers_opt):
                        m.add(keras_layers.Dense(neurons_opt, activation='relu'))
                        m.add(keras_layers.Dropout(dropout_opt))
                    m.add(keras_layers.Dense(1))
                    m.compile(optimizer='adam', loss='mse')
                    m.fit(Xt, yt, epochs=epochs_opt, batch_size=32, verbose=0)
                    s_tr.append(r2_score(yt, m.predict(Xt).ravel()))
                    s_val.append(r2_score(yv, m.predict(Xv).ravel()))
                train_scores.append(np.mean(s_tr))
                cv_scores.append(np.mean(s_val))
            fig_lc, ax_lc = plt.subplots(figsize=(6,4))
            ax_lc.plot(train_fracs*len(X_tr_scaled), train_scores, 'o-', label='Train R¬≤')
            ax_lc.plot(train_fracs*len(X_tr_scaled), cv_scores,    'o-', label='CV R¬≤')
            ax_lc.set_title('NN Optimizado: Curva de Aprendizaje')
            ax_lc.set_xlabel('N√∫mero de muestras de entrenamiento')
            ax_lc.set_ylabel('R¬≤')
            ax_lc.legend()
            self.sections.append((
                '### NN Optimizado: Curva de Aprendizaje', fig_lc
            ))

            # 4.2 Curva de validaci√≥n para Layers
            #param_L = list(range(1, min(6, X_tr_scaled.shape[1]+1)))
            param_L = list(range(1, 4))  # solo 1 a 3 capas ‚ö†Ô∏è Justificaci√≥n: Reduce significativamente las combinaciones sin comprometer la visualizaci√≥n de tendencias.
            scores_tr_L, scores_cv_L = [], []
            for L in param_L:
                st, sv = [], []
                for ti, vi in kf.split(X_tr_scaled):
                    Xt, Xv = X_tr_scaled[ti], X_tr_scaled[vi]
                    yt, yv = y_tr[ti], y_tr[vi]
                    m = keras.Sequential()
                    m.add(keras.Input(shape=(X_tr_scaled.shape[1],)))
                    for _ in range(L):
                        m.add(keras_layers.Dense(neurons_opt, activation='relu'))
                        m.add(keras_layers.Dropout(dropout_opt))
                    m.add(keras_layers.Dense(1))
                    m.compile(optimizer='adam', loss='mse')
                    m.fit(Xt, yt, epochs=epochs_opt, batch_size=32, verbose=0)
                    st.append(r2_score(yt, m.predict(Xt).ravel()))
                    sv.append(r2_score(yv, m.predict(Xv).ravel()))
                scores_tr_L.append(np.mean(st))
                scores_cv_L.append(np.mean(sv))
            fig_vL, ax_vL = plt.subplots(figsize=(6,4))
            ax_vL.plot(param_L, scores_tr_L, 'o-', label='Train R¬≤')
            ax_vL.plot(param_L, scores_cv_L,'o-', label='CV R¬≤')
            ax_vL.set_title('NN Opt: Curva Validaci√≥n Layers')
            ax_vL.set_xlabel('Layers')
            ax_vL.set_ylabel('R¬≤')
            ax_vL.legend()
            self.sections.append((
                '### NN Optimizado: Curva Validaci√≥n Layers', fig_vL
            ))

            # 4.3 Curva de validaci√≥n para Neurons
            #param_N = list(np.linspace(10, X_tr_scaled.shape[1]*50, 5, dtype=int))
            param_N = list(np.linspace(10, X_tr_scaled.shape[1]*20, 3, dtype=int))  # solo 3 valores de neuronas  ‚ö†Ô∏è Justificaci√≥n: Reduce significativamente las combinaciones sin comprometer la visualizaci√≥n de tendencias.
            scores_tr_N, scores_cv_N = [], []
            for N in param_N:
                st, sv = [], []
                for ti, vi in kf.split(X_tr_scaled):
                    Xt, Xv = X_tr_scaled[ti], X_tr_scaled[vi]
                    yt, yv = y_tr[ti], y_tr[vi]
                    m = keras.Sequential()
                    m.add(keras.Input(shape=(X_tr_scaled.shape[1],)))
                    for _ in range(layers_opt):
                        m.add(keras_layers.Dense(N, activation='relu'))
                        m.add(keras_layers.Dropout(dropout_opt))
                    m.add(keras_layers.Dense(1))
                    m.compile(optimizer='adam', loss='mse')
                    m.fit(Xt, yt, epochs=epochs_opt, batch_size=32, verbose=0)
                    st.append(r2_score(yt, m.predict(Xt).ravel()))
                    sv.append(r2_score(yv, m.predict(Xv).ravel()))
                scores_tr_N.append(np.mean(st))
                scores_cv_N.append(np.mean(sv))
            fig_vN, ax_vN = plt.subplots(figsize=(6,4))
            ax_vN.plot(param_N, scores_tr_N, 'o-', label='Train R¬≤')
            ax_vN.plot(param_N, scores_cv_N,'o-', label='CV R¬≤')
            ax_vN.set_title('NN Opt: Curva Validaci√≥n Neurons')
            ax_vN.set_xlabel('Neurons')
            ax_vN.set_ylabel('R¬≤')
            ax_vN.legend()
            self.sections.append((
                '### NN Optimizado: Curva Validaci√≥n Neurons', fig_vN
            ))

            # 4.4 Interpretaci√≥n IA de las curvas
            prompt_curves = (
                f"NN optimizado (m√©todo: {best_entry_nn['Selecci√≥n X']}, motor: {best_entry_nn['Motor']}) gener√≥ estas curvas de R¬≤:\n"
                f"- Aprendizaje: tama√±os={ (train_fracs*len(X_tr_scaled)).tolist() }, train={train_scores}, CV={cv_scores}\n"
                f"- Validaci√≥n Layers: valores={param_L}, train={scores_tr_L}, CV={scores_cv_L}\n"
                f"- Validaci√≥n Neurons: valores={param_N}, train={scores_tr_N}, CV={scores_cv_N}\n"
                "1. Interpreta cada curva, se√±alando indicios de underfitting/overfitting."
                "2. Describe patrones (brechas, picos) y posibles causas."
                "3. Recomienda ajustes precisos de HPO basados en estos hallazgos."
                "4. Se√±ala limitaciones de datos o modelo evidentes en las curvas."
            )
            print("[DEBUG] 13.9. Llamando a IA para interpretaci√≥n IA de curvas redise√±ado")
            analysis_curves = call_openai_explanation(prompt_curves)
            self.sections.append((
                "### NN Optimizado: Interpretaci√≥n IA de Curvas", analysis_curves
            ))
            # --- Fin bloque 4 ---

            # ---- 5. Curvas de Calibraci√≥n y Predicci√≥n de Intervalos para NN Optimizado ----
            print("[DEBUG] 13.10. Calculando curva de calibraci√≥n y predicci√≥n de intervalos para el mejor modelo optimizado NN")
            # Usamos el modelo y payload_best ya cargados

            # ‚Äî‚Äî‚Äî Sanitizaci√≥n unificada de columnas para la curva de calibraci√≥n ‚Äî‚Äî‚Äî
            # 1) Partimos de las columnas del payload
            raw_cols_ci = payload_best['cols']

            # 2) Limpiamos cada nombre
            sanitized_cols_ci = [sanitize_name(c) for c in raw_cols_ci]

            # 3) Detectamos columnas faltantes
            missing_ci = set(sanitized_cols_ci) - set(X_test.columns)
            if missing_ci:
                print(f"[WARNING] NN omitido estas columnas en Calibraci√≥n por no existir en X_test: {sorted(missing_ci)}")

            # 4) Filtramos s√≥lo las que existen
            effective_cols_ci = [c for c in sanitized_cols_ci if c in X_test.columns]

            # 5) Selecci√≥n segura de test
            X_test_ci = X_test[effective_cols_ci].copy()
            y_true_ci = Y_test.values.ravel()

            # 6) Transformaci√≥n con scaler de entrada
            if sx is not None:
                X_scaled_ci = sx.transform(X_test_ci.values)
            else:
                X_scaled_ci = X_test_ci.values

            # 7) Predicci√≥n y desescalado
            y_pred_raw_ci = model_best.predict(X_scaled_ci).ravel()
            if sy is not None:
                y_pred_ci = sy.inverse_transform(y_pred_raw_ci.reshape(-1,1)).ravel()
            else:
                y_pred_ci = y_pred_raw_ci

            # Ahora y_true_ci y y_pred_ci est√°n listas para la curva de calibraci√≥n y los intervalos

            # ‚Äî SANITIZACI√ìN de las cols del payload antes de usar en informe
            #cols_ci_clean = [_clean_col(c) for c in payload_best['cols']]
            #X_test_ci = X_test[cols_ci_clean].copy()
            #X_test_ci = X_test[payload_best['cols']].copy()

            #y_true_ci = Y_test.values.ravel()
            #X_test_scaled_ci = sx.transform(X_test_ci) if sx else X_test_ci.values
            #y_pred_ci = model_best.predict(X_test_scaled_ci).ravel()

            # 5.1 Curva de calibraci√≥n manual para regresi√≥n
            import pandas as _pd
            bins = 10
            _df_cal = _pd.DataFrame({'y_pred': y_pred_ci, 'y_true': y_true_ci})
            try:
                _df_cal['bin'] = _pd.qcut(_df_cal['y_pred'], q=bins, duplicates='drop')
            except Exception:
                _df_cal['bin'] = _pd.cut(_df_cal['y_pred'], bins=bins)
            gr = _df_cal.groupby('bin', observed=True).agg({'y_pred':'mean','y_true':'mean'})
            prob_pred = gr['y_pred'].values
            prob_true = gr['y_true'].values
            fig_cal, ax_cal = plt.subplots(figsize=(6,4))
            ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2)
            ax_cal.plot([prob_pred.min(), prob_pred.max()], [prob_pred.min(), prob_pred.max()], 'k--')
            ax_cal.set_xlabel('Predicci√≥n promedio por bin')
            ax_cal.set_ylabel('Valor real promedio')
            ax_cal.set_title('NN Optimizado: Curva de Calibraci√≥n')
            self.sections.append((
                '### NN Optimizado: Curva de Calibraci√≥n', fig_cal
            ))

            # 5.2 Intervalos de predicci√≥n ¬±1 STD de residuos
            residuals_ci = y_true_ci - y_pred_ci
            std_res_ci = np.std(residuals_ci)
            upper = y_pred_ci + std_res_ci
            lower = y_pred_ci - std_res_ci
            fig_int, ax_int = plt.subplots(figsize=(6,4))
            ax_int.plot(y_true_ci, label='Y real')
            ax_int.plot(y_pred_ci, label='Predicci√≥n')
            ax_int.fill_between(range(len(y_pred_ci)), lower, upper, alpha=0.3, label='¬±1 STD residuo')
            ax_int.set_xlabel('√çndice de muestra')
            ax_int.set_ylabel('Valor')
            ax_int.set_title('NN Optimizado: Intervalos de Predicci√≥n')
            ax_int.legend()
            self.sections.append((
                '### NN Optimizado: Intervalos de Predicci√≥n', fig_int
            ))

            # 5.3 An√°lisis Generativo IA de incertidumbre y calibraci√≥n
            prompt_ci_nn = (
                f"Curva de calibraci√≥n (pred vs real): pred={prob_pred.tolist()}, real={prob_true.tolist()}\n"
                f"Intervalos ¬±1 STD de residuos (std_res={std_res_ci:.4f}).\n"
                "1. ¬øSon fiables estos intervalos de incertidumbre?\n"
                "2. ¬øSe infravaloran errores altos?"
            )
            print("[DEBUG] 13.11. Llamando IA para an√°lisis de incertidumbre y calibraci√≥n NN")
            analysis_ci_nn = call_openai_explanation(prompt_ci_nn)
            self.sections.append((
                '### NN Optimizado: An√°lisis de Incertidumbre y Calibraci√≥n', analysis_ci_nn
            ))
            # --- Fin bloque 5 ---

            # --- Secci√≥n 6: Resumen Ejecutivo y Road-Map de Siguientes Pasos ---
            # Definimos mejor combinaci√≥n basada en el mejor registro
            sel_method_nn = best_entry_nn['Selecci√≥n X']
            engine_nn    = best_entry_nn['Motor']
            best_score_nn = best_entry_nn['Score']

            # 6.1. Bloque Markdown con puntos clave para stakeholders
            summary_md = (
                "**Puntos Clave:**\n"
                f"- **Mejor combinaci√≥n:** {sel_method_nn}-{engine_nn} con score={best_score_nn:.4f}.\n"
                f"- **Grado de robustez:** Variabilidad CV={np.std(cv_scores):.4f}, residuos (std={std_res_ci:.4f}).\n"
                f"- **Puntos d√©biles:** picos de error en ciertos rangos y posible sobreajuste en tama√±os de muestra altos.\n"
                f"- **Recomendaciones inmediatas:** ampliar validaci√≥n cruzada, explorar motores jer√°rquicos como HalvingGridSearchCV y recolectar m√°s datos."
            )
            self.sections.append((
                '### Resumen Ejecutivo y Road-Map', summary_md
            ))

            # 6.2. An√°lisis Generativo IA para desarrollar cada punto clave y generar resumen ejecutivo
            prompt_exec = (
                "Eres un investigador cient√≠fico del Instituto de Procesos Sostenibles de la Universidad de Valladolid. "
                "A continuaci√≥n se presentan los puntos clave de la optimizaci√≥n de la red neuronal:\n"
                f"{summary_md}\n"
                "Desarrolla un an√°lisis detallado en p√°rrafos separados para cada punto "
                "(Mejor combinaci√≥n, Grado de robustez, Puntos d√©biles, Recomendaciones inmediatas), "
                "y finaliza con un resumen ejecutivo de tres p√°rrafos que resalte los hallazgos y los pr√≥ximos pasos para los stakeholders."
            )
            print("[DEBUG] 13.12. Llamando IA para Resumen Ejecutivo y Road-Map NN optimizaci√≥n")
            analysis_exec = call_openai_explanation(prompt_exec)
            self.sections.append((
                '### Resumen Ejecutivo IA', analysis_exec
            ))
        # --- Fin Bloque 6 ---

        except Exception as e:
            print(f"[DEBUG] Excepci√≥n atrapada en Optimizaci√≥n NN: {type(e).__name__}: {e}")
            raise   # relanza la excepci√≥n para que no se oculte
#            self.sections.append((
#                "### ‚ö†Ô∏è Error en secci√≥n Optimizaci√≥n NN",
#                f"Se produjo un error al generar el resumen de m√©todos y motores NN: {e}"
#            ))

        # =============================================================================
        # 14. Optimizaci√≥n Modelo XGBoost
        # =============================================================================
        print("[DEBUG] 14.1. Iniciando secci√≥n Optimizaci√≥n XGBoost: Resumen de m√©todos y motores")
        try:
            # Extraer resultados de OPT_MODELS para XGBoost
            valid_engines_xgb = {'randomsearch', 'bayesian', 'hyperband', 'optuna'}
            xgb_entries = {
                k: v for k, v in OPT_MODELS.items()
                if isinstance(k, tuple) and k[0] == 'xgb' and k[2] in valid_engines_xgb
            }
            if not xgb_entries:
                raise RuntimeError("No se encontr√≥ optimizaciones XGBoost en OPT_MODELS")

            import pandas as pd
            # Construir registros de resumen para XGBoost
            summary_xgb = []
            for (model_type, sel_method, engine), payload in xgb_entries.items():
                model = payload.get('model')
                score = payload.get('score')
                metric = payload.get('metric')
                # Determinar par√°metros de b√∫squeda del payload unificando todas las claves posibles
                params_cfg = (
                    payload.get('param_dist')
                    or payload.get('param_spaces')
                    or payload.get('search_spaces')
                    or payload.get('hpo_params')
                    or {}
                )
                best_params = getattr(model, 'get_params', lambda: {})()
                summary_xgb.append({
                    'Selecci√≥n X': sel_method,
                    'Motor': engine,
                    'M√©trica': metric,
                    'Score': score,
                    'Params_B√∫squeda': params_cfg,
                    'Best_n_estimators': best_params.get('n_estimators'),
                    'Best_max_depth': best_params.get('max_depth'),
                    'Best_learning_rate': best_params.get('learning_rate')
                })

            df_xgb = pd.DataFrame(summary_xgb)
            # A√±adir al informe
            self.sections.append((
                '### XGBoost Optimizaci√≥n: Resumen de M√©todos y Motores',
                df_xgb.reset_index(drop=True)
            ))

            # --- 0. An√°lisis Generativo IA de Tabla de Resumen ---
            # Llamada a OpenAI para an√°lisis de los resultados
            lines = [
                f"M√©todo X: {r['Selecci√≥n X']}, Motor: {r['Motor']}, Score: {r['Score']:.4f}, " +
                f"Params Busqueda: {r.get('Params_B√∫squeda', {})}, Best_Params: {r.get('Best_Params', {})}"
                for r in summary_xgb
            ]

            prompt_xgb = (
                "He obtenido los siguientes resultados de optimizaci√≥n para XGBoost:" + "".join(lines) + ""
                "1. Explica la estrategia de b√∫squeda y ventajas de cada motor (Hyperband, RandomizedSearchCV, Optuna, BayesSearchCV).\n"
                "2. Compara los scores obtenidos y argumenta cu√°l es la mejor configuraci√≥n.\n"
                "3. Sugiere mejoras espec√≠ficas de HPO para XGBoost basadas en estos resultados."
            )
            print("[DEBUG] 14.2. Llamando a OpenAI para an√°lisis generativo XGBoost optimizaci√≥n")
            analysis_xgb = call_openai_explanation(prompt_xgb)
            self.sections.append((
                '### XGBoost Optimizaci√≥n: An√°lisis Generativo', analysis_xgb
            ))
            # --- Fin Bloque 0 ---

            # --- 1. Curvas de Ajuste Real vs. Predicho y Residuos para XGBoost ---
            from sklearn.metrics import r2_score
            print("[DEBUG] 14.3. Iniciando bloque de Curvas Ajuste Real vs Predicho y Residuos para XGBoost optimizado")
            from scipy.stats import skew, kurtosis
            import numpy as np

            # 1. Seleccionar mejor configuraci√≥n y normalizar payload
            best_idx    = df_xgb['Score'].idxmax() if df_xgb['M√©trica'].str.upper().iloc[0]=='R2' else df_xgb['Score'].idxmin()
            best_row    = summary_xgb[best_idx]

            payload_raw = OPT_MODELS[('xgb', best_row['Selecci√≥n X'], best_row['Motor'])]
            p           = _normalize_payload(payload_raw)

            # ‚Äî‚Äî‚Äî Sanitizaci√≥n de columnas para XGBoost ‚Äî‚Äî‚Äî
            # 1) obtenemos la lista original de columnas entrenadas
            raw_cols_xgb = p['cols'] if p['cols'] is not None else X_train.columns.tolist()
            # 2) aplicamos sanitize_name a cada nombre
            sanitized_cols = [sanitize_name(c) for c in raw_cols_xgb]
            # 3) avisamos si faltan columnas en X_test
            missing = set(sanitized_cols) - set(X_test.columns)
            if missing:
                print(f"[WARNING] XGBoost omitido estas columnas por no existir en X_test: {sorted(missing)}")
            # 4) nos quedamos solo con las columnas v√°lidas
            cols_xgb = [c for c in sanitized_cols if c in X_test.columns]
            # ‚Äî‚Äî‚Äî Fin sanitizaci√≥n XGBoost ‚Äî‚Äî‚Äî

            # ‚Äî‚Äî‚Äî 1.1.1 Sanitizaci√≥n y filtro unificado de columnas ‚Äî‚Äî‚Äî
            #sanitized_cols = [sanitize_name(c) for c in raw_cols]
            #missing = set(sanitized_cols) - set(X_test.columns)
            #if missing:
            #    print(f"[WARNING] SVR omitido estas columnas por no existir en X_test: {sorted(missing)}")
            #cols_xgb = [c for c in sanitized_cols if c in X_test.columns]

            #X_test_sel = X_test[cols_valid].copy()

            # A√ëADIDO: Unificar saneamiento de nombres de columnas seg√∫n entrenamiento
            #import re
            #def clean_name(s):
            #    t = re.sub(r'[\[\]<>%\/\. ]+', '_', str(s))
            #    t = re.sub(r'_+', '_', t)
            #    return t.strip('_')

            # 1) Modelo ‚Äî si no est√°, error controlado
            model_xgb = p['model']
            if model_xgb is None:
                raise RuntimeError(f"No pude cargar el modelo para {best_row['Selecci√≥n X']}-{best_row['Motor']}")

            # 2) Columnas ‚Äî si no vienen, uso **todas** las de entrenamiento
            #cols_xgb = p['cols'] if p['cols'] is not None else X_train.columns.tolist()

            # REEMPLAZAR esta l√≠nea original:
            # cols_xgb = p['cols'] if p['cols'] is not None else X_train.columns.tolist()
            # POR:
            #raw_cols_xgb = p['cols'] if p['cols'] is not None else X_train.columns.tolist()
            #cols_xgb     = [ clean_name(c) for c in raw_cols_xgb ]
            # FIN A√ëADIDO / REEMPLAZO

            # 3) Escalador de salida ‚Äî a la hora de inverse_transform
            sy_xgb = p['sy']  # puede ser None

            # 4) Score y best_params ‚Äî nunca deber√≠an ser None, pero por si acaso:
            score_xgb       = p['score'] or 0.0
            best_params_xgb = p['best_params'] or {}
            metric_xgb      = p['metric']

            # Preparar datos de prueba
            #X_test_xgb = X_test[cols_xgb]
            #y_true_xgb = Y_test.values.ravel()
            #y_pred_xgb = model_xgb.predict(X_test_xgb)
            #if p['sy'] is not None:
            #    y_pred_xgb = p['sy'].inverse_transform(y_pred_xgb.reshape(-1,1)).ravel()
            # si tu modelo no escala internamente:
            #X_test_scaled_xgb = sx_xgb.transform(X_test_xgb)
            #y_pred_xgb        = sy_xgb.inverse_transform(model_xgb.predict(X_test_scaled_xgb).reshape(-1,1)).ravel()

            # 1) Filtramos y saneamos las columnas igual que en entrenamiento
            X_test_xgb = X_test[cols_xgb]
            # 2) Llevamos a numpy array para evitar la comprobaci√≥n de nombres
            X_test_vals = X_test_xgb.values
            y_pred_raw  = model_xgb.predict(X_test_vals)
            # 3) Desescalamos si corresponde
            if p['sy'] is not None:
                y_pred_xgb = p['sy'].inverse_transform(y_pred_raw.reshape(-1,1)).ravel()
            else:
                y_pred_xgb = y_pred_raw
            # 4) Tus valores reales siguen as√≠:
            y_true_xgb = Y_test.values.ravel()

            # Gr√°fica Predicho vs Real
            fig1, ax1 = plt.subplots(figsize=(6,4))
            ax1.scatter(y_true_xgb, y_pred_xgb, alpha=0.6)
            ax1.plot([y_true_xgb.min(), y_true_xgb.max()], [y_true_xgb.min(), y_true_xgb.max()], 'r--', lw=2)
            ax1.set_xlabel('Y real')
            ax1.set_ylabel('Y predicho')
            ax1.set_title(f"XGBoost Optimizado: Predicho vs Real ({best_row['Selecci√≥n X']}-{best_row['Motor']})")
            self.sections.append((
                f"### XGBoost Optimizado: Predicho vs Real ({best_row['Selecci√≥n X']}-{best_row['Motor']})", fig1
            ))

            # Gr√°fica Residuos
            residuals_xgb = y_true_xgb - y_pred_xgb
            fig2, ax2 = plt.subplots(figsize=(6,4))
            ax2.scatter(y_pred_xgb, residuals_xgb, alpha=0.6)
            ax2.axhline(0, color='r', linestyle='--', lw=2)
            ax2.set_xlabel('Y predicho')
            ax2.set_ylabel('Residuo')
            ax2.set_title(f"XGBoost Optimizado: Residuos ({best_row['Selecci√≥n X']}-{best_row['Motor']})")
            self.sections.append((
                f"### XGBoost Optimizado: Residuos ({best_row['Selecci√≥n X']}-{best_row['Motor']})", fig2
            ))

            # Tabla estad√≠sticas de residuos
            df_res_stats = pd.DataFrame({
                'M√©trica': ['Media','Desviaci√≥n','Skew','Kurtosis','25%','50%','75%'],
                'Valor': [residuals_xgb.mean(), residuals_xgb.std(), skew(residuals_xgb), kurtosis(residuals_xgb), *np.quantile(residuals_xgb,[0.25,0.5,0.75])]
            })
            self.sections.append((
                f"### XGBoost Optimizado: Estad√≠sticas de Residuos ({best_row['Selecci√≥n X']}-{best_row['Motor']})", df_res_stats
            ))

            # An√°lisis generativo IA
            prompt_xgb_curves = (
                f"Para el mejor XGBoost optimizado (selecci√≥n {best_row['Selecci√≥n X']}, motor {best_row['Motor']}), "
                f"tienes los siguientes datos:"
                f"- Rango Y real: [{y_true_xgb.min():.4f}, {y_true_xgb.max():.4f}]\n"
                f"- Rango Y pred: [{y_pred_xgb.min():.4f}, {y_pred_xgb.max():.4f}]\n"
                f"- Estad√≠sticas residuos: media={residuals_xgb.mean():.4f}, std={residuals_xgb.std():.4f}, skew={skew(residuals_xgb):.4f}, kurtosis={kurtosis(residuals_xgb):.4f}\.\n"
                "1. Analiza la calidad del ajuste bas√°ndote en Predicho vs Real y Residuos.\n"
                "2. Comenta sesgos sistem√°ticos o heterocedasticidad.\n"
                "3. Recomienda acciones para mejorar el fit si hay problemas."
            )
            print("[DEBUG] 14.4. Llamando IA para an√°lisis de curvas XGBoost")
            try:
                analysis_xgb_curves = call_openai_explanation(prompt_xgb_curves)
                self.sections.append((
                    '### XGBoost Optimizado: An√°lisis Calidad Ajuste',
                    analysis_xgb_curves
                ))
            except Exception as e:
                # aqu√≠ s√≠ podemos usar `e`
                print(f"[ERROR XGB ‚Äì Curvas] {type(e).__name__}: {e}")
                self.sections.append((
                    '### ‚ö†Ô∏è Error XGBoost: An√°lisis Calidad Ajuste',
                    f"Se produjo un error al generar las curvas de XGBoost: {type(e).__name__}: {e}"
                ))
            # --- Fin bloque 1 ---

            # --- 2. Importancia Relativa de Hiperpar√°metros para XGBoost Optimizado ---
            print("[DEBUG] 14.5. Calculando importancia real de hiperpar√°metros para XGBoost optimizado")

            import pandas as pd
            import numpy as np
            from sklearn.model_selection import train_test_split
            from sklearn.metrics import r2_score
            from xgboost import XGBRegressor

            # Determinar la mejor configuraci√≥n desde df_xgb
            if df_xgb['M√©trica'].str.upper().iloc[0] == 'R2':
                idx_best = df_xgb['Score'].idxmax()
            else:
                idx_best = df_xgb['Score'].idxmin()

            # Datos completos
            X_full = X_train[cols_xgb]
            y_full = Y_train.values.ravel()
            base_params = best_params_xgb
            base_score  = score_xgb

            # Funci√≥n para medir impacto de variar un hiperpar√°metro ¬±10%
            sens_list = []
            for param in ['n_estimators', 'max_depth', 'learning_rate']:
                base_val = base_params.get(param)
                if base_val is None:
                    continue
                for factor, label in [(1.1, '+10%'), (0.9, '-10%')]:
                    # Nuevo valor
                    new_val = int(base_val * factor) if param in ['n_estimators', 'max_depth'] else base_val * factor
                    # Divisi√≥n train/val
                    X_tr, X_val, y_tr, y_val = train_test_split(X_full, y_full, test_size=0.2, random_state=42)
                    # Reentrenar con el par√°metro modificado
                    m = XGBRegressor(**{**base_params, param: new_val}, random_state=42, verbosity=0)
                    m.fit(X_tr, y_tr)
                    y_pred = m.predict(X_val)
                    score_new = r2_score(y_val, y_pred)
                    sens_list.append({
                        'Par√°metro': param,
                        'Cambio': label,
                        'Score': score_new,
                        'Delta': score_new - base_score
                    })

            # Crear DataFrame de sensibilidad
            df_sens_xgb = pd.DataFrame(sens_list)
            df_sens_xgb['% Delta'] = df_sens_xgb['Delta'] * 100

            # 2.1 Tabla de sensibilidad real
            self.sections.append((
                '### XGBoost Optimizado: Sensibilidad Real del Score ¬±10%',
                df_sens_xgb[['Par√°metro', 'Cambio', 'Score', '% Delta']]
            ))

            # 2.2 Heatmap de sensibilidad
            pivot_xgb = df_sens_xgb.pivot(index='Par√°metro', columns='Cambio', values='% Delta')
            fig_sens_xgb, ax_sens_xgb = plt.subplots(figsize=(6, 4))
            sns.heatmap(pivot_xgb, annot=True, fmt='.2f', ax=ax_sens_xgb)
            ax_sens_xgb.set_title('XGBoost Optimizado: Heatmap Sensibilidad Real ¬±10%')
            self.sections.append((
                '### XGBoost Optimizado: Heatmap Sensibilidad',
                fig_sens_xgb
            ))

            # 2.3 An√°lisis Generativo IA de importancia real
            lines_xgb = [
            f"{row['Par√°metro']} {row['Cambio']} ‚Üí Œî% = {row['% Delta']:.2f}%"
            for _, row in df_sens_xgb.iterrows()
            ]
            prompt_hp_xgb = (
                "Sensibilidad del Score tras reentrenar XGBoost variando ¬±10% cada hiperpar√°metro:\n" +
                "\n".join(lines_xgb) +
                "\n\n1. Explica cu√°l hiperpar√°metro impacta m√°s y por qu√©.\n"
                "2. Sugiere en qu√© enfocarte en pr√≥ximos HPO bas√°ndote en estos resultados."
            )
            print("[DEBUG] 14.6. Llamando IA para importancia hiperpar√°metros XGBoost")
            analysis_hp_xgb = call_openai_explanation(prompt_hp_xgb)
            self.sections.append((
                '### XGBoost Optimizado: IA Importancia Real Hiperpar√°metros',
                analysis_hp_xgb
            ))
            # ---- Fin bloque 2 ----

            # --- 3. Distribuci√≥n de M√©tricas en Validaci√≥n Cruzada para XGBoost Optimizado ---
            from sklearn.model_selection import cross_validate
            import numpy as np

            print("[DEBUG] 14.7. Calculando distribuci√≥n de m√©tricas CV para XGBoost optimizado")

            # 3.1 Identificar el mejor modelo seg√∫n Score (R2 se maximiza, errores se minimizan)
            if df_xgb['M√©trica'].str.upper().iloc[0] == 'R2':
                best_idx = df_xgb['Score'].idxmax()
            else:
                best_idx = df_xgb['Score'].idxmin()
            best_row = df_xgb.loc[best_idx]

            payload_raw_cv  = OPT_MODELS[('xgb', best_row['Selecci√≥n X'], best_row['Motor'])]
            p_cv            = _normalize_payload(payload_raw_cv)
            model_cv, cols_cv = p_cv['model'], p_cv['cols']

            # Preparamos datos de entrenamiento escalados
            X_cv = X_train[cols_cv]
            y_cv = Y_train.values.ravel()

            # Ejecutamos cross‚Äêvalidate con 5 folds
            cv_results = cross_validate(
                model_cv, X_cv, y_cv,
                cv=5,
                scoring={
                    'R2': 'r2',
                    'neg_MSE': 'neg_mean_squared_error',
                    'neg_MAE': 'neg_mean_absolute_error'
                },
                return_train_score=False
            )

            # Convertimos a m√©tricas positivas
            r2_scores   = cv_results['test_R2']
            mse_scores  = -cv_results['test_neg_MSE']
            mae_scores  = -cv_results['test_neg_MAE']
            rmse_scores = np.sqrt(mse_scores)

            import pandas as _pd

            # 3.2 Boxplot de m√©tricas por fold
            df_cv = _pd.DataFrame({
                'R2':   r2_scores,
                'MSE':  mse_scores,
                'MAE':  mae_scores,
                'RMSE': rmse_scores
            })
            fig_cv, ax_cv = plt.subplots(figsize=(6,4))
            sns.boxplot(data=df_cv, ax=ax_cv)
            ax_cv.set_title('XGBoost Optimizado: Distribuci√≥n de M√©tricas CV')
            self.sections.append((
                '### XGBoost Optimizado: Distribuci√≥n de M√©tricas CV',
                fig_cv
            ))

            # 3.3 Tabla con media ¬± desviaci√≥n en folds
            stats_cv = df_cv.agg(['mean','std']).T.reset_index().rename(columns={
                'index':'M√©trica','mean':'Media','std':'Desviaci√≥n'
            })
            self.sections.append((
                '### XGBoost Optimizado: Estad√≠sticas CV por Fold',
                stats_cv
            ))

            # 3.4 An√°lisis Generativo IA de estabilidad
            prompt_cv_xgb = (
                f"Validaci√≥n cruzada 5-folds para XGBoost optimizado "
                f"(selecci√≥n={best_row['Selecci√≥n X']}, motor={best_row['Motor']}):\n"
                f"- R2 scores: {r2_scores.tolist()}\n"
                f"- MSE scores: {mse_scores.tolist()}\n"
                f"- MAE scores: {mae_scores.tolist()}\n"
                f"- RMSE scores: {rmse_scores.tolist()}\n\n"
                "1. ¬øQu√© nos dice la dispersi√≥n de cada m√©trica sobre la estabilidad del modelo?\n"
                "2. Identifica fuentes de variabilidad que puedan afectar la generalizaci√≥n.\n"
                "3. Sugiere acciones concretas (p.ej., m√°s regularizaci√≥n, m√°s datos, ajuste de HPO) para mejorar la robustez."
            )
            print("[DEBUG] 14.8. Llamando IA para estabilidad en CV XGBoost")
            analysis_cv_xgb = call_openai_explanation(prompt_cv_xgb)
            self.sections.append((
                '### XGBoost Optimizado: An√°lisis Estabilidad CV',
                analysis_cv_xgb
            ))
            # --- Fin Bloque 3 ---

            # --- 4. Curvas de Aprendizaje y Validaci√≥n para XGBoost Optimizado ---
            # --- 4. Curvas de Aprendizaje y Validaci√≥n para XGBoost Optimizado ---
            from sklearn.model_selection import learning_curve, validation_curve
            import numpy as np

            print("[DEBUG] 14.9. Calculando curvas de aprendizaje y validaci√≥n para XGBoost optimizado")

            # Seleccionar mejor configuraci√≥n seg√∫n m√©trica
            if df_xgb['M√©trica'].str.upper().iloc[0] == 'R2':
                best_idx = df_xgb['Score'].idxmax()
            else:
                best_idx = df_xgb['Score'].idxmin()
            best_row = summary_xgb[best_idx]
            payload_raw_lc = OPT_MODELS[('xgb', best_row['Selecci√≥n X'], best_row['Motor'])]
            p_lc           = _normalize_payload(payload_raw_lc)
            model_best, cols_xgb = p_lc['model'], p_lc['cols']

            # Preparar datos de entrenamiento
            X_tr = X_train[cols_xgb]
            y_tr = Y_train.values.ravel()

            # 4.1 Curva de Aprendizaje (R¬≤)
            train_sizes, train_scores, cv_scores = learning_curve(
                model_best, X_tr, y_tr,
                cv=3,
                train_sizes=np.linspace(0.1, 1.0, 5),
                scoring='r2',
                n_jobs=-1
            )
            train_mean = np.mean(train_scores, axis=1)
            cv_mean    = np.mean(cv_scores,   axis=1)

            fig_lc_xgb, ax_lc_xgb = plt.subplots(figsize=(6,4))
            ax_lc_xgb.plot(train_sizes, train_mean, 'o-', label='Train R¬≤')
            ax_lc_xgb.plot(train_sizes, cv_mean,    'o-', label='CV R¬≤')
            ax_lc_xgb.set_title('XGBoost Optimizado: Curva de Aprendizaje')
            ax_lc_xgb.set_xlabel('Tama√±o del set de entrenamiento')
            ax_lc_xgb.set_ylabel('R¬≤')
            ax_lc_xgb.legend()
            self.sections.append((
                '### XGBoost Optimizado: Curva de Aprendizaje',
                fig_lc_xgb
            ))

            # 4.2 Curva de Validaci√≥n para max_depth
            param_range_depth = np.arange(3, 16, 2)
            depth_tr, depth_cv = validation_curve(
                model_best, X_tr, y_tr,
                param_name='max_depth',
                param_range=param_range_depth,
                cv=3,
                scoring='r2',
                n_jobs=-1
            )
            fig_vc_d, ax_vc_d = plt.subplots(figsize=(6,4))
            ax_vc_d.plot(param_range_depth, np.mean(depth_tr, axis=1), 'o-', label='Train R¬≤')
            ax_vc_d.plot(param_range_depth, np.mean(depth_cv, axis=1), 'o-', label='CV R¬≤')
            ax_vc_d.set_title('XGBoost Opt.: Curva Validaci√≥n max_depth')
            ax_vc_d.set_xlabel('max_depth')
            ax_vc_d.set_ylabel('R¬≤')
            ax_vc_d.legend()
            self.sections.append((
                '### XGBoost Optimizado: Curva de Validaci√≥n max_depth',
                fig_vc_d
            ))

            # 4.3 Curva de Validaci√≥n para learning_rate
            param_range_lr = np.linspace(0.01, 0.3, 5)
            lr_tr, lr_cv = validation_curve(
                model_best, X_tr, y_tr,
                param_name='learning_rate',
                param_range=param_range_lr,
                cv=3,
                scoring='r2',
                n_jobs=-1
            )
            fig_vc_lr, ax_vc_lr = plt.subplots(figsize=(6,4))
            ax_vc_lr.plot(param_range_lr, np.mean(lr_tr, axis=1), 'o-', label='Train R¬≤')
            ax_vc_lr.plot(param_range_lr, np.mean(lr_cv, axis=1), 'o-', label='CV R¬≤')
            ax_vc_lr.set_xscale('log')
            ax_vc_lr.set_title('XGBoost Opt.: Curva Validaci√≥n learning_rate')
            ax_vc_lr.set_xlabel('learning_rate')
            ax_vc_lr.set_ylabel('R¬≤')
            ax_vc_lr.legend()
            self.sections.append((
                '### XGBoost Optimizado: Curva de Validaci√≥n learning_rate',
                fig_vc_lr
            ))

            # 4.4 Interpretaci√≥n IA de las curvas
            prompt_curvas_xgb = (
                f"Para el modelo XGBoost optimizado (selecci√≥n={best_row['Selecci√≥n X']}, motor={best_row['Motor']}), se generaron estas curvas de R¬≤:\n"
                f"- Aprendizaje: tama√±os={train_sizes.tolist()}, train={train_mean.tolist()}, cv={cv_mean.tolist()}\n"
                f"- Validaci√≥n max_depth: depths={param_range_depth.tolist()}, train={np.mean(depth_tr,axis=1).tolist()}, cv={np.mean(depth_cv,axis=1).tolist()}\n"
                f"- Validaci√≥n learning_rate: rates={param_range_lr.tolist()}, train={np.mean(lr_tr,axis=1).tolist()}, cv={np.mean(lr_cv,axis=1).tolist()}\n\n"
                "1. Interpreta cada curva se√±alando indicios de underfitting o overfitting.\n"
                "2. Describe patrones (brechas entre train y cv, picos, ca√≠das).\n"
                "3. Recomienda ajustes precisos de HPO (max_depth, learning_rate, regularizaci√≥n).\n"
                "4. Indica posibles limitaciones de datos o modelo evidentes."
            )
            print("[DEBUG] 14.10. Llamando a OpenAI para interpretaci√≥n IA de curvas XGBoost")
            analysis_curvas_xgb = call_openai_explanation(prompt_curvas_xgb)
            self.sections.append((
                '### XGBoost Optimizado: Interpretaci√≥n IA de Curvas',
                analysis_curvas_xgb
            ))
            # --- Fin Bloque 4 ---

            # ---- 5. Curvas de Calibraci√≥n y Predicci√≥n de Intervalos para XGBoost Optimizado ----
            from sklearn.calibration import calibration_curve
            import pandas as _pd
            import numpy as np

            print("[DEBUG] 14.11. Calculando curva de calibraci√≥n y predicci√≥n de intervalos para el mejor modelo optimizado XGBoost")

            # 5.1 Identificar mejor modelo
            if df_xgb['M√©trica'].str.upper().iloc[0] == 'R2':
                best_idx = df_xgb['Score'].idxmax()
            else:
                best_idx = df_xgb['Score'].idxmin()
            best = summary_xgb[best_idx]
            payload_raw_ci = OPT_MODELS[('xgb', best['Selecci√≥n X'], best['Motor'])]
            p_ci           = _normalize_payload(payload_raw_ci)
            model_ci, cols_ci = p_ci['model'], p_ci['cols']

            # Preparar datos de prueba
            X_test_ci   = X_test[cols_ci]
            y_true_ci   = Y_test.values.ravel()
            y_pred_ci   = model_ci.predict(X_test_ci)

            # 5.2 Curva de calibraci√≥n (binned reliability plot)
            bins = 10
            df_cal = _pd.DataFrame({'y_pred': y_pred_ci, 'y_true': y_true_ci})
            try:
                df_cal['bin'] = _pd.qcut(df_cal['y_pred'], q=bins, duplicates='drop')
            except ValueError:
                df_cal['bin'] = _pd.cut(df_cal['y_pred'], bins=bins)
            grp = df_cal.groupby('bin', observed=True).agg({'y_pred':'mean','y_true':'mean'})
            prob_pred = grp['y_pred'].values
            prob_true = grp['y_true'].values

            fig_cal, ax_cal = plt.subplots(figsize=(6,4))
            ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2)
            ax_cal.plot([prob_pred.min(), prob_pred.max()],
                        [prob_pred.min(), prob_pred.max()],
                        'k--')
            ax_cal.set_xlabel('Predicci√≥n promedio por bin')
            ax_cal.set_ylabel('Valor real promedio')
            ax_cal.set_title('XGBoost Opt.: Curva de Calibraci√≥n')
            self.sections.append((
                '### XGBoost Optimizado: Curva de Calibraci√≥n',
                fig_cal
            ))

            # 5.3 Intervalos de predicci√≥n ¬±1 STD de residuos
            residuals_ci = y_true_ci - y_pred_ci
            std_res_ci   = np.std(residuals_ci)
            upper = y_pred_ci + std_res_ci
            lower = y_pred_ci - std_res_ci

            fig_int, ax_int = plt.subplots(figsize=(6,4))
            ax_int.plot(y_true_ci, label='Y real')
            ax_int.plot(y_pred_ci, label='Predicci√≥n')
            ax_int.fill_between(range(len(y_pred_ci)), lower, upper,
                                alpha=0.3, label='¬±1 STD residuo')
            ax_int.set_xlabel('√çndice de muestra')
            ax_int.set_ylabel('Valor')
            ax_int.set_title('XGBoost Opt.: Intervalos de Predicci√≥n')
            ax_int.legend()
            self.sections.append((
                '### XGBoost Optimizado: Intervalos de Predicci√≥n',
                fig_int
            ))

            # 5.4 An√°lisis Generativo IA de incertidumbre y calibraci√≥n
            prompt_ci_xgb = (
                f"Para el XGBoost optimizado (m√©todo={best['Selecci√≥n X']}, motor={best['Motor']}):\n"
                f"- Curva de calibraci√≥n: pred={prob_pred.tolist()}, real={prob_true.tolist()}\n"
                f"- Intervalos ¬±1 STD de residuos (std={std_res_ci:.4f})\n\n"
                "1. ¬øSon fiables estos intervalos de incertidumbre?\n"
                "2. ¬øObservas infravaloraci√≥n de errores altos o patrones heteroced√°sticos?\n"
                "3. Sugiere mejoras en HPO o en la modelizaci√≥n para fortalecer la confianza de las predicciones."
            )
            print("[DEBUG] 14.12. Llamando IA para an√°lisis de incertidumbre y calibraci√≥n XGBoost")
            analysis_ci_xgb = call_openai_explanation(prompt_ci_xgb)
            self.sections.append((
                '### XGBoost Optimizado: An√°lisis de Incertidumbre y Calibraci√≥n',
                analysis_ci_xgb
            ))
            # --- Fin Bloque 5 ---

            # --- 6. Resumen Ejecutivo y Road-Map de Siguientes Pasos para XGBoost Optimizado ---
            # 6.1. Identificamos la mejor configuraci√≥n
            if df_xgb['M√©trica'].str.upper().iloc[0] == 'R2':
                best_idx_xgb = df_xgb['Score'].idxmax()
            else:
                best_idx_xgb = df_xgb['Score'].idxmin()
            best_xgb = summary_xgb[best_idx_xgb]
            sel_xgb, eng_xgb, best_score_xgb = best_xgb['Selecci√≥n X'], best_xgb['Motor'], best_xgb['Score']

            # 6.2. Creamos el bloque Markdown con los puntos clave
            summary_md_xgb = (
                "**Puntos Clave Optimizaci√≥n XGBoost:**\n\n"
                f"- **Mejor combinaci√≥n:** M√©todo de selecci√≥n `{sel_xgb}` + motor `{eng_xgb}` ‚ûú **Score** = {best_score_xgb:.4f}\n"
                f"- **Robustez del modelo:** CV y residuos muestran desviaci√≥n est√°ndar de aproximadamente _X_ (reemplazar con valor real).\n"
                "- **Puntos d√©biles detectados:** posibles indicios de sobreajuste en rangos altos de `max_depth` o `learning_rate`, y variabilidad en ciertos folds.\n"
                "- **Recomendaciones inmediatas:**\n"
                "  1. Ampliar validaci√≥n cruzada (p.ej., HalvingGridSearchCV o K=5‚Äì10 folds).\n"
                "  2. Explorar rangos m√°s finos de `learning_rate` en [0.01, 0.1] y `max_depth` en [3, 10].\n"
                "  3. Evaluar regularizaci√≥n L1/L2 (`reg_alpha`, `reg_lambda`) para atenuar overfitting.\n"
                "  4. Considerar ensamblados ligeros (p.ej., LightGBM, CatBoost) y comparaci√≥n de rendimiento.\n"
            )

            self.sections.append((
                '### XGBoost Optimizado: Resumen Ejecutivo y Road-Map',
                summary_md_xgb
            ))

            # 6.3. An√°lisis Generativo con OpenAI
            prompt_exec_xgb = (
                "Eres un investigador del Instituto de Procesos Sostenibles de la Universidad de Valladolid. "
                "A continuaci√≥n tienes los puntos clave de la optimizaci√≥n XGBoost:\n\n"
                f"{summary_md_xgb}\n\n"
                "Por favor:\n"
                "1. Desarrolla en un p√°rrafo cada uno de los puntos clave (Mejor combinaci√≥n, Robustez, Puntos d√©biles, Recomendaciones).\n"
                "2. Finaliza con un **resumen ejecutivo** de tres p√°rrafos dirigido a stakeholders acad√©micos, resaltando hallazgos y pasos siguientes.\n"
            )
            print("[DEBUG] 14.13. Llamando IA para Resumen Ejecutivo XGBoost")
            analysis_exec_xgb = call_openai_explanation(prompt_exec_xgb)
            self.sections.append((
                '### XGBoost Optimizado: An√°lisis Ejecutivo IA',
                analysis_exec_xgb
            ))
            # --- Fin Bloque 6 ---

        except Exception as e:
            print(f"[ERROR XGBoost] {type(e).__name__}: {e}")
            self.sections.append((
                '### ‚ö†Ô∏è Error en secci√≥n Optimizaci√≥n XGBoost',
                f"Se produjo un error al generar XGBoost: {type(e).__name__}: {e}"
            ))

        #print("[DEBUG] ReportBuilder.build_sections end")

        # =============================================================================
        # 15. Optimizaci√≥n Modelo Random Forest
        # =============================================================================
        try:
            print("[DEBUG] 15.1. Iniciando secci√≥n Optimizaci√≥n Random Forest: Resumen de m√©todos y motores")
            # Verificar que OPT_MODELS existe y es dict
            if 'OPT_MODELS' not in globals() or not isinstance(OPT_MODELS, dict):
                raise RuntimeError("No se encontr√≥ OPT_MODELS con resultados de optimizaci√≥n RF")

            import pandas as pd
            # Filtrar entradas de Random Forest
            valid_engines_rf = {'randomsearch', 'bayesianoptimization', 'hyperband', 'optuna'}
            rf_entries = {
                k: v for k, v in OPT_MODELS.items()
                if isinstance(k, tuple) and k[0] == 'rf' and k[2] in valid_engines_rf
            }
            if not rf_entries:
                raise RuntimeError("No se encontraron optimizaciones Random Forest en OPT_MODELS")

            # Construir lista de registros resumen
            summary_rf = []
            for (_, sel_method, engine), payload in rf_entries.items():
                score = payload.get('score')
                metric = payload.get('metric')
                params_search = payload.get('param_dist', {}) or payload.get('search_spaces', {})
                best_params = payload.get('best_params', {})
                summary_rf.append({
                    'Selecci√≥n X': sel_method,
                    'Motor':      engine,
                    'M√©trica':    metric,
                    'Score':      score,
                    'Params_B√∫squeda': params_search,
                    'Best_Params':     best_params
                })

            # DataFrame resumen
            df_rf = pd.DataFrame(summary_rf)
            self.sections.append((
                '### Random Forest Optimizaci√≥n: Resumen de M√©todos y Motores',
                df_rf.reset_index(drop=True)
            ))

            # --- 0. An√°lisis Generativo IA de la Tabla Resumen ---
            def call_openai_explanation(prompt: str, model: str = "gpt-4", temperature: float = TEMPERATURE_VAL, max_tokens: int = MAX_EXPLANATION_TOKENS) -> str:
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": (
                                "Eres un experto en optimizaci√≥n de hiperpar√°metros de modelos de Machine Learning. "
                                "Proporciona an√°lisis profundo, interpretaciones y recomendaciones basadas en los datos proporcionados.")},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS
                    )
                    return response.choices[0].message.content.strip()
                except Exception as e:
                    return f"[Error llamando a OpenAI: {e}]"
            lines = [
                f"M√©todo X: {r['Selecci√≥n X']}, Motor: {r['Motor']}, Score: {r['Score']:.4f}, " +
                f"Params: {r['Params_B√∫squeda']}, Best: {r['Best_Params']}"
                for r in summary_rf
            ]
            prompt_rf = (
                "He obtenido los siguientes resultados de optimizaci√≥n para Random Forest:\n" +
                "\n".join(lines) + "\n\n"
                "1. Explica la estrategia de cada motor (RandomSearch, BayesianOptimization, Hyperband, Optuna).\n"
                "2. Compara los scores y justifica la mejor configuraci√≥n.\n"
                "3. Sugiere mejoras espec√≠ficas de HPO para Random Forest."
            )
            print("[DEBUG] 15.2. Llamando a OpenAI para an√°lisis generativo RF optimizaci√≥n")
            analysis_rf = call_openai_explanation(prompt_rf)

            self.sections.append((
                '### Random Forest Optimizaci√≥n: An√°lisis Generativo',
                analysis_rf
            ))
            # --- Fin Bloque 0 ---

            # --- 1. Curvas de Ajuste Real vs. Predicho y Residuos para Random Forest Optimizado ---
            from sklearn.metrics import r2_score
            from scipy.stats import skew, kurtosis
            print("[DEBUG] 15.3. Iniciando bloque de Curvas Ajuste Real vs Predicho y Residuos para Random Forest optimizado")

            # 1. Seleccionar mejor configuraci√≥n y normalizar payload
            best_idx  = df_rf['Score'].idxmax()
            best_row  = summary_rf[best_idx]

            payload_raw = OPT_MODELS[('rf', best_row['Selecci√≥n X'], best_row['Motor'])]
            p = _normalize_payload(payload_raw)

            model_rf     = p['model']
            sx_rf, sy_rf = p['sx'], p['sy']
            cols_rf      = p['cols']
            score_rf     = p['score']
            metric_rf    = p['metric']
            best_params_rf = p['best_params']

            # ‚Äî‚Äî‚Äî 15.1 Sanitizaci√≥n unificada de columnas para RF ‚Äî‚Äî‚Äî
            sanitized_cols_rf = [sanitize_name(c) for c in cols_rf]
            missing_rf = set(sanitized_cols_rf) - set(X_test.columns)
            if missing_rf:
                print(f"[WARNING] RF omitido estas columnas por no existir en X_test: {sorted(missing_rf)}")
            cols_valid_rf = [c for c in sanitized_cols_rf if c in X_test.columns]

            # Selecci√≥n segura de test
            X_test_sel = X_test[cols_valid_rf].copy()

            # Preparar datos de prueba
            #X_test_sel = X_test[cols_rf]
            y_true = Y_test.values.ravel()
            if sx_rf and sy_rf:
                X_scaled = sx_rf.transform(X_test_sel)
                y_pred = sy_rf.inverse_transform(model_rf.predict(X_scaled).reshape(-1,1)).ravel()
            elif sx_rf:
                X_scaled = sx_rf.transform(X_test_sel)
                y_pred = model_rf.predict(X_scaled)
            else:
                y_pred = model_rf.predict(X_test_sel)

            # Gr√°fica Predicho vs Real
            fig1, ax1 = plt.subplots(figsize=(6,4))
            ax1.scatter(y_true, y_pred, alpha=0.6)
            ax1.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
            ax1.set_xlabel("Y real")
            ax1.set_ylabel("Y predicho")
            ax1.set_title(f"RF Optimizado: Predicho vs Real ({best_row['Selecci√≥n X']}-{best_row['Motor']})")
            self.sections.append((
                f"### Random Forest Optimizado: Predicho vs Real ({best_row['Selecci√≥n X']}-{best_row['Motor']})", fig1
            ))

            # Gr√°fica Residuos
            residuals = y_true - y_pred
            fig2, ax2 = plt.subplots(figsize=(6,4))
            ax2.scatter(y_pred, residuals, alpha=0.6)
            ax2.axhline(0, color='r', linestyle='--', lw=2)
            ax2.set_xlabel("Y predicho")
            ax2.set_ylabel("Residuo")
            ax2.set_title(f"RF Optimizado: Residuos ({best_row['Selecci√≥n X']}-{best_row['Motor']})")
            self.sections.append((
                f"### Random Forest Optimizado: Residuos ({best_row['Selecci√≥n X']}-{best_row['Motor']})", fig2
            ))

            # Estad√≠sticas de residuos
            mean_res = float(residuals.mean())
            std_res = float(residuals.std())
            skew_res = float(skew(residuals))
            kurt_res = float(kurtosis(residuals))
            q25, q50, q75 = [float(x) for x in np.quantile(residuals, [0.25, 0.5, 0.75])]
            df_stats = pd.DataFrame({
                'M√©trica':['Media','Desviaci√≥n','Skew','Kurtosis','25%','50%','75%'],
                'Valor':[mean_res,std_res,skew_res,kurt_res,q25,q50,q75]
            })
            self.sections.append((
                f"### Random Forest Optimizado: Estad√≠sticas de Residuos ({best_row['Selecci√≥n X']}-{best_row['Motor']})", df_stats
            ))

            # An√°lisis generativo IA de calidad de ajuste
            print("[DEBUG] 15.4. Llamando IA para an√°lisis de curvas Random Forest")
            prompt_curves_rf = (
                f"Para el Random Forest optimizado (selecci√≥n {best_row['Selecci√≥n X']}, motor {best_row['Motor']}), tiene:\n"
                f"- Rango Y real: [{y_true.min():.4f}, {y_true.max():.4f}]\n"
                f"- Rango Y pred: [{y_pred.min():.4f}, {y_pred.max():.4f}]\n"
                f"- Residuales: media={mean_res:.4f}, std={std_res:.4f}, skew={skew_res:.4f}, kurtosis={kurt_res:.4f}, quantiles 25%={q25:.4f}, 50%={q50:.4f}, 75%={q75:.4f}.\n"
                "1. Analiza la gr√°fica Predicho vs Real y comenta sobre sesgo o varianza.\n"
                "2. Interpreta la distribuci√≥n de residuos: sesgos sistem√°ticos, heterocedasticidad y normalidad.\n"
                "3. Sugiere acciones para mejorar el ajuste si detectas problemas (p.ej. m√°s √°rboles, regularizaci√≥n, m√°s datos...)."
            )
            analysis_curves_rf = call_openai_explanation(prompt_curves_rf)
            self.sections.append((
                '### Random Forest Optimizado: An√°lisis Calidad Ajuste', analysis_curves_rf
            ))
            # --- Fin bloque 1 ---

            # --- 2. Importancia Relativa de Hiperpar√°metros para Random Forest Optimizado ---
            from sklearn import utils
            import seaborn as sns

            print("[DEBUG] 15.5. Iniciando bloque de Importancia Relativa de Hiperpar√°metros para RF optimizado")

            # Construir matriz Score vs n_estimators y max_depth para heatmap
            # (si existen ambos hiperpar√°metros en Best_Params)
            params_for_heat = ['n_estimators', 'max_depth']
            heat_records = []
            for r in summary_rf:
                bp = r['Best_Params']
                if all(p in bp for p in params_for_heat):
                    heat_records.append({
                        'n_estimators': bp['n_estimators'],
                        'max_depth':    bp['max_depth'],
                        'Score':        r['Score']
                    })
            if heat_records:
                df_heat = pd.DataFrame(heat_records)
                heat = df_heat.pivot(index='n_estimators', columns='max_depth', values='Score')
                fig_heat, ax_heat = plt.subplots(figsize=(6,5))
                sns.heatmap(heat, annot=True, fmt='.4f', ax=ax_heat)
                ax_heat.set_title('RF Optimizado: Heatmap Score vs n_estimators y max_depth')
                self.sections.append((
                    '### RF Optimizado: Heatmap Score vs n_estimators & max_depth', fig_heat
                ))

            # Sensibilidad ¬±10% sobre cada hiperpar√°metro de cada entrada
            sens = []
            for r in summary_rf:
                base_score = r['Score']
                bp = r['Best_Params']
                for param, base_val in bp.items():
                    if isinstance(base_val, (int, float)):
                        for factor, label in [(1.1, '+10%'), (0.9, '-10%')]:
                            sens.append({
                                'Par√°metro': param,
                                'Cambio':    label,
                                '% Œî Score': (base_score * factor - base_score) / abs(base_score) * 100,
                                'Selecci√≥n X': r['Selecci√≥n X'],
                                'Motor':      r['Motor']
                            })
            if sens:
                df_sens = pd.DataFrame(sens)
                fig_sens, ax_sens = plt.subplots(figsize=(6,4))
                sns.barplot(data=df_sens, x='% Œî Score', y='Par√°metro', hue='Cambio', ax=ax_sens)
                ax_sens.set_title('RF Optimizado: Sensibilidad del Score ¬±10%')
                self.sections.append((
                    '### RF Optimizado: Sensibilidad del Score', fig_sens
                ))

            # IA: explicar qu√© par√°metro impulsa m√°s mejora y por qu√©
            print("[DEBUG] 15.6. Llamando IA para importancia de hiperpar√°metros RF")
            lines = [f"{row['Par√°metro']} {row['Cambio']} ‚Üí {row['% Œî Score']:.2f}%"
                    for row in sens if row['Selecci√≥n X']==best_row['Selecci√≥n X'] and row['Motor']==best_row['Motor']]
            prompt_hp_rf = (
                "Sensibilidad del Score al ¬±10% para el mejor RF optimizado "
                f"(selecci√≥n {best_row['Selecci√≥n X']}, motor {best_row['Motor']}):\n" +
                "\n".join(lines) +
                "\n\n1. ¬øQu√© hiperpar√°metro impulsa m√°s la mejora y por qu√©?\n"
                "2. Sugiere focos de ajuste prioritarios basados en esta sensibilidad."
            )
            analysis_hp_rf = call_openai_explanation(prompt_hp_rf)
            self.sections.append((
                '### RF Optimizado: IA Importancia Hiperpar√°metros', analysis_hp_rf
            ))
            # ---- Fin bloque 2 ----

            # --- 3. Distribuci√≥n de M√©tricas en Validaci√≥n Cruzada para Random Forest Optimizado ---
            from sklearn.model_selection import cross_validate
            print("[DEBUG] 15.7. Calculando distribuci√≥n de m√©tricas CV para Random Forest optimizado")

            # Identificar mejor configuraci√≥n
            best_idx_rf = df_rf['Score'].idxmax()
            best_row_rf = summary_rf[best_idx_rf]

            payload_raw = OPT_MODELS[('rf', best_row_rf['Selecci√≥n X'], best_row_rf['Motor'])]
            p = _normalize_payload(payload_raw)

            model_cv = p['model']
            sx_cv    = p['sx']
            cols_cv  = p['cols']

            # Preparar datos de entrenamiento escalados
            X_cv = X_train[cols_cv].copy()
            y_cv = Y_train.values.ravel()
            if sx_cv:
                X_cv_scaled = sx_cv.transform(X_cv)
            else:
                X_cv_scaled = X_cv

            # Cross-validate con m√©tricas m√∫ltiples
            cv_results_rf = cross_validate(
                model_cv, X_cv_scaled, y_cv,
                cv=5,
                scoring={
                    'r2':'r2',
                    'neg_mse':'neg_mean_squared_error',
                    'neg_mae':'neg_mean_absolute_error'
                },
                return_train_score=False
            )

            # Procesar resultados
            r2_scores_rf  = cv_results_rf['test_r2']
            mse_scores_rf = [-v for v in cv_results_rf['test_neg_mse']]
            mae_scores_rf = [-v for v in cv_results_rf['test_neg_mae']]
            rmse_scores_rf = np.sqrt(mse_scores_rf)

            df_cv_rf = pd.DataFrame({
                'R2': r2_scores_rf,
                'MSE': mse_scores_rf,
                'MAE': mae_scores_rf,
                'RMSE': rmse_scores_rf
            })

            # 3.1 Boxplot de m√©tricas por fold
            fig_cv_rf, ax_cv_rf = plt.subplots(figsize=(6,4))
            sns.boxplot(data=df_cv_rf, ax=ax_cv_rf)
            ax_cv_rf.set_title('RF Optimizado: Distribuci√≥n de M√©tricas CV')
            self.sections.append((
                '### Random Forest Optimizado: Distribuci√≥n de M√©tricas CV', fig_cv_rf
            ))

            # 3.2 Tabla con media ¬± desviaci√≥n
            stats_cv_rf = df_cv_rf.agg(['mean','std']).T.reset_index().rename(columns={
                'index':'M√©trica','mean':'Media','std':'Desviaci√≥n'
            })
            self.sections.append((
                '### Random Forest Optimizado: Estad√≠sticas CV por Fold', stats_cv_rf
            ))

            # 3.3 An√°lisis Generativo IA de Estabilidad CV
            print("[DEBUG] 15.8. Llamando IA para estabilidad CV Random Forest")
            prompt_cv_rf = (
                f"Validaci√≥n cruzada 5 folds RF optimizado (Selecci√≥n {best_row_rf['Selecci√≥n X']}, Motor {best_row_rf['Motor']}):\n"
                f"- R2 por fold: {r2_scores_rf.tolist()} \n"
                f"- MAE por fold: {mae_scores_rf}\n"
                f"- RMSE por fold: {rmse_scores_rf}\n"
                "Analiza la dispersi√≥n de cada m√©trica y comenta sobre la estabilidad y generalizaci√≥n del modelo."
            )
            analysis_cv_rf = call_openai_explanation(prompt_cv_rf)
            self.sections.append((
                '### Random Forest Optimizado: An√°lisis Estabilidad CV', analysis_cv_rf
            ))
            # --- Fin Bloque 3 ---

            # --- 4. Curvas de Aprendizaje y Validaci√≥n para Random Forest Optimizado ---
            from sklearn.model_selection import learning_curve, validation_curve
            import numpy as np

            print("[DEBUG] 15.9. Iniciando bloque de Curvas de Aprendizaje y Validaci√≥n para Random Forest optimizado")

            # Seleccionar mejor configuraci√≥n seg√∫n Score
            best_idx = df_rf['Score'].idxmax()
            best_row = summary_rf[best_idx]

            payload_raw = OPT_MODELS[('rf', best_row['Selecci√≥n X'], best_row['Motor'])]
            p = _normalize_payload(payload_raw)

            model_rf = p['model']
            sx_rf    = p['sx']
            cols_rf  = p['cols']

            # Preparar datos de entrenamiento escalados
            X_train_sel = X_train[cols_rf]
            y_train = Y_train.values.ravel()
            X_train_scaled = sx_rf.transform(X_train_sel) if sx_rf else X_train_sel

            # 4.1 Curva de Aprendizaje (R¬≤)
            train_sizes, train_scores, val_scores = learning_curve(
                model_rf, X_train_scaled, y_train,
                cv=5, scoring='r2', train_sizes=np.linspace(0.1,1.0,5), n_jobs=-1
            )
            train_mean = np.mean(train_scores, axis=1)
            val_mean   = np.mean(val_scores,   axis=1)
            fig_lc, ax_lc = plt.subplots(figsize=(6,4))
            ax_lc.plot(train_sizes, train_mean, 'o-', label='Train R¬≤')
            ax_lc.plot(train_sizes, val_mean,   'o-', label='CV R¬≤')
            ax_lc.set_title('RF Optimizado: Curva de Aprendizaje')
            ax_lc.set_xlabel('Tama√±o del set de entrenamiento')
            ax_lc.set_ylabel('R¬≤')
            ax_lc.legend()
            self.sections.append((
                '### RF Optimizado: Curva de Aprendizaje', fig_lc
            ))

            # Funci√≥n auxiliar para Curvas de Validaci√≥n
            def plot_vc(param_name, param_range):
                  # Ajuste: validation_curve devuelve solo train_scores y test_scores
                train_scores_vc, val_scores_vc = validation_curve(
                    model_rf, X_train_scaled, y_train,
                    param_name=param_name, param_range=param_range,
                    cv=5, scoring='r2', n_jobs=-1
                )
                fig, ax = plt.subplots(figsize=(6,4))
                ax.plot(param_range, np.mean(train_scores_vc, axis=1), 'o-', label='Train R¬≤')
                ax.plot(param_range, np.mean(val_scores_vc, axis=1), 'o-', label='CV R¬≤')
                ax.set_title(f"RF Optimizado: Curva de Validaci√≥n {param_name}")
                ax.set_xlabel(param_name)
                ax.set_ylabel('R¬≤')
                if param_name == 'n_estimators':
                    ax.set_xscale('log')
                ax.legend()
                return fig, train_scores_vc, val_scores_vc

            # 4.2 Curva de Validaci√≥n n_estimators
            param_range_n = np.arange(50, 501, 50)
            fig_vc_n, tsn, vsn = plot_vc('n_estimators', param_range_n)
            self.sections.append((
                '### RF Optimizado: Curva de Validaci√≥n n_estimators', fig_vc_n
            ))

            # 4.3 Curva de Validaci√≥n max_depth
            param_range_md = np.arange(3, 16, 2)
            fig_vc_md, tsm, vsm = plot_vc('max_depth', param_range_md)
            self.sections.append((
                '### RF Optimizado: Curva de Validaci√≥n max_depth', fig_vc_md
            ))

            # 4.4 Interpretaci√≥n IA de Curvas
            print("[DEBUG] 15.10. Llamando IA para an√°lisis de curvas Random Forest")
            prompt_curvas_rf = (
                f"Random Forest optimizado (Selecci√≥n {best_row['Selecci√≥n X']}, Motor {best_row['Motor']}):\n"
                f"- Curva de Aprendizaje: tama√±os={train_sizes.tolist()}, train={train_mean.tolist()}, cv={val_mean.tolist()}\n"
                f"- Curva de Validaci√≥n n_estimators: {param_range_n.tolist()}, train={np.mean(tsn,axis=1).tolist()}, cv={np.mean(vsn,axis=1).tolist()}\n"
                f"- Curva de Validaci√≥n max_depth: {param_range_md.tolist()}, train={np.mean(tsm,axis=1).tolist()}, cv={np.mean(vsm,axis=1).tolist()}\n\n"
                "1. Analiza cada curva e identifica underfitting o overfitting.\n"
                "2. Se√±ala brechas clave entre entrenamiento y validaci√≥n y su impacto en la generalizaci√≥n.\n"
                "3. Recomienda ajustes concretos de n_estimators y max_depth para mejorar el modelo."
            )
            analysis_vc_rf = call_openai_explanation(prompt_curvas_rf)
            self.sections.append((
                '### RF Optimizado: Interpretaci√≥n IA de Curvas de Aprendizaje y Validaci√≥n', analysis_vc_rf
            ))
            # --- Fin Bloque 4 ---

            # --- 5. Curvas de Calibraci√≥n y Predicci√≥n de Intervalos para Random Forest Optimizado ---
            from sklearn.calibration import calibration_curve
            import pandas as _pd

            print("[DEBUG] 15.11. Iniciando bloque de Curvas de Calibraci√≥n y Predicci√≥n de Intervalos para Random Forest optimizado")

            # Preparar datos de prueba
            y_true_rf = Y_test.values.ravel()
            y_pred_scaled = model_rf.predict(X_test[cols_rf])
            y_pred_rf = sy_rf.inverse_transform(y_pred_scaled.reshape(-1,1)).ravel() if sy_rf else y_pred_scaled

            # 5.1 Curva de calibraci√≥n (binned reliability plot para regresi√≥n)
            bins = 10
            df_cal = _pd.DataFrame({'y_pred': y_pred_rf, 'y_true': y_true_rf})
            try:
                df_cal['bin'] = _pd.qcut(df_cal['y_pred'], q=bins, duplicates='drop')
            except:
                df_cal['bin'] = _pd.cut(df_cal['y_pred'], bins=bins)
            grp = df_cal.groupby('bin', observed=True).agg({'y_pred': 'mean', 'y_true': 'mean'})
            prob_pred, prob_true = grp['y_pred'].values, grp['y_true'].values
            fig_cal, ax_cal = plt.subplots(figsize=(6, 4))
            ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2)
            ax_cal.plot([prob_pred.min(), prob_pred.max()], [prob_pred.min(), prob_pred.max()], 'k--')
            ax_cal.set_xlabel('Predicci√≥n promedio en bin')
            ax_cal.set_ylabel('Valor real promedio')
            ax_cal.set_title('RF Optimizado: Curva de Calibraci√≥n')
            self.sections.append((
                '### RF Optimizado: Curva de Calibraci√≥n', fig_cal
            ))

            # 5.2 Intervalos de predicci√≥n ¬±1 STD de residuos
            residuals_rf = y_true_rf - y_pred_rf
            std_res_rf = np.std(residuals_rf)
            upper_rf = y_pred_rf + std_res_rf
            lower_rf = y_pred_rf - std_res_rf
            fig_int, ax_int = plt.subplots(figsize=(6, 4))
            ax_int.plot(y_true_rf, label='Y real')
            ax_int.plot(y_pred_rf, label='Predicci√≥n')
            ax_int.fill_between(range(len(y_pred_rf)), lower_rf, upper_rf, alpha=0.3, label='¬±1 STD residuo')
            ax_int.set_xlabel('√çndice de muestra')
            ax_int.set_ylabel('Valor')
            ax_int.set_title('RF Optimizado: Intervalos de Predicci√≥n')
            ax_int.legend()
            self.sections.append((
                '### RF Optimizado: Intervalos de Predicci√≥n', fig_int
            ))

            # 5.3 An√°lisis Generativo IA de Incertidumbre y Calibraci√≥n
            print("[DEBUG] 15.12. Llamando IA para an√°lisis de incertidumbre y calibraci√≥n RF optimizado")
            prompt_ci_rf = (
                f"Curva de calibraci√≥n (pred:{prob_pred.tolist()}, real:{prob_true.tolist()}) y "
                f"intervalos ¬±1 STD (std_res={std_res_rf:.4f}).\n"
                "1. Eval√∫a la fiabilidad de los intervalos de incertidumbre.\n"
                "2. Identifica infravaloraci√≥n de errores altos o patrones de heterocedasticidad.\n"
                "3. Sugiere mejoras para la calibraci√≥n y estimaci√≥n de incertidumbre."
            )
            analysis_ci_rf = call_openai_explanation(prompt_ci_rf)
            self.sections.append((
                '### RF Optimizado: An√°lisis de Incertidumbre y Calibraci√≥n', analysis_ci_rf
            ))
            # --- Fin Bloque 5 ---

            # --- 6. Resumen Ejecutivo y Road-Map de Siguientes Pasos para Random Forest Optimizado ---
            print("[DEBUG] 15.13. Iniciando bloque de Resumen Ejecutivo y Road-Map para Random Forest optimizado")
            # Variables clave
            sel_rf    = best_row['Selecci√≥n X']
            eng_rf    = best_row['Motor']
            best_score_rf = best_row['Score']
            # Estad√≠sticas de residuos y validaci√≥n
            cv_std    = float(np.std(val_mean))
            res_std   = std_res_rf
            res_kurt  = kurtosis(residuals_rf)
            q25_rf, q50_rf, q75_rf = [float(x) for x in np.quantile(residuals_rf, [0.25,0.5,0.75])]

            summary_md_rf = (
                "**Puntos Clave Optimizaci√≥n Random Forest:**\n "
                f"- **Mejor combinaci√≥n:** Selecci√≥n `{sel_rf}` + motor `{eng_rf}` ‚ûú **Score** = {best_score_rf:.4f}\n"
                f"- **Robustez del modelo:** desviaci√≥n est√°ndar CV = {cv_std:.4f}, std residuos = {res_std:.4f}\n"
                f"- **Curtosis de residuos:** {res_kurt:.4f}, quantiles (25%,50%,75%) = ({q25_rf:.4f},{q50_rf:.4f},{q75_rf:.4f})\n"
                "- **Recomendaciones inmediatas:**\n"
                "  1. Ajustar `n_estimators` y `max_depth` seg√∫n el balance sesgo-varianza observado.\n"
                "  2. Explorar regularizaci√≥n adicional (`min_samples_split`, `min_samples_leaf`) para reducir varianza.\n"
                "  3. Ampliar validaci√≥n cruzada a 7‚Äì10 folds e incluir `oob_score` para medir robustez.\n"
                "  4. Considerar ensambles adicionales (e.g., GradientBoosting, LightGBM) para comparar rendimiento"
            )
            self.sections.append((
                '### RF Optimizado: Resumen Ejecutivo y Road-Map', summary_md_rf
            ))

            print("[DEBUG] 15.14. Llamando IA para Resumen Ejecutivo y Road-Map RF optimizado")
            prompt_exec_rf = (
                "Eres un investigador de Machine Learning avanzado. Bas√°ndote en los puntos clave de optimizaci√≥n:\n"
                f"{summary_md_rf}\n"
                "1. Desarrolla un an√°lisis detallado en p√°rrafos separados para cada punto clave.\n"
                "2. Prop√≥n un plan de acci√≥n prioritizado de 3‚Äì5 pasos claros para stakeholders.\n"
                "3. Finaliza con un breve resumen ejecutivo de 2‚Äì3 p√°rrafos enfatizando impacto y pr√≥ximos hitos."
            )
            analysis_exec_rf = call_openai_explanation(prompt_exec_rf)
            self.sections.append((
                '### RF Optimizado: Resumen Ejecutivo IA', analysis_exec_rf
            ))
            # --- Fin Bloque 6 ---

        except Exception as e:
            self.sections.append((
                '### ‚ö†Ô∏è Error en secci√≥n Optimizaci√≥n Random Forest',
                f"Se produjo un error en Optimizaci√≥n Random Forest: {e}"
            ))

        # =============================================================================
        # 16. Optimizaci√≥n Modelo RNN
        # =============================================================================
        import numpy as np
        # --- Bloque 0: Resumen Optimizaci√≥n RNN ---
        try:
            print("[DEBUG] 16.1. Bloque 0 Optimizaci√≥n RNN: Resumen de m√©todos y motores")

            # Funci√≥n de invocaci√≥n a OpenAI (igual que en SVR, NN, XGBoost, RF)
            def call_openai_explanation(prompt: str, model: str = "gpt-4") -> str:
                try:
                    response = _client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content":
                                "Eres un experto en optimizaci√≥n de hiperpar√°metros de redes neuronales recurrentes. "
                                "Analiza y ofrece conclusiones detalladas basadas en los datos proporcionados."
                            },
                            {"role": "user", "content": prompt}
                        ],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS
                    )
                    return response.choices[0].message.content.strip()
                except Exception as e:
                    return f"[Error llamando a OpenAI: {e}]"

            # 0.1) Verificar resultados en OPT_MODELS
            if 'OPT_MODELS' not in globals() or not isinstance(OPT_MODELS, dict):
                raise RuntimeError("No se encontr√≥ OPT_MODELS con resultados de optimizaci√≥n RNN")

            valid_engines = {'RandomSearch', 'Bayesian', 'Hyperband', 'Optuna'}
            rnn_entries = {
                k: v for k, v in OPT_MODELS.items()
                if isinstance(k, tuple) and k[0] == 'rnn' and k[2] in valid_engines
            }
            if not rnn_entries:
                raise RuntimeError("No se encontraron optimizaciones RNN en OPT_MODELS")

            # ‚Äî‚Äî‚Äî Normalizar payload del mejor RNN para todos los bloques ‚Äî‚Äî‚Äî
            # Elegimos la clave que maximiza/minimiza el score seg√∫n la m√©trica
            # (usamos la misma l√≥gica que df_sel, pero sobre rnn_entries)
            keys = list(rnn_entries.keys())
            scores = [rnn_entries[k]['score'] for k in keys]
            metrics = [rnn_entries[k].get('metric','').upper() for k in keys]
            if metrics[0] == 'R2':
                best_idx = int(np.argmax(scores))
            else:
                best_idx = int(np.argmin(scores))
            best_key = keys[best_idx]

            payload_raw      = OPT_MODELS[best_key]
            p                = _normalize_payload(payload_raw)
            model_rnn        = p['model']
            sx_rnn, sy_rnn   = p.get('sx'), p.get('sy')
            cols_rnn         = p['cols']
            score_rnn        = p['score']
            metric_rnn       = p['metric']
            best_params_rnn  = p['best_params']
            # ‚Äî‚Äî‚Äî fin normalizaci√≥n ‚Äî‚Äî‚Äî

            # 0.2) Construir lista de registros resumen
            summary_records = []
            for (_, metodo, motor), payload in rnn_entries.items():
                score = payload.get('score')
                # Extraer hiperpar√°metros √≥ptimos
                best_est = payload.get('best')
                if best_est is not None and hasattr(best_est, 'get_params'):
                    params = best_est.get_params()
                else:
                    params = payload.get('params', {}) or payload.get('best_params', {})

                # S√≥lo los hiperpar√°metros relevantes
                hp_keys = ['units', 'dropout_rate', 'learning_rate', 'epochs', 'batch_size']
                best_hp = {k: params.get(k) for k in hp_keys if k in params}

                # A√±adir registro
                rec = {
                    'M√©todo': metodo,
                    'Motor': motor,
                    'metric': payload.get('metric'),  # ‚Üê aqu√≠ incluyes la m√©trica
                    'Score': score
                }
                rec.update({f"Best_{k}": v for k, v in best_hp.items()})
                summary_records.append(rec)

            # 0.3) DataFrame de resumen
            df_rnn = pd.DataFrame(summary_records)
            df_rnn.rename(
                columns={col: col.replace("Best_", "") for col in df_rnn.columns if col.startswith("Best_")},
                inplace=True
            )
            self.sections.append((
                "### RNN Optimizaci√≥n: Resumen de M√©todos y Motores",
                df_rnn
            ))

            # 0.4) Preparar prompt para IA
            prompt_lines = []
            for rec in summary_records:
                hp_str = ", ".join(f"{k}={rec[f'Best_{k}']}" for k in best_hp.keys())
                prompt_lines.append(
                    f"M√©todo: {rec['M√©todo']}, Motor: {rec['Motor']}, "
                    f"Score: {rec['Score']:.4f}, Hiperpar√°metros: {hp_str}"
                )
            prompt = (
                "He obtenido los siguientes resultados de optimizaci√≥n para el modelo RNN:\n\n"
                + "\n".join(prompt_lines)
                + "\n\n"
                "1. Describe en detalle las fortalezas y debilidades de cada motor de b√∫squeda "
                "(RandomSearch, Bayesian, Hyperband, Optuna) aplicado a RNN.\n"
                "2. Compara los scores y explica por qu√© una configuraci√≥n es superior.\n"
                "3. Analiza el impacto de los hiperpar√°metros optimizados en entrenamiento y generalizaci√≥n.\n"
                "4. Prop√≥n estrategias avanzadas para mejorar la RNN "
                "(learning‚Äêrate scheduling, regularizaci√≥n, early stopping, augmentation de series temporales).\n"
                "5. Sugiere un roadmap de pr√≥ximos pasos para validar robustez y escalar el modelo."
            )

            print("[DEBUG] 16.2. Llamando a OpenAI para an√°lisis generativo RNN optimizaci√≥n")
            analysis = call_openai_explanation(prompt)
            self.sections.append((
                "### RNN Optimizaci√≥n: An√°lisis Generativo",
                analysis
            ))
            # --- Fin Bloque 0 ---

            # --- 1. Curvas de Ajuste Real vs. Predicho y Residuos para Random Forest Optimizado ---
            try:
                print("[DEBUG] 16.3. Iniciando Bloque 1: Curvas Real vs Predicho y Residuos RNN Optimizado")

                # ========== Cargar modelo RNN entrenado desde metadatos ==========
                import pickle, glob

                # Buscar el archivo m√°s reciente para el m√©todo y motor seleccionados
                archivos_meta = sorted(glob.glob(f"modelos_opt/rnn_{metodo.lower()}_{motor.lower()}_opt_*.pkl"))
                if not archivos_meta:
                    raise FileNotFoundError(f"No se encontr√≥ el archivo de metadatos para {metodo} + {motor}")
                archivo_meta = archivos_meta[-1]

                # Cargar metadatos
                with open(archivo_meta, "rb") as f:
                    metadata = pickle.load(f)

                # Reconstruir ruta al modelo .keras
                ts = metadata["fecha"]
                ruta_modelo = f"modelos_opt/rnn_{metodo.lower()}_{motor.lower()}_opt_{ts}.keras"

                # Cargar modelo
                model_rnn = load_model(ruta_modelo)


                import pickle
                from scipy.stats import skew, kurtosis
                from sklearn.metrics import r2_score
                import matplotlib.pyplot as plt
                from tensorflow.keras.models import load_model

                # 1.1 Seleccionar la mejor configuraci√≥n seg√∫n la m√©trica
                # Reconstruimos un peque√±o DataFrame para elegir el mejor √≠ndice
                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
                df_sel = pd.DataFrame([
                    {
                        'M√©todo': k[1],
                        'Motor':  k[2],
                        'Score':  v['score'],
                        'M√©trica': v['metric']
                    }
                    for k, v in OPT_MODELS.items()
                    if k[0]=='rnn' and k[2] in valid_engines
                ])
                if df_sel.empty:
                    raise RuntimeError("No hay optimizaciones RNN registradas en OPT_MODELS")
                # Elegir mejor row
                if df_sel['M√©trica'].str.upper().iloc[0] == 'R2':
                    idx_best = df_sel['Score'].idxmax()
                else:
                    idx_best = df_sel['Score'].idxmin()
                best_row = df_sel.loc[idx_best]
                metodo   = best_row['M√©todo']
                motor    = best_row['Motor']

                # 1.1bis) Extraer los params del payload en lugar de Best_*
                payload    = OPT_MODELS[('rnn', metodo, motor)]
                # si guardaste 'params' en OPT_MODELS‚Ä¶
                params     = payload.get('params') or payload['best'].get_params()
                # s√≥lo las cinco keys que nos interesan
                hp_keys    = ['units','dropout_rate','learning_rate','epochs','batch_size']
                best_params = { k: params[k] for k in hp_keys }

                # 1.2 Cargar payload y metadatos
                # Usamos el payload normalizado:
                model     = model_rnn
                sx        = sx_rnn
                sy        = sy_rnn
                cols      = cols_rnn

                # ‚Äî‚Äî‚Äî Sanitizaci√≥n unificada de columnas para RNN ‚Äî‚Äî‚Äî
                raw_cols_rnn       = cols_rnn      # viene de _normalize_payload
                sanitized_cols_rnn = [sanitize_name(c) for c in raw_cols_rnn]
                effective_cols     = [c for c in sanitized_cols_rnn if c in X_test.columns]
                print(f"[DEBUG] 16.4. RNN cols esperadas: {len(raw_cols_rnn)}, sanitizadas v√°lidas: {len(effective_cols)} ‚Üí {effective_cols}")

                # ‚úîÔ∏è Se mantiene: comprobaci√≥n del modelo
                from tensorflow.keras.models import Sequential
                if not isinstance(model_rnn, Sequential):
                    raise TypeError("[ERROR] El objeto 'model_rnn' no es un modelo v√°lido de Keras. ¬øSe ha sobrescrito accidentalmente?")

                # ========== Verificar columnas ==========
                expected_cols = cols_rnn
                actual_cols = [c for c in expected_cols if c in X_test.columns]
                print(f"[DEBUG] 16.5. RNN cols esperadas: {len(expected_cols)}, sanitizadas v√°lidas: {len(actual_cols)} ‚Üí {actual_cols}")

                if len(actual_cols) != len(expected_cols):
                    raise ValueError(
                        f"[ERROR] Las columnas del modelo RNN ({len(expected_cols)} esperadas) "
                        f"no coinciden con las disponibles en X_test ({len(actual_cols)} encontradas)."
                        f"\nEsperadas: {expected_cols}\nEncontradas: {actual_cols}"
                    )

                # ========== Escalar y preparar datos ==========
                X_test_sel_df = X_test[actual_cols]
                X_scaled = sx_rnn.transform(X_test_sel_df.values)
                print(f"[DEBUG] 16.6. X_scaled.shape = {X_scaled.shape}")
                print(f"[DEBUG] 16.7. n_samples = {X_scaled.shape[0]}, n_features = {X_scaled.shape[1]}")

                X3_test = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))
                print(f"[DEBUG] 16.8. X3_test.shape = {X3_test.shape}")
                print("[DEBUG] 16.9. Llamando a model_rnn.predict con entrada:", X3_test.shape)

                # ========== Predicci√≥n ==========
                y_pred_raw = model_rnn.predict(X3_test).ravel()

                print(f"[DEBUG] 16.10. X3_test.shape = {X3_test.shape}")
                print("[DEBUG] 16.11. Llamando a model_rnn.predict con entrada:", X3_test.shape)

                y_pred     = sy_rnn.inverse_transform(y_pred_raw.reshape(-1,1)).ravel() if sy_rnn else y_pred_raw
                y_true     = Y_test.values.ravel()

                # 1.4 Gr√°fica Predicho vs Real
                fig1, ax1 = plt.subplots(figsize=(6,4))
                ax1.scatter(y_true, y_pred, alpha=0.6)
                ax1.plot([y_true.min(), y_true.max()],
                        [y_true.min(), y_true.max()],
                        'r--', linewidth=2, label='Ideal')
                ax1.set_xlabel("Y real")
                ax1.set_ylabel("Y predicho")
                ax1.set_title(f"RNN Optimizado ({metodo}-{motor}) Predicho vs Real")
                ax1.legend()
                self.sections.append((
                    f"### RNN Optimizado: Predicho vs Real ({metodo}-{motor})",
                    fig1
                ))

                # 1.5 Gr√°fica de Residuos
                residuals = y_true - y_pred
                fig2, ax2 = plt.subplots(figsize=(6,4))
                ax2.scatter(y_pred, residuals, alpha=0.6)
                ax2.axhline(0, color='r', linestyle='--', linewidth=2)
                ax2.set_xlabel("Y predicho")
                ax2.set_ylabel("Residuo")
                ax2.set_title(f"RNN Optimizado ({metodo}-{motor}) Residuos")
                self.sections.append((
                    f"### RNN Optimizado: Residuos ({metodo}-{motor})",
                    fig2
                ))

                # 1.6 Tabla de estad√≠sticas de residuos
                stats_df = pd.DataFrame({
                    'M√©trica': ['Media', 'Desviaci√≥n', 'Skew', 'Kurtosis', '25%', '50%', '75%'],
                    'Valor': [
                        residuals.mean(),
                        residuals.std(),
                        skew(residuals),
                        kurtosis(residuals),
                        *np.quantile(residuals, [0.25, 0.5, 0.75])
                    ]
                })
                self.sections.append((
                    f"### RNN Optimizado: Estad√≠sticas de Residuos ({metodo}-{motor})",
                    stats_df
                ))

                # 1.7 An√°lisis generativo con IA
                prompt = (
                    f"Para el mejor RNN optimizado (M√©todo={metodo}, Motor={motor}) tenemos:\n"
                    f"- Rango Y real: [{y_true.min():.4f}, {y_true.max():.4f}]\n"
                    f"- Rango Y predicho: [{y_pred.min():.4f}, {y_pred.max():.4f}]\n"
                    f"- Estad√≠sticas de residuos: media={residuals.mean():.4f}, "
                    f"std={residuals.std():.4f}, skew={skew(residuals):.4f}, "
                    f"kurtosis={kurtosis(residuals):.4f}, "
                    f"quantiles25/50/75={[f'{q:.4f}' for q in np.quantile(residuals,[0.25,0.5,0.75])]}.\n\n"
                    "1. Analiza la calidad del ajuste considerando ambas gr√°ficas: identifica sesgos o heterocedasticidad.\n"
                    "2. Comenta sobre la normalidad de los errores.\n"
                    "3. Prop√≥n ajustes de HPO o transformaciones de datos para mejorar la RNN."
                )
                print("[DEBUG] 16.12. Llamando a OpenAI para an√°lisis de curvas RNN optimizado")
                analysis = call_openai_explanation(prompt)
                self.sections.append((
                    "### RNN Optimizado: An√°lisis Calidad Ajuste",
                    analysis
                ))

            except Exception as e:
                # 1) Imprime la excepci√≥n para trazar el error
                print(f"[DEBUG] Error Bloque¬†1 Optimizaci√≥n RNN: {e}")
                # 2) Luego sigues registrando la secci√≥n de error como antes
                self.sections.append((
                    "### ‚ö†Ô∏è Error Bloque 1 Optimizaci√≥n RNN",
                    f"Se produjo un error en Curvas Real vs Predicho y Residuos RNN: {e}"
                ))
            # --- Fin Bloque 1 ---
            # --- 2. Importancia Relativa de Hiperpar√°metros para RNN Optimizado ---
            try:
                print("[DEBUG] 16.13. Iniciando bloque 2: Importancia de Hiperpar√°metros RNN Optimizado")

                import seaborn as sns
                from sklearn.metrics import r2_score
                import pickle

                # --- a) Recuperar el best_row del bloque 1 ---
                # (Aseg√∫rate de que best_row lo tienes en el scope, √≥ bien vuelve a
                #  reconstruir tu peque√±o df_sel y lo vuelves a extraer)
                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
                df_sel = pd.DataFrame([
                    {'M√©todo':k[1], 'Motor':k[2], 'Score':v['score'], 'M√©trica':v['metric']}
                    for k,v in OPT_MODELS.items()
                    if k[0]=='rnn' and k[2] in valid_engines
                ])
                if df_sel['M√©trica'].str.upper().iloc[0]=='R2':
                    idx_best = df_sel['Score'].idxmax()
                else:
                    idx_best = df_sel['Score'].idxmin()
                best_row = df_sel.loc[idx_best]

                # --- b) Recuperar payload y metadatos de OPT_MODELS ---
                key = ('rnn', best_row['M√©todo'], best_row['Motor'])
                payload = OPT_MODELS[key]

                # 2.1) **Carga aqu√≠** los scalers que guardaste
                # Usamos el payload normalizado:
                model     = model_rnn
                sx        = sx_rnn
                sy        = sy_rnn
                cols      = cols_rnn

                # 2.2) ahora extrae base_score y best_params
                base_score = payload['score']
                if 'params' in payload and payload['params']:
                    best_params = payload['params']
                else:
                    best_params = payload['best'].get_params()

                # ‚îÄ‚îÄ Aqu√≠ definimos de nuevo los subsets ‚îÄ‚îÄ
                X_train_sel = X_train[cols]
                Y_train_sel = Y_train.copy()
                X_test_sel  = X_test[cols]
                Y_test_sel  = Y_test.copy()

                # summary_records viene del bloque 0: lista de dicts con M√©todo, Motor, Score y Best_<hp>
                # Lo transformamos en un DataFrame m√°s ‚Äúusable‚Äù
                df_hp = pd.DataFrame([
                    {
                        'M√©todo'       : rec['M√©todo'],
                        'Motor'        : rec['Motor'],
                        'Score'        : rec['Score'],
                        **{hp: rec[f"Best_{hp}"] for hp in ['units','dropout_rate','learning_rate','epochs','batch_size']
                          if f"Best_{hp}" in rec}
                    }
                    for rec in summary_records
                ])

                # 2.1 Heatmap Score vs combinaci√≥n de dos par√°metros continuos, p.e. learning_rate y dropout_rate
                heat_params = ['learning_rate','dropout_rate']
                heat_recs = []
                for _, row in df_hp.iterrows():
                    if all(p in row and pd.notna(row[p]) for p in heat_params):
                        heat_recs.append({
                            heat_params[0]: row[heat_params[0]],
                            heat_params[1]: row[heat_params[1]],
                            'Score':       row['Score']
                        })
                if heat_recs:
                    df_heat = pd.DataFrame(heat_recs)
                    heat = df_heat.pivot(index=heat_params[0], columns=heat_params[1], values='Score')
                    fig_heat, ax_heat = plt.subplots(figsize=(6,5))
                    sns.heatmap(heat, annot=True, fmt=".4f", ax=ax_heat)
                    ax_heat.set_title('RNN Optimizado: Heatmap Score vs learning_rate y dropout_rate')
                    self.sections.append((
                        "### RNN Optimizado: Heatmap Score vs learning_rate & dropout_rate",
                        fig_heat
                    ))

                # 2.2 Sensibilidad ¬±1% para cada hiperpar√°metro (reentrenando sobre TEST)
                sens = []
                #for param, base_val in best_params.items():
                for param, base_val in list(best_params.items())[:3]:  # ‚ö†Ô∏è limitar a 3 primeros hiperpar√°metros para evitar evaluar todos.
                    if isinstance(base_val, (int, float)):
                        #for factor, label in [(1.01, '+1%'), (0.99, '-1%')]:
                        for factor, label in [(1.05, '+5%'), (0.95, '-5%')]:      # Reducci√≥n del ¬±1% al ¬±5% para evaluar sensibilidad, disminuyendo ciclos de entrenamiento.
                            # Construye nuevos par√°metros variando uno solo
                            new_params = best_params.copy()
                            new_params[param] = base_val * factor

                            # Reentrena el modelo con estos new_params
                            model = RNNRegressor(**new_params, sy=sy)
                            model.fit(
                                sx.transform(X_train_sel.values),
                                sy.transform(Y_train_sel.values.reshape(-1,1)).ravel()
                            )
                            # Eval√∫a en validaci√≥n (o test, seg√∫n prefieras)
                            # ‚Üí aqu√≠ uso X_test_sel y Y_test en lugar de X_val_sel/Y_val
                            Xs = sx.transform(X_test_sel.values)
                            X3 = Xs.reshape((Xs.shape[0], 1, Xs.shape[1]))
                            y_hat_scaled = model.predict(Xs)        # el wrapper a√±ade la dimensi√≥n del ‚Äútimesteps=1‚Äù
                            y_hat        = sy.inverse_transform(y_hat_scaled.reshape(-1,1)).ravel()
                            new_score    = r2_score(Y_test.values.ravel(), y_hat)

                            sens.append({
                              'Par√°metro': param,
                              'Cambio':    label,
                              '% Œî Score': (new_score - base_score) / abs(base_score) * 100,
                              #'% Œî Score': new_score - base_score,
                              'Motor':     best_row['Motor'],
                              'M√©todo':    best_row['M√©todo']
                          })
                if sens:
                    df_sens = pd.DataFrame(sens)
                    fig_sens, ax_sens = plt.subplots(figsize=(6,4))
                    sns.barplot(data=df_sens, x='% Œî Score', y='Par√°metro', hue='Cambio', ax=ax_sens)
                    ax_sens.set_title('RNN Optimizado: Sensibilidad del Score ¬±1%')
                    self.sections.append((
                        "### RNN Optimizado: Sensibilidad del Score",
                        fig_sens
                    ))

                # 2.3 IA: an√°lisis de importancia
                # Filtramos s√≥lo para el mejor (best_row viene de bloque 1)
                lines = []
                for row in sens:
                    if row['M√©todo']==best_row['M√©todo'] and row['Motor']==best_row['Motor']:
                        lines.append(f"{row['Par√°metro']} {row['Cambio']} ‚Üí {row['% Œî Score']:.2f}%")
                prompt_hp_rnn = (
                    f"Sensibilidad del Score al ¬±10% para el mejor RNN optimizado "
                    f"(m√©todo {best_row['M√©todo']}, motor {best_row['Motor']}):\n"
                    + "\n".join(lines)
                    + "\n\n1. ¬øQu√© hiperpar√°metro impulsa m√°s la mejora y por qu√©?\n"
                    "2. Bas√°ndote en esta sensibilidad, ¬øqu√© foco de ajuste priorizar√≠as?"
                )
                print("[DEBUG] 16.14. Llamando a OpenAI para importancia de hiperpar√°metros RNN")
                analysis_hp_rnn = call_openai_explanation(prompt_hp_rnn)
                self.sections.append((
                    "### RNN Optimizado: IA Importancia Hiperpar√°metros",
                    analysis_hp_rnn
                ))

            except Exception as e:
                self.sections.append((
                    "### ‚ö†Ô∏è Error Bloque 2 Optimizaci√≥n RNN",
                    f"Se produjo un error en Importancia de Hiperpar√°metros RNN: {e}"
                ))
            # --- Fin Bloque 2 ---
            # --- 3. Distribuci√≥n de M√©tricas en Validaci√≥n Cruzada para RNN Optimizado ---
            try:
                print("[DEBUG] 16.15. Iniciando bloque 3: Distribuci√≥n de M√©tricas CV para RNN Optimizado")

                import pickle
                from sklearn.model_selection import cross_validate
                from sklearn.pipeline import make_pipeline
                from sklearn.compose import TransformedTargetRegressor
                from sklearn.preprocessing import StandardScaler

                # 3.1) Recuperar payload y metadatos
                cols_cv = cols_rnn

                # 3.2) Pipeline: escalar X ‚Üí RNNRegressor
                rnn_pipe = make_pipeline(
                    StandardScaler(),    # escala X dentro de cada fold
                    RNNRegressor()       # tu wrapper, sin pasar sy aqu√≠
                )

                # 3.3) TransformedTargetRegressor: para escalar Y dentro de cada fold
                rnn_ttr = TransformedTargetRegressor(
                    regressor   = rnn_pipe,
                    transformer = StandardScaler()
                )

                # 3.4) Ejecutar cross_validate usando directamente el pipeline completo
                cv_results = cross_validate(
                    rnn_ttr,
                    X_train[cols_cv].values,
                    Y_train.values.ravel(),
                    #cv=5,
                    cv=3,                                      # A√ëADIDO PARA ALIGERAR LOS CICLOS DE ENTRENAMIENTO CRUZADO
                    scoring={
                        'r2':      'r2',
                        'neg_mse': 'neg_mean_squared_error',
                        'neg_mae': 'neg_mean_absolute_error'
                    },
                    return_train_score=False
                )

                # 3.5) Formatear resultados
                r2_scores  = cv_results['test_r2']
                mse_scores = [-v for v in cv_results['test_neg_mse']]
                mae_scores = [-v for v in cv_results['test_neg_mae']]
                rmse_scores = np.sqrt(mse_scores)

                df_cv = pd.DataFrame({
                    'R2':   r2_scores,
                    'MSE':  mse_scores,
                    'MAE':  mae_scores,
                    'RMSE': rmse_scores
                })

                # 3.6) Boxplot
                fig_cv, ax_cv = plt.subplots(figsize=(6,4))
                sns.boxplot(data=df_cv, ax=ax_cv)
                ax_cv.set_title('RNN Optimizado: Distribuci√≥n de M√©tricas CV')
                self.sections.append((
                    '### RNN Optimizado: Distribuci√≥n de M√©tricas CV', fig_cv
                ))

                # 3.7) Tabla de media ¬± desviaci√≥n
                stats_cv = df_cv.agg(['mean','std']).T.reset_index().rename(columns={
                    'index':'M√©trica','mean':'Media','std':'Desviaci√≥n'
                })
                self.sections.append((
                    '### RNN Optimizado: Estad√≠sticas CV por Fold', stats_cv
                ))

                # 3.8) An√°lisis generativo
                prompt_cv = (
                    f"Validaci√≥n cruzada 5 folds RNN optimizado (M√©todo={best_row['M√©todo']}, "
                    f"Motor={best_row['Motor']}):\n"
                    f"- R2 por fold: {r2_scores.tolist()}\n"
                    f"- MSE por fold: {mse_scores}\n"
                    f"- MAE por fold: {mae_scores}\n"
                    f"- RMSE por fold: {rmse_scores}\n\n"
                    "Analiza la estabilidad y generalizaci√≥n de la RNN bas√°ndote en la dispersi√≥n de cada m√©trica."
                )
                print("[DEBUG] 16.16. Llamando IA para estabilidad CV RNN optimizado")
                analysis_cv = call_openai_explanation(prompt_cv)
                self.sections.append((
                    '### RNN Optimizado: An√°lisis Estabilidad CV', analysis_cv
                ))

            except Exception as e:
                self.sections.append((
                    "### ‚ö†Ô∏è Error Bloque 3 Optimizaci√≥n RNN",
                    f"Se produjo un error en Distribuci√≥n de M√©tricas CV RNN: {e}"
                ))
            # --- Fin Bloque 3 ---

            # --- 4. Curvas de Aprendizaje y Validaci√≥n para RNN Optimizado ---
            # --- 4. Curvas de Aprendizaje y Validaci√≥n para RNN Optimizado ---
            try:
                print("[DEBUG] 16.17. Iniciando Bloque 4: Curvas de Aprendizaje y Validaci√≥n RNN Optimizado")
                import numpy as np
                from sklearn.model_selection import learning_curve, validation_curve
                from sklearn.pipeline import make_pipeline
                from sklearn.compose import TransformedTargetRegressor
                from sklearn.preprocessing import StandardScaler
                import matplotlib.pyplot as plt

                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
                df_sel = pd.DataFrame([
                    {'M√©todo': k[1], 'Motor': k[2], 'Score': v['score'], 'M√©trica': v['metric']}
                    for k,v in OPT_MODELS.items()
                    if k[0]=='rnn' and k[2] in valid_engines
                ])
                if df_sel['M√©trica'].str.upper().iloc[0] == 'R2':
                    idx_best = df_sel['Score'].idxmax()
                else:
                    idx_best = df_sel['Score'].idxmin()
                best_row = df_sel.loc[idx_best]

                p = _normalize_payload(payload_raw)
                best_params = p.get('best_params', {})
                sx_rnn, sy_rnn = p['sx'], p['sy']
                cols_rnn = p['cols']
                model_rnn = p['model']

                if not best_params:
                    best_params = model_rnn.get_params()
                    print("[DEBUG] Se han obtenido best_params desde model.get_params()")

                # ‚ö†Ô∏è Reducci√≥n expl√≠cita de carga
                best_params['epochs'] = min(best_params.get('epochs', 100), 20)
                best_params['verbose'] = 0

                rnn_pipe = make_pipeline(
                    StandardScaler(),
                    RNNRegressor(**best_params)
                )
                rnn_ttr = TransformedTargetRegressor(regressor=rnn_pipe, transformer=StandardScaler())

                X_train_sel = X_train[cols_rnn].values[:250]  # ‚ö†Ô∏è limitar tama√±o
                y_train = Y_train.values.ravel()[:250]

                from joblib import parallel_backend
                with parallel_backend('threading'):
                    train_sizes, train_scores, val_scores = learning_curve(
                        rnn_ttr, X_train_sel, y_train,
                        cv=2,  # ‚ö†Ô∏è menos folds
                        scoring='r2',
                        train_sizes=np.linspace(0.5, 1.0, 2),  # ‚ö†Ô∏è menos tama√±os
                        n_jobs=1
                    )

                train_mean = np.mean(train_scores, axis=1)
                val_mean = np.mean(val_scores, axis=1)

                fig_lc, ax_lc = plt.subplots(figsize=(4.5,2.8))  # ‚ö†Ô∏è m√°s peque√±o
                ax_lc.plot(train_sizes, train_mean, 'o-', label='Train R¬≤')
                ax_lc.plot(train_sizes, val_mean, 'o-', label='CV R¬≤')
                ax_lc.set_title('RNN Optimizado: Curva de Aprendizaje')
                ax_lc.set_xlabel('Tama√±o del set de entrenamiento')
                ax_lc.set_ylabel('R¬≤')
                ax_lc.legend()
                self.sections.append((
                    '### RNN Optimizado: Curva de Aprendizaje', fig_lc
                ))

                if 'units' not in best_params:
                    raise KeyError("[ERROR] El par√°metro 'units' no est√° presente en best_params. Claves disponibles: " + str(list(best_params.keys())))

                #units_range = np.unique(np.linspace(
                #    max(1, best_params['units']//2),
                #    best_params['units']*2,
                #    2, dtype=int  # ‚ö†Ô∏è solo dos valores
                #))
                #units_range = [best_params['units']]  # ‚ö†Ô∏è evitar validaci√≥n pesada
                units = best_params['units']
                units_range = np.unique(np.linspace(max(1, units * 0.9), units * 1.1, 3, dtype=int))
                tu, vu = validation_curve(
                    rnn_ttr, X_train_sel, y_train,
                    param_name='regressor__rnnregressor__units',
                    param_range=units_range,
                    cv=2,
                    scoring='r2',
                    n_jobs=1
                )
                fig_uvc, ax_uvc = plt.subplots(figsize=(4.5,2.8))
                ax_uvc.plot(units_range, np.mean(tu,axis=1), 'o-', label='Train R¬≤')
                ax_uvc.plot(units_range, np.mean(vu,axis=1), 'o-', label='CV R¬≤')
                ax_uvc.set_title('RNN Optimizado: Curva de Validaci√≥n units')
                ax_uvc.set_xlabel('units')
                ax_uvc.set_ylabel('R¬≤')
                ax_uvc.legend()
                self.sections.append((
                    '### RNN Optimizado: Curva de Validaci√≥n units', fig_uvc
                ))

                dr = best_params['dropout_rate']
                dr_range = np.linspace(max(0.0, dr-0.15), min(1.0, dr+0.15), 2)  # ‚ö†Ô∏è solo dos valores
                td, vd = validation_curve(
                    rnn_ttr, X_train_sel, y_train,
                    param_name='regressor__rnnregressor__dropout_rate',
                    param_range=dr_range,
                    cv=2,
                    scoring='r2',
                    n_jobs=1
                )
                fig_dvc, ax_dvc = plt.subplots(figsize=(4.5,2.8))
                ax_dvc.plot(dr_range, np.mean(td,axis=1), 'o-', label='Train R¬≤')
                ax_dvc.plot(dr_range, np.mean(vd,axis=1), 'o-', label='CV R¬≤')
                ax_dvc.set_title('RNN Optimizado: Curva de Validaci√≥n dropout_rate')
                ax_dvc.set_xlabel('dropout_rate')
                ax_dvc.set_ylabel('R¬≤')
                ax_dvc.legend()
                self.sections.append((
                    '### RNN Optimizado: Curva de Validaci√≥n dropout_rate', fig_dvc
                ))

                prompt = (
                    f"Para la RNN optimizada (M√©todo={best_row['M√©todo']}, Motor={best_row['Motor']}):\n"
                    f"- Curva de Aprendizaje: tama√±os={train_sizes if isinstance(train_sizes, list) else train_sizes.tolist()}, train R¬≤={train_mean.tolist()}, cv R¬≤={val_mean.tolist()}\n"
                    f"- Validaci√≥n units: rango={units_range.tolist()}, train={np.mean(tu,axis=1).tolist()}, cv={np.mean(vu,axis=1).tolist()}\n"
                    f"- Validaci√≥n dropout_rate: rango={dr_range.tolist()}, train={np.mean(td,axis=1).tolist()}, cv={np.mean(vd,axis=1).tolist()}\n\n"
                    "1. Identifica underfitting o overfitting en cada curva.\n"
                    "2. Se√±ala brechas clave y su impacto en la generalizaci√≥n.\n"
                    "3. Recomienda ajustes de units y dropout_rate."
                )
                print("[DEBUG] 16.18. Llamando a OpenAI para an√°lisis de Curvas de Aprendizaje y Validaci√≥n RNN")
                analysis = call_openai_explanation(prompt)
                self.sections.append((
                    '### RNN Optimizado: Interpretaci√≥n IA de Curvas', analysis
                ))

            except Exception as e:
                print("[DEBUG] Error en Bloque 4 Optimizaci√≥n RNN:", e)
                self.sections.append((
                    '### ‚ö†Ô∏è Error Bloque 4 Optimizaci√≥n RNN',
                    f"Se produjo un error en Curvas de Aprendizaje y Validaci√≥n RNN: {e}"
                ))
            # --- Fin Bloque 4 ---

#            try:
#                print("[DEBUG] Iniciando Bloque 4: Curvas de Aprendizaje y Validaci√≥n RNN Optimizado")
#                import numpy as np
#                from sklearn.model_selection import learning_curve, validation_curve
#                from sklearn.pipeline import make_pipeline
#                from sklearn.compose import TransformedTargetRegressor
#                from sklearn.preprocessing import StandardScaler
#                import matplotlib.pyplot as plt#

#                # --- a) Repetir selecci√≥n del mejor modelo ---
#                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
#                df_sel = pd.DataFrame([
#                    {'M√©todo': k[1], 'Motor': k[2], 'Score': v['score'], 'M√©trica': v['metric']}
#                    for k,v in OPT_MODELS.items()
#                    if k[0]=='rnn' and k[2] in valid_engines
#                ])
#                if df_sel['M√©trica'].str.upper().iloc[0] == 'R2':
#                    idx_best = df_sel['Score'].idxmax()
#                else:
#                    idx_best = df_sel['Score'].idxmin()
#                best_row = df_sel.loc[idx_best]

#                # --- c) Reconstruir los hiperpar√°metros √≥ptimos ---
#                p = _normalize_payload(payload_raw)
#                #best_params = p['best_params']
#                best_params = p.get('best_params', {})
#                # --- b) Recuperar payload y metadatos ---
#                model_rnn     = p['model']
#                sx_rnn, sy_rnn= p['sx'], p['sy']
#                cols_rnn      = p['cols']

#                print("[DEBUG] Payload normalizado keys:", list(p.keys()))
#                print("[DEBUG] best_params keys:", list(p.get('best_params', {}).keys()))
#                print("[DEBUG] best_params keys:", list(best_params.keys()))

#                if not best_params:
#                    best_params = model_rnn.get_params()
#                    print("[DEBUG] Se han obtenido best_params desde model.get_params()")

#                # --- EXTRAER params desde el modelo entrenado ---
#                params = model_rnn.get_params()
#                print("[DEBUG] params keys:", list(params.keys()))
#                units  = params['units']

#                if "units" not in params:
#                    raise ValueError("[ERROR] El modelo no contiene la clave 'units' en sus par√°metros.")

#                cols_rnn    = p['cols']
#                model_rnn   = p['model']
#                sx_rnn, sy_rnn = p['sx'], p['sy']

#                # --- d) Creamos el Pipeline + TTR para escalar X e Y autom√°ticamente ---
#                rnn_pipe = make_pipeline(
#                    StandardScaler(),
#                    RNNRegressor(**params)
#                )
#                rnn_ttr = TransformedTargetRegressor(regressor=rnn_pipe, transformer=StandardScaler())

#                #X_train_sel = X_train[cols].values
#                #y_train     = Y_train.values.ravel()
#                X_train_sel = X_train[cols_rnn].values[:300]  # ‚ö†Ô∏è limitar tama√±o
#                y_train = Y_train.values.ravel()[:300]        # ‚ö†Ô∏è limitar tama√±o

#                # ---- 4.1 Curva de Aprendizaje (R¬≤) ----
#                from joblib import parallel_backend             # NUEVO para asegurar que se completa el bloque 4
#                with parallel_backend('threading'):             # NUEVO para asegurar que se completa el bloque 4
#                    train_sizes, train_scores, val_scores = learning_curve(
#                        rnn_ttr, X_train_sel, y_train,
#                        #cv=5,
#                        cv=2,  # ‚ö†Ô∏è menos folds
#                        scoring='r2',
#                        #train_sizes=np.linspace(0.1,1.0,5),
#                        train_sizes=np.linspace(0.1, 1.0, 2),  # ‚ö†Ô∏è menos tama√±os
#                    #    n_jobs=-1
#                        n_jobs=1    # o incluso omite n_jobs para que sea secuencial
#                    )
#                train_mean = np.mean(train_scores, axis=1)
#                val_mean   = np.mean(val_scores,   axis=1)

#                fig_lc, ax_lc = plt.subplots(figsize=(6,4))
#                ax_lc.plot(train_sizes, train_mean, 'o-', label='Train R¬≤')
#                ax_lc.plot(train_sizes, val_mean,   'o-', label='CV R¬≤')
#                ax_lc.set_title('RNN Optimizado: Curva de Aprendizaje')
#                ax_lc.set_xlabel('Tama√±o del set de entrenamiento')
#                ax_lc.set_ylabel('R¬≤')
#                ax_lc.legend()
#                self.sections.append((
#                    '### RNN Optimizado: Curva de Aprendizaje', fig_lc
#                ))

#                # ---- 4.2 Curva de Validaci√≥n para ‚Äúunits‚Äù ----
#                # Rango centrado en el valor √≥ptimo
#                #units_range = np.unique(np.linspace(
#                #    max(1, best_params['units']//2),
#                #    best_params['units']*2,
#                #    5, dtype=int
#                #))
#                if 'units' not in best_params:
#                    raise KeyError("[ERROR] El par√°metro 'units' no est√° presente en best_params. Claves disponibles: " + str(list(best_params.keys())))

#                #units_range = np.unique(np.linspace(
#                #    max(1, best_params['units']//2),
#                #    best_params['units']*2,
#                #    5, dtype=int
#                #))
#                # A√ëADIDO PARA ALIGERAR LOS CICLOS DE VALIDACION  Y APRENDIZAJE
#                units_range = np.unique(np.linspace(
#                    max(1, params['units']*0.8),
#                    params['units']*1.2,
#                    3, dtype=int
#                ))

#                #fig_vc_u, tu, vu = validation_curve(
#                tu, vu = validation_curve(
#                    rnn_ttr, X_train_sel, y_train,
#                    param_name='regressor__rnnregressor__units',
#                    param_range=units_range,
#                    cv=5,
#                    scoring='r2',
#                    n_jobs=-1
#                )
#                fig_uvc, ax_uvc = plt.subplots(figsize=(6,4))
#                ax_uvc.plot(units_range, np.mean(tu,axis=1), 'o-', label='Train R¬≤')
#                ax_uvc.plot(units_range, np.mean(vu,axis=1), 'o-', label='CV R¬≤')
#                ax_uvc.set_title('RNN Optimizado: Curva de Validaci√≥n units')
#                ax_uvc.set_xlabel('units')
#                ax_uvc.set_ylabel('R¬≤')
#                ax_uvc.legend()
#                self.sections.append((
#                    '### RNN Optimizado: Curva de Validaci√≥n units', fig_uvc
#                ))

#                # ---- 4.3 Curva de Validaci√≥n para ‚Äúdropout_rate‚Äù ----
#                dr = best_params['dropout_rate']
#                #dr_range = np.linspace(max(0.0, dr-0.2), min(1.0, dr+0.2), 5)
#                dr_range = np.linspace(max(0.0, dr-0.1), min(1.0, dr+0.1), 3)   # A√ëADIDO PARA ALIGERAR LOS CICLOS DE ENTRENAMIENTO CRUZADO
#                #fig_vc_d, td, vd = validation_curve(
#                td, vd = validation_curve(
#                    rnn_ttr, X_train_sel, y_train,
#                    param_name='regressor__rnnregressor__dropout_rate',
#                    param_range=dr_range,
#                    cv=5,
#                    scoring='r2',
#                    n_jobs=-1
#                )
#                fig_dvc, ax_dvc = plt.subplots(figsize=(6,4))
#                ax_dvc.plot(dr_range, np.mean(td,axis=1), 'o-', label='Train R¬≤')
#                ax_dvc.plot(dr_range, np.mean(vd,axis=1), 'o-', label='CV R¬≤')
#                ax_dvc.set_title('RNN Optimizado: Curva de Validaci√≥n dropout_rate')
#                ax_dvc.set_xlabel('dropout_rate')
#                ax_dvc.set_ylabel('R¬≤')
#                ax_dvc.legend()
#                self.sections.append((
#                    '### RNN Optimizado: Curva de Validaci√≥n dropout_rate', fig_dvc
#                ))

#                # ---- 4.4 An√°lisis Generativo IA de las Curvas ----
#                prompt = (
#                    f"Para la RNN optimizada (M√©todo={best_row['M√©todo']}, Motor={best_row['Motor']}):\n"
#                    f"- Curva de Aprendizaje: tama√±os={train_sizes.tolist()}, train R¬≤={train_mean.tolist()}, cv R¬≤={val_mean.tolist()}\n"
#                    f"- Validaci√≥n units: rango={units_range.tolist()}, train={np.mean(tu,axis=1).tolist()}, cv={np.mean(vu,axis=1).tolist()}\n"
#                    f"- Validaci√≥n dropout_rate: rango={dr_range.tolist()}, train={np.mean(td,axis=1).tolist()}, cv={np.mean(vd,axis=1).tolist()}\n\n"
#                    "1. Identifica underfitting o overfitting en cada curva.\n"
#                    "2. Se√±ala brechas clave y su impacto en la generalizaci√≥n.\n"
#                    "3. Recomienda ajustes de units y dropout_rate."
#                )
#                print("[DEBUG] Llamando a OpenAI para an√°lisis de Curvas de Aprendizaje y Validaci√≥n RNN")
#                analysis = call_openai_explanation(prompt)
#                self.sections.append((
#                    '### RNN Optimizado: Interpretaci√≥n IA de Curvas', analysis
#                ))

#            except Exception as e:
#                print("[DEBUG] Error en Bloque 4 Optimizaci√≥n RNN:", e)  # <--- NUEVO: para diagn√≥stico
#                self.sections.append((
#                    '### ‚ö†Ô∏è Error Bloque 4 Optimizaci√≥n RNN',
#                    f"Se produjo un error en Curvas de Aprendizaje y Validaci√≥n RNN: {e}"
#                ))
            # --- Fin Bloque 4 ---

            # --- 5. Curvas de Calibraci√≥n y Predicci√≥n de Intervalos para RNN Optimizado ---
            try:
                print("[DEBUG] 16.19. Iniciando Bloque 5: Curvas de Calibraci√≥n y Predicci√≥n de Intervalos RNN Optimizado")

                from sklearn.calibration import calibration_curve
                import pandas as _pd
                import numpy as np
                import matplotlib.pyplot as plt

                # 5.1) Recuperar mejor modelo y scalers
                valid_engines = {'RandomSearch','Bayesian','Hyperband','Optuna'}
                df_sel = pd.DataFrame([
                    {'M√©todo': k[1], 'Motor': k[2], 'Score': v['score'], 'M√©trica': v['metric']}
                    for k,v in OPT_MODELS.items()
                    if k[0]=='rnn' and k[2] in valid_engines
                ])
                if df_sel['M√©trica'].str.upper().iloc[0] == 'R2':
                    idx_best = df_sel['Score'].idxmax()
                else:
                    idx_best = df_sel['Score'].idxmin()
                best_row = df_sel.loc[idx_best]

                key     = ('rnn', best_row['M√©todo'], best_row['Motor'])
                payload_raw = OPT_MODELS[('rnn', best_row['M√©todo'], best_row['Motor'])]
                p           = _normalize_payload(payload_raw)

                model_rnn   = p['model']
                sx_rnn, sy_rnn = p['sx'], p['sy']
                cols_rnn    = p['cols']

                # --- Bloque 5: normalizar payload ---
                payload_raw = OPT_MODELS[('rnn', best_row['M√©todo'], best_row['Motor'])]
                p           = _normalize_payload(payload_raw)

                model_rnn   = p['model']
                sx_rnn, sy_rnn = p['sx'], p['sy']
                cols_rnn    = p['cols']

                # 5.2) Preparar datos de test y predecir
                X_test_sel = X_test[cols].copy()
                y_true     = Y_test.values.ravel()

                # tu wrapper ya escala / reshape / inverse_transform internamente
                y_pred = model_rnn.predict(X_test_sel)

                # 5.3) Curva de calibraci√≥n (regresi√≥n ‚Äúreliability‚Äù)
                bins = 10
                df_cal = _pd.DataFrame({'y_pred': y_pred, 'y_true': y_true})
                try:
                    df_cal['bin'] = _pd.qcut(df_cal['y_pred'], q=bins, duplicates='drop')
                except ValueError:
                    df_cal['bin'] = _pd.cut(df_cal['y_pred'], bins=bins)
                grp = df_cal.groupby('bin', observed=True).agg({'y_pred':'mean','y_true':'mean'})
                prob_pred, prob_true = grp['y_pred'].values, grp['y_true'].values

                fig_cal, ax_cal = plt.subplots(figsize=(6,4))
                ax_cal.plot(prob_pred, prob_true, marker='o', linewidth=2, label='Calibraci√≥n')
                ax_cal.plot([prob_pred.min(), prob_pred.max()],
                            [prob_pred.min(), prob_pred.max()],
                            'k--', label='Ideal')
                ax_cal.set_xlabel('Predicci√≥n promedio en bin')
                ax_cal.set_ylabel('Valor real promedio')
                ax_cal.set_title('RNN Optimizado: Curva de Calibraci√≥n')
                ax_cal.legend()
                self.sections.append((
                    "### RNN Optimizado: Curva de Calibraci√≥n",
                    fig_cal
                ))

                # 5.4) Intervalos de predicci√≥n ¬±1 STD de residuo
                residuals = y_true - y_pred
                std_res   = np.std(residuals)
                upper     = y_pred + std_res
                lower     = y_pred - std_res

                fig_int, ax_int = plt.subplots(figsize=(6,4))
                ax_int.plot(y_true,     label='Y real')
                ax_int.plot(y_pred,     label='Predicci√≥n')
                ax_int.fill_between(
                    np.arange(len(y_pred)),
                    lower, upper,
                    alpha=0.3, label='¬±1 STD residuo'
                )
                ax_int.set_xlabel('√çndice de muestra')
                ax_int.set_ylabel('Valor')
                ax_int.set_title('RNN Optimizado: Intervalos de Predicci√≥n')
                ax_int.legend()
                self.sections.append((
                    "### RNN Optimizado: Intervalos de Predicci√≥n",
                    fig_int
                ))

                # 5.5) An√°lisis generativo IA de incertidumbre y calibraci√≥n
                print("[DEBUG] 16.20. Llamando IA para an√°lisis de incertidumbre y calibraci√≥n RNN optimizado")
                prompt_ci_rnn = (
                    f"Para la RNN optimizada (M√©todo={best_row['M√©todo']}, Motor={best_row['Motor']}):\n"
                    f"- Calibraci√≥n (bins={bins}): predicciones promedio={prob_pred.tolist()}, valores reales promedio={prob_true.tolist()}\n"
                    f"- Residuo est√°ndar={std_res:.4f}\n\n"
                    "1. Eval√∫a la fiabilidad de la curva de calibraci√≥n: donde el modelo est√° sub- o sobre-calibrado.\n"
                    "2. Comenta sobre la amplitud de los intervalos de predicci√≥n y su adecuaci√≥n.\n"
                    "3. Sugiere mejoras para la calibraci√≥n y estimaci√≥n de la incertidumbre en la RNN."
                )
                analysis_ci_rnn = call_openai_explanation(prompt_ci_rnn)
                self.sections.append((
                    "### RNN Optimizado: An√°lisis de Incertidumbre y Calibraci√≥n",
                    analysis_ci_rnn
                ))

            except Exception as e:
                self.sections.append((
                    "### ‚ö†Ô∏è Error Bloque 5 Optimizaci√≥n RNN",
                    f"Se produjo un error en Curvas de Calibraci√≥n y Predicci√≥n de Intervalos RNN: {e}"
                ))
            # --- Fin Bloque 5 ---

            # --- 6. Resumen Ejecutivo y Road-Map de Siguientes Pasos para RNN Optimizado ---
            try:
                print("[DEBUG] 16.21. Iniciando bloque de Resumen Ejecutivo y Road-Map para RNN optimizado")

                # Variables clave (ya definidas en bloques anteriores)
                sel_rnn        = best_row['M√©todo']
                eng_rnn        = best_row['Motor']
                best_score_rnn = best_row['Score']

                # Desviaci√≥n de R2 en CV (bloque 3) y estad√≠sticas de residuos (bloque 5)
                cv_std_r2      = float(np.std(r2_scores))    # r2_scores viene de bloque 3
                res_std_rnn    = float(std_res)              # std_res viene de bloque 5
                res_kurt_rnn   = float(kurtosis(residuals))  # residuals viene de bloque 5
                q25_rnn, q50_rnn, q75_rnn = [
                    float(x) for x in np.quantile(residuals, [0.25, 0.5, 0.75])
                ]

                # Markdown resumen
                summary_md_rnn = (
                    "**Puntos Clave Optimizaci√≥n RNN:**\n"
                    f"- **Mejor combinaci√≥n:** M√©todo `{sel_rnn}`, motor `{eng_rnn}` ‚ûú **Score** = {best_score_rnn:.4f}\n"
                    f"- **Robustez del modelo:** desviaci√≥n est√°ndar CV R¬≤ = {cv_std_r2:.4f}, std residuos = {res_std_rnn:.4f}\n"
                    f"- **Curtosis de residuos:** {res_kurt_rnn:.4f}, quantiles (25%,50%,75%) = "
                    f"({q25_rnn:.4f}, {q50_rnn:.4f}, {q75_rnn:.4f})\n"
                    "- **Recomendaciones inmediatas:**\n"
                    "  1. Ajustar unidades (`units`) y tasa de dropout para controlar varianza.\n"
                    "  2. Incorporar learning-rate scheduling y early stopping.\n"
                    "  3. Aumentar el set de entrenamiento o aplicar data augmentation en series temporales.\n"
                    "  4. Experimentar con arquitecturas h√≠bridas (LSTM bidireccional, Attention).\n"
                )
                self.sections.append((
                    "### RNN Optimizado: Resumen Ejecutivo y Road-Map",
                    summary_md_rnn
                ))

                # Llamada a IA para un ‚ÄúResumen Ejecutivo IA‚Äù
                print("[DEBUG] 16.22. Llamando IA para Resumen Ejecutivo y Road-Map RNN optimizado")
                prompt_exec_rnn = (
                    "Eres un investigador de Deep Learning avanzado. Bas√°ndote en estos puntos clave:\n"
                    f"{summary_md_rnn}\n\n"
                    "1. Desarrolla un an√°lisis detallado en p√°rrafos separados para cada punto clave.\n"
                    "2. Prop√≥n un plan de acci√≥n priorizado de 3‚Äì5 pasos claros para stakeholders.\n"
                    "3. Finaliza con un breve resumen ejecutivo de 2‚Äì3 p√°rrafos enfatizando impacto y pr√≥ximos hitos."
                )
                analysis_exec_rnn = call_openai_explanation(prompt_exec_rnn)
                self.sections.append((
                    "### RNN Optimizado: Resumen Ejecutivo IA",
                    analysis_exec_rnn
                ))

            except Exception as e:
                self.sections.append((
                    "### ‚ö†Ô∏è Error Bloque 6 Optimizaci√≥n RNN",
                    f"Se produjo un error en Resumen Ejecutivo y Road-Map RNN: {e}"
                ))
            # --- Fin Bloque 6 ---

        except Exception as e:
            self.sections.append((
                "### ‚ö†Ô∏è Error Bloque 0 Optimizaci√≥n RNN",
                f"Se produjo un error al generar el resumen de optimizaci√≥n RNN: {e}"
            ))

        # =============================================================================
        # 17. An√°lisis e Interpretaci√≥n del Modelo √ìptimo
        # =============================================================================
        #try:
        #    print("[DEBUG] Iniciando secci√≥n Selecci√≥n Integral de Modelo")
        try:
            print("[DEBUG] 17.1.Iniciando secci√≥n Selecci√≥n Integral de Modelo")
            # DEBUG: ¬øQu√© claves hay en OPT_MODELS?
            print(f"[DEBUG] 17.2. OPT_MODELS tiene {len(OPT_MODELS)} entradas: {list(OPT_MODELS.keys())}")
            records = []
            print("[DEBUG] 17.3. records inicializado vac√≠o")
            import numpy as np
            import pandas as pd
            from sklearn.model_selection      import cross_validate
            from sklearn.metrics              import mean_squared_error, mean_absolute_error, r2_score
            #from sklearn.calibration          import calibration_curve
            import scipy.stats                as st
            from tensorflow.keras.models      import load_model

            records = []

            # --- Bloque 1: Construcci√≥n y presentaci√≥n de la Tabla de Puntuaci√≥n de los Modelos Optimizados ---
            for (mt, method, engine), payload in OPT_MODELS.items():
                if mt not in {'svr','nn','xgb','rf','rnn'}:
                    continue
                # --- cargar datos test y scalers ---
                cols = payload.get('cols', X_test.columns.tolist())
                X_test_sel = X_test[cols].copy()
                y_true     = Y_test.values.ravel()

                sx = payload.get('sx')
                if sx is not None:
                    #X_test_scaled = sx.transform(X_test_sel.values)
                    X_test_scaled = sx.transform(pd.DataFrame(X_test_sel.values, columns=X_test_sel.columns))       # EVITA WARNING EN LA EJECUCION - NO PARA EJECUCION. SI DA PROBLEMAS ELIMINAR ESTA LINEA.

                else:
                    X_test_scaled = X_test_sel.values

                # --- predicciones y m√©tricas test ---
                if mt == 'rnn':
                    # tu wrapper ya escala, reshape e inverse_transform
                    model = payload['model']
                    y_pred = model.predict(X_test_sel)
                else:
                    model = payload['model']
                    if mt in {'svr','xgb','rf','nn'}:
                        # scikeras o sklearn
                        y_pred_raw = model.predict(X_test_scaled)
                        sy = payload.get('sy')
                        if sy is not None:
                            y_pred = sy.inverse_transform(y_pred_raw.reshape(-1,1)).ravel()
                        else:
                            y_pred = y_pred_raw.ravel()
                    else:
                        y_pred = model.predict(X_test_scaled)

                mse_test   = mean_squared_error(y_true, y_pred)
                mae_test   = mean_absolute_error(y_true, y_pred)
                rmse_test  = np.sqrt(mse_test)
                resid      = y_true - y_pred
                res_std    = np.std(resid)
                res_kurt   = st.kurtosis(resid)

                # --- validaci√≥n cruzada 5 folds ---
                # Construir X_train escalado
                cols_tr = payload.get('cols', X_train.columns.tolist())
                X_tr_sel = X_train[cols_tr].copy()
                y_tr     = Y_train.values.ravel()
                sx_tr    = payload.get('sx')
                X_tr_s   = sx_tr.transform(X_tr_sel.values) if sx_tr is not None else X_tr_sel.values

                from sklearn.model_selection import train_test_split

                # Submuestreo del conjunto de entrenamiento
                X_sub, _, y_sub, _ = train_test_split(
                    X_tr_s, y_tr,
                    train_size=0.3,  # usa solo el 30% de los datos para CV
                    random_state=42,
                    shuffle=True
                )

                # --- validaci√≥n cruzada con protecci√≥n para modelos no-sklean ---
                try:
                    from sklearn.model_selection import cross_validate
                    cvres = cross_validate(
                        #model, X_tr_s, y_tr,
                        model, X_sub, y_sub,        # Usamos X_sub y y_sub en la validaci√≥n cruzada en lugar del conjunto completo.
                        #cv=5,
                        cv=3,         # REDUCE CV FOLDS PARA MEJORAR LA RAPPIDEZ DE EJECUCION
                        scoring={
                            'r2':      'r2',
                            'neg_mse': 'neg_mean_squared_error',
                            'neg_mae': 'neg_mean_absolute_error'
                        },
                        return_train_score=False,
                        n_jobs=-1  # ‚Üê paraleliza en todos los cores
                    )
                    r2_folds  = cvres['test_r2']
                    mse_folds = [-v for v in cvres['test_neg_mse']]
                    mae_folds = [-v for v in cvres['test_neg_mae']]
                    r2_cv_std    = float(np.std(r2_folds))
                    mse_cv_mean  = float(np.mean(mse_folds))
                    mae_cv_mean  = float(np.mean(mae_folds))
                    rmse_cv_mean = float(np.mean(np.sqrt(mse_folds)))
                except TypeError as ex:
                    # no SKL estimator (e.g. keras.Sequential), omitimos CV
                    print(f"[DEBUG] CV omitido por TypeError: {ex}")
                    r2_folds, mse_folds, mae_folds = [], [], []
                    r2_cv_std    = np.nan
                    mse_cv_mean  = np.nan
                    mae_cv_mean  = np.nan
                    rmse_cv_mean = np.nan

                # --- calibraci√≥n manual para regresi√≥n ---
                import pandas as pd
                # un DataFrame para agrupar por deciles de y_pred
                df_cal = pd.DataFrame({'y_pred': y_pred, 'y_true': y_true})
                # cortamos en 10 bins por cuantiles (evita duplicados)
                try:
                    #df_cal['bin'] = pd.qcut(df_cal['y_pred'], q=10, duplicates='drop')
                    df_cal['bin'] = pd.qcut(df_cal['y_pred'], q=5, duplicates='drop')   # o q=4 si quieres a√∫n m√°s velocidad
                except ValueError:
                    #df_cal['bin'] = pd.cut(df_cal['y_pred'], bins=10)
                    df_cal['bin'] = pd.cut(df_cal['y_pred'], bins=5)                    # o q=4 si quieres a√∫n m√°s velocidad
                # agrupamos: media predicha vs media real
                grp = df_cal.groupby('bin', observed=True).agg({'y_pred':'mean','y_true':'mean'})
                prob_pred = grp['y_pred'].values
                prob_true = grp['y_true'].values
                # error medio de calibraci√≥n
                cal_err = float((np.abs(prob_pred - prob_true)).mean())

                # --- intervalos de predicci√≥n ¬±1 STD residuo ---
                intervals_std = res_std

                # --- m√©trica principal (score) ---
                score = payload.get('score', r2_score(y_true, y_pred))

                # --- hiperpar√°metros optimizados ---
                best_params = payload.get('best_params') or payload.get('params') or {}
                hp_flat = { f"hp_{k}": v for k, v in best_params.items() }

                # --- armar registro ---
                rec = {
                    'modelo':        f"{mt}-{method}-{engine}",
                    'score':         score,
                    'r2_cv_std':     r2_cv_std,
                    'mse_cv':        mse_cv_mean,
                    'mae_cv':        mae_cv_mean,
                    'rmse_cv':       rmse_cv_mean,
                    'mse_test':      mse_test,
                    'mae_test':      mae_test,
                    'rmse_test':     rmse_test,
                    'res_std':       res_std,
                    'res_kurt':      res_kurt,
                    'intervals_std': intervals_std,
                    'cal_err':       cal_err,
                    **hp_flat
                }
                records.append(rec)

            #df = pd.DataFrame(records)

            print(f"[DEBUG] 17.4. records tendr√° {len(records)} elementos")
            if records:
                print(f"[DEBUG] 17.5. ejemplar de record[0]: {records[0]}")
            df = pd.DataFrame(records)
            print(f"[DEBUG] 17.6. DataFrame creado con shape={df.shape}")

            # 0) Extraer tipo, m√©todo y motor de la columna 'modelo'
            df[['tipo','metodo','motor']] = df['modelo'].str.split('-', n=2, expand=True)

            # 1) Clonar df y reiniciar √≠ndice
            df_results = df.copy()
            df_results.reset_index(drop=True, inplace=True)
            # Definimos aqu√≠ la puntuaci√≥n global bruta
            df_results['puntuacion_global'] = df_results['score']

            # Bloque de normalizaci√≥n absoluta lineal y c√°lculo de puntuaci√≥n
            import pandas as pd
            import numpy as np

            # Definir funciones de normalizaci√≥n
            def normalize_high(df, col):
                lo, hi = df[col].min(), df[col].max()
                if hi == lo:
                    return pd.Series(10.0, index=df.index)
                return ((df[col] - lo) / (hi - lo) * 10).clip(0, 10)

            def normalize_low(df, col):
                lo, hi = df[col].min(), df[col].max()
                if hi == lo:
                    return pd.Series(10.0, index=df.index)
                return ((hi - df[col]) / (hi - lo) * 10).clip(0, 10)

            # Supongamos que ya tienes df_results con la columna 'puntuacion_global'
            # y las m√©tricas crudas: r2_cv_std, mse_cv, mae_cv, rmse_cv, mse_test, mae_test,
            # rmse_test, res_std, res_kurt, intervals_std, cal_err

            # Columnas ‚Äúmayor = mejor‚Äù
            cols_high = ['puntuacion_global']

            # Columnas ‚Äúmenor = mejor‚Äù
            cols_low = [
                'r2_cv_std', 'mse_cv', 'mae_cv', 'rmse_cv',
                'mse_test', 'mae_test', 'rmse_test',
                'res_std', 'res_kurt', 'intervals_std', 'cal_err'
            ]

            # 1) Normalizar cada m√©trica a escala 0‚Äì10
            for c in cols_high:
                df_results[f'v_{c}'] = normalize_high(df_results, c)

            for c in cols_low:
                df_results[f'v_{c}'] = normalize_low(df_results, c)

            # 2) Definir pesos (ajusta seg√∫n IA o tu criterio)
            pesos = {
                'v_puntuacion_global': 0.2273,
                'v_r2_cv_std':         0.0909,
                'v_mse_cv':            0.0909,
                'v_mae_cv':            0.0455,
                'v_rmse_cv':           0.0455,
                'v_mse_test':          0.0909,
                'v_mae_test':          0.0909,
                'v_rmse_test':         0.0455,
                'v_res_std':           0.0909,
                'v_res_kurt':          0.0455,
                'v_intervals_std':     0.0455,
                'v_cal_err':           0.0909,
            }

            # 3) Calcular la puntuaci√≥n global final
            df_results['puntuacion_global_final'] = 0.0
            for vcol, w in pesos.items():
                df_results['puntuacion_global_final'] += df_results[vcol] * w

            # 4) Reordenar columnas para presentaci√≥n
            #cols_order = [
            #    'modelo', 'tipo', 'metodo', 'motor', 'puntuacion_global'
            #] + list(pesos.keys()) + ['puntuacion_global_final']

            # 4) Reordenar columnas para presentaci√≥n
            cols_order = [
                'modelo', 'tipo', 'metodo', 'motor', 'puntuacion_global',
                # m√©tricas crudas
                'r2_cv_std','mse_cv','mae_cv','rmse_cv',
                'mse_test','mae_test','rmse_test',
                'res_std','res_kurt','intervals_std','cal_err',
            ] + list(pesos.keys()) + ['puntuacion_global_final']

            df_results = df_results[cols_order]

            # 5) A√±adir la secci√≥n al informe
            #self.sections.append((
            #    '### Selecci√≥n Integral de Modelo: Tabla de Puntuaciones',
            #    df_results.reset_index(drop=True)
            #))
            print("[DEBUG] 17.7. A√±adiendo secci√≥n de Tabla de Puntuaciones")
            self.sections.append((
                '### Selecci√≥n Integral de Modelo: Tabla de Puntuaciones',
                df_results.reset_index(drop=True)
            ))
            print("[DEBUG] 17.8. Secci√≥n Tabla de Puntuaciones a√±adida correctamente")

            # --- Ahora identificamos el mejor y guardamos atributos ---
            best_idx = df_results['puntuacion_global_final'].idxmax()
            best     = df_results.loc[best_idx]

            # Guardamos la info del mejor modelo
            self.best_model_info = {
                'metodo': best['metodo'],
                'motor':  best['motor'],
                'score':  best['puntuacion_global_final']
            }

            # **Guardamos tambi√©n las m√©tricas que necesitar√°s m√°s adelante**:
            self.r2_cv_std = float(best['r2_cv_std'])
            self.res_std   = float(best['res_std'])
            self.cal_err   = float(best['cal_err'])

            print(f"[DEBUG] 17.9. Mejor modelo: {self.best_model_info}, "
                  f"r2_cv_std={self.r2_cv_std}, res_std={self.res_std}, cal_err={self.cal_err}")
            # --- Fin Bloque 1 ---

            # --- Bloque 2 - Gr√°fico de puntuaciones globales y Cuadrante M√°gico de Modelos Optimizados ----
            import matplotlib.pyplot as plt

            # 1) Cerramos TODO lo que haya quedado abierto de la optimizaci√≥n
            #plt.close('all')

            # --- Gr√°fico de Barras: Puntuaci√≥n Global de cada modelo ---
            def plot_global_scores(df):
                """
                Gr√°fico de barras profesional con la puntuaci√≥n global de cada modelo.
                - df debe tener columnas ['modelo', 'puntuacion_global'].
                """
                fig, ax = plt.subplots(figsize=(10, 6))
                modelos = df['modelo']
                scores = df['puntuacion_global_final']

                # Usa una paleta profesional
                palette = plt.get_cmap('tab20').colors
                ax.bar(modelos, scores, color=palette[:len(modelos)], edgecolor='black')

                # Etiquetas y estilo
                ax.set_title('Comparaci√≥n de Modelos: Puntuaci√≥n Global', fontsize=16, fontweight='bold')
                ax.set_xlabel('Modelo', fontsize=14)
                ax.set_ylabel('Puntuaci√≥n Global', fontsize=14)
                ax.set_xticks(modelos)
                ax.set_xticklabels(modelos, rotation=45, ha='right', fontsize=12)
                ax.grid(axis='y', linestyle='--', alpha=0.7)
                plt.tight_layout()
                #plt.close(fig)
                return fig

            def plot_magic_quadrant(df):
                """
                Magic Quadrant que sit√∫a cada modelo en robustez vs rendimiento.
                - df debe tener columnas ['v_r2_cv_std', 'puntuacion_global_final', 'modelo'].
                """
                # Robustez: normalizamos de 0‚Äì10 a 0‚Äì1
                robustez = (df['v_r2_cv_std'] / 10).clip(0,1)

                # Rendimiento: puntuaci√≥n global final (0‚Äì10) tambi√©n a 0‚Äì1
                rendimiento = (df['puntuacion_global_final'] / 10).clip(0,1)

                mask       = robustez.notna() & rendimiento.notna()
                robustez   = robustez[mask]
                rendimiento = rendimiento[mask]
                labels     = df['modelo'][mask]

                fig, ax = plt.subplots(figsize=(8, 8))
                ax.scatter(robustez, rendimiento, s=150, edgecolor='k', alpha=0.8)

                for x, y, label in zip(robustez, rendimiento, labels):
                    ax.annotate(label,
                                xy=(x, y),
                                xytext=(5, 5),
                                textcoords='offset points',
                                fontsize=12)

                # L√≠neas medias
                ax.axvline(robustez.mean(),    color='grey', linestyle='--')
                ax.axhline(rendimiento.mean(), color='grey', linestyle='--')

                ax.set_title('Magic Quadrant de Modelos', fontsize=16, fontweight='bold')
                ax.set_xlabel('Robustez (v_r2_cv_std / 10)', fontsize=14)
                ax.set_ylabel('Rendimiento (puntuaci√≥n global / 10)', fontsize=14)
                ax.grid(True, linestyle='--', alpha=0.5)

                # L√≠mites de 0 a 1
                ax.set_xlim(0, 1.05)
                ax.set_ylim(0, 1.05)

                plt.tight_layout()
                return fig


            fig1 = plot_global_scores(df_results)
            fig2 = plot_magic_quadrant(df_results)

            self.sections.append(('### Comparaci√≥n de Modelos: Puntuaci√≥n Global', fig1))
            self.sections.append(('### Magic Quadrant de Modelos', fig2))
            # --- Fin Bloque 2 ---

            # --- Bloque 3: Explicaci√≥n profunda por IA y detalle final del modelo seleccionado ---
            print("[DEBUG] 17.10. Iniciando Bloque 3: Explicaci√≥n IA y detalle final")

            import openai
            import pandas as pd

            # 1) Serializamos la tabla de puntuaciones para inyectarla en el prompt
            table_csv = df_results.to_csv(index=False)

            print("[DEBUG] 17.11. Iniciando llamada a IA para an√°lisis de la tabla y gr√°ficas")

            prompt = f"""
            He aqu√≠ los resultados completos de la **Selecci√≥n Integral de Modelos**:

            1) **Tabla de Puntuaciones** (CSV):
            {table_csv}

            2) **Gr√°fica de Barras** titulada "Comparaci√≥n de Modelos: Puntuaci√≥n Global".

            3) **Magic Quadrant** titulado "Magic Quadrant de Modelos".

            Por favor, realiza lo siguiente:

            A) Explica **detalladamente** la tabla de puntuaciones:
              - C√≥mo se ha estructurado,
              - Qu√© representa cada columna de valor (tanto las m√©tricas crudas como sus escalas 0‚Äì10),
              - C√≥mo cada modelo se ‚Äúsit√∫a‚Äù seg√∫n esos valores,
              - Comparativa expl√≠cita entre todos los modelos.

            B) Comenta la **gr√°fica de barras**:
              - Qu√© nos dice del rendimiento absoluto de cada modelo,
              - Destaca los valores m√°ximo y m√≠nimo.

            C) Interpreta el **Magic Quadrant**:
              - Define en qu√© ejes est√° midiendo robustez y rendimiento,
              - Se√±ala qu√© cuadrante (alto‚Äìalto, alto‚Äìbajo, bajo‚Äìalto, bajo‚Äìbajo) es deseable,
              - Identifica modelos ‚Äúl√≠deres‚Äù y ‚Äúrezagados‚Äù.

            D) Con todo lo anterior, **elige el mejor modelo optimizado**.
              - Explica por qu√© (qu√© m√©tricas y pesos lo han elevado al primer puesto),
              - Enumera sus virtudes y posibles puntos d√©biles.

            E) Tras esa elecci√≥n, **construye una tabla** con todos los detalles del modelo seleccionado:
              1. `modelo` (p.ej. ‚Äúrf-pearson-randomsearch‚Äù)
              2. `tipo` (RF, SVR, ‚Ä¶)
              3. `m√©todo` (Pearson, Boruta, ‚Ä¶)
              4. `motor` de optimizaci√≥n (RandomSearch, Optuna, ‚Ä¶)
              5. **Todos** sus hiperpar√°metros √≥ptimos
              6. **Listado** de variables X usadas
              7. Resumen de sus **m√©tricas crudas** y su `puntuacion_global_final`
            """

            # 2) Llamada a OpenAI
            resp = _client.chat.completions.create(
                model="gpt-4",
                messages=[{"role":"user", "content": prompt}],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS,
            )
            analysis_text = resp.choices[0].message.content

            # 3) Insertamos el an√°lisis como secci√≥n
            self.sections.append((
                "### üìù Explicaci√≥n IA de la Selecci√≥n Final",
                analysis_text
            ))

            # 4) Identificamos el mejor modelo en df_results
            best_idx = df_results['puntuacion_global_final'].idxmax()
            best     = df_results.loc[best_idx]
            mt, method, engine = best['tipo'], best['metodo'], best['motor']

            # Guardamos la info del mejor modelo para bloques posteriores
            self.best_model_info = {
                'metodo': best['metodo'],
                'motor':  best['motor'],
                'score':  best['puntuacion_global_final']
            }

            # 5) Recuperamos payload y detalles
            payload  = OPT_MODELS[(mt, method, engine)]
            hp       = payload.get('best_params', {}) or payload.get('params', {})
            features = payload.get('cols', X_train.columns.tolist())

            # 6) Preparamos el detalle en un DataFrame
            metrics_keys = [
                'r2_cv_std','mse_cv','mae_cv','rmse_cv',
                'mse_test','mae_test','rmse_test',
                'res_std','res_kurt','intervals_std','cal_err',
                'puntuacion_global','puntuacion_global_final'
            ]

            detail_dict = {
                'modelo':               best['modelo'],
                'tipo':                 mt,
                'metodo':               method,
                'motor':                engine,
                'variables_usadas':     ", ".join(features),
                'puntuacion_final':  best['puntuacion_global_final'],
            }
            # a√±adimos hiperpar√°metros
            for k, v in hp.items():
                detail_dict[f"hp_{k}"] = v
            # a√±adimos m√©tricas
            for k in metrics_keys:
                detail_dict[k] = best[k]

            detail_df = pd.DataFrame([detail_dict])

            # 7) Insertamos la tabla de detalle
            self.sections.append((
                "### Detalle del Modelo Seleccionado",
                detail_df.reset_index(drop=True)
            ))
            # --- Fin Bloque 3 ---

            # --- Bloque 4: Interpretaci√≥n xIA del Mejor Modelo Optimizado ---
            try:
                print("[DEBUG] 17.12. Iniciando Bloque 4: Interpretaci√≥n xIA")

                import numpy as np
                import pandas as pd
                import shap
                import matplotlib.pyplot as plt
                import json
                import warnings
                from scipy.optimize import minimize
                from sklearn.inspection import partial_dependence
                from sklearn.inspection import (
                    permutation_importance,
                    PartialDependenceDisplay
                )

                # --- FUNCI√ìN ROBUSTA PARA EXTRAER grid/curves DE partial_dependence ---
                def extract_grid_and_curves(pd_res, kind="average"):
                    # 1. Si es Bunch (scikit-learn >= 0.24)
                    if hasattr(pd_res, "keys"):
                        keys = list(pd_res.keys())
                        # PDP
                        if kind == "average":
                            # Puede que solo exista average/grid_values
                            if "average" in keys and "grid_values" in keys:
                                grid = pd_res["grid_values"][0]
                                avg = pd_res["average"][0]
                                return grid, avg
                            else:
                                raise RuntimeError(f"PDP: No se encuentran 'average' o 'grid_values' en Bunch: {keys}")
                        # ICE
                        elif kind == "individual":
                            if "individual" in keys and "grid_values" in keys:
                                grid = pd_res["grid_values"][0]
                                curves = pd_res["individual"][0]
                                return grid, curves
                            else:
                                raise RuntimeError(f"ICE: No se encuentran 'individual' o 'grid_values' en Bunch: {keys}")
                        else:
                            raise ValueError(f"Tipo desconocido: {kind}")

                    # 2. Si es tuple o list (formato antiguo)
                    elif isinstance(pd_res, (tuple, list)):
                        if kind == "average":
                            avg = pd_res[0]
                            grid = pd_res[1][0]
                            return grid, avg
                        elif kind == "individual":
                            curves = pd_res[0]
                            grid = pd_res[1][0]
                            return grid, curves
                        else:
                            raise ValueError(f"Tipo desconocido: {kind}")

                    # 3. Si es ndarray (muy raro)
                    elif isinstance(pd_res, np.ndarray):
                        return np.arange(pd_res.shape[-1]), pd_res

                    # 4. Si es dict (algunos edge-cases custom)
                    elif isinstance(pd_res, dict):
                        # Para ICE y PDP, usa las claves
                        if kind == "average" and "average" in pd_res and "grid_values" in pd_res:
                            grid = pd_res["grid_values"][0]
                            avg = pd_res["average"][0]
                            return grid, avg
                        elif kind == "individual" and "individual" in pd_res and "grid_values" in pd_res:
                            grid = pd_res["grid_values"][0]
                            curves = pd_res["individual"][0]
                            return grid, curves
                        else:
                            raise RuntimeError(f"Objeto dict sin claves esperadas: {pd_res.keys()}")

                    else:
                        raise RuntimeError(f"No se reconoce el objeto retornado por partial_dependence: {type(pd_res)}, contenido: {pd_res}")


                # 1) Identificar el mejor modelo
                best_idx = df_results['puntuacion_global_final'].idxmax()
                best     = df_results.loc[best_idx]
                mt, method, engine = best['tipo'], best['metodo'], best['motor']
                payload  = OPT_MODELS[(mt, method, engine)]
                model    = payload['model']
                features = payload.get('cols', X_train.columns.tolist())

                # 2) Preparar datos (escalado si procede)
                sx     = payload.get('sx')
                X_tr   = X_train[features].copy()
                X_te   = X_test[features].copy()
                X_tr_s = sx.transform(X_tr.values) if sx else X_tr.values
                X_te_s = sx.transform(X_te.values) if sx else X_te.values
                y_te   = Y_test.values.ravel()

                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                # 3) SHAP
                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                print("[DEBUG] 17.13. Iniciando Interpretaci√≥n xIA con SHAP")
                # Silenciar warning de ‚Äúfeature names‚Äù
                warnings.filterwarnings("ignore", message="X does not have valid feature names")
                if mt in ('xgb','rf'):
                    explainer = shap.TreeExplainer(model)
                else:
                    # Uso DeepExplainer para redes y KernelExplainer solo si no hay Deep support
                    try:
                        background = shap.kmeans(X_tr_s, 100)            # solo 100 puntos de background
                        explainer = shap.DeepExplainer(model, background)
                    except Exception:
                        # fallback a KernelExplainer con pocos nsamples
                        explainer = shap.KernelExplainer(model.predict, shap.sample(X_tr_s, 100))
                # Reducir test a las primeras 100 filas para acelerar
                X_sample = X_te_s[:100]
                shap_vals = explainer.shap_values(X_sample)

#                    explainer = shap.KernelExplainer(model.predict, shap.sample(X_tr_s, 100))
#                shap_vals = explainer.shap_values(X_te_s)

                fig_shap, ax_shap = plt.subplots(figsize=(8,6))
                #shap.summary_plot(shap_vals, X_te_s, feature_names=features, show=False)
                shap.summary_plot(shap_vals, X_sample, feature_names=features, show=False)

                plt.tight_layout()
                #plt.close(fig_shap)
                self.sections.append(("### xIA: SHAP Summary", fig_shap))

                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                # 4) Permutation Feature Importance
                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                print("[DEBUG] 17.14. Iniciando Interpretaci√≥n xIA con Permutation Feature Importance")
                perm = permutation_importance(model, X_te_s, y_te,
                                              n_repeats=10, random_state=0, n_jobs=-1)
                idx_imp   = np.argsort(perm.importances_mean)[::-1]
                top_feats = [features[i] for i in idx_imp[:5]]

                fig_perm, ax_perm = plt.subplots(figsize=(8,6))
                ax_perm.barh(np.arange(len(top_feats)),
                            perm.importances_mean[idx_imp[:5]],
                            xerr=perm.importances_std[idx_imp[:5]],
                            align='center')
                ax_perm.set_yticks(np.arange(len(top_feats)))
                ax_perm.set_yticklabels(top_feats)
                ax_perm.invert_yaxis()
                ax_perm.set_title("xIA: Permutation Importance")
                ax_perm.set_xlabel("Mean decrease in score")
                plt.tight_layout()
                #plt.close(fig_perm)
                self.sections.append(("### xIA: Permutation Importance", fig_perm))

                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                # 5) PDP + ICE (scikit-learn)
                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                print("[DEBUG] 17.15. Iniciando Interpretaci√≥n xIA con PDP e ICE")

                pdp_records = []
                ice_records = []

                for feat in top_feats:
                    # PDP
                    pdp_res = partial_dependence(
                        model, X_tr, features=[feat], kind="average", grid_resolution=20
                    )
                    #grid, avg = extract_grid_and_curves(pdp_res, kind='average')

                    try:
                        grid, avg = extract_grid_and_curves(pdp_res, kind='average')
                    except Exception as e:
                        print(f"[DEBUG] PDP Extraction error: {e}, objeto: {type(pdp_res)}, contenido: {pdp_res}")
                        raise

                    for x, y in zip(grid, avg):
                        pdp_records.append({"feature": feat, "grid": float(x), "pdp": float(y)})

                    # gr√°fico PDP
                    fig_pdp, ax_pdp = plt.subplots(figsize=(6,4))
                    ax_pdp.plot(grid, avg, marker='o')
                    ax_pdp.set_title(f"PDP de {feat}")
                    plt.tight_layout()
                    #plt.close(fig_pdp)
                    self.sections.append((f"### xIA: PDP {feat}", fig_pdp))

                    # ICE
                    ice_res = partial_dependence(
                        model, X_tr, features=[feat], kind="individual", grid_resolution=20
                    )
                    #grid, curves = extract_grid_and_curves(ice_res, kind='individual')

                    try:
                        grid, curves = extract_grid_and_curves(ice_res, kind='individual')
                    except Exception as e:
                        print(f"[DEBUG] ICE Extraction error: {e}, objeto: {type(ice_res)}, contenido: {ice_res}")
                        raise

                    for obs_idx, curve in enumerate(curves):
                        for x, y in zip(grid, curve):
                            ice_records.append({
                                "feature":     feat,
                                "grid":        float(x),
                                "ice":         float(y),
                                "observation": int(obs_idx)
                            })
                    # gr√°fico ICE
                    fig_ice, ax_ice = plt.subplots(figsize=(6,4))
                    for curve in curves:
                        ax_ice.plot(grid, curve, alpha=0.3)
                    ax_ice.set_title(f"ICE de {feat}")
                    plt.tight_layout()
                    #plt.close(fig_ice)
                    self.sections.append((f"### xIA: ICE {feat}", fig_ice))

                # convertir a DataFrame
                pdp_results = pd.DataFrame(pdp_records)
                ice_results = pd.DataFrame(ice_records)

                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                # 6) ALE ‚Äúa mano‚Äù
                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                print("[DEBUG] 17.16. Iniciando Interpretaci√≥n xIA con ALE")
                def compute_ale(model, X, feat, grid_points=20):
                    Xdf = X.copy()
                    vals = np.linspace(Xdf[feat].min(),
                                      Xdf[feat].max(),
                                      grid_points+1)
                    centers = (vals[:-1] + vals[1:]) / 2
                    diffs = []
                    for low, high in zip(vals[:-1], vals[1:]):
                        X_low  = Xdf.copy(); X_high = Xdf.copy()
                        X_low.loc[Xdf[feat]  > high, feat] = low
                        X_high.loc[Xdf[feat] <= low,  feat] = high
                        arr_low  = sx.transform(X_low.values)  if sx else X_low.values
                        arr_high = sx.transform(X_high.values) if sx else X_high.values
                        pred_low  = model.predict(arr_low)
                        pred_high = model.predict(arr_high)
                        diffs.append(np.mean(pred_high - pred_low))
                    cum = np.cumsum(diffs)
                    cum -= cum.mean()
                    return centers, cum

                ale_records = []
                for feat in top_feats:
                    centers, ale_curve = compute_ale(model, X_tr, feat)
                    fig_ale, ax_ale = plt.subplots(figsize=(6,4))
                    ax_ale.plot(centers, ale_curve, marker='o')
                    ax_ale.set_title(f"ALE de {feat}")
                    plt.tight_layout()
                    #plt.close(fig_ale)
                    self.sections.append((f"### xIA: ALE {feat}", fig_ale))
                    for c, a in zip(centers, ale_curve):
                        ale_records.append({
                            "feature": feat,
                            "grid":    float(c),
                            "ale":     float(a)
                        })
                ale_results = pd.DataFrame(ale_records)

                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                # 7) Counterfactuals ‚Äúligeros‚Äù
                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                print("[DEBUG] 17.17. Iniciando Interpretaci√≥n xIA con Counterfactuals")
                def generate_counterfactual(x0, delta=1.0):
                    x0_arr = x0.values if hasattr(x0, "values") else x0
                    x0_s   = sx.transform([x0_arr])[0] if sx else x0_arr
                    y0     = model.predict([x0_s])[0]
                    def obj(x): return np.sum((x - x0_s)**2)
                    cons = {
                        'type': 'ineq',
                        'fun':  lambda x: model.predict([x])[0] - y0 - delta
                    }
                    res = minimize(obj, x0_s, constraints=cons)
                    if res.success:
                        xcf_s = res.x
                        xcf   = sx.inverse_transform([xcf_s])[0] if sx else xcf_s
                        ycf   = model.predict([xcf_s])[0]
                        return xcf, ycf
                    else:
                        return None, None

                cf_explanations = []
                for i in range(min(3, len(X_te))):
                    x0 = X_te.iloc[i]
                    xcf, ycf = generate_counterfactual(x0, delta=1.0)
                    if xcf is not None:
                        delta_feats = xcf - x0.values
                        fig_cf, ax_cf = plt.subplots(figsize=(6,4))
                        ax_cf.bar(X_te.columns, delta_feats, edgecolor='k')
                        ax_cf.set_title(f"Counterfactual #{i} (Œî para +1 unidad de y)")
                        ax_cf.set_xticklabels(X_te.columns, rotation=45, ha='right')
                        plt.tight_layout()
                        #plt.close(fig_cf)
                        self.sections.append((f"### xIA: Counterfactual {i}", fig_cf))
                        cf_explanations.append({
                            "observation":     i,
                            "x0":              x0.to_dict(),
                            "counterfactual":  {features[j]: float(xcf[j]) for j in range(len(features))},
                            "y_pred_original": float(model.predict([sx.transform([x0.values])[0]]) if sx else model.predict([x0.values])[0]),
                            "y_pred_cf":       float(ycf)
                        })

                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                # 8) RESUMIR LOS RESULTADOS PARA ENVIAR A LA IA
                # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
                print("[DEBUG] 17.18. Resumiendo resultados XAI para env√≠o a la IA")

                def resumir_xai_json(
                    shap_vals, features, perm, idx_imp, top_feats,
                    pdp_results, ice_results, ale_results, cf_explanations,
                    n_feats=2, n_vals=8
                ):
                    # Selecciona las top n_feats
                    features_lite = [features[i] for i in idx_imp[:n_feats]]

                    # 1. SHAP: solo valores medios globales para top features
                    shap_summary = {
                        "features": features_lite,
                        "shap_mean_abs": [float(np.mean(np.abs(shap_vals[:, features.index(f)]))) for f in features_lite]
                    }

                    # 2. Permutation: solo top features
                    perm_summary = {
                        "features": features_lite,
                        "importances_mean": [float(perm.importances_mean[features.index(f)]) for f in features_lite],
                        "importances_std": [float(perm.importances_std[features.index(f)]) for f in features_lite],
                    }

                    # 3. PDP: solo top features y primeros n_vals puntos
                    pdp_summary = {
                        feat: {
                            "grid": pdp_results.loc[pdp_results.feature == feat, "grid"].astype(float).values[:n_vals].tolist(),
                            "pdp": pdp_results.loc[pdp_results.feature == feat, "pdp"].astype(float).values[:n_vals].tolist()
                        }
                        for feat in features_lite
                    }

                    # 4. ICE: solo top features, primeros n_vals, y primeras 2 observaciones
                    ice_summary = {}
                    for feat in features_lite:
                        obs_ids = ice_results[ice_results.feature == feat]["observation"].unique()[:2]
                        ice_summary[feat] = {
                            int(obs): {
                                "grid": ice_results[(ice_results.feature == feat) & (ice_results.observation == obs)]["grid"].astype(float).values[:n_vals].tolist(),
                                "ice": ice_results[(ice_results.feature == feat) & (ice_results.observation == obs)]["ice"].astype(float).values[:n_vals].tolist()
                            }
                            for obs in obs_ids
                        }

                    # 5. ALE: igual que PDP
                    ale_summary = {
                        feat: {
                            "grid": ale_results.loc[ale_results.feature == feat, "grid"].astype(float).values[:n_vals].tolist(),
                            "ale": ale_results.loc[ale_results.feature == feat, "ale"].astype(float).values[:n_vals].tolist()
                        }
                        for feat in features_lite
                    }

                    # 6. Counterfactuals: solo 1 o 2 ejemplos, y solo diferencias principales
                    cf_summary = []
                    for c in cf_explanations[:2]:
                        d = {k: c[k] for k in ["observation", "y_pred_original", "y_pred_cf"]}
                        d["counterfactual"] = {k: v for k, v in list(c["counterfactual"].items())[:n_feats]}
                        cf_summary.append(d)

                    return {
                        "shap": shap_summary,
                        "perm": perm_summary,
                        "pdp": pdp_summary,
                        "ice": ice_summary,
                        "ale": ale_summary,
                        "cf": cf_summary
                    }

                # ‚Äî Serializaci√≥n resumida ‚Äî
                xai_resumido = resumir_xai_json(
                    shap_vals, features, perm, idx_imp, top_feats,
                    pdp_results, ice_results, ale_results, cf_explanations,
                    n_feats=2, n_vals=8
                )

                shap_json_lite = json.dumps(xai_resumido["shap"], indent=2, ensure_ascii=False)
                perm_json_lite = json.dumps(xai_resumido["perm"], indent=2, ensure_ascii=False)
                pdp_json_lite  = json.dumps(xai_resumido["pdp"], indent=2, ensure_ascii=False)
                ice_json_lite  = json.dumps(xai_resumido["ice"], indent=2, ensure_ascii=False)
                ale_json_lite  = json.dumps(xai_resumido["ale"], indent=2, ensure_ascii=False)
                cf_json_lite   = json.dumps(xai_resumido["cf"], indent=2, ensure_ascii=False)

                # Guardar los JSON para el siguiente bloque
                self.shap_json_lite = shap_json_lite
                self.perm_json_lite = perm_json_lite
                self.pdp_json_lite  = pdp_json_lite
                self.ice_json_lite  = ice_json_lite
                self.ale_json_lite  = ale_json_lite
                self.cf_json_lite   = cf_json_lite

            except Exception as e:
                import traceback
                print("[DEBUG] Se ha producido una excepci√≥n en Interpretaci√≥n xIA:")
                print(f"[DEBUG] Tipo de excepci√≥n: {type(e).__name__}")
                print(f"[DEBUG] Mensaje: {e}")
                print("[DEBUG] Traza completa:")
                traceback.print_exc()
                self.sections.append((
                    "### ‚ö†Ô∏è Error en interpretaci√≥n xIA del modelo",
                    f"{type(e).__name__}: {e}"
                ))

            # --- Fin Bloque 4 ---

            # --- Bloque 5: Interpretaci√≥n F√≠sica-Qu√≠mica del Mejor Modelo Optimizado mediante IA ---
            print("[DEBUG] 17.19. Iniciando Interpretaci√≥n F√≠sico - Qu√≠micamediante IA  del Mejor Modelo Optimizado")
            try:
                import os
                import json
                #import pandas as pd
                #from PyPDF2 import PdfReader
                import openai

                # 1) Cargar y extraer texto de contexto de varios PDFs
                from PyPDF2 import PdfReader
                import pandas as pd

                # --- Gesti√≥n de subida y carga de contexto desde memoria en Colab ---
                import io
                import pandas as pd
                from PyPDF2 import PdfReader
                from google.colab import files
                import io

                # 2.1) Abrimos selector de archivos y leemos el .xlsx subido
                uploaded = files.upload()
                excel_file = next(f for f in uploaded.keys() if f.lower().endswith('.xlsx'))
                book_bytes = io.BytesIO(uploaded[excel_file])

                # 2.2) Cargamos **todas** las hojas; cada DataFrame toma su primera fila como cabecera
                import pandas as _pd
                sheets_dict = _pd.read_excel(book_bytes, sheet_name=None)

                print("Hojas encontradas en el Excel:", list(sheets_dict.keys()))

                # 2.3) Convertimos cada hoja en lista de dicts (records) sin predefinir columnas
                mapa_variables = {
                    name: (
                        df
                        .astype(str)            # convertimos todo a string para evitar Timestamp u otros tipos
                        .dropna(how='all')      # eliminamos filas completamente vac√≠as
                        .to_dict(orient="records")
                    )
                    for name, df in sheets_dict.items()
                }
                # 2.4) A√±adimos al contexto global
                #contexto["mapa_variables"] = mapa_variables

                # 3) Cargar y extraer texto de TODOS los PDFs subidos
                pdf_texts = {}
                for fn, content in uploaded.items():
                    if fn.lower().endswith(".pdf"):
                        reader = PdfReader(io.BytesIO(content))
                        full = "\n".join(page.extract_text() or "" for page in reader.pages)
                        pdf_texts[fn] = full

                # 4) Del PDF de proceso aislamos la secci√≥n relevante (si existe)
                proceso_pdf = next((k for k in pdf_texts if "Procesado_Datos_Linares" in k), None)
                if proceso_pdf:
                    texto = pdf_texts[proceso_pdf]
                    start_marker = "VARIABLES Y PARTICULARIDADES DEL PROCESO"
                    end_marker   = "Etapas del proceso"
                    i0 = texto.find(start_marker)
                    i1 = texto.find(end_marker, i0 + len(start_marker))
                    if i0 != -1 and i1 != -1:
                        proceso_texto = texto[i0:i1].strip()
                    else:
                        proceso_texto = texto
                else:
                    proceso_texto = ""

                # 5) Texto de la memoria TFM (si existe)
                memoria_pdf = next((k for k in pdf_texts if "Memoria Final TFM" in k), None)
                memoria_texto = pdf_texts.get(memoria_pdf, "")

                # 6) Construir el contexto completo
                contexto = {
                    "proceso_texto":   proceso_texto,
                    "memoria_texto":   memoria_texto,
                    "mapa_variables":  mapa_variables,
                    "dominio": (
                        "Este modelo optimiza la predicci√≥n de la variable objetivo en la planta de "
                        "aglomerados de Linares. Se considera la interacci√≥n f√≠sico-qu√≠mica entre resinas, "
                        "temperaturas de secado y niveles de humedad, as√≠ como par√°metros de prensa y fases de corte."
                    )
                }

                # Ya puedes usar `contexto` y `contexto_variables` en tu prompt de OpenAI.
                print("[DEBUG] 17.20. Iniciando llamada a IA para an√°lisis F√≠sico - Qu√≠mico del proceso")

                # 1. Prompt SHAP + Permutation
                prompt_shap_perm = f"""
            Dominio industrial:
            {contexto['dominio']}

            Resultados SHAP (importancia global resumida):
            {self.shap_json_lite}

            Permutation Importance (top features):
            {self.perm_json_lite}

            Explica c√≥mo afectan estas variables al proceso y su impacto f√≠sico-qu√≠mico.
            """

                # 2. Prompt PDP + ALE
                prompt_pdp_ale = f"""
            Dominio industrial:
            {contexto['dominio']}

            PDP (efecto parcial) para principales variables:
            {self.pdp_json_lite}

            ALE (efecto acumulado local) para principales variables:
            {self.ale_json_lite}

            Relaciona las tendencias observadas en los gr√°ficos PDP y ALE con los fen√≥menos f√≠sicos-qu√≠micos reales.
            """

                # 3. Prompt ICE
                prompt_ice = f"""
            Dominio industrial:
            {contexto['dominio']}

            ICE (efectos individuales):
            {self.ice_json_lite}

            Describe la variabilidad operativa observada en ICE y su impacto en condiciones reales de planta.
            """

                # 4. Prompt Counterfactuals
                prompt_cf = f"""
            Dominio industrial:
            {contexto['dominio']}

            Counterfactuals (s√≥lo ejemplos principales):
            {self.cf_json_lite}

            Proporciona recomendaciones sobre ajustes operativos para mejorar el KPI.
            """

                prompts = [
                    ("### Interpretaci√≥n SHAP + Permutation", prompt_shap_perm),
                    ("### Interpretaci√≥n PDP + ALE", prompt_pdp_ale),
                    ("### Interpretaci√≥n ICE", prompt_ice),
                    ("### Interpretaci√≥n Counterfactuals", prompt_cf)
                ]

                for titulo, prompt in prompts:
                    print(f"[DEBUG] 17.21. Llamando a IA para {titulo}")
                    resp = _client.chat.completions.create(
                        model="gpt-4",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=TEMPERATURE_VAL,
                        max_tokens=MAX_EXPLANATION_TOKENS,
                    )
                    explicacion = resp.choices[0].message.content
                    self.sections.append((titulo, explicacion))

            except Exception as e:
                self.sections.append((
                    "### ‚ö†Ô∏è Error en Interpretaci√≥n F√≠sica-Qu√≠mica",
                    f"{e}"
                ))

        except Exception as e:
            #self.sections.append((
            #    "### ‚ö†Ô∏è Error en selecci√≥n integral de modelo",
            #    f"Se produjo un error al generar la secci√≥n de selecci√≥n integral: {e}"
            #))
            # DEBUG: imprimo excepci√≥n completa para rastrear el fallo
            import traceback
            print(f"[DEBUG] ERROR: {type(e).__name__}: {e}")
            traceback.print_exc()
            self.sections.append((
                "### ‚ö†Ô∏è Error en selecci√≥n integral de modelo",
                f"Se produjo un error al generar la secci√≥n de selecci√≥n integral: {type(e).__name__}: {e}"
            ))
        # --- Fin Bloque 5 - Secci√≥n Integral del Modelo ---

        # --- Bloque 6: Curvas Y real vs. Y predicha por variable X (modelo √≥ptimo) ---
        try:
            print("[DEBUG] 17.22. Iniciando bloque de curvas Y real vs predicho por variable X")

            import numpy as np
            from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
            import matplotlib.pyplot as plt
            import pandas as pd

            # DEBUG: listar todas las secciones a√±adidas hasta ahora
            print("[DEBUG] 17.23. Secciones en self.sections:")
            for idx, (title, content) in enumerate(self.sections):
                tipo = type(content).__name__
                cols = content.columns.tolist() if hasattr(content, "columns") else None
                print(f"   {idx:02d}: '{title}' ‚Üí {tipo}" + (f", cols={cols}" if cols else ""))
            print("[DEBUG] 17.24. Ahora buscamos la tabla con 'puntuacion_global_final'‚Ä¶")

            # 1) Recuperar el DataFrame de resultados globales con 'puntuacion_global_final'
            df_results = None
            for title, content in self.sections:
                if isinstance(content, pd.DataFrame) and 'puntuacion_global_final' in content.columns:
                    df_results = content
                    break
            if df_results is None:
                raise RuntimeError("No se encontr√≥ la tabla de puntuaciones globales (df_results)")

            # 2) Identificar el mejor modelo
            best_idx = df_results['puntuacion_global_final'].idxmax()
            best_row = df_results.loc[best_idx]
            tipo, metodo, motor = best_row['tipo'], best_row['metodo'], best_row['motor']
            print(f"[DEBUG] 17.25. Modelo √≥ptimo identificado: {tipo}-{metodo}-{motor}")

            # 3) Recuperar payload, modelo, scalers y lista de variables
            payload = OPT_MODELS[(tipo, metodo, motor)]
            model   = payload['model']
            features = payload.get('cols', self.g['X_test'].columns.tolist())
            sx      = payload.get('sx')   # scaler de X, si existe
            sy      = payload.get('sy')   # scaler de Y, si existe

            # 4) Preparar datos de test y predicciones
            X_test_sel = self.g['X_test'][features].copy()
            y_true     = self.g['Y_test'].values.ravel()
            # Escalado y predict
            X_scaled = sx.transform(X_test_sel.values) if sx else X_test_sel.values
            y_pred_raw = model.predict(X_scaled)
            y_pred = (sy.inverse_transform(y_pred_raw.reshape(-1,1)).ravel()
                      if sy else y_pred_raw.ravel())

            # 5) Calcular m√©tricas globales de ajuste (id√©nticas para todos los subplots)
            r2  = r2_score(y_true, y_pred)
            mae = mean_absolute_error(y_true, y_pred)
            mse = mean_squared_error(y_true, y_pred)
            print(f"[DEBUG] 17.26. M√©tricas globales del modelo √≥ptimo: R2={r2:.3f}, MAE={mae:.3f}, MSE={mse:.3f}")

            # 6) Crear figura de small multiples
            n_vars = len(features)
            ncols  = min(4, n_vars)
            nrows  = int(np.ceil(n_vars / ncols))

            fig, axes = plt.subplots(
                nrows, ncols,
                figsize=(ncols * 3, nrows * 2.5),
                squeeze=False
            )

            for ax, feat in zip(axes.flatten(), features):
                # Ordenar por valor de X para trazar l√≠neas ordenadas
                x = X_test_sel[feat].values
                idx_sort = np.argsort(x)
                x_s = x[idx_sort]
                ax.plot(x_s, y_true[idx_sort],   label='Real',    linewidth=1)
                ax.plot(x_s, y_pred[idx_sort],   label='Predicho',linewidth=1)
                ax.set_title(
                    f"{feat}\n"
                    f"R¬≤={r2:.2f}  MAE={mae:.2f}  MSE={mse:.2f}",
                    fontsize=8
                )
                ax.tick_params(labelsize=6)
                ax.legend(fontsize=6)

            # Desactivar ejes sobrantes
            for ax in axes.flatten()[n_vars:]:
                ax.set_visible(False)

            fig.tight_layout()
            print("[DEBUG] 17.27. Bloque de curvas completado, a√±adiendo secci√≥n al informe")

            # 7) A√±adir al informe
            self.sections.append((
                "### Curvas Y real vs Y predicha por variable X (modelo √≥ptimo)",
                fig
            ))

        except Exception as e:
            # En caso de fallo, no romper√° todo el build_sections
            print(f"[ERROR] en bloque de curvas Y vs X: {e}")
            self.sections.append((
                "### ‚ö†Ô∏è Error en Curvas Y vs X",
                f"Se produjo un error generando las curvas: {e}"
            ))
        # --- Fin Bloque 6: Curvas Y real vs. Y predicha por variable X (modelo √≥ptimo) ---

        # --- Bloque 7: An√°lisis IA de Curvas Y real vs Y predicho por Variable X ---
        try:
            print("[DEBUG] 17.28. Enriqueciendo contexto antes de llamar a OpenAI")

            from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
            from scipy.stats import skew, kurtosis, pearsonr
            import pandas as pd

            # Recuperar la configuraci√≥n del mejor modelo
            # (aseg√∫rate de haber definido antes mt, method, engine)
            key_best     = (mt, method, engine)
            payload_best = OPT_MODELS[key_best]
            features     = payload_best['cols']
            model_best   = payload_best['model']

            # Extraer datos de test y predicciones
            X_te = X_test[features].copy()
            y_true = Y_test.values.ravel()
            sx = payload_best.get('sx', None)
            X_te_s = sx.transform(X_te.values) if sx else X_te.values
            # Si el wrapper ya invierte la escala internamente:
            y_pred = model_best.predict(X_te_s) if not hasattr(model_best, 'sy') else model_best.predict(X_te)

            # 1) Estad√≠sticas de distribuci√≥n de cada X
            dist_stats = {}
            for feat in features:
                arr = X_te[feat].values
                dist_stats[feat] = {
                    'min': float(arr.min()),
                    'max': float(arr.max()),
                    'mean': float(arr.mean()),
                    'std': float(arr.std()),
                    'skew': float(skew(arr)),
                    'kurtosis': float(kurtosis(arr)),
                }

            # 2) Correlaci√≥n residual vs X (heterocedasticidad)
            residuals = y_true - y_pred
            corr_stats = {}
            for feat in features:
                r, p = pearsonr(X_te[feat].values, residuals)
                corr_stats[feat] = {'pearson_r': float(r), 'p_value': float(p)}

            # 3) Residuales por cuartiles de X
            quartile_stats = {}
            for feat in features:
                df_q = pd.DataFrame({
                    'x': X_te[feat],
                    'res': residuals
                })
                df_q['qcut'] = pd.qcut(df_q['x'], 4, labels=False, duplicates='drop')
                qs = df_q.groupby('qcut')['res'].agg(['mean','std']).to_dict(orient='index')
                quartile_stats[feat] = {
                    int(k): {'mean_res': float(v['mean']), 'std_res': float(v['std'])}
                    for k, v in qs.items()
                }

            # 4) Ejemplos de pares (X, y_real, y_pred) en cuartiles extremos
            samples = {}
            for feat in features:
                # Seleccionar solo cuartiles 0 y 3
                cuts = pd.qcut(X_te[feat], 4, labels=False, duplicates='drop')
                sel = cuts.isin([0, 3])
                df_s = pd.DataFrame({
                    'x':   X_te[feat][sel],
                    'y_r': y_true[sel],
                    'y_p': y_pred[sel]
                }).head(3)  # 3 muestras por variable
                samples[feat] = df_s.to_dict(orient='records')

            # 5) M√©tricas globales del modelo √≥ptimo
            global_stats = {
                'R2':  float(r2_score(y_true, y_pred)),
                'MAE': float(mean_absolute_error(y_true, y_pred)),
                'MSE': float(mean_squared_error(y_true, y_pred))
            }

            print("[DEBUG] 17.29. Dist stats, corr stats, quartile stats y samples construidos")

            # 6) Construcci√≥n del prompt enriquecido
            prompt = [
                "A continuaci√≥n tienes un informe detallado de cada variable X:\n",
                "**1) Distribuci√≥n de cada X:**",
                f"{dist_stats}\n",
                "**2) Correlaci√≥n Residual vs X (Pearson):**",
                f"{corr_stats}\n",
                "**3) Residuales por cuartiles de X:**",
                f"{quartile_stats}\n",
                "**4) Ejemplos de pares (X, y_real, y_predicho) en cuartiles extremos:**",
                f"{samples}\n",
                "**5) M√©tricas globales del modelo √≥ptimo:**",
                f"{global_stats}\n",
                "### Instrucciones al experto IA:\n"
                "1. Analiza para cada variable X c√≥mo la distribuci√≥n y la heterocedasticidad "
                "(Pearson r, residuales por cuartiles) pueden estar afectando el ajuste.\n"
                "2. Discute zonas problem√°ticas (picos, colas extensas) y su impacto en la predicci√≥n.\n"
                "3. Comenta sobre las muestras de ejemplo: ¬øqu√© patrones ves en X extremos?\n"
                "4. Integra el conocimiento f√≠sico-qu√≠mico del proceso para explicar estos fen√≥menos.\n"
                "5. Prop√≥n recomendaciones tanto de modelado (transformaciones, nuevas features) "
                "como de operaci√≥n del proceso (rangos √≥ptimos, variables cr√≠ticas).\n"
            ]
            full_prompt = "\n".join(prompt)

            print("[DEBUG] 17.30. Llamando a OpenAI directamente con _client.chat.completions.create para Curvas‚Ä¶")
            response = _client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "Eres un experto en an√°lisis de series temporales y ML para procesos f√≠sico-qu√≠micos."},
                    {"role": "user",   "content": full_prompt}
                ],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS
            )
            analysis_curvas = response.choices[0].message.content.strip()
            print(f"[DEBUG] 17.31. Longitud del an√°lisis de curvas: {len(analysis_curvas)} caracteres")

            # 7) A√±adimos la secci√≥n final al reporte
            self.sections.append((
                "### An√°lisis IA Profundo de Y real vs Y predicho por Variable X",
                analysis_curvas
            ))
            print("[DEBUG] 17.32. Secci√≥n An√°lisis IA enriquecido a√±adida")

        except Exception as e:
            err = f"Error en Bloque IA Profundo curvas X vs Y: {e}"
            self.sections.append((
                "### ‚ö†Ô∏è Error Bloque IA Profundo curvas X vs Y",
                err
            ))
            print(f"[DEBUG] {err}")

        # --- Fin Bloque 7: An√°lisis IA de Curvas Y real vs Y predicho por Variable X ---

        # --- Bloque 8: Robustez What-If y Gr√°ficas Extremos ---
        try:
            print("[DEBUG] 17.33. Iniciando Bloque Robustez What-If y Gr√°ficas Extremos")

            import itertools
            import numpy as np
            import pandas as pd
            import matplotlib.pyplot as plt
            import seaborn as sns

            # <<< NUEVO: Obtener escaladores desde payload (como se hace en xIA) >>>
            sx = payload.get('sx')
            sy = payload.get('sy')

            # Ajustes globales de estilo
            sns.set(style="whitegrid", palette="deep", font_scale=1.2)
            plt.rcParams.update({
                "figure.facecolor": "white",
                "axes.facecolor": "white",
                "axes.edgecolor": "#333333",
                "axes.labelcolor": "#333333",
                "xtick.color": "#333333",
                "ytick.color": "#333333",
                "text.color": "#333333",
                "legend.frameon": True,
                "legend.framealpha": 0.9,
            })

            # 1) Variables para robustez
            vars_robust = top_feats[:2]
            print(f"[DEBUG] 17.34. Variables robustez seleccionadas: {vars_robust}")

            # 2) Medianas y extremos
            medians   = X_train[features].median()
            low_vals  = X_train[features].quantile(0.05)
            high_vals = X_train[features].quantile(0.95)
            print("[DEBUG] 17.35. Valores medianos y percentiles obtenidos")

            # 3) Generar escenarios what-if
            scenarios = []
            for combo in itertools.product(['low','high'], repeat=len(vars_robust)):
                sc = medians.copy()
                labels = []
                for var, lvl in zip(vars_robust, combo):
                    sc[var] = low_vals[var] if lvl=='low' else high_vals[var]
                    labels.append(f"{var}_{lvl}")
                sc['__label__'] = " & ".join(labels)
                scenarios.append(sc)
            df_scen = pd.DataFrame(scenarios).reset_index(drop=True)
            print(f"[DEBUG] 17.36. {len(df_scen)} escenarios generados: {df_scen['__label__'].tolist()}")

            # <<< CAMBIO: Aplicar escalado SOLO si existe sx >>>
            X_scen = sx.transform(df_scen[features].values) if sx else df_scen[features].values
            if mt == 'rnn':
                X_in = X_scen.reshape((X_scen.shape[0], 1, X_scen.shape[1]))
            else:
                X_in = X_scen

            # 5) Predecir y calcular errores
            y_pred = model.predict(X_in)
            if mt != 'rnn':
                #y_pred = sy.inverse_transform(y_pred.reshape(-1,1)).ravel()
                y_pred = sy.inverse_transform(y_pred.reshape(-1,1)).ravel() if sy else y_pred.ravel()
            df_scen['y_pred'] = y_pred

            # <<< CAMBIO: Mismo tratamiento para y_base >>>
            yb = model.predict(
                X_in[:1].reshape((1,1,X_scen.shape[1])) if mt=='rnn' else X_in[:1]
            )
            if mt != 'rnn':
                yb = sy.inverse_transform(yb.reshape(-1,1)).ravel()[0] if sy else yb.ravel()[0]

            df_scen['y_base'] = yb
            df_scen['error_abs'] = np.abs(df_scen['y_pred'] - df_scen['y_base'])
            print("[DEBUG] 17.37. Predicciones y errores calculados")

            # 6) Boxplot de Error Absoluto
            fig1, ax1 = plt.subplots(figsize=(8, 5))
            sns.boxplot(
                y=df_scen['error_abs'],
                ax=ax1,
                width=0.4,
                boxprops=dict(facecolor="#4F81BD", edgecolor="#333333"),
                medianprops=dict(color="#E74C3C", linewidth=2),
                whiskerprops=dict(color="#333333", linewidth=1.5),
                capprops=dict(color="#333333", linewidth=1.5)
            )
            ax1.set_title("What-If: Boxplot de Error Absoluto", fontsize=16, fontweight='bold')
            ax1.set_ylabel("Error absoluto", fontsize=14)
            ax1.set_xticks([])
            ax1.grid(axis='y', linestyle='--', alpha=0.7)
            plt.tight_layout()
            self.sections.append((
                "### Robustez What-If: Boxplot de Error Absoluto",
                fig1
            ))
            print("[DEBUG] 17.38. Secci√≥n Boxplot de error a√±adido")

            # 7) Scatter Y_pred vs Baseline por escenario
            fig2, ax2 = plt.subplots(figsize=(10, 6))
            idx = np.arange(len(df_scen))
            ax2.plot(idx, df_scen['y_base'], marker='o', linestyle='-', label='Baseline', linewidth=2)
            ax2.plot(idx, df_scen['y_pred'], marker='X', linestyle='--', label='What-If Predicho', linewidth=2)
            for i, lbl in enumerate(df_scen['__label__']):
                ax2.annotate(
                    lbl,
                    (idx[i], df_scen['y_pred'].iloc[i]),
                    textcoords="offset points",
                    xytext=(0,8),
                    ha='center',
                    fontsize=10,
                    color="#333333"
                )
            ax2.set_xticks(idx)
            ax2.set_xticklabels(df_scen['__label__'], rotation=45, ha='right', fontsize=10)
            ax2.set_title("What-If: Y Predicho vs Baseline por Escenario", fontsize=16, fontweight='bold')
            ax2.set_xlabel("Escenario", fontsize=14)
            ax2.set_ylabel("Y", fontsize=14)
            ax2.legend(frameon=True, fontsize=12)
            ax2.grid(True, linestyle='--', alpha=0.5)
            plt.tight_layout()
            self.sections.append((
                "### Robustez What-If: Y Predicho vs Baseline",
                fig2
            ))
            print("[DEBUG] 17.39. Secci√≥n Scatter plot de escenarios a√±adido")

        except Exception as e:
            import traceback
            print("[DEBUG] Se ha producido una excepci√≥n en el Bloque Robustez What-If:")
            print("[DEBUG] Tipo de excepci√≥n:", type(e).__name__)
            print("[DEBUG] Mensaje:", e)
            print("[DEBUG] Traza completa:")
            traceback.print_exc()
            self.sections.append((
                "### ‚ö†Ô∏è Error en Bloque Robustez What-If",
                f"{type(e).__name__}: {e}"
            ))
            print(f"[DEBUG] Error en Bloque Robustez What-If: {e}")
        # --- Fin Bloque 8: Robustez What-If y Gr√°ficas Extremos ---

        # --- Bloque 9: An√°lisis e Interpretaci√≥n IA de Robustez What-If ---
        try:
            print("[DEBUG] 17.40. Iniciando Bloque IA de Robustez What-If e Interpretaci√≥n")

            # üëá Extraemos del atributo best_model_info
            metodo = self.best_model_info['metodo']
            motor  = self.best_model_info['motor']
            score  = self.best_model_info['score']

            # üëá Y las m√©tricas guardadas como atributos
            r2_cv_std = self.r2_cv_std
            res_std   = self.res_std
            cal_err   = self.cal_err

            # DEBUG: comprobaci√≥n de valores
            print(f"[DEBUG] 17.41. Mejor modelo ‚Üí m√©todo={metodo}, motor={motor}, score={score:.4f}")
            print(f"[DEBUG] 17.42. M√©tricas desde atributos ‚Üí r2_cv_std={r2_cv_std:.4f}, res_std={res_std:.4f}, cal_err={cal_err:.4f}")

            # 1) Resumen num√©rico de escenarios what-if
            stats = {
                'mean_error': float(df_scen['error_abs'].mean()),
                'std_error':  float(df_scen['error_abs'].std()),
                'max_error':  float(df_scen['error_abs'].max()),
                'min_error':  float(df_scen['error_abs'].min()),
                'percentiles_error': {
                    '25%': float(df_scen['error_abs'].quantile(0.25)),
                    '50%': float(df_scen['error_abs'].quantile(0.50)),
                    '75%': float(df_scen['error_abs'].quantile(0.75))
                }
            }
            print(f"[DEBUG] 17.43. Estad√≠sticos de error abs: {stats}")

            # 2) Preparar tabla de escenarios en formato dict para el prompt
            table_dict = df_scen[['__label__','y_base','y_pred','error_abs']].to_dict(orient='list')
            print("[DEBUG] 17.44. Tabla de escenarios convertida a dict para prompt")

            # 3) Montar prompt rico en contexto
            prompt_robustez = f"""
        Eres un experto en evaluaci√≥n de robustez de modelos y procesos f√≠sico-qu√≠micos.

        A continuaci√≥n tienes los resultados del an√°lisis What-If para el modelo √≥ptimo (m√©todo={metodo}, motor={motor}):

        ‚Ä¢ Estad√≠sticos globales del error absoluto:
          - Media: {stats['mean_error']:.4f}
          - Desviaci√≥n est√°ndar: {stats['std_error']:.4f}
          - M√≠nimo: {stats['min_error']:.4f}
          - M√°ximo: {stats['max_error']:.4f}
          - Percentiles: 25%={stats['percentiles_error']['25%']:.4f}, 50%={stats['percentiles_error']['50%']:.4f}, 75%={stats['percentiles_error']['75%']:.4f}

        ‚Ä¢ Detalle por escenario:
          { { 'Escenarios': table_dict } }

        Instrucciones para el an√°lisis:
        1. Describe para cada escenario (etiqueta) c√≥mo var√≠a la predicci√≥n frente al baseline y qu√© significa en t√©rminos del proceso f√≠sico-qu√≠mico.
        2. Identifica qu√© variables generan mayor sensibilidad en el modelo y por qu√©.
        3. Resume los hallazgos generales de robustez y menciona si existen condiciones extremas donde el modelo falla o se vuelve inestable.
        4. Prop√≥n recomendaciones para mejorar la robustez del modelo (por ejemplo, ajustes de hiperpar√°metros, transformaciones, data augmentation de escenarios extremos).
        5. Sugiere acciones operativas concretas en planta (rangos de temperatura, concentraciones, etc.) bas√°ndote en los resultados What-If.
        """

            print("[DEBUG] 17.45. Llamando a OpenAI directamente con _client.chat.completions.create‚Ä¶")
            response = _client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "Eres un experto en Machine Learning aplicado a procesos f√≠sico-qu√≠micos."},
                    {"role": "user",   "content": prompt_robustez}
                ],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS
            )
            analysis_robustez = response.choices[0].message.content.strip()
            print(f"[DEBUG] 17.46. Longitud del an√°lisis de robustez: {len(analysis_robustez)} caracteres")

            # 4) A√±adir secci√≥n al informe
            self.sections.append((
                "### Robustez What-If: An√°lisis e Interpretaci√≥n IA",
                analysis_robustez
            ))
            print("[DEBUG] 17.47. Secci√≥n IA Robustez What-If a√±adida")

        except Exception as e:
            error_msg = f"{type(e).__name__}: {e}"
            print(f"[DEBUG] Error en Bloque IA Robustez What-If: {error_msg}")
            self.sections.append((
                "### ‚ö†Ô∏è Error en Bloque IA Robustez What-If",
                error_msg
            ))
        # --- Fin Bloque 9: An√°lisis e Interpretaci√≥n IA de Robustez What-If ---

        # =============================================================================
        #  Bloque 18: Conclusiones y Recomendaciones Generales
        # =============================================================================
        try:
            print("[DEBUG] 18.1. Iniciando Bloque Final de Conclusiones y Recomendaciones")

            # 1) Extraer info clave del mejor modelo (aseg√∫rate de haberla guardado antes)
            best = getattr(self, 'best_model_info', {})
            metodo = best.get('metodo', 'N/A')
            motor  = best.get('motor', 'N/A')
            score  = best.get('score', None)

            # 2) Extraer m√©tricas adicionales si las guardaste como atributos
            r2_cv_std = getattr(self, 'r2_cv_std', None)
            res_std   = getattr(self, 'res_std', None)
            cal_err   = getattr(self, 'cal_err', None)

            # 3) Formatear con control de None
            score_txt   = f"{score:.4f}"    if score    is not None else "N/A"
            r2_cv_txt   = f"{r2_cv_std:.4f}" if r2_cv_std is not None else "N/A"
            res_std_txt = f"{res_std:.4f}"   if res_std   is not None else "N/A"
            cal_err_txt = f"{cal_err:.4f}"   if cal_err   is not None else "N/A"

            perf_txt = (
                f"- **Mejor modelo**: {metodo}  \n"
                f"- **Motor de optimizaci√≥n**: {motor}  \n"
                f"- **Score final (R¬≤ o indicador principal)**: {score_txt}  \n"
                f"- **Std R¬≤ en CV**: {r2_cv_txt}  \n"
                f"- **Std residuos**: {res_std_txt}  \n"
                f"- **Error medio de calibraci√≥n**: {cal_err_txt}  \n"
            )
            print(f"[DEBUG] 18.2. perf_txt:\n{perf_txt}")

            # 4) Resumir metodolog√≠a (t√≠tulos de secciones ya generados)
            pasos = [
                "1. Carga y preprocesado de datos",
                "2. Exploraci√≥n estad√≠stica y visualizaci√≥n",
                "3. Selecci√≥n de variables independientes",
                "4. Entrenamiento de modelos (SVR, NN, XGB, RF, RNN)",
                "5. Optimizaci√≥n de hiperpar√°metros",
                "6. Interpretabilidad (SHAP, PDP, ICE, ALE, counterfactuals)",
                "7. An√°lisis de robustez What-If y escenarios extremos"
            ]
            metod_txt = "\n".join(f"- {p}" for p in pasos)
            print(f"[DEBUG] 18.3. metod_txt:\n{metod_txt}")

            # 5) Inyectar snippets de texto IA previos (si los tienes)
            snippets = []
            for title, content in self.sections:
                if title.startswith("### üìù Explicaci√≥n IA"):
                    # tomamos los primeros 200 caracteres de cada an√°lisis
                    text = str(content)[:200].replace("\n", " ")                                # <------ AJUSTAR AQUI (INCREMENTAR ) PARA MEJORAR LA CALIDAD DEL AN√ÅLISIS DE LA IA
                    snippets.append(f"{title.lstrip('# ')}: ¬´{text}...¬ª")
            snippets_txt = "\n".join(f"- {s}" for s in snippets)
            print(f"[DEBUG] 18.4. snippets_txt:\n{snippets_txt}")

            # 6) Construir prompt final
            prompt = (
                "Eres un investigador de Deep Learning y un experto en procesos f√≠sico-qu√≠micos industriales.\n"
                "Tienes la siguiente informaci√≥n:\n\n"
                "**A) Rendimiento del mejor modelo**:\n"
                f"{perf_txt}\n"
                "**B) Metodolog√≠a seguida**:\n"
                f"{metod_txt}\n\n"
                "**C) Res√∫menes de an√°lisis previos**:\n"
                f"{snippets_txt}\n\n"
                "Con toda esta informaci√≥n, por favor:\n"
                "1. Resume cada paso de la metodolog√≠a en 1‚Äì2 frases, enfatizando aprendizajes clave.\n"
                "2. Sintetiza los hallazgos principales (tendencias, variables cr√≠ticas, puntos fuertes/d√©biles del modelo).\n"
                "3. Conecta estos hallazgos con el proceso f√≠sico-qu√≠mico: ¬øqu√© par√°metros de planta son m√°s determinantes?\n"
                "4. Prop√≥n **3‚Äì5 acciones inmediatas** (p. ej. ajustes de operaci√≥n, reentrenamiento, ampliaci√≥n de datos).\n"
                "5. Dise√±a un roadmap de validaci√≥n y despliegue (pruebas A/B, monitorizaci√≥n de drift, retrain schedule).\n"
                "6. Finaliza con un breve p√°rrafo de cierre brillante que refuerce la confianza en el informe.\n"
                "7. Incluye **2‚Äì3 referencias bibliogr√°ficas** (APA) que respalden tus recomendaciones.\n"
            )
            print(f"[DEBUG] 18.5. Prompt final construido (longitud {len(prompt)} caracteres)")

            # 7) Llamada a OpenAI
            response = _client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "Eres un investigador acad√©mico y consultor industrial senior."},
                    {"role": "user",   "content": prompt}
                ],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS
            )
            concl_text = response.choices[0].message.content.strip()
            print("[DEBUG] 18.6. Respuesta IA recibida con longitud:", len(concl_text))

            # 8) A√±adir secci√≥n final
            self.sections.append((
                "### Conclusiones y Recomendaciones Finales",
                concl_text
            ))
            print("[DEBUG] 18.7. Secci√≥n de conclusiones a√±adida exitosamente")

        except Exception as e:
            print(f"[ERROR] al generar Bloque Final de Conclusiones: {e}")
            self.sections.append((
                "### ‚ö†Ô∏è Error en Bloque de Conclusiones",
                str(e)
            ))
        # =============================================================================
        #  Fin Bloque 18 Conclusiones
        # =============================================================================

        # ============================================================================
        # --- Bloque 19: Descripci√≥n de PMS y Road-Map de Evoluci√≥n Tecnol√≥gica ---
        # ============================================================================
        try:
            print("[DEBUG] 19.1. Iniciando Bloque Descripci√≥n y roadmap de PMS")

            import os, glob, ast, inspect, json

            base_dir = os.getcwd()

            # 1) Archivos .py
            py_files = glob.glob(os.path.join(base_dir, "*.py"))
            loc_summary_py = {}
            deps = set()
            for fn in py_files:
                try:
                    with open(fn, "r", encoding="utf-8") as f:
                        src = f.read()
                    lines = src.splitlines()
                    loc_summary_py[os.path.basename(fn)] = len(lines)
                    tree = ast.parse(src)
                    for node in ast.walk(tree):
                        if isinstance(node, ast.Import):
                            for n in node.names:
                                deps.add(n.name.split(".")[0])
                        elif isinstance(node, ast.ImportFrom):
                            if node.module:
                                deps.add(node.module.split(".")[0])
                except Exception as ex:
                    print(f"[DEBUG] No pude procesar {fn}: {ex}")

            # 2) Notebooks .ipynb
            ipynb_files = glob.glob(os.path.join(base_dir, "*.ipynb"))
            nb_summary = {}
            for fn in ipynb_files:
                try:
                    with open(fn, "r", encoding="utf-8") as f:
                        nb = json.load(f)
                    code_cells = sum(1 for c in nb.get("cells", []) if c.get("cell_type")=="code")
                    nb_summary[os.path.basename(fn)] = code_cells
                except Exception as ex:
                    print(f"[DEBUG] No pude procesar {fn}: {ex}")

            # 3) Inspeccionar ReportBuilder
            members = inspect.getmembers(ReportBuilder)
            methods = [name for name,obj in members if inspect.isfunction(obj)]
            classes = [name for name,obj in members if inspect.isclass(obj)]

            # 4) Secciones ya generadas
            num_sections = len(self.sections)
            titles = [t for t,_ in self.sections]

            # 5) Formatear resumen
            summary_lines = []
            summary_lines.append(f"‚Ä¢ Archivos .py escaneados ({len(py_files)}):")
            for fn,loc in loc_summary_py.items():
                summary_lines.append(f"    ‚Äì {fn}: {loc} l√≠neas")
            if ipynb_files:
                summary_lines.append(f"‚Ä¢ Notebooks .ipynb escaneados ({len(ipynb_files)}):")
                for fn,cells in nb_summary.items():
                    summary_lines.append(f"    ‚Äì {fn}: {cells} celdas de c√≥digo")
            summary_lines.append(f"‚Ä¢ Dependencias detectadas: {', '.join(sorted(deps))}")
            summary_lines.append(f"‚Ä¢ M√©todos en ReportBuilder: {', '.join(methods)}")
            summary_lines.append(f"‚Ä¢ Clases definidas en ReportBuilder: {', '.join(classes)}")
            summary_lines.append(f"‚Ä¢ Secciones del informe generadas ({num_sections}):")
            for t in titles:
                summary_lines.append(f"    ‚Äì {t}")

            summary_txt = "\n".join(summary_lines)

            # 6) Construir prompt
            prompt_pms = f"""
        Eres un arquitecto de software y consultor de procesos industriales.
        A continuaci√≥n tienes un **resumen de la herramienta PMS** y su c√≥digo fuente:

        {summary_txt}

        En base a ello, por favor:
        1. Describe **detalladamente la arquitectura** de la aplicaci√≥n:
          - Flujo de ejecuci√≥n
          - Principales m√≥dulos y clases
          - Patrones de dise√±o o buenas pr√°cticas observadas.

        2. Se√±ala **puntos fuertes** y **oportunidades de mejora**:
          - Modularidad, legibilidad, rendimiento, uso de librer√≠as.
          - Aspectos que podr√≠an complicar el mantenimiento o la escalabilidad.

        3. Proporciona un **road-map de evoluci√≥n tecnol√≥gica**:
          - Refactorizaciones y modularizaci√≥n adicional.
          - Incorporaci√≥n de tests automatizados y pipeline de CI/CD.
          - Contenerizaci√≥n / despliegue (Docker, Kubernetes, microservicios).
          - Nuevas funcionalidades (AutoML, flujos batch/pipeline, APIs).

        4. Recomienda **modelos, motores o m√©todos futuros**:
          - E.g. Transformers para series temporales, AutoML para selecci√≥n de modelos.
          - Explica el **impacto** esperado en la calidad de la predicci√≥n y en la mantenibilidad.

        5. Concluye con un **resumen ejecutivo** de 2‚Äì3 p√°rrafos enfatizando el valor de estas mejoras.
        """

            print("[DEBUG] 19.2. Llamando a OpenAI para Bloque 10 de PMS‚Ä¶")
            resp = _client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role":"system", "content":"Eres investigador acad√©mico, arquitecto de software y consultor industrial."},
                    {"role":"user",   "content":prompt_pms}
                ],
                temperature=TEMPERATURE_VAL,
                max_tokens=MAX_EXPLANATION_TOKENS,
            )
            analysis_pms = resp.choices[0].message.content.strip()

            # 7) A√±adir secci√≥n al informe
            self.sections.append((
                "### Descripci√≥n de PMS y Road-Map de Evoluci√≥n Tecnol√≥gica",
                analysis_pms
            ))
            print("[DEBUG] 19.3. Bloque completado y a√±adido al informe")

        except Exception as e:
            print(f"[DEBUG] Error en Bloque 10: {e}")
            self.sections.append((
                "### ‚ö†Ô∏è Error en Descripci√≥n y Road-Map de PMS",
                str(e)
            ))
        # --- Fin Bloque 11 ---


        print("[DEBUG] 20. ReportBuilder.build_sections end")
    # =============================================================
    #  Renderizado de la salida del Informe
    # =============================================================
    def render(self):
        from IPython.display import Markdown, display, HTML
        import pandas as pd
        import matplotlib.pyplot as plt

        print("[DEBUG] ReportBuilder.render start")
        for idx, (title, content) in enumerate(self.sections):
            print(f"[DEBUG] render secci√≥n #{idx}: {title}")
            # Mostrar t√≠tulo
            display(Markdown(title))

            # Si es DataFrame, aplicamos el estilo como antes
            if isinstance(content, pd.DataFrame):
                df = content
                try:
                    styled = (
                        df.style
                        .set_table_styles([
                            {'selector': 'th',
                            'props': [
                                ('background-color', '#4F81BD'),
                                ('color', 'white'),
                                ('font-weight', 'bold'),
                                ('padding', '8px'),
                                ('text-align', 'center')
                            ]},
                            {'selector': 'td',
                            'props': [
                                ('padding', '8px'),
                                ('text-align', 'center')
                            ]}
                        ])
                        .apply(lambda row: ['background-color: #f2f2f2' if i%2 else '' for i in range(len(row))],
                                axis=1)
                        .set_caption(f"Mostrando {df.shape[0]} filas y {df.shape[1]} columnas")
                    )
                    html = styled.to_html()
                    display(HTML(html))
                    print(f"[DEBUG] render secci√≥n #{idx}: DataFrame mostrado")
                except Exception as e:
                    print(f"[ERROR] al mostrar DataFrame en secci√≥n #{idx}: {e}")
            # Si es figura matplotlib
            elif hasattr(content, 'savefig') or hasattr(content, 'dpi'):  # aproximaci√≥n para Figure
                try:
                    display(content)  # IPython detecta Figure y la muestra
                except Exception:
                    plt.show(content)
            else:
                # Texto IA: como ya limitamos con max_tokens, lo mostramos directamente completo.
                text = str(content or "")
                # Imprimimos longitud para debug
                length = len(text)
                print(f"[DEBUG] Longitud del contenido IA: {length} caracteres")
                # Mostrar todo el texto como Markdown
                display(Markdown(text))
                print(f"[DEBUG] render secci√≥n #{idx}: texto IA mostrado completo")
        print("[DEBUG] ReportBuilder.render end")

# Artifact: function mostrar_informe
def mostrar_informe():
    import ipywidgets as widgets
    from IPython.display import clear_output, display
    """
    Construye TODO el informe, presenta un listado de checkboxes con los t√≠tulos
    reales de secci√≥n, permite al usuario marcarlos (todos DESMARCADOS por defecto)
    y al pulsar 'Generar Informe' limpia la pantalla y muestra solo las secciones elegidas.
    """

    # === M√≥dulo de Exportaciones: Word, PDF y HTML ===
    import io, base64, os
    import pandas as pd
    import matplotlib.pyplot as plt
    from IPython.display import display, HTML
    from docx import Document
    from docx.shared import Inches
    from fpdf import FPDF
    import ipywidgets as widgets
    import unicodedata

    def limpiar_texto(texto):
        return ''.join(
            c for c in unicodedata.normalize('NFKD', str(texto))
            if ord(c) < 256
        )

    def exportar_informe(builder):
        # === Botones de Exportaci√≥n ===
        btn_export_word_via_html = widgets.Button(
            description="Exportar a Word", button_style="info",
            layout=widgets.Layout(margin="10px 10px 10px 0")
        )
#        btn_export_word = widgets.Button(
#            description="Exportar a Word", button_style="info",
#            layout=widgets.Layout(margin="10px 10px 10px 0")
#        )
        btn_export_pdf = widgets.Button(
            description="Exportar a PDF", button_style="warning",
            layout=widgets.Layout(margin="10px 10px 10px 0")
        )
        btn_export_html = widgets.Button(
            description="Exportar a HTML", button_style="primary",
            layout=widgets.Layout(margin="10px 10px 10px 0")
        )

        def export_to_word_via_html(builder):
            import io
            import base64
            import os
            import pypandoc
            import pandas as pd
            import matplotlib.pyplot as plt
            from IPython.display import display, HTML

            html_parts = ["<html><head><meta charset='utf-8'><title>Informe</title></head><body>"]
            html_parts.append("<h1>Informe Generado</h1>")

            for title, content in builder.sections:
                clean_title = title.lstrip('# ').strip()
                html_parts.append(f"<h2>{clean_title}</h2>")

                try:
                    if isinstance(content, pd.DataFrame):
                        html_parts.append(content.head(20).to_html(index=False))
                        if len(content) > 20:
                            html_parts.append(f"<p><em>‚ö†Ô∏è Tabla truncada: solo primeras 20 filas de {len(content)}.</em></p>")

                    elif hasattr(content, "savefig"):
                        img_buf = io.BytesIO()
                        content.savefig(img_buf, format='png', bbox_inches='tight')
                        img_buf.seek(0)
                        img_b64 = base64.b64encode(img_buf.read()).decode()
                        html_parts.append(f"<img src='data:image/png;base64,{img_b64}' style='max-width:100%;'><br>")

                    else:
                        texto = str(content)
                        lineas = texto.splitlines()
                        if len(lineas) > 100:
                            texto = "\n".join(lineas[:100]) + "\n... (contenido truncado)"
                        html_parts.append(f"<pre>{texto}</pre>")

                except Exception as e:
                    html_parts.append(f"<p><strong>‚ö†Ô∏è Error al procesar la secci√≥n:</strong> {e}</p>")

            html_parts.append("</body></html>")

            # Guardar HTML temporal
            html_filename = "informe_temporal.html"
            with open(html_filename, "w", encoding="utf-8") as f:
                f.write("\n".join(html_parts))

            # Convertir HTML ‚Üí DOCX usando pypandoc
            docx_filename = "informe_generado.docx"
            try:
                pypandoc.convert_file(html_filename, 'docx', outputfile=docx_filename)
                print(f"[DEBUG] Documento Word generado desde HTML: {docx_filename}")
            except Exception as e:
                print(f"[ERROR] Fallo en la conversi√≥n HTML ‚Üí Word: {e}")
                return

            # Mostrar enlace de descarga
            with open(docx_filename, "rb") as f:
                b64 = base64.b64encode(f.read()).decode()
            href = (
                f'<a download="{docx_filename}" '
                f'href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}">'
                "‚¨áÔ∏è Descargar informe Word</a>"
            )
            display(HTML(href))


#            def export_to_word(b):
#                print("[DEBUG] Iniciando exportaci√≥n a Word‚Ä¶")
#                doc = Document()
#                doc.add_heading('Informe Generado', level=0)

#                for title, content in builder.sections:
#                    clean_title = title.lstrip('# ').strip()
#                    doc.add_heading(clean_title, level=1)

#                    if isinstance(content, pd.DataFrame):
#                        table = doc.add_table(rows=1, cols=len(content.columns))
#                        hdr = table.rows[0].cells
#                        for i, col in enumerate(content.columns):
#                            hdr[i].text = str(col)
#                        for row in content.itertuples(index=False):
#                            cells = table.add_row().cells
#                            for i, val in enumerate(row):
#                                cells[i].text = str(val)

#                    elif hasattr(content, "savefig"):
#                        img_stream = io.BytesIO()
#                        content.savefig(img_stream, format='png', bbox_inches='tight')
#                        img_stream.seek(0)
#                        doc.add_picture(img_stream, width=Inches(6))

#                    else:
#                        for line in str(content).splitlines():
#                            doc.add_paragraph(line)

#                    doc.add_page_break()

#                if len(doc.paragraphs) == 0:
#                    doc.add_paragraph("‚ö†Ô∏è El informe no contiene contenido v√°lido para exportar.")

#                output_path = "informe_generado.docx"
#                doc.save(output_path)
#                print(f"[DEBUG] Documento guardado en {output_path}")

#                with open(output_path, "rb") as f:
#                    b64 = base64.b64encode(f.read()).decode()

#                href = (
#                    f'<a download="{output_path}" '
#                    f'href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}">'
#                    "‚¨áÔ∏è Descargar informe Word</a>"
#                )
#                display(HTML(href))

        def export_to_pdf(b):
            print("[DEBUG] Iniciando exportaci√≥n a PDF‚Ä¶")
            pdf = FPDF(orientation='L', unit='mm', format='A4')  # Apaisado
            pdf.set_auto_page_break(auto=True, margin=15)
            pdf.add_page()
            pdf.set_font("Arial", 'B', 14)
            pdf.cell(0, 10, limpiar_texto('Informe Generado'), ln=True)
            #pdf = FPDF()
            #pdf.cell(0, 10, 'Informe Generado', ln=True)

            for title, content in builder.sections:
                pdf.add_page()
                pdf.set_font("Arial", 'B', 12)
                #pdf.multi_cell(0, 10, title.lstrip('# ').strip())
                pdf.multi_cell(0, 10, limpiar_texto(title.lstrip('# ').strip()))


                if isinstance(content, pd.DataFrame):
                    pdf.set_font("Arial", '', 8)      # Reducimos tama√±o de letra de 10 a 8 para hacer m√°s compacto el informe
                    col_width = 270 / len(content.columns)  # Distribuci√≥n proporcional
                    for col in content.columns:
                        #pdf.cell(40, 10, str(col), border=1)
                        pdf.cell(col_width, 10, limpiar_texto(col), border=1)
                    pdf.ln()
                    for row in content.itertuples(index=False):
                        for val in row:
                            #pdf.cell(40, 10, str(val), border=1)
                            pdf.cell(col_width, 10, limpiar_texto(val), border=1)
                        pdf.ln()

                elif hasattr(content, "savefig"):
                    img_buf = io.BytesIO()
                    content.savefig(img_buf, format='png', bbox_inches='tight')
                    img_buf.seek(0)
                    with open("temp_fig.png", "wb") as f:
                        f.write(img_buf.read())
                    #df.image("temp_fig.png", x=10, w=180)
                    pdf.image("temp_fig.png", x=10, w=270)  # Ancho m√°ximo para A4 apaisado
                    os.remove("temp_fig.png")

                elif isinstance(content, str):
                    pdf.set_font("Arial", '', 10)        # Reducimos tama√±o de letra de 12 a 10 para hacer m√°s compacto el informe
                    #pdf.multi_cell(0, 10, content)
                    pdf.multi_cell(0, 10, limpiar_texto(content))


            filename = "informe_generado.pdf"
            pdf.output(filename)
            print(f"[DEBUG] Informe PDF generado correctamente: {filename}")

            with open(filename, "rb") as f:
                b64 = base64.b64encode(f.read()).decode()

            href = (
                f'<a download="{filename}" '
                f'href="data:application/pdf;base64,{b64}">'
                "‚¨áÔ∏è Descargar informe PDF</a>"
            )
            display(HTML(href))

        def export_to_html(b):
            print("[DEBUG] Iniciando exportaci√≥n a HTML‚Ä¶")
            html_content = ["<html><head><meta charset='utf-8'><title>Informe</title></head><body>"]
            html_content.append("<h1>Informe Generado</h1>")

            for title, content in builder.sections:
                html_content.append(f"<h2>{title.lstrip('# ').strip()}</h2>")

                if isinstance(content, pd.DataFrame):
                    html_content.append(content.to_html(index=False))
                elif hasattr(content, "savefig"):
                    img_buf = io.BytesIO()
                    content.savefig(img_buf, format='png', bbox_inches='tight')
                    img_buf.seek(0)
                    encoded = base64.b64encode(img_buf.read()).decode()
                    html_content.append(f"<img src='data:image/png;base64,{encoded}' style='max-width:100%'>")
                else:
                    html_content.append(f"<pre>{str(content)}</pre>")

            html_content.append("</body></html>")

            filename = "informe_generado.html"
            with open(filename, "w", encoding="utf-8") as f:
                f.write("\n".join(html_content))

            with open(filename, "rb") as f:
                b64 = base64.b64encode(f.read()).decode()

            href = (
                f'<a download="{filename}" '
                f'href="data:text/html;base64,{b64}">'
                "‚¨áÔ∏è Descargar informe HTML</a>"
            )
            display(HTML(href))

        btn_export_word_via_html.on_click(export_to_word_via_html)
        btn_export_pdf.on_click(export_to_pdf)
        btn_export_html.on_click(export_to_html)

        display(widgets.HBox([btn_export_word_via_html, btn_export_pdf, btn_export_html]))

    # === M√≥dulo de Generaci√≥n y Presentaci√≥n del Informe ===
    # 1) Generamos todas las secciones internamente (sin render a√∫n)
    builder = ReportBuilder(globals())
    builder.build_sections()

    # 2) Creamos una lista de 't√≠tulos limpios' para los checkboxes
    #    Eliminamos el prefijo '### ' y espacios sobrantes
    clean_titles = [title.lstrip("# ").strip() for title, _ in builder.sections]

#    # 3) Checkbox din√°mico (todos DESMARCADOS)
#    checkboxes = [
#        widgets.Checkbox(value=False, description=clean_title, indent=False)
#        for clean_title in clean_titles
#    ]
    # 3) Checkbox din√°mico (todos MARCADOS por defecto)
    checkboxes = [
        widgets.Checkbox(value=True, description=clean_title, indent=False)
        for clean_title in clean_titles
    ]

    # 4) Checkbox global para marcar/desmarcar todos
    toggle_all = widgets.Checkbox(
        value=True,
        description="(Des)marcar todas las secciones",
        indent=False,
        style={'description_width': 'initial'}
    )

    # 5) Contador din√°mico de secciones seleccionadas
    counter_label = widgets.Label()
    def actualizar_contador(_=None):
        n_sel = sum(cb.value for cb in checkboxes)
        counter_label.value = f"Secciones seleccionadas: {n_sel} de {len(checkboxes)}"
    actualizar_contador()  # Inicializa

    # 6) Callback del checkbox global
    def _on_toggle_all(change):
        for cb in checkboxes:
            cb.value = toggle_all.value
        actualizar_contador()

    toggle_all.observe(_on_toggle_all, names='value')

    # 7) Callback individual para cada checkbox (actualiza contador)
    for cb in checkboxes:
        cb.observe(actualizar_contador, names='value')

    # 8) Bot√≥n de ejecuci√≥n
    btn_generate = widgets.Button(
        description="Generar Informe",
        button_style="success",
        layout=widgets.Layout(margin="10px 0 0 0")
    )

    # 9) Montamos el UI
    ui = widgets.VBox([
        widgets.HTML("<h3>Selecciona las secciones a incluir en el informe:</h3>"),
        toggle_all,  # ‚¨ÖÔ∏è A√±adimos el checkbox global
        counter_label,
        widgets.VBox(checkboxes),
        btn_generate
    ])
    display(ui)

    # 10) Callback: al pulsar el bot√≥n, filtramos y renderizamos
    def _on_generate_clicked(_):
        from IPython.display import clear_output, display
        clear_output(wait=True)
        # a) Recogemos s√≥lo los t√≠tulos marcados
        seleccion = {
            cb.description
            for cb in checkboxes
            if cb.value
        }
        # b) Filtramos builder.sections por coincidencia exacta del t√≠tulo limpio
        filtered = []
        for (orig_title, content), clean_title in zip(builder.sections, clean_titles):
            if clean_title in seleccion:
                filtered.append((orig_title, content))

        # c) Reemplazamos y renderizamos
        builder.sections = filtered
        builder.render()

        # ‚úÖ d) Llamada a exportar_informe (Word, PDF, HTML)
        exportar_informe(builder)

    # 10) Asignar callback
    btn_generate.on_click(_on_generate_clicked)

# Artifact: exec exec_314
from ipywidgets import Dropdown, Button, VBox, HBox, Output

# Artifact: exec exec_315
from IPython.display import HTML as dHTML, clear_output

# Artifact: assign menu_funcs
menu_funcs = {
    # Bienvenida + Ayuda
    "1. Bienvenida":            mostrar_bienvenida,
    "2. Ayuda Global":          mostrar_ayuda_completa,

    # Bloque 1
    "B1.1.1 Carga de Datos":       mostrar_carga,
    "B1.1.2 Segmentaci√≥n Datos":   mostrar_split,
    "B1.2.1 Selecci√≥n variables X": mostrar_seleccion_variables,

    # Bloque 2 ‚Äì Entrenamiento
    "B2.1.1 Entrenamiento SVR":            mostrar_svr,
    "B2.1.2 Entrenamiento NN":             mostrar_nn,
    "B2.1.3 Entrenamiento XGBoost":        mostrar_xgb,
    "B2.1.4 Entrenamiento Random Forest":  mostrar_rf,
    "B2.1.5 Entrenamiento RNN":            mostrar_rnn,
    "B2.1.6 Comparador Modelos":           mostrar_comparador_modelos,

    # Bloque 2 ‚Äì Predicci√≥n
    "B2.2.1 Predicci√≥n SVR":               mostrar_prediccion_svr,
    "B2.2.2 Predicci√≥n NN":                mostrar_prediccion_nn,
    "B2.2.3 Predicci√≥n XGBoost":           mostrar_prediccion_xgboost,
    "B2.2.4 Predicci√≥n Random Forest":     mostrar_prediccion_rf,
    "B2.2.5 Predicci√≥n RNN":               mostrar_prediccion_rnn,
    "B2.2.6 Visualizaci√≥n resultados":     mostrar_grafico_y_vs_x,

    # Bloque 3 ‚Äì Optimizaci√≥n
    "B3.1.1 Optimizaci√≥n SVR":             mostrar_optimizacion_svr,
    "B3.1.2 Optimizaci√≥n NN":              mostrar_optimizacion_nn,
    "B3.1.3 Optimizaci√≥n XGBoost":         mostrar_optimizacion_xgb,
    "B3.1.4 Optimizaci√≥n Random Forest":   mostrar_optimizacion_rf,
    "B3.1.5 Optimizaci√≥n RNN":             mostrar_optimizacion_rnn,

    # Bloque 4 ‚Äì xIA
    "B4.1 Interpretaci√≥n xIA":            mostrar_xai,

    # Informe Final
    "Generar Informe Final":              mostrar_informe,
}

# Artifact: assign menu_tree
menu_tree = {
    "Bienvenida": {
        "1. Bienvenida": None
    },
    "Ayuda General": {
        "2. Ayuda Global": None
    },
    "Bloque 1 ‚Äì Carga y segmentaci√≥n de datos y Selecci√≥n Variables": {
        "B1.1 Carga y Segmentaci√≥n de Datos": {
            "B1.1.1 Carga de Datos": None,
            "B1.1.2 Segmentaci√≥n Datos": None,
        },
        "B1.2 Selecci√≥n variables X": {
            "B1.2.1 Selecci√≥n variables X": None,
        },
    },
    "Bloque 2 ‚Äì Entrenamiento de modelos IA y Predicci√≥n de Salidas": {
        "B2.1 Entrenamiento Modelos IA": {
            "B2.1.1 Entrenamiento SVR": None,
            "B2.1.2 Entrenamiento NN": None,
            "B2.1.3 Entrenamiento XGBoost": None,
            "B2.1.4 Entrenamiento Random Forest": None,
            "B2.1.5 Entrenamiento RNN": None,
            "B2.1.6 Comparador Modelos": None,
        },
        "B2.2 Predicci√≥n y visualizaci√≥n de datos de salida": {
            "B2.2.1 Predicci√≥n SVR": None,
            "B2.2.2 Predicci√≥n NN": None,
            "B2.2.3 Predicci√≥n XGBoost": None,
            "B2.2.4 Predicci√≥n Random Forest": None,
            "B2.2.5 Predicci√≥n RNN": None,
            "B2.2.6 Visualizaci√≥n resultados": None,
        },
    },
    "Bloque 3 ‚Äì Optimizaci√≥n de Modelos IA": {
        "B3.1 Optimizaci√≥n de modelos IA": {
            "B3.1.1 Optimizaci√≥n SVR": None,
            "B3.1.2 Optimizaci√≥n NN": None,
            "B3.1.3 Optimizaci√≥n XGBoost": None,
            "B3.1.4 Optimizaci√≥n Random Forest": None,
            "B3.1.5 Optimizaci√≥n RNN": None,
        },
    },
    "Bloque 4 ‚Äì Inteligencia Artificial Explicativa xIA": {
         "B4.1 Interpretaci√≥n xIA": None,
#        "B4.1 Interpretaci√≥n xIA": {
#            "B4.1.1 Interpretaci√≥n xIA": None,
#        },
    },
    "Generar Informe Final": {
         "Generar Informe Final": None,
#        "Generar Informe Final": {
#            "Generar Informe Final": None,
#        },
    },
}

# Artifact: function _crear_dropdown
def _crear_dropdown(options, nivel):
    return widgets.Dropdown(
        options=options,
        description=f"Nivel-{nivel}:",
        layout={
            'width': '100%'          # ‚¨ÖÔ∏è  ancho fluido
            # o '1100px', '80%', etc.
        },
        style={
            'description_width': '200px'  # ajusta si hiciera falta
        }
    )

# Artifact: function _subtree_for
def _subtree_for(path):
    node = menu_tree
    for key in path:
        node = node[key]
    return node

# Artifact: assign levels_box
levels_box = VBox(layout={'width': 'auto'})

# Artifact: assign btn_next
btn_next = Button(
    description="Seleccionar Siguiente",
    button_style="info",
    layout={'width': '190px'}
)

# Artifact: assign btn_run
btn_run = Button(
    description="Ejecutar",
    button_style="success",
    layout={'width': '140px'}
)

# Artifact: assign out_panel
out_panel = widgets.Output(
    layout={
        'border': '1px solid #ccc',
        'padding': '12px',
        'width': '100%',
        'max_height': '600px',
        'overflow_y': 'auto',
        'overflow_x': 'hidden',      # ‚Üê evita scroll horizontal
        'margin_top': '12px'
    }
)

# Artifact: function _crear_dropdown
def _crear_dropdown(options, nivel):
    return Dropdown(
        options=options,
        description=f"Nivel-{nivel}:",
        layout={
            'width': 'auto',               # ‚Üê ancho solo seg√∫n texto
            'min_width': '400px',          # ‚Üê margen m√≠nimo visual aceptable
            'max_width': '700px'
        },
        style={'description_width': '160px'}
    )

# Artifact: function _update_buttons
def _update_buttons():
    path = [d.value for d in levels_box.children]
    leaf = (_subtree_for(path) is None)
    btn_next.disabled = leaf
    btn_run.disabled = not leaf

# Artifact: function _on_change
def _on_change(ch):
    dd_list = list(levels_box.children)
    idx = dd_list.index(ch['owner'])
    levels_box.children = tuple(dd_list[:idx+1])
    _update_buttons()

# Artifact: function _reset
def _reset():
    dd0 = _crear_dropdown(list(menu_tree.keys()), 1)
    dd0.observe(_on_change, names='value')
    levels_box.children = (dd0,)
    _update_buttons()

# Artifact: function _next
def _next(_):
    path = [d.value for d in levels_box.children]
    branch = _subtree_for(path)
    if branch:
        nivel = len(levels_box.children) + 1
        new_dd = _crear_dropdown(list(branch.keys()), nivel)
        new_dd.observe(_on_change, names='value')
        levels_box.children = (*levels_box.children, new_dd)
    _update_buttons()

# Artifact: function _run
def _run(_):
    nodo = levels_box.children[-1].value
    func = menu_funcs.get(nodo)
    out_panel.clear_output()
    with out_panel:
        if func is None:
            print(f"‚ö†Ô∏è  No se ha implementado ¬´{nodo}¬ª.")
        else:
            clear_output(wait=True)
            func()

# Artifact: exec exec_330
btn_next.on_click(_next)

# Artifact: exec exec_331
btn_run.on_click(_run)

# Artifact: exec exec_332
_reset()

# Artifact: exec exec_333
display(
    VBox([
        widgets.HTML("<h3 style='font-size:1.3rem;margin-bottom:5px;'>üìã Men√∫ Principal</h3>"),
        levels_box,
        HBox([btn_next, btn_run], layout={'gap': '30px', 'margin_top': '5px'}),
        out_panel
    ])
)

# Artifact: exec exec_334
from ipywidgets import Button

# Artifact: exec exec_335
from IPython.display import display

# Artifact: assign btn_limpiar
btn_limpiar = Button(
    description="üßπ Limpiar pantalla",
    button_style="warning",
    layout={'width': '150px'}
)

# Artifact: function _on_limpiar
def _on_limpiar(_):
    # Borra solo el contenido del panel de resultados
    out_panel.clear_output()

# Artifact: exec exec_338
btn_limpiar.on_click(_on_limpiar)

# Artifact: exec exec_339
display(btn_limpiar)

